ID,Title,Abstract,DOI,Keywords,Origin,Summary,Financial instrument?,Instrument,AI?,Probabilistic?
WOS:000779594700001,<i>DL-GuesS</i>: Deep Learning and Sentiment Analysis-Based Cryptocurrency Price Prediction,"Cryptocurrencies are peer-to-peer-based transaction systems where the data exchanges are secured using the secure hash algorithm (SHA)-256 and message digest (MD)-5 algorithms. The prices of cryptocurrencies are highly volatile and follow stochastic moments and have reached their unpredictable limits. They are commonly used for investment and have become a substitute for other types of investment like metals, estates, and the stock market. Their importance in the market raises the strict requirement for a sturdy forecasting model. However, cryptocurrency price prediction is quite challenging due to its dependency on other cryptocurrencies. Many researchers have used machine learning and deep learning models, and other market sentiment-based models to predict the price of cryptocurrencies. As all the cryptocurrencies belong to a specific class, we can infer that the increase in the price of one cryptocurrency can lead to a price change for other cryptocurrencies. Researchers had also utilized the sentiments from tweets and other social media platforms to increase the performance of their proposed system. Motivated by these, in this paper, we propose a hybrid and robust framework, DL-Gues, for cryptocurrency price prediction, that considers its interdependency on other cryptocurrencies and also on market sentiments. We have considered price prediction of Dash carried out using price history and tweets of Dash, Litecoin, and Bitcoin for various loss functions for validation. Further, to check the usability of DL-GuesS on other cryptocurrencies, we have also inferred results for price prediction of Bitcoin-Cash with the price history and tweets of Bitcoin-Cash, Litecoin, and Bitcoin.",10.1109/access.2022.3163305,Cryptography; Predictive models; Bitcoin; Hidden Markov models; Deep learning; Data models; Social networking (online); Cryptocurrency; complex systems; fusion of cryptocurrency; price prediction; VADER; sentiment analysis; deep learning; systems of systems,WOS,"DL-GuesS, a hybrid deep learning and sentiment analysis framework, is proposed for cryptocurrency price prediction by considering interdependencies among cryptocurrencies and market sentiments, outperforming state-of-the-art models.",✔️,Cryptocurrency,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408721,A Bayesian Learning Method for Financial Time-Series Analysis,"This article develops a sequential Bayesian learning method to estimate the parameters and recover the state variables for generalized autoregressive conditional heteroscedasticity (GARCH) models, which are commonly used in the financial time-series analysis. This simulation-based method combines particle-filtering technology with a Markov chain Monte Carlo algorithm when the model is non-linear and the number of observed variables is relatively sparse. We compare the performance of the sequential Bayesian learning approach with the numerical maximum likelihood estimation (NMLE) in estimating models based on S&P 500 return rates. Our research concludes that the sequential parameter learning approach performs more robustly and accurately than the NMLE, by taking into account the uncertainty of the model. We also carry out simulation studies to confirm that the sequential Bayesian learning method is extremely reliable for GARCH models.",10.1109/access.2018.2853998,Bayes methods;Biological system modeling;Numerical models;Autoregressive processes;Analytical models;Computational modeling;Maximum likelihood estimation;Sequential Bayesian learning;GARCH models;Markov chain Monte Carlo;particle filtering;sparse recovery,IEEE,"The paper introduces a sequential Bayesian learning method for parameter estimation in GARCH models for financial time series, demonstrating superior robustness and accuracy compared to maximum likelihood estimation.",✔️,"Financial time series (e.g., S&P 500)",❌,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9366736,A Bayesian Regularized Neural Network for Analyzing Bitcoin Trends,"Bitcoin is a decentralized digital currency without a central bank or single administrator sent from user to user on the peer-to-peer bitcoin blockchain network without intermediaries’ need. In this Bitcoin trend analysis work, initial attributes are considered from five sectors based on financial, social, token, network, and that count to thirteen attributes. The thirteen attributes considered are price, volume, market cap, a mean dollar invested age, social volume, social dominance, development activity, transaction volume, token age consumed, token velocity, token circulation, market value to realized value, and realized cap. We apply the attribute selection and trend analysis mapped with potential seven attributes: Price, Volume, Market Cap, Social Dominance, Development Activity, Market Value to Realized Value & Realized Cap. We have conducted Nonlinear Autoregressive with External Input analysis considering seven attributes. The work employed three training algorithms to train a neural network as Levenberg-Marquard, Bayesian Regularization, and Scaled Conjugate Gradient algorithm. The Error histogram and regression plots results indicate that the Bayesian Regularized Neural Network is showing good performance and thus provides a better forecast.",10.1109/access.2021.3063243,Bitcoin;Predictive models;Blockchain;Market research;Prediction algorithms;Neural networks;Bayes methods;Bitcoin;market cap;neural network;realized cap;nonlinear autoregressive with external input (narx);neural network (NN);Levenberg-Marquard (LM);Bayesian Regularization (BR);Scaled Conjugate Gradient (SCG);Bayesian Regularized Neural Network (BRNN),IEEE,A Bayesian Regularized Neural Network model is developed to analyze and forecast Bitcoin trends using various attributes across financial and social sectors.,✔️,Bitcoin,✔️,✔️
WOS:000889065800003,A Bayesian analysis based on multivariate stochastic volatility model: evidence from green stocks,"Green stocks are companies environmental protective and friendly. We test Green stock index in Shanghai Stock Exchange and China Securities Index as safe-havens for global investors. Suitable multivariate-SV model and Bayesian method are used to estimate the spillover effect between different assets among local and global markets. We choose multivariate volatility model because it can efficiently simulate the spillover effect by using machine learning MCMC method. The results show that the Environmental Protection Index (EPI) of Shanghai Stock Exchange (SSE) and China Securities Index (CSI) have no significant volatility spillover from Shanghai Stock index, S &P index, gold price, oil future prices of USA and China. During COVID-19 pandemic, we find Green stock index is a suitable safe-haven with low volatility spillover. Green stock indexes has a strongly one-way spillover to the crude oil future price. Environmentally friendly investor can use diversity green assets to provide a low risk investment portfolio in EPI stock market. The DCGCt-MSV model using machine learning of MCMC method is accurate and outperform others in Bayes parameter estimation.",10.1007/s10878-022-00936-0,Green stock; Spillover Effect; Machine learning; Markov chain Monte Carlo; Bayesian analysis,WOS,"Employs Bayesian multivariate stochastic volatility models to analyze and predict volatility in green stock indices, demonstrating their suitability as safe-haven assets with low volatility spillover.",✔️,Green Stock Indices,✔️,✔️
WOS:000863229400001,A Bayesian-based classification framework for financial time series trend prediction,"Financial time series have been extensively studied within the past decades; however, the advent of machine learning and deep neural networks opened new horizons to apply supercomputing techniques to extract more insights from the underlying patterns of price data. This paper presents a tri-state labeling approach to classify the underlying patterns in price data into up, down and no-action classes. The introduction of a no-action state in our novel approach alleviates the burden of denoising the dataset as a preprocessing task. The performance of our labeling algorithm is experimented with using machine learning and deep learning models. The framework is augmented by applying the Bayesian optimization technique for the selection of the best tuning values of the hyperparameters. The price trend prediction module generates the required trading signals. The results show that the average annualized Sharpe ratio as the trading performance metric is about 2.823, indicating the framework produces excellent cumulative returns.",10.1007/s11227-022-04834-4,Trend prediction; Machine learning; Deep learning; Financial time series; Feature engineering; Classification,WOS,"The paper presents a Bayesian-optimized classification framework for predicting financial time series trends, incorporating a novel no-action state and generating trading signals with uncertainty measures.",✔️,Financial time series,✔️,✔️
https://doi.org/10.1142/S1793005711001974,A COMPARATIVE STUDY OF BAYESIAN AND MAXIMUM LIKELIHOOD APPROACHES FOR ARCH MODELS WITH EVIDENCE FROM BRAZILIAN FINANCIAL SERIES,"The purpose of this study is to address the inference problem of the parameters of autoregressive conditional heteroscedasticity (ARCH) models. Specifically, we present a comparison of the two approaches - Bayesian and Maximum Likelihood (ML) for ARCH models, and the specific mathematical and algorithmic formulations of these approaches. In the ML, estimation we obtain confidence intervals by using the Bootstrap simulation technique. In the Bayesian estimation, we present a reparametrization of the model which allows us to apply prior normal densities to the transformed parameters. The posterior estimates are obtained using Monte Carlo Markov Chain (MCMC) methods. The methodology is exemplified by considering two Brazilian financial time series: the Bovespa Stock Index - IBovespa and the Telebras series. The order of each ARCH model is selected by using the Bayesian Information Criterion (BIC).",10.1142/s1793005711001974,,Proquest,"A study comparing Bayesian and Maximum Likelihood methods for ARCH models applied to Brazilian financial time series, specifically the Bovespa Stock Index and Telebras series.",❌,?,❌,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8988162,A Fuzzy Interval Time-Series Energy and Financial Forecasting Model Using Network-Based Multiple Time-Frequency Spaces and the Induced-Ordered Weighted Averaging Aggregation Operation,"Forecasting time series is an emerging topic in operational research. Existing time-series models have limited prediction accuracy when faced with the characteristics of nonlinearity and nonstationarity in complex situations related to energy and finance. To enhance overall prediction capabilities and improve forecasting accuracy, in this article we propose a fuzzy interval time-series forecasting model on the basis of network-based multiple time-frequency spaces and the induced-ordered weighted averaging aggregation (IOWA) operation. Specifically, a time-series signal is decomposed into ensemble empirical modes and then reconstructed as various time-frequency spaces, which are transformed into visibility graphs. Then, forecasting intervals in different spaces can be collected after the local random walker link prediction model is adopted. Furthermore, a rule-based representation value function inspired by Yager's golden rule approach is defined, and an appropriate representation value is calculated. Finally, after IOWA is used to aggregate the forecasting outcomes in different time-frequency spaces, the final forecast value can be obtained from the fuzzy forecasting interval. Considering that energy issues are of widespread interest in nature and the social economy, two cases, based on a hydrological time series from the Biliuhe River in China and two well-known sets of financial time-series data, Taiwan Stock Exchange Capitalization Weighted Stock Index and Hang Seng Index, are studied to test the performance of the proposed approach in comparison with existing models. Our results show that the proposed approach can achieve better performance than well-developed models.",10.1109/tfuzz.2020.2972823,Time series analysis;Forecasting;Predictive models;Time-frequency analysis;Autoregressive processes;Prediction algorithms;Ensemble empirical mode decomposition (EEMD);financial time series;golden rule;hydrological time series;induced-ordered weighted averaging aggregation (IOWA);link prediction;network analysis;time-series forecasting,IEEE,"The paper presents a fuzzy interval time-series model leveraging multiple time-frequency spaces and aggregation operations for energy and financial forecasting, demonstrating superior performance on stock index data.",✔️,"Taiwan Stock Index, Hang Seng Index",❌,❌
10.48048/tis.2022.3045,A Gaussian Process Regression Model for Forecasting Stock Exchange of Thailand,"A stock price index measures the change in several share prices, which can describe the market and assist investors in deciding on a specific investment. Thus, foreseeing the stock price index benefits investors in creating a better investment strategy. However, forecasting the stock price index can be challenging due to its non-linearity, non-stationary and high uncertainty. Gaussian process regression (GPR) is an attractive and powerful approach for prediction, especially when the data fluctuates over time with fewer restrictions. Besides, the GPR gains advantages over other forecasting techniques as it can offer predictions with uncertainty to provide margin errors. In this study, we evaluate the use of GPR to predict the stock price of Thailand (SET). The SET data are divided into 2 datasets; the data in the year 2015-2020 and the data in the year 2020 due to the massive change during the COVID-19 pandemic. The prediction results from the GPR are then compared to the machine learning approaches, artificial neural network (ANN) and recurrent neural network (RNN) using evaluation scores; the root mean square error (RMSE), the mean absolute error (MAE), the mean absolute percentage error (MAPE) and the Nash-Sutcliffe efficiency (NSE). The results indicate that the GPR is superior to the ANN and RNN for both datasets as it provides a high prediction accuracy. Moreover, the results suggest that the GPR is less sensitive to the number of input lags in the model. Therefore, the GPR is more favorable for the prediction of SET than the ANN and RNN. © 2022, Walailak University. All rights reserved.",10.48048/tis.2022.3045,Artificial neural network; Gaussian process regression; Recurrent neural network; Stock price index,SCOPUS,"Applies Gaussian Process Regression to forecast the Stock Exchange of Thailand indices, comparing to ANN and RNN, finding GPR superior.",✔️,Stock Exchange of Thailand,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448324,A Hybrid Approach of Bayesian Structural Time Series With LSTM to Identify the Influence of News Sentiment on Short-Term Forecasting of Stock Price,"In the financial sector, the stock market and its trends are highly volatile in nature. Recent studies have shown that news articles and social media analysis can have an immense impact on investors’ opinion toward financial markets. Thus, the purpose of this study is to explore the relationship between news sentiment and stock market movement using information from different news agencies, business magazines, and financial portals. This study offers an application of the Bayesian structural time (BST) series model that is more transparent and facilitates better handling of uncertainty than the autoregressive integrated moving average (ARIMA) model and the vector autoregression (VAR) method by using prior information about the structure of the model. One of the main pitfalls of this model is the presumption of linearity. The long short-term memory (LSTM) model is a nonlinear model that can capture various nonlinear structures present in the data set. We propose a hybrid model, which combines the LSTM model with the BST model along with the regression component that captures information from different news sources to identify market predictors. The proposed model detects unusual behavior or anomalous pattern of the stock price movement, which makes our model superior compared to the traditional methods. Our new hybrid model accumulates error with lower rates (3.5%) and shows a remarkable performance over some of the other existing hybrid models, such as AR-MLP, ARIMA-LSTM, and VAR-LSTM model.",10.1109/tcss.2021.3073964,Predictive models;Mathematical model;Data models;Market research;Stock markets;Time series analysis;Logic gates;Anomaly detection;state-space time series model;stock forecasting;text mining;unsupervised learning,IEEE,"The paper presents a hybrid Bayesian Structural Time Series and LSTM model to incorporate news sentiment data for short-term stock price forecasting, achieving lower error rates and improved performance.",✔️,Stocks,✔️,✔️
10.1155/2023/9963940,A Hybrid Model Using PCA and BP Neural Network for Time Series Prediction in Chinese Stock Market with TOPSIS Analysis,"The stock price changes rapidly and is highly nonlinear in the financial market. One of the common concerns of many scholars and investors is how to accurately predict the stock price and the trend of rising and falling in a short time. Machine learning and deep learning techniques have found their place in financial institutions thanks to the ability of time series data prediction with high precision. However, the prediction accuracy of these models is still far from satisfactory. Most existing studies use original, single prediction algorithms that cannot overcome inherent limitations. This study proposes a hybrid model using principal component analysis (PCA) and backpropagation (BP) neural networks. The historical records of China Merchants Bank are used for data collection from 2015 to 2021. PCA preprocesses the original data to reduce the dimensionality and is then adopted by the BP neural network to predict the stock closing price of China Merchants Bank. We compare and analyze the PCA-BP model with three training algorithms, and the results indicate that the Bayesian regularization algorithm performs best. Besides, we perform the stock prediction using a traditional exponential smoothing approach. The experiment results show that the predicted stock closing price is close to the actual value, and the mean absolute percentage error can reach 0.0130, which is more significant than the traditional approach. Furthermore, A TOPSIS approach is utilized to evaluate the robustness of the proposed model. Finally, we demonstrate the usability of the designed hybrid model by predicting the stock price of another selected stock.  © 2023 Lei Hang et al.",10.1155/2023/9963940,,SCOPUS,"The study proposes a hybrid PCA and BP neural network model for predicting stock prices in the Chinese market, demonstrating improved accuracy over traditional methods.",✔️,Stock,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745535,A Hybrid Prediction Model Integrating GARCH Models With a Distribution Manipulation Strategy Based on LSTM Networks for Stock Market Volatility,"Accurate prediction of volatility is one of the most important tasks in financial decision making. Recently, the hybrid models integrating artificial neural networks with GARCH-type models have been developed, and performance gains from the models have been found to be outstanding. However, there have been few studies of hybrid models considering the nature of the distribution of financial data. Distribution of volatility time-series is highly concentrated near zero, and such aspect can cause low prediction performance on the whole domain of probability density function because weights in the networks can be trained to obtain accurate prediction only for the high frequency region, that is, near zero. To overcome the challenge, we propose a new hybrid model with GARCH-type models based on a novel non-linear filtering method to mitigate concentration property of volatility. For the filtering, we utilize root-type functions that transform extremely left-biased and pointed distribution of original volatility to a volume-upped (VU) distribution shifted to the right. Long short-term memory (LSTM) is employed as the basic implementation model, and the realized volatility of S&P 500 is predicted using the proposed models. It is found that the proposed hybrid model (VU-GARCH-LSTM) obtains 21.03% performance gain with respect to the root mean square error (RMSE) against the mean performances of the existing hybrid models integrating LSTM with GARCH-type models. Furthermore, the proposed model improves prediction performance in the right domain region of label probability density by making the prediction distribution comparable to the label distribution.",10.1109/access.2022.3163723,Predictive models;Data models;Stock markets;Stochastic processes;Recurrent neural networks;Stock market volatility;long short-term memory;GARCH models;distribution manipulation,IEEE,"The study develops a hybrid model integrating GARCH and LSTM networks with distribution manipulation for predicting stock market volatility, achieving significant performance improvements.",✔️,Stock market volatility,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138772,A Latent Factor-Based Bayesian Neural Networks Model in Cloud Platform for Used Car Price Prediction,"The selling price of a used car can be predicted based on its historical information. Accurate and reasonable used car price evaluation will be able to promote the healthy progress of the used car industry. Current used car price prediction models are troubled by data quality and the inability to provide estimates of uncertain information, and the prediction accuracy cannot meet the needs of real-world scenarios. In this work, we propose a price prediction model based on a Bayesian neural networks with latent factor (LFBNN) in a cloud platform, which is capable of performing latent factor extraction operations on structured data of used cars as a way to remove the effect of noise in the dataset on the model performance. Moreover, the weight parameters of the Bayesian neural networks (NNs) are represented as probability distributions, which is equivalent to introducing uncertainty and acting as a regularization effect compared to a NN with fixed weights, thus making it possible to alleviate the overfitting problem. The LFBNN model uses a cloud platform for data transmission and storage, enabling it to run faster. Compared with the current benchmark models, the model proposed in this work achieves excellent experimental results on two real datasets. The experimental results on the $Car_{1}$ dataset are 1.498 for mse, 1.224 for rmse, and 0.995 for MAE, and 1.519 for mse, 1.232 for rmse, and 1.002 for MAE on the $Car_{2}$ dataset.",10.1109/tem.2023.3270301,Automobiles;Predictive models;Bayes methods;Artificial neural networks;Data models;Data mining;Mathematical models;Bayesian neural networks (NNs);latent factor;price prediction model;used car,IEEE,"Implements a Commitment Machine metaheuristic to adaptively select and combine Expected Shortfall estimation methods using machine learning, enhancing financial risk assessment.",✔️,Portfolio Expected Shortfall,✔️,✔️
https://doi.org/10.1088/1742-6596/2287/1/012018,A Machine Learning Model for Healthcare Stocks Forecasting in the US Stock Market during COVID-19 Period,"This paper study the nowcasting and forecasting for the healthcare stock price in the united states during the Covid-19 period including the google trend data information. The data is collected in monthly data from 2015 to 2020 which are five interested stock price indexes in the healthcare sector. Empirically, the finding reveals that the Bayesian structural time series analysis can be used to investigate the stock price indexes with the google trend data is becoming useful for the prediction in term of current movement. In term of the machine learning algorithms, the unsupervised learning k-Mean algorithm is employed to cluster the cycle regimes of the stock market which provided three regimes such as Bull market, Sideways and Bear market. There are twenty-nine months stand for bull market, thirty-seven months are predictively provided sideways market and five months are referred as the bear market. Additionally, the supervised learning algorithms by using the Linear Discriminant Analysis (LDA), k-Nearest Neighbors (kNN) and Support vector machine (SVM) are used to investigate the cycle regimes of healthcare stock in next five year. The results indicated that LDA is chosen by the highest coefficient validation which represented the the regimes of stock in the healcare sector of the unites states of America will stay on the sideways periods in the next five years. Thus, the finding in this paper can be the useful information for investor to manage their portfolio especially, in healthcare sector during the Covid-19 period.",10.1088/1742-6596/2287/1/012018,,Proquest,"The paper develops machine learning models, including Bayesian structural time series and various classifiers, to forecast US healthcare stock prices during the COVID-19 period, aiding investment decisions.",✔️,Healthcare stocks in the US stock market,✔️,✔️
WOS:000657434500001,A New Deep Learning-Based Zero-Inflated Duration Model for Financial Data Irregularly Spaced in Time,"In stock trading markets, trade duration (i. e., inter-arrival times of trades) usually exhibits high uncertainty and excessive zero values. To forecast conditional distribution of trade duration, this study proposes a hybrid model called ""DL-ZIACD"" for short, which addresses the problem of excessive zero values by a zero-inflated distribution. Meanwhile, dynamics of the distribution time-varying parameters are captured by a specially designed deep learning (DL) architecture in which the behavioral patterns of large traders and small individual traders are represented separately by different blocks. The proposed hybrid model takes advantage of the strong fitting ability of deep learning methods while allowing for providing a probabilistic output. This paper empirically applied the established model to a large-scale dataset, containing 9,900,000 transactions of the Chinese Shenzhen Stock Exchange 100 Index (SZSE 100) constituents. To the best of our knowledge, no previous studies have applied conditional duration models to a dataset of such a large scale. For both the central location forecasting and the extreme quantile forecasting, our proposed model exhibited significant superiority over the benchmark models, which indicates that our DL-ZIACD model can provide accurate forecasts in conditional duration distribution.",10.3389/fphy.2021.651528,hybrid model; deep learning; conditional duration; tick data; distribution forecasting,WOS,"This paper introduces a deep learning-based zero-inflated duration model (DL-ZIACD) for forecasting trade durations in financial markets, effectively handling irregularly spaced data and excessive zeros, and outperforming benchmark models in accuracy for large-scale transaction datasets.",❌,,✔️,✔️
10.1109/ACCESS.2023.3308298,A New Framework for Fraud Detection in Bitcoin Transactions Through Ensemble Stacking Model in Smart Cities,"Bitcoin has a reputation of being used for unlawful activities, such as money laundering, dark web transactions, and payments for ransomware in the context of smart cities. Blockchain technology prevents illegal transactions, but cannot detect these transactions. Anomaly detection is a fundamental technique for recognizing potential fraud. The heuristic and signature-based approaches were the foundation of earlier detection techniques, but tragically, these methods were insufficient to explore the entire complexity of anomaly detection. Machine Learning (ML) is a promising approach to anomaly detection, as it can be trained on large datasets of known malware samples to identify patterns and features of the transactions. Researchers are focusing on determining an efficient fraud and security threat detection model that overcomes the drawbacks of the existing methods. Therefore, ensemble learning can be applied to anomaly detection in Bitcoin by combining multiple ML classifiers. In the proposed model, the ADASYN-TL (Adaptive Synthetic + Tomek Link) balancing technique is used for data balancing. Random search, grid search and Bayesian optimization are used for hyperparameter tuning. The hyperparameters have a great impact on the performance of the model. For classification, we used the stacking model by combining Decision Tree, Naive Bayes, K-Nearest Neighbors, and Random Forest. We used SHapley Additive exPlanation (SHAP) to interpret the predictions of the stacking model. The model also explores the performance of different classifiers using accuracy, F1-score, Area Under Curve-Receiver Operating Characteristic (AUC-ROC), precision, recall, False Positive Rate (FPR) and execution time, and ultimately selects the ideal model. The proposed model contributes to the development of effective fraud detection models that address the limitations of the existing algorithms. Our stacking model, which combines the prediction of multiple classifiers, achieved the highest F1-score of 97%, precision of 96%, recall of 98%, accuracy of 97%, AUC-ROC of 99% and FPR of 3%.  © 2013 IEEE.",10.1109/access.2023.3308298,Bitcoin transaction; hyperparameter tuning; machine learning; ransomware attack; smart cities; stacking model,SCOPUS,"The study develops an ensemble stacking model for fraud detection in Bitcoin transactions within smart cities, achieving high accuracy in identifying fraudulent activities.",❌,,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597552,A Nonlinear Autoregressive Exogenous (NARX) Neural Network Model for the Prediction of Timestamp Influence on Bitcoin Value,"The transaction and market of bitcoin is volatile, meaning it’s uncertain because it changes frequently. There have been a number of research studies that have presented bitcoin price prediction models, but none of them have looked at the controlling variables linked with bitcoin transaction timestamps. It might be that price is not the only key criteria influencing bitcoin transactions, or the available model for bitcoin price prediction is yet to consider timestamp as a determining factor in its transaction. A better and more accurate model would be required to predict how the Timestamp influences changes of bitcoin transactions. That is why this current study utilized a Nonlinear Autoregressive Exogenous (NARX) Neural Network Model for the prediction of timestamp influence on Bitcoin value. Bitcoin historical datasets which are converted to a nonlinear regression into a “well-formulated” statistical problem in the manner of a ridge regression are used. Simulation analysis indicates that bitcoin digital currency’s performance variation is highly influenced by its transaction timestamp with the prediction accuracy of 96%. The contributions of this research lies with the fact that specific Bitcoin transaction events repeat themselves over and over again, meaning that the Open-Price, High-Price, Low-Price, and Close-Price of Bitcoin price over timestamp developed a pattern that was predicted by NARX with less That means those involved in the transaction of bitcoin at the wrong timestamp will certainly face the uncertainty negative effect of the bitcoin market.",10.1109/access.2021.3124629,Bitcoin;Predictive models;Uncertainty;Bayes methods;Online banking;Computer science;Social networking (online);Bitcoin (digital currency);volume of BTC;bitcoin;timestamp,IEEE,"The study employs a NARX neural network to predict the influence of timestamps on Bitcoin value, achieving high accuracy by identifying recurring transaction patterns.",✔️,Bitcoin,✔️,❌
WOS:001140460100001,A Novel Deterministic Probabilistic Forecasting Framework for Gold Price with a New Pandemic Index Based on Quantile Regression Deep Learning and Multi-Objective Optimization,"The significance of precise gold price forecasting is accentuated by its financial attributes, mirroring global economic conditions, market uncertainties, and investor risk aversion. However, predicting the gold price is challenging due to its inherent volatility, influenced by multiple factors, such as COVID-19, financial crises, geopolitical issues, and fluctuations in other metals and energy prices. These complexities often lead to non-stationary time series, rendering traditional time series modeling methods inadequate. Our paper presents a multi-objective optimization algorithm that refines the interval prediction framework with quantile regression deep learning in response to this issue. This framework comprehensively responds to gold's financial market dynamics and uncertainties with a screening process of various factors, including pandemic-related indices, geopolitical indices, the US dollar index, and prices of various commodities. The quantile regression deep-learning models optimized by multi-objective optimization algorithms deliver robust, interpretable, and highly accurate predictions for handling non-linear relationships and complex data structures and enhance the overall predictive performance. The results demonstrate that the QRBiLSTM model, optimized using the MOALO algorithm, delivers excellent forecasting performance. The composite indicator AIS reaches -15.6240 and -11.5581 at 90% and 95% confidence levels, respectively. This underscores the model's high forecasting accuracy and its potential to provide valuable insights for assessing future trends in gold prices. The deterministic and probabilistic forecasting framework for gold prices captures the market dynamics with the new pandemic index and comprehensively sets a new benchmark for predictive modeling in volatile market commodities like gold.",10.3390/math12010029,gold price forecasting; quantile regression; probabilistic prediction models; feature screening; multi-objective optimization algorithms,WOS,"Proposes a manifold learning-based framework with regression models to forecast high-dimensional time series, applied to foreign exchange rates.",✔️,Foreign Exchange Rates,✔️,❌
10.25728/assa.2023.23.01.1251,A Novel Method for Predicting Technology Trends Based on Processing Multiple Data Sources,"In order to gain competing capability in conditions of quickly scientific changes, it is crucial to track the evolution of existing technologies and to explore promising and emerging technologies. Moreover, numerous previous studies showed that sudden changes in R&D and patents are actually correlated with great variations in the market profit of firms. For this reason, if stock prices of an enterprise keep uptrend, then the technologies developed by considered one will be likely to become promising innovations in future. In this paper, we proposed a method to predict technology trends based on processing multiple data sources by mining Web news, forecasting stock price trends of high-tech companies, and patent clustering analysis. Different from other studies, our proposed method promotes an idea of predicting technology trends by forecasting stock price trend using univariate and multivariate data preparation approaches, with the utilization of Bayesian optimization for exploring best hyperparameters of machine/deep learning models, also a new method for patent analysis. Besides, a program system was created for analyzing word burst detection, predicting trend of stock prices, and analyzing patent applications. After collecting patents of Samsung Electronics Co Ltd, as a case study, clustering analysis is implemented on extracted noun phrases to explore technology trends developed by the company. These technology trends have recently been confirmed by domain experts in their corresponding published articles. The obtained forecast precision is about 93.8%, which proves that the proposed method gains positive reliability. © 2023 ASSA.",10.25728/assa.2023.23.01.1251,Bayesian optimization; clustering analysis; deep learning; extraction; machine learning; patent analysis; Samsung; stock price; technology forecast; Web news,SCOPUS,"Proposes a method to predict technology trends by integrating web news mining, stock price trend forecasting using Bayesian optimization, and patent clustering analysis, achieving high forecast precision.",❌,?,✔️,?
10.1007/s40031-018-0343-7,A Novel Model for Stock Price Prediction Using Hybrid Neural Network,"The foremost challenge for investors is to select stock price by analyzing financial data which is a menial task as of distort associated and massive pattern. Thereby, selecting stock poses one of the greatest difficulties for investors. Nowadays, prediction of financial market like stock market, exchange rate and share value are very challenging field of research. The prediction and scrutinization of stock price is also a potential area of research due to its vital significance in decision making by financial investors. This paper presents an intelligent and an optimal model for prophecy of stock market price using hybridization of Adaline Neural Network (ANN) and modified Particle Swarm Optimization (PSO). The connoted model hybrid of Adaline and PSO uses fluctuations of stock market as a factor and employs PSO to optimize and update weights of Adaline representation to depict open price of Bombay stock exchange. The prediction performance of the proposed model is compared with different representations like interval measurements, CMS-PSO and Bayesian-ANN. The result indicates that proposed scheme has an edge over all the juxtaposed schemes in terms of mean absolute percentage error. © 2018, The Institution of Engineers (India).",10.1007/s40031-018-0343-7,Artificial Intelligence; Data mining; Neural network; Prediction; Soft computing; Stock market,SCOPUS,"This paper introduces a hybrid neural network model combining Adaline Neural Network and Particle Swarm Optimization to predict stock prices of the Bombay Stock Exchange, demonstrating improved accuracy over existing methods.",✔️,Stock,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5356151,A Stochastic HMM-Based Forecasting Model for Fuzzy Time Series,"Recently, fuzzy time series have attracted more academic attention than traditional time series due to their capability of dealing with the uncertainty and vagueness inherent in the data collected. The formulation of fuzzy relations is one of the key issues affecting forecasting results. Most of the present works adopt IF-THEN rules for relationship representation, which leads to higher computational overhead and rule redundancy. Sullivan and Woodall proposed a Markov-based formulation and a forecasting model to reduce computational overhead; however, its applicability is limited to handling one-factor problems. In this paper, we propose a novel forecasting model based on the hidden Markov model by enhancing Sullivan and Woodall's work to allow handling of two-factor forecasting problems. Moreover, in order to make the nature of conjecture and randomness of forecasting more realistic, the Monte Carlo method is adopted to estimate the outcome. To test the effectiveness of the resulting stochastic model, we conduct two experiments and compare the results with those from other models. The first experiment consists of forecasting the daily average temperature and cloud density in Taipei, Taiwan, and the second experiment is based on the Taiwan Weighted Stock Index by forecasting the exchange rate of the New Taiwan dollar against the U.S. dollar. In addition to improving forecasting accuracy, the proposed model adheres to the central limit theorem, and thus, the result statistically approximates to the real mean of the target value being forecast.",10.1109/tsmcb.2009.2036860,Stochastic processes;Hidden Markov models;Predictive models;Fuzzy sets;Fuzzy logic;Uncertainty;Atmospheric measurements;Pollution measurement;Time measurement;Information management;Forecasting;fuzzy time series;hidden Markov model (HMM);Monte Carlo method,IEEE,"The paper develops a stochastic hidden Markov model-based forecasting method for fuzzy time series, applying it to weather and exchange rate data, improving forecasting accuracy.",✔️,New Taiwan dollar/USD exchange rate,❌,✔️
WOS:000505589700021,A Study Concerning Soft Computing Approaches for Stock Price Forecasting,"Financial time-series are well known for their non-linearity and non-stationarity nature. The application of conventional econometric models in prediction can incur significant errors. The fast advancement of soft computing techniques provides an alternative approach for estimating and forecasting volatile stock prices. Soft computing approaches exploit tolerance for imprecision, uncertainty, and partial truth to progressively and adaptively solve practical problems. In this study, a comprehensive review of latest soft computing tools is given. Then, examples incorporating a series of machine learning models, including both single and hybrid models, to predict prices of two representative indexes and one stock in Hong Kong's market are undertaken. The prediction performances of different models are evaluated and compared. The effects of the training sample size and stock patterns (viz. momentum and mean reversion) on model prediction are also investigated. Results indicate that artificial neural network (ANN)-based models yield the highest prediction accuracy. It was also found that the determination of optimal training sample size should take the pattern and volatility of stocks into consideration. Large prediction errors could be incurred when stocks exhibit a transition between mean reversion and momentum trend.",10.3390/axioms8040116,machine learning; stock price prediction; Hong Kong's market; SVR; HMM; ANN; DWT; EMD,WOS,"A comprehensive review of soft computing approaches for stock price forecasting is provided, highlighting the effectiveness of artificial neural networks in predicting volatile stock prices.",✔️,Stocks,✔️,❌
10.18576/jsap/12S115,A Study of The Saudi Stock Market Using Some Statistical Models,"The objective of this paper is to estimate the diversification effects/benefits of an investment in a portfolio consisting of the South African Industrial (J520) and the Financial (J580) Indices using the Generalised Pareto Distributions (GPDs) with an extreme value Gumbel copula. The GPD is used as the marginal distribution to both assets to better characterize the extreme risk of returns in both Indices tails. The extreme value Gumbel copula captures the dependence structure (co-movement) of the financial assets in the portfolio. The Akaike information criterion (AIC) and Bayesian information criterion (BIC) goodness of fit tests and the scatterplots indicate that the upper tail of the gains (the larger gains) risk and the losses tail (the larger losses) are best captured using the extreme value Gumbel copula. Monte Carlo simulation of an equally weighted portfolio of the two Indices is used to estimate the portfolio risk. The univariate marginal risks and the portfolio risks are used to calculate the diversification effects/benefits. The results show that there are benefits in diversification since the riskiness of the portfolio is less than the sum of the risk of the two financial assets. This implies that VaR, although not additive theoretically, is sub-additive in this practical situation. This property of sub-additivity represents the benefits of diversification for a portfolio. The implication is that investors investing in individual risky assets can benefit from constructing such a portfolio to reduce extreme risk. Due to high dependence and contagion between developed markets/Global markets, this is useful information for local and international investors seeking a portfolio which includes developing countries' market Indices, such as South African assets, which are less correlated with other Global markets, thereby reducing the risk of contagion. © 2023 NSP Natural Sciences Publishing Cor.",10.18576/jsap/12s115,ARIMA models; GARCH models; Leverage effect; Machine Learning; Statistical Model; Stock market; Volatility clustering,SCOPUS,"This study uses Generalised Pareto Distributions and extreme value Gumbel copula to analyze the diversification benefits of a portfolio comprising South African Industrial and Financial Indices, demonstrating reduced portfolio risk.",✔️,Stock Indices,❌,✔️
WOS:001104674200001,A Systematic Survey of AI Models in Financial Market Forecasting for Profitability Analysis,"Artificial intelligence (AI)-based models have emerged as powerful tools in financial markets, capable of reducing investment risks and aiding in selecting highly profitable stocks by achieving precise predictions. This holds immense value for investors, as it empowers them to make data-driven decisions. Identifying current and future trends in multi-class forecasting techniques employed within financial markets, particularly profitability analysis as an evaluation metric is important. The review focuses on examining stud-ies conducted between 2018 and 2023, sourced from three prominent academic databases. A meticulous three-stage approach was employed, encompassing the systematic planning, conduct, and analysis of the se-lected studies. Specifically, the analysis emphasizes technical assessment, profitability analysis, hybrid mod-eling, and the type of results generated by models. Articles were shortlisted based on inclusion and exclusion criteria, while a rigorous quality assessment through ten quality criteria questions, utilizing a Likert-type scale was employed to ensure methodological robustness. We observed that ensemble and hybrid models with long short-term memory (LSTM) and support vector machines (SVM) are being more adopted for financial trends and price prediction. Moreover, hybrid models employing AI algorithms for feature engineering have great potential at par with ensemble techniques. Most studies only employ performance metrics and lack utilization of profitability metrics or investment or trading strategy (simulated or real-time). Similarly, research on multi-class or output is severely lacking in financial forecasting and can be a good avenue for future research.",10.1109/access.2023.3330156,Forecasting; Predictive models; Artificial intelligence; Hidden Markov models; Analytical models; Measurement; Investment; Financial management; Convolutional neural networks; Cryptocurrency; Deep learning; Stock markets; financial forecasting; deep learning; stock market analysis; convolution neural network; cryptocurrency,WOS,"A systematic survey reviews AI-based models in financial market forecasting for profitability analysis, highlighting the adoption of ensemble and hybrid models but noting a lack of profitability metrics in most studies.",❌,,✔️,?
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9584890,A Two-Factor Fuzzy-Fluctuation Time Series Forecasting Model for Stock Markets Based on a Probabilistic Linguistic Preference Relationship and Similarity Measure,"An increasing number of scholars have tried to incorporate external factors affecting the disturbance of a time series into their forecasting models. However, these studies only verify the linkage relationship of two or more time series by empirical tests without providing any theoretical explanation. This makes it difficult to choose a linkage time series without using many tests. In this paper, a novel two-factor fuzzy-fluctuation time series (FFTS) forecasting model is proposed based on the probabilistic linguistic preference relationship (PLPR) and similarity measure. It not only proposes the idea of combining external factors with internal potential trends but also explains the linkage mechanism of time series fluctuations from the perspective of behavioral preference. Specifically, the probabilistic linguistic preference logical relationship (PLPLR) is employed to express the fluctuation behavior rule and preference attribute from the history testing dataset. The Euclidean distance or Hamming distance between the “current state” and the left side of training PLPLRs is introduced as a similarity comparison method for the identification of appropriate rules. The proposed model is tested using a traditional time series (e.g., the enrollment of the University of Alabama) to compare its performance with existing models. The model is also employed to forecast realistic stock markets, such as the Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX) and Hang Seng Index (HSI). The performance comparison illustrates the effectiveness and universality of the model.",10.1109/access.2021.3122142,Time series analysis;Forecasting;Linguistics;Fluctuations;Predictive models;Probabilistic logic;Stock markets;Fuzzy-fluctuation time series;forecasting;probabilistic linguistic preference relationship;similarity measurement,IEEE,"Proposes a hybrid model combining GARCH-type models with LSTM networks, using non-linear filtering to adjust volatility distributions, enhancing prediction accuracy for S&P 500 volatility.",✔️,Stock Market Volatility (S&P 500),✔️,✔️
10.1108/PRR-04-2017-0023,A big data Bayesian approach to earnings profitability in the S&P 500,"Purpose: The impact of volatility crush can be devastating to an option buyer and results in a substantial capital loss, even with a directionally correct strategy. As a result, most volatility plays are for option sellers, but the profit they can achieve is limited and the sellers carry unlimited risk. This paper aims to demonstrate the dynamics of implied volatility (IV) as being influenced by effects of persistence, leverage, market sentiment and liquidity. From the exploratory factor analysis (EFA), they extract four constructs and the results from the confirmatory factor analysis (CFA) indicated a good model fit for the constructs. Design/methodology/approach: This section describes the methodology used for conducting the study. This includes the study area, study approach, sources of data, sampling technique and the method of data analysis. Findings: Although there is extensive literature on methods for estimating IV dynamics during earnings announcement, few researchers have looked at the impact of expected market maker move, IV differential and IV Rank on the IV path after the earnings announcement. One reason for this research gap is because of the recent introduction of weekly options for equities by the Chicago Board of Options Exchange (CBOE) back in late 2010. Even then, the CBOE only released weekly options four individual equities – Bank of America (BAC.N), Apple (AAPL.O), Citigroup (C.N) and US-listed shares of BP (BP.L) (BP.N). The introduction of weekly options provided more trading flexibility and precision timing from shorter durations. This automatically expanded expiration choices, which in turned offered greater access and flexibility from the perspective of trading volatility during earnings announcement. This study has demonstrated the impact of including market sentiment and liquidity into the forecasting model for IV during earnings. This understanding in turn helps traders to formulate strategies that can circumvent the undefined risk associated with trading options strategies such as writing strangles. Research limitations/implications: The first limitation of the study is that the firms included in the study are relatively large, and the results of the study can therefore not be generalized to medium sized and small firms. The second limitation lies in the current sample size, which in many cases was not enough to be able to draw reliable conclusions on. Scaling the sample size up is only a function of time and effort. This is easily overcome and should not be a limitation in the future. The third limitation concerns the measurement of the variables. Under the assumption of a normal distribution of returns (i.e. stock prices follow a random walk process), which means that the distribution of returns is symmetrical, one can estimate the probabilities of potential gains or losses associated with each amount. This means the standard deviation of securities returns, which is called historical volatility and is usually calculated as a moving average, can be used as a risk indicator. The prices used for the calculations are usually the closing prices, but Parkinson (1980) suggests that the day’s high and low prices would provide a better estimate of real volatility. One can also refine the analysis with high-frequency data. Such data enable the avoidance of the bias stemming from the use of closing (or opening) prices, but they have only been available for a relatively short time. The length of the observation period is another topic that is still under debate. There are no criteria that enable one to conclude that volatility calculated in relation to mean returns over 20 trading days (or one month) and then annualized is any more or less representative than volatility calculated over 130 trading days (or six months) and then annualized, or even than volatility measured directly over 260 trading days (one year). Nonetheless, the guidelines adopted in this study represent the best practices of researchers thus far. Practical implications: This study has indicated that an earnings announcement can provide a volatility mispricing opportunity to allow an investor to profit from a sudden, sharp drop in IV. More specifically, the methodology developed by Tan and Bing is now well supported both empirically and theoretically in terms of qualifying opportunities that can be profitable because of the volatility crush. Conventionally, the option strategy of shorting strangles carries unlimited theoretical risk; however, the methodology has demonstrated that this risk can be substantially reduced if followed judiciously. This profitable strategy relies on a set of qualifying parameters including liquidity, premium collection, volatility differential, expected market move and market sentiment. Building upon this framework, the understanding of the effects of persistence and leverage resulted in further reducing the risk associated with trading options during earnings announcements. As a guideline, the sentiment and liquidity variables help to qualify a trade and the effects of persistence and leverage help to close the qualified trade. Social implications: The authors find a positive association between the effects of market sentiment, liquidity, persistence and leverage in the dynamics of IV during earnings announcement. These findings substantiate further the four factors that influence IV dynamics during earnings announcement and conclude that just looking at persistence and leverage alone will not generate profitable trading opportunities. Originality/value: The impact of volatility crush can be devastating to the option buyer with substantial capital loss, even for a directionally correct strategy. As a result, most volatility plays are for option sellers; however, the profit is limited and the sellers carry unlimited risk. The authors demonstrate the dynamics of IV as being influenced by effects of persistence, leverage, market sentiment and liquidity. From the EFA, they extracted four constructs and the results from the CFA indicated a good model fit for the constructs. Using EFA, CFA and Bayesian analysis, how this model can help investors formulate the right strategy to achieve the best risk/reward mix is demonstrated. Using Bayesian estimation and IV differential to proxy for differences of opinion about term structures in option pricing, the authors find a positive association among the effects of market sentiment, liquidity, persistence and leverage in the dynamics of IV during earnings announcement. © 2018, Teik-Kheong Tan and Merouane Lakehal-Ayat.",10.1108/prr-04-2017-0023,Bayesian; Data analytics; Factor analysis; Implied volatility; Machine learning; Structured equation modeling,SCOPUS,"The study utilizes a Bayesian approach to model implied volatility dynamics during earnings announcements in the S&P 500, helping investors strategize to manage volatility risks.",✔️,S&P 500 Options,❌,✔️
WOS:001009666300001,A case study of Gulf Securities Market in the last 20 years: A Long Short-Term Memory approach,"Various researches have been conducted on forecasting stock prices. Several tools ranging from statistical techniques to quantitative methods have been used by researchers to forecast the market. But so far, very little research has been done on forecasting the stock markets of the Gulf countries such as Saudi Arabia, United Arab Emirates, Oman, Kuwait, Bahrain, and Qatar. Our approach is to predict the market indices of the Gulf countries using Long Short-Term Memory (LSTM) techniques. Thereafter, we optimized the hyperparameters of the LSTM technique using various optimization methods such as Grid Search and Bayesian Optimization with Gaussian Process and found out the best-suited hyperparameter for the LSTM model. We tried the LSTM method for predicting the indices using data from the last twenty years.",10.1111/stan.12309,deep learning; hyperparameter optimization; LSTM; Middle East markets; stock market prediction,WOS,Applies Long Short-Term Memory (LSTM) neural networks with optimized hyperparameters to forecast the stock market indices of Gulf countries over a 20-year period.,✔️,Stock Market Indices,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=935099,A comparison of nonlinear methods for predicting earnings surprises and returns,"We compare four nonlinear methods on their ability to learn models from data. The problem requires predicting whether a company will deliver an earnings surprise a specific number of days prior to announcement. This problem has been well studied in the literature using linear models. A basic question is whether machine learning-based nonlinear models such as tree induction algorithms, neural networks, naive Bayesian learning, and genetic algorithms perform better in terms of predictive accuracy and in uncovering interesting relationships among problem variables. Equally importantly, if these alternative approaches perform better, why? And how do they stack up relative to each other? The answers to these questions are significant for predictive modeling in the financial arena, and in general for problem domains characterized by significant nonlinearities. In this paper, we compare the four above-mentioned nonlinear methods along a number of criteria. The genetic algorithm turns out to have some advantages in finding multiple ""small disjunct"" patterns that can be accurate and collectively capable of making predictions more often than its competitors. We use some of the nonlinearities we discovered about the problem domain to explain these results.",10.1109/72.935099,,IEEE,"Compares nonlinear machine learning methods for predicting earnings surprises and returns, finding genetic algorithms effective in capturing predictive patterns.",✔️,Financial Returns (Stocks),✔️,❌
10.1016/j.neunet.2020.03.022,A fast conformal predictive system with regularized extreme learning machine,"A conformal predictive system(CPS) is based on the learning framework of conformal prediction, which outputs cumulative distribution functions(CDFs) for labels in regression problems. The CDFs output by a CPS provide useful information for users, as they not only provide probability for the events related to the test labels, but also can be transformed to prediction intervals with the corresponding quantiles. Moreover, CPSs have the property of validity since the distributions and intervals they output have statistical compatibility with the realizations. This property is very useful for many risk-sensitive applications such as financial time series forecast and weather forecast. However, as based on conformal predictors, CPSs inherit the computational issue. To build a fast CPS, in this paper, we propose a CPS with regularized extreme learning machine as the underlying algorithm. To be specific, we combine the leave-one-out cross-conformal predictive system(Leave-One-Out CCPS), a variant of the original CPS, with regularized extreme learning machine(RELM), which is named as LOO-CCPS-RELM. We analyse the computational complexity of it and prove its asymptotic validity based on some regularity assumptions. We also prove that the error rate of the prediction interval output by LOO-CCPS-RELM is under control in the asymptotic setting. Experiments with 20 public data sets were conducted to test LOO-CCPS-RELM and the results showed that LOO-CCPS-RELM is empirically valid and compared favourably with the other CPSs. © 2020 Elsevier Ltd",10.1016/j.neunet.2020.03.022,Asymptotic validity; Conformal predictive system; Cross-conformal predictive system; Cumulative distribution function; Regularized extreme learning machine,SCOPUS,"The paper proposes a fast conformal predictive system incorporating regularized extreme learning machines to generate probabilistic forecasts and prediction intervals for financial time series, demonstrating validity and performance improvements.",✔️,Financial time series,✔️,✔️
WOS:000400717200027,A feature weighted support vector machine and K-nearest neighbor algorithm for stock market indices prediction,"This study investigates stock market indices prediction that is an interesting and important research in the areas of investment and applications, as it can get more profits and returns at lower risk rate with effective exchange strategies. To realize accurate prediction, various methods have been tried, among which the machine learning methods have drawn attention and been developed. In this paper, we propose a basic hybridized framework of the feature weighted support vector machine as well as feature weighted K-nearest neighbor to effectively predict stock market indices. We first establish a detailed theory of feature weighted SVM for the data classification assigning different weights for different features with respect to the classification importance. Then, to get the weights, we estimate the importance of each feature by computing the information gain. Lastly, we use feature weighted K-nearest neighbor to predict future stock market indices by computing k weighted nearest neighbors from the historical dataset. Experiment results on two well known Chinese stock market indices like Shanghai and Shenzhen stock exchange indices are finally presented to test the performance of our established model. With our proposed model, it can achieve a better prediction capability to Shanghai Stock Exchange Composite Index and Shenzhen Stock Exchange Component Index in the short, medium and long term respectively. The proposed algorithm can also be adapted to other stock market indices prediction. (C) 2017 Elsevier Ltd. All rights reserved.",10.1016/j.eswa.2017.02.044,Feature weighted SVM (FWSVM); Information gain; Feature weighted K-nearest neighbor (FWKNN); Stock market indices,WOS,"Proposes feature-weighted SVM and K-nearest neighbor algorithms to effectively predict Chinese stock market indices, demonstrating superior prediction capabilities in short, medium, and long-term forecasts.",✔️,Chinese Stock Market Indices,✔️,❌
WOS:000652785100001,A general Bayesian model for heteroskedastic data with fully conjugate full-conditional distributions,"Models for heteroskedastic data are relevant in a variety of applications ranging from financial time series to environmental statistics. However, the topic of modelling the variance function conditionally has not seen as much attention as modelling the mean. Volatility models have been used in specific applications, but these models can be difficult to fit in a Bayesian setting due to posterior distributions that are challenging to sample efficiently. In this work, we introduce a general model for heteroskedastic data. This approach models the conditional variance as a function of any desired covariates or random effects. We rely on multivariate log-Gamma distribution theory to construct priors that yield fully conjugate full-conditional distributions for Gibbs sampling. Furthermore, we extend the model to a deep learning approach that can provide highly accurate estimates for time dependent data. We also provide an extension for heavy-tailed data. We illustrate our methodology via three applications.",10.1080/00949655.2021.1925279,Deep learning; echo state network; Gibbs sampling; mixed models; multivariate log-Gamma; spatial; volatility,WOS,"A Bayesian model for heteroskedastic data using multivariate log-Gamma distributions is proposed, facilitating efficient Gibbs sampling for financial volatility modeling.",❌,Volatility Data,✔️,✔️
10.1016/j.techfore.2023.122719,A granular machine learning framework for forecasting high-frequency financial market variables during the recent black swan event,"This paper analyses highly voluminous 1-minute intraday movements of the closing prices of Bitcoin, crude oil, the Dow Jones Industrial Average (DJIA) and the euro–U.S. dollar exchange rate in various non-overlapping regimes spanning across the COVID-19 pandemic, a recent black swan event. The empirical characteristics of the intraday dynamics of chosen assets are gauged using nonlinear modelling tools and tests. The proposed methodological framework utilises maximal overlap discrete wavelet transformation, Bayesian structural time series forecasting and random walk with drift to evaluate the quantum of predictability of select variables in different phases across the pandemic horizon. The framework survives a series of performance and statistical checks to justify the efficacy of drawing highly accurate predictions from big data setups. The findings suggest that, despite chaotic traces, all variables can be precisely forecast across different sub-regimes, eliminating the adverse effects of the first and second waves of the COVID-19 pandemic. High-frequency movements of Bitcoin and Euro–U.S. dollar exchange rates are relatively better predictable, signifying resilience during the pandemic. Finally, the outcome of this research will help mitigate financial risk during volatile periods. © 2023 Elsevier Inc.",10.1016/j.techfore.2023.122719,Bayesian structural time series; Big data analytics; High-frequency financial market forecasting; Maximal overlap discrete wavelet transformation; Nonlinear dynamics,SCOPUS,Proposes a granular machine learning framework using Bayesian structural time series and wavelet transformation for forecasting high-frequency financial market variables during COVID-19.,✔️,"Bitcoin, Crude Oil, DJIA, EUR/USD",✔️,✔️
10.1016/j.ins.2010.01.014,A hybrid model based on rough sets theory and genetic algorithms for stock price forecasting,"In the stock market, technical analysis is a useful method for predicting stock prices. Although, professional stock analysts and fund managers usually make subjective judgments, based on objective technical indicators, it is difficult for non-professionals to apply this forecasting technique because there are too many complex technical indicators to be considered. Moreover, two drawbacks have been found in many of the past forecasting models: (1) statistical assumptions about variables are required for time series models, such as the autoregressive moving average model (ARMA) and the autoregressive conditional heteroscedasticity (ARCH), to produce forecasting models of mathematical equations, and these are not easily understood by stock investors; and (2) the rules mined from some artificial intelligence (AI) algorithms, such as neural networks (NN), are not easily realized. In order to overcome these drawbacks, this paper proposes a hybrid forecasting model, using multi-technical indicators to predict stock price trends. Further, it includes four proposed procedures in the hybrid model to provide efficient rules for forecasting, which are evolved from the extracted rules with high support value, by using the toolset based on rough sets theory (RST): (1) select the essential technical indicators, which are highly related to the future stock price, from the popular indicators based on a correlation matrix; (2) use the cumulative probability distribution approach (CDPA) and minimize the entropy principle approach (MEPA) to partition technical indicator value and daily price fluctuation into linguistic values, based on the characteristics of the data distribution; (3) employ a RST algorithm to extract linguistic rules from the linguistic technical indicator dataset; and (4) utilize genetic algorithms (GAs) to refine the extracted rules to get better forecasting accuracy and stock return. The effectiveness of the proposed model is verified with two types of performance evaluations, accuracy and stock return, and by using a six-year period of the TAIEX (Taiwan Stock Exchange Capitalization Weighted Stock Index) as the experiment dataset. The experimental results show that the proposed model is superior to the two listed forecasting models (RST and GAs) in terms of accuracy, and the stock return evaluations have revealed that the profits produced by the proposed model are higher than the three listed models (Buy-and-Hold, RST and GAs). © 2010 Elsevier Inc. All rights reserved.",10.1016/j.ins.2010.01.014,Cumulative probability distribution approach; Genetic algorithms; Minimize entropy principle approach; Rough set theory; Technical indicators,SCOPUS,"The study proposes a hybrid forecasting model combining rough sets theory and genetic algorithms to predict stock prices using multiple technical indicators, achieving superior accuracy and returns.",✔️,Stocks,✔️,❌
10.1016/j.jfds.2016.03.002,A hybrid stock trading framework integrating technical analysis with machine learning techniques,"In this paper, a novel decision support system using a computational efficient functional link artificial neural network (CEFLANN) and a set of rules is proposed to generate the trading decisions more effectively. Here the problem of stock trading decision prediction is articulated as a classification problem with three class values representing the buy, hold and sell signals. The CEFLANN network used in the decision support system produces a set of continuous trading signals within the range 0–1 by analyzing the nonlinear relationship exists between few popular technical indicators. Further the output trading signals are used to track the trend and to produce the trading decision based on that trend using some trading rules. The novelty of the approach is to engender the profitable stock trading decision points through integration of the learning ability of CEFLANN neural network with the technical analysis rules. For assessing the potential use of the proposed method, the model performance is also compared with some other machine learning techniques such as Support Vector Machine (SVM), Naive Bayesian model, K nearest neighbor model (KNN) and Decision Tree (DT) model. © 2016 China Science Publishing & Media Ltd.",10.1016/j.jfds.2016.03.002,CEFLANN; Stock trading; Stock trend analysis; Technical indicators,SCOPUS,"This study introduces a hybrid stock trading framework that combines a functional link artificial neural network with technical analysis rules to generate trading decisions, outperforming several machine learning models.",✔️,Stocks,✔️,❌
10.1016/j.tre.2018.03.005,A machine learning approach for the operationalization of latent classes in a discrete shipment size choice model,"This paper elaborates a novel approach for implementation of latent segments concerning behaviorally sensitive shipment size choice in strategic interregional freight transport models. Discrete shipment size choice models are estimated for different homogenous segments formed by latent class analysis. A machine learning technique called Bayesian classifier is applied to link segments obtained from a sample to data of commodity flows being available on a national level. Finally, in an exemplary scenario, the impact of information and communication technologies on shipment size distributions is calculated, revealing moderate elasticities and a predominant substitution of less than truck loads by full truck loads. © 2018 Elsevier Ltd",10.1016/j.tre.2018.03.005,Bayesian classification; Freight transport; Latent class analysis; Machine learning; Shipment size,SCOPUS,"A machine learning approach is introduced for operationalizing latent classes in a shipment size choice model, enhancing strategic freight transport decision-making.",❌,Shipment Sizes,✔️,❌
10.3233/978-1-61499-361-2-158,A multidimensional market analysis method using level-velocity-momentum time-series vector space,"Numerous stock market analysis methods have been proposed from simple moving average to the use of artificial intelligence such as neural networks and Bayesian networks. In this paper, we introduce a new concept and a methodology that enable predictability of asset price movement in the market by way of inference from the past data. We use schema to describe an economic instance, and a set of schema in time series to describe the flow of economic instances in the past. Within the schema, we introduce a concept of velocity and momentum to effectively characterize the dynamic nature of the market. We compare the current and the past instances to identify resemblance and take inference as a predictive capability of future asset price movement. © 2014 The authors and IOS Press.",10.3233/978-1-61499-361-2-158,market; momentum; multidimensional; prediction; schema; time-series; Vector space analysis; velocity,SCOPUS,Introduces a multidimensional market analysis method using level-velocity-momentum features for asset price movement prediction.,✔️,Asset Prices,❌,❌
WOS:000951753200001,A new heavy tailed distribution with actuarial measures,"Actuaries are constantly on the lookout for heavy-tailed (HT) distributions in order to model data important to business and actuarial risk problems. In this article, we describe a novel type of heavy-tailed distribution that may be used to model data in the financial disciplines. Our proposed model, identified as a Kavya-Manoharan power Lomax (KMPLo) distribution, is thoroughly studied. Some fundamental characterizations, such as the quantile function and moments, have been developed. The maximum likelihood (ML) and Bayesian (B) analytical techniques are used to acquire estimates of the unknown parameters of the new model. A detailed simulation study is undertaken to evaluate the performance of the ML and B estimators. The KMPLo model's utility is demonstrated by an application to a HT insurance loss data set. The experimental results reveal that the sug-gested model is more adaptable and affordable than the other seven competing models including (i) the four -parameter model is the power Lomax (PLo) model; (ii) the four-parameter models odd log-logistic modified Weibull (OLLMW), Kumaraswamy Weibull (KW), generalized modified Weibull (GMW), extended odd Weibull Lomax (EOWL), Weibull-Lomax (WL), Marshall-Olkin power Lomax (MOPLo), Marshall-Olkin alpha power Lomax (MOAPLo) and exponentiated generalized alpha power exponential (EGAPEx) distributions (iii) the five -parameter distributions; , Kumaraswamy generalized power Lomax (KGPLo) and Marshall-Olkin alpha power exponentiated Weibull (MOAPEW) distribution. In addition, certain essential actuarial metrics, such like value at risk and conditional value at risk, are determined.",10.1016/j.jrras.2023.100562,Kavya-manoharan generated family; Power lomax model; Maximum likelihood; Moments; Simulation; Actuarial measures,WOS,"A new heavy-tailed distribution, Kavya-Manoharan power Lomax (KMPLo), is proposed for actuarial applications, offering improved fit and risk measures like VaR.",❌,Insurance and Actuarial Data,✔️,✔️
WOS:000864527500006,A non-ferrous metal price ensemble prediction system based on innovative combined kernel extreme learning machine and chaos theory,"Non-ferrous metal futures, as a significant component of the financial market, are complementary and coordinated with other financial elements, which has been a key area of research in recent years. However, given the apparent volatility and chaotic nature of the non-ferrous metal price sequence, forecasting it remains a difficult challenge. While prior research employed a variety of methodologies to forecast metal prices, they overlooked the critical role of chaos feature analysis and the necessity of error analysis, severely limiting prediction accuracy. This paper designs a novel non-ferrous metal price ensemble prediction system that incorporates data decomposition, phase space reconstruction, multi-objective optimization, point prediction, and interval prediction. A combined kernel extreme learning machine based on the improved multi-objective lion swarm optimization algorithm is developed and theoretically explained to improve prediction accuracy and reliability. Additionally, the appropriate creation of the prediction interval based on the best-fit distribution of the point prediction error enabled the examination of various levels of uncertainty. In an empirical experiment using copper and aluminum prices from the London Metal Exchange, the proposed system demonstrated benefits in point and interval prediction, providing decision makers with useful prediction references.",10.1016/j.resourpol.2022.102975,Non-ferrous metal price prediction; Machine learning; Combined kernel extreme learning machine; Phase space reconstruction; Multi-objective optimization algorithm,WOS,"An ensemble prediction system using kernel extreme learning machines and chaos theory is designed for non-ferrous metal prices, providing accurate point and interval predictions.",✔️,"Non-ferrous Metals (Copper, Aluminum)",✔️,✔️
10.3233/IDT-180346,A review and empirical analysis of neural networks based exchange rate prediction,"Financial time series data is very chaotic, noisy, fluctuating and nonlinear as different events have occurred in various time periods. Therefore, it is very challenging for researchers to develop the accurate predictive model. Prediction for Foreign Exchange rate is also a very crucial task for N days ahead prediction because of volatile nature of Foreign Exchange rate data. It is also become highly desirable due to it's role in financial and managerial decision making capacity of any country. A lot of efforts have been done by researchers over many years for the development of efficient models to improve the forecasting accuracy. As a result, various important time series forecasting models have been evolved in literature. From the literature survey we have analyzed that statistical techniques are not able to efficiently predict the Foreign Exchange rate. Hence, different machine learning techniques have been used by many researchers for accurate prediction. Over the years different types of neural network models such as multi - layer perceptron, radial basis function neural network, functional link artificial neural network and integrated model such as auto - regressive integrated moving average models are developed to predict the currency exchange rates of different countries with varying parameters. In this paper, we divide our effort into two parts. In the first part, we have reviewed a few selected models based on neural networks and statistical methods including fundamental and technical aspects of currency exchange rate prediction. In the second part, we have made a thorough and careful empirical study of the models reviewed in part one. Our study reveals that the daily currency exchange rates with multi - layer neural network having Bayesian learning technique produces more accurate results against the multi - layer neural network with back propagation learning technique. Similarly, integrated models of radial basis function neural network and functional link neural networks produce less amount of error in comparison to single radial basis neural networks and functional link neural network models. Additionally, we critically analyze an integrated work on statistical model such as auto-regressive integrated moving average model with neural networks and revealed that the integrated models produces better results than the individual models. © 2018 - IOS Press and the authors. All rights reserved.",10.3233/idt-180346,autoregressive integrated moving average; Bayesian learning; cascaded functional link artificial neural networks; currency exchange rate; Foreign exchange rate; functional link artificial neural network; multilayer perceptron; neural network; radial basis function network,SCOPUS,"Reviews and empirically analyzes neural network models for exchange rate prediction, finding Multi-Layer Perceptron with Bayesian learning superior.",✔️,Currency Exchange Rates,✔️,✔️
WOS:000412252000021,A stacked generalization system for automated FOREX portfolio trading,"Multiple FOREX time series forecasting is a hot research topic in the literature of portfolio trading. To this end, a large variety of machine learning algorithms have been examined. However, it is now widely understood that, in real-world trading settings, no single machine learning model can consistently outperform the alternatives. In this work, we examine the efficacy and the feasibility of developing a stacked generalization system, intelligently combining the predictions of diverse machine learning models. Our approach establishes a novel inferential framework that comprises the following levels of data processing: (i) We model the dependence patterns between major currency pairs via a diverse set of commonly used machine learning algorithms, namely support vector machines (SVMs), random forests (RFs), Bayesian autoregressive trees (BART), dense-layer neural networks (NNs), and naive Bayes (NB) classifiers. (ii) We generate implied signals of exchange rate fluctuation, based on the output of these models, as well as appropriate side information obtained by analyzing the correlations across currency pairs in our training datasets. (iii) We finally combine these implied signals into an aggregate predictive waveforth, by leveraging majority voting, genetic algorithm optimization, and regression weighting techniques. We thoroughly test our framework in real-world trading scenarios; we show that our system leads to significantly better trading performance than the considered benchmarks. Thus, it represents an attractive solution for financial firms and corporations that perform foreign exchange portfolio management and daily trading. Our system can be used as an integrated part in international commercial trade activities or in a quantitative investing framework for algorithmic trading and carry-trade speculation. (C) 2017 Elsevier Ltd. All rights reserved.",10.1016/j.eswa.2017.08.011,Forex forecasting; Algorithmic trading; Portfolio management; Machine learning; Stacked generalization,WOS,"Develops a stacked generalization system combining multiple ML models to predict Forex trades, achieving better performance than benchmarks.",✔️,Forex,✔️,❌
10.1016/0925-2312(91)90026-8,A stock selection strategy using fuzzy neural networks,"This paper describes, from a general system-design perspective, an artificial neural network (ANN) approach to a stock selection strategy. The paper suggests a concept of neural gates which are similar to the processing elements in ANN, but generalized for handling various types of information such as fuzzy logic, probabilistic and Boolean information together. Forecasting of stock market returns, assessing of country risk and rating of stocks based on fuzzy rules, probabilistic and Boolean data can be done using the proposed neural gates. Fuzzy logic is known to be useful for decision-making where there is a great deal of uncertainty as well as vague phenomena, but lacks the learning capability; on the other hand, neural networks are useful in constructing an adaptive system which can learn from historical data, but are not able to process ambiguous rules and probabilistic data sets. This paper describes how these problems can be solved using the proposed neural gates. © 1991.",10.1016/0925-2312(91)90026-8,artificial intelligence; financial analysis; fuzzy logic; neural network; risk analysis; Stock market analysis,SCOPUS,"Develops a stock selection strategy using fuzzy neural networks to handle fuzzy, probabilistic, and Boolean information for forecasting returns and assessing risks.",✔️,Stocks,✔️,✔️
WOS:001177961600001,A survey on uncertainty quantification in deep learning for financial time series prediction,"Investors make decisions about buying and selling a financial asset based on available information. The traditional approach in Deep Learning when trying to predict the behavior of an asset is to take a price history, train a model, and forecast one single price in the near future. This is called the frequentist perspective. Uncertainty Quantification is an alternative in which models manage a probability distribution for prediction. It provides investors with more information than the traditional frequentist way, so they can consider the risk of making or not making a certain decision. We systematically reviewed the existing literature on Uncertainty Quantification methods in Deep Learning to predict the behavior of financial assets, such as foreign exchange, stock market, cryptocurrencies and others. The article discusses types of model, categories of financial assets, prediction characteristics and types of uncertainty. We found that, in general terms, references focus on price accuracy as a metric, although other metrics, such as trend accuracy, might be more appropriate. Very few authors analyze both epistemic and aleatoric uncertainty, and none analyze in depth how to decouple them. The time period analyzed includes the years 2001 to 2022.",10.1016/j.neucom.2024.127339,Deep Learning; Time series; Uncertainty quantification; Prediction; Financial assets,WOS,"Surveys uncertainty quantification methods in deep learning models for financial time series prediction, highlighting the importance of probabilistic approaches in enhancing prediction reliability.",❌,Financial Time Series,✔️,✔️
WOS:000524974800004,A system approach towards prediction of food safety hazards: Impact of climate and agrichemical use on the occurrence of food safety hazards,"In this study, we aimed to demonstrate the aptness of a system approach to predict the level of contamination in a given agricultural product. As a showcase, the impact of climate and agrichemical use on the occurrence of food safety hazards in feed of dairy cows in the Netherlands was used. Data on chemical hazards in dairy cows' feed in the Netherlands for the years 2000 to 2013 were retrieved from the Dutch monitoring program KAP (Quality Program for Agricultural Products). Climate data (17 variables) and agrichemical usage figs. (6 variables) for the Netherlands were obtained from the NOAA's National Centers for Environmental Information, the European Commission Joint Research Center's Agri4Cast database, and FAO's FAOSTAT. A Bayesian Network (BN) was constructed with this data and optimized for the prediction of the contamination level. The overall accuracy of prediction of the level of contamination in feed was 90.3%. Sensitivity analysis demonstrated that many climate and agrichemical variables contributed to the prediction; however, their individual contribution was generally small. The applicability of the BN was demonstrated in more detail for grass and maize as feed components. The observed trends in contamination of these crops were accounted for by climate and agrichemical variables, with the impact varying amongst the specific variables and commodities. The variables with the highest impact were ""days of precipitations in a month with >= 2.5 mm"" and ""annual use of herbicides"". The results demonstrate that data-driven BNs can capture complex interactions, thereby enabling high-accuracy predictions. Whilst the applicability of this approach to the safety of dairy cows' feed in the Netherlands has thus been demonstrated, it can also be applied to other areas of food safety when a systems approach is needed. Such models can support risk assessors and risk managers in their understanding of the impacts of a given factor on food and feed safety, and inform the latter's decisions to mitigate potential risks.",10.1016/j.agsy.2019.102760,Food supply chain; Bayesian Networks; Dairy and milk; Feed; Machine learning,WOS,Demonstrates a system approach using Bayesian Networks to predict contamination levels in dairy cow feed based on climate and agrichemical use data.,❌,?,✔️,✔️
WOS:000878568700001,A two-step framework for arbitrage-free prediction of the implied volatility surface,"In this study, we propose a two-step framework to predict the implied volatility surface (IVS) in a manner that excludes static arbitrage. First, we select features to represent the surface and predict them. Second, we use the predicted features to construct the IVS using a deep neural network (DNN) model by incorporating constraints that can prevent static arbitrage. We consider three methods to extract features from the implied volatility data: principal component analysis, variational autoencoder, and sampling the surface. We predict these features using the long short-term memory model. Additionally, we use a long time series of implied volatility data for S&P500 index options to train our models. We find that two feature construction methods (i.e. sampling the surface and variational autoencoders combined with DNN for surface construction) are the best performers in the out-of-sample prediction. Furthermore, both of them substantially outperform a popular regression model. We also find that the DNN model for surface construction not only removes static arbitrage but also significantly reduces the prediction error compared with a standard interpolation method.",10.1080/14697688.2022.2135454,Implied volatility surface; Static arbitrage; Prediction; Deep learning; Variational autoencoder,WOS,"A two-step framework using deep neural networks and Hidden Markov Models is proposed to predict the implied volatility surface in an arbitrage-free manner, significantly reducing prediction errors compared to traditional methods.",✔️,Implied Volatility,✔️,❌
WOS:000331200200015,AMERICAN OPTION PRICING UNDER GARCH DIFFUSION MODEL: AN EMPIRICAL STUDY,"The GARCH diffusion model has received much attention in recent years, as it describes financial time series better when compared to many other models. In this paper, the authors study the empirical performance of American option pricing model when the underlying asset follows the GARCH diffusion. The parameters of the GARCH diffusion model are estimated by the efficient importance sampling-based maximum likelihood (EIS-ML) method. Then the least-squares Monte Carlo (LSMC) method is introduced to price American options. Empirical pricing results on American put options in Hong Kong stock market shows that the GARCH diffusion model outperforms the classical constant volatility (CV) model significantly.",10.1007/s11424-014-3279-2,American option; efficient importance sampling; GARCH diffusion model; least-squares Monte Carlo; maximum likelihood,WOS,"The empirical performance of American option pricing under a GARCH diffusion model is studied, showing significant outperformance over classical constant volatility models.",✔️,American Options,✔️,❌
WOS:001199959100001,Accurate Stock Price Forecasting Based on Deep Learning and Hierarchical Frequency Decomposition,"The stock market is playing an increasingly important role in the global economy. Accurate stock price forecasting not only aids the government in predicting economic trends but also helps investors anticipate higher expected returns. Nevertheless, hurdles such as nonlinearity, complexity and high volatility make it a daunting task to predict stock prices. To address this issue, this study proposes a new hybrid model, termed Hierarchical Decomposition-based Forecasting Model (HDFM), to decompose and forecast stock prices in a hierarchical fashion. The model utilizes complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) for the initial decomposition of stock price time series. To enhance the predictive efficiency, sub-series with similar sample entropy from the decomposition were combined using the K-means clustering method. Through a thorough analysis, it was found that the first combined sub-series contained more high-frequency signals. Therefore, the first combined sub-series is subjected to a second decomposition with variational mode decomposition (VMD). Subsequently, the gated recurrent unit (GRU) model was used to individually predict each sub-series. The final results were obtained by merging the prediction outcomes. The proposed model was evaluated on three different stock markets. The experimental results show that the proposed model outperforms other forecasting methods across all stock indices. Moreover, ablation studies demonstrated the effectiveness of each component within the proposed model.",10.1109/access.2024.3384430,Predictive models; Hidden Markov models; Forecasting; Autoregressive processes; Deep learning; Time series analysis; Adaptation models; Stock markets; Hierarchical systems; Clustering algorithms; Stock price prediction; deep learning; hierarchical decomposition; clustering,WOS,"This study introduces a new hybrid deep learning model, Hierarchical Decomposition-based Forecasting Model (HDFM), for accurate stock price prediction by decomposing stock price time series hierarchically and leveraging GRU models, outperforming other forecasting methods across multiple stock markets.",✔️,Stock,✔️,❌
10.11591/eei.v12i6.4987,Adaptation of stochasticity into activation function of deep learning for stock price forecasting,"Stock market is an example of a stochastic environment in the real world. multilayer perceptron (MLP) is often applied to forecast stock price. However, it is widely used to approximate the input-output mapping deterministically. Hence, this study aims to adapt stochasticity into MLP by introducing the Gaussian process into the sigmoid activation function. In addition, the adapted activation function incorporates Roger-Satchell and Yang-Zhang volatity estimators. Besides, the stochastic activation function was considered as a hyperparameter by applying it either only in training time or in both testing and training time. The stochastic multilayer perceptron (S-MLP) is then applied to forecast one day's highest stock price of eight constituents in FTSE Bursa Malaysia KLCI (FBMKLCI). The result shows that the proposed network is inferior in comparison to MLP except for several constituents. In addition, S-MLP with stochastic activation function during both the training and testing time performs better compared to the presence of stochastic activation function in S-MLP during training time only. © 2023, Institute of Advanced Engineering and Science. All rights reserved.",10.11591/eei.v12i6.4987,Forecasting stock price; Gaussian process; Multilayer perceptron; Stochastic neural network,SCOPUS,"Utilizes machine learning, including stacked ensemble models and Shapley value analysis, to model and optimize Estimated Ultimate Recovery (EUR) in the liquid-rich Duvernay Formation, enhancing oil and gas project feasibility assessments.",✔️,Estimated Ultimate Recovery (EUR),✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120214,Adaptive Temporal-Frequency Network for Time-Series Forecasting,"A novel adaptive temporal-frequency network (ATFN), which is an end-to-end hybrid model incorporating deep learning networks and frequency patterns, is proposed for mid- and long-term time series forecasting. Within the framework of the ATFN, an augmented sequence to sequence model is used to learn the trend feature of complicated nonstationary time series, a frequency-domain block is used to capture dynamic and complicated periodic patterns of time series data, and a fully connected neural network is used to combine the trend and periodic features for producing a final forecast. An adaptive frequency mechanism consisting of phase adaption, frequency adaption, and amplitude adaption is designed for mapping the frequency spectrum of the current sliding window to that of the forecasting interval. The multilayer neural networks conduct a transformation similar to the inverse discrete Fourier transform for generating a periodic feature forecast. Synthetic data and real-world data with different periodic characteristics are used to evaluate the effectiveness of the proposed model. The experimental results indicate that the ATFN has promising performance and strong adaptability for long-term time-series forecasting.",10.1109/tkde.2020.3003420,Forecasting;Predictive models;Time series analysis;Adaptation models;Time-frequency analysis;Autoregressive processes;Adaptive frequency;deep learning;long-term forecasting;recurrent neural networks;time-series prediction,IEEE,"The paper proposes an adaptive temporal-frequency network model for time-series forecasting, applied successfully to financial stock indices and demonstrating superior performance over existing approaches.",✔️,"Taiwan Stock Index, Hang Seng Index",✔️,❌
WOS:000734789000001,Adoption of deep learning Markov model combined with copula function in portfolio risk measurement,"In order to accurately describe the risk dependence structure and correlation between financial variables, carry out scientific financial risk assessment, and provide the basis for accurate financial decision-making, first the basic theory of Copula function is established and the mixed Copula model is constructed. Then the hybrid Copula model is nested in a hidden Markov model (HMM), the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio. Finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed Copula model based on HMM is more effective than the single Copula and the mixed Copula models. The empirical structure shows that among the four major financial industries in China, the banking and insurance industries have strong interdependence and high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by Copula-Garch model are 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56% respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion, so that the macro or systemic risks may arise, and the deep-learning Markov model can be adopted to predict the stock prices.",10.2478/amns.2021.2.00065,mixed Copula model; HMM; financial index; risk contagion; investment failure rate,WOS,"The adoption of a deep learning Markov model combined with copula functions is explored for portfolio risk measurement, indicating strong interdependence among Chinese financial industries.",✔️,Stocks,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310891,An Adaptive SVR for High-Frequency Stock Price Forecasting,"In order to mitigate investments, stock price forecasting has attracted more attention in recent years. Aiming at the discreteness, non-normality, high-noise in high-frequency data, a support vector machine regression (SVR) algorithm is introduced in this paper. However, the characteristics in different periods of the same stock, or the same periods of different stocks are significantly different. So, SVR with fixed parameters is difficult to satisfy with the constantly changing data flow. To tackle this problem, an adaptive SVR was proposed for stock data at three different time scales, including daily data, 30-min data, and 5-min data. Experiments show that the improved SVR with dynamic optimization of learning parameters by particle swarm optimization can get a better result than compared methods including SVR and back-propagation neural network.",10.1109/access.2018.2806180,Forecasting;Training;Particle swarm optimization;Hidden Markov models;Support vector machines;Optimization;Kernel;Support vector machine;regression;particle swarm optimization;stock price forecasting;high-frequency data,IEEE,"A Multi-Layer Coupled Hidden Markov Model is proposed for hierarchical cross-market behavior analysis and trend forecasting, effectively capturing relationships between markets across countries.",✔️,Stock Market Indices,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125674,An Empirical Study on Modeling and Prediction of Bitcoin Prices With Bayesian Neural Networks Based on Blockchain Information,"Bitcoin has recently attracted considerable attention in the fields of economics, cryptography, and computer science due to its inherent nature of combining encryption technology and monetary units. This paper reveals the effect of Bayesian neural networks (BNNs) by analyzing the time series of Bitcoin process. We also select the most relevant features from Blockchain information that is deeply involved in Bitcoin's supply and demand and use them to train models to improve the predictive performance of the latest Bitcoin pricing process. We conduct the empirical study that compares the Bayesian neural network with other linear and non-linear benchmark models on modeling and predicting the Bitcoin process. Our empirical studies show that BNN performs well in predicting Bitcoin price time series and explaining the high volatility of the recent Bitcoin price.",10.1109/access.2017.2779181,Bitcoin;Predictive models;Neural networks;Time series analysis;Bayes methods;Biological system modeling;Bitcoin;blockchain;Bayesian neural network;time-series analysis;predictive model,IEEE,"Uses Bayesian neural networks incorporating blockchain information to model and predict Bitcoin prices, outperforming other benchmark models.",✔️,Cryptocurrency (Bitcoin),✔️,✔️
10.1109/ACCESS.2024.3368874,An Expeditious and Expressive Vehicle Dynamics Model for Applications in Controls and Reinforcement Learning,"We present a Vehicle Model (VM) that has 17 degrees of freedom and includes nonlinear tire and powertrain subsystems. Implemented as a relatively small piece of C++ code, the model runs vehicle dynamics 2000 times faster than real time at a simulation time step of 1 × 10^-3, s on a single core of a commodity CPU. When executed on the GPU, one can perform 300000 vehicle simulations in real-time. These properties make the model a good candidate for reinforcement learning, model predictive control, model predictive path integral control, path planning, state estimation, and traffic simulation tasks. The model is expressive in that it can capture the dynamics of vastly different vehicles. This is demonstrated by first calibrating the model to mimic the dynamics of a 1/6^th scale vehicle called the Autonomy Research Testbed (ART) vehicle, which has a mass of approximately 5.8 kg. Subsequently, the model is calibrated to mimic the dynamics of a heavy-duty High Mobility Multipurpose Wheeled Vehicle (HMMWV), which has a mass of 2097 kg. The Bayesian calibration process discussed can (i) handle real-life measurement noise, and (ii) provide model parameter probability distributions. The vehicle model, which is open source and freely available in a public repository, can also be imported into Python owing to SWIG wrapping.  © 2013 IEEE.",10.1109/access.2024.3368874,Bayesian inference; calibration; control; machine learning; state estimation; traffic simulation; Vehicle models,SCOPUS,"The paper introduces a fast and detailed vehicle dynamics model suitable for control and reinforcement learning applications, featuring Bayesian calibration for handling uncertainties.",❌,,✔️,✔️
WOS:000518042000069,An Improved Probabilistic Neural Network Model for Directional Prediction of a Stock Market Index,"Financial market prediction attracts immense interest among researchers nowadays due to rapid increase in the investments of financial markets in the last few decades. The stock market is one of the leading financial markets due to importance and interest of many stakeholders. With the development of machine learning techniques, the financial industry thrived with the enhancement of the forecasting ability. Probabilistic neural network (PNN) is a promising machine learning technique which can be used to forecast financial markets with a higher accuracy. A major limitation of PNN is the assumption of Gaussian distribution as the distribution of input variables which is violated with respect to financial data. The main objective of this study is to improve the standard PNN by incorporating a proper multivariate distribution as the joint distribution of input variables and addressing the multi-class imbalanced problem persisting in the directional prediction of the stock market. This model building process is illustrated and tested with daily close prices of three stock market indices: AORD, GSPC and ASPI and related financial market indices. Results proved that scaled t distribution with location, scale and shape parameters can be used as more suitable distribution for financial return series. Global optimization methods are more appropriate to estimate better parameters of multivariate distributions. The global optimization technique used in this study is capable of estimating parameters with considerably high dimensional multivariate distributions. The proposed PNN model, which considers multivariate scaled t distribution as the joint distribution of input variables, exhibits better performance than the standard PNN model. The ensemble technique: multi-class undersampling based bagging (MCUB) was introduced to handle class imbalanced problem in PNNs is capable enough to resolve multi-class imbalanced problem persisting in both standard and proposed PNNs. Final model proposed in the study with proposed PNN and proposed MCUB technique is competent in forecasting the direction of a given stock market index with higher accuracy, which helps stakeholders of stock markets make accurate decisions.",10.3390/app9245334,probabilistic neural network (PNN); multi-class undersampling based bagging (MCUB); stock market indices; multivariate distribution; global optimization; directional prediction,WOS,Enhances the Probabilistic Neural Network by incorporating multivariate scaled t distributions and ensemble techniques to improve directional prediction accuracy of stock market indices.,✔️,Stock Market Index,✔️,✔️
WOS:000980522800001,An algorithmic trading system based on a stacked generalization model and hidden Markov model in the foreign exchange market,"The Forex market has been one of the most attractive markets to researchers, funds, and traders. Literature shows that a single model algorithm usually cannot perform satisfactorily on the foreign exchange (Forex) time series because of the market's complexity. This study develops an algorithm based on two stacked generalization models consisting of four machine-learning models. First, the optimal lags of features are found using the Fisher discriminant ratio and partial autocorrelation function. Second, one stacked model fits the bullish trends, and the other holds the bearish trends resulting from a hidden Markov model. We reinforce the predictive signals of these models by extracting relationships between currency pairs with correlation and mutual information. Lastly, the proposed algorithm constructs a portfolio based on the strength of signals dependent on correlation and mutual information. As a result, this paper compares the performance of the proposed approach with different states of the model and several established benchmarks regarding return and risk metrics. The outcomes show that the proposed model's added features-such as time series clustering, considering a range of inputs, and internal relationships among different assets-can increase its performance in the Forex market.",10.1016/j.gfj.2023.100825,Foreign exchange market; Stacked generalization model; Hidden Markov model; Time series forecasting; Time series clustering,WOS,"An algorithmic trading system utilizing stacked generalization models and hidden Markov models is developed for the foreign exchange market, showing enhanced performance in predicting Forex trends.",✔️,Foreign Exchange (Forex),✔️,❌
10.1016/j.rse.2023.113678,An approach to estimating forest biomass while quantifying estimate uncertainty and correcting bias in machine learning maps,"Providing forest biomass estimates with desired accuracy and precision for small areas is a key challenge to incorporating forest carbon offsets into commodity trading programs. Enrolled forest carbon projects and verification entities typically rely on probabilistically sampled field data and design-based (DB) estimators to estimate carbon storage and characterize uncertainty. However, this methodology requires a large amount of field data to achieve sufficient precision and collection of these data can be prohibitively expensive. This has spurred interest in developing regional-scale maps of forest biomass that incorporate remote sensing data as an alternative to collecting expensive plot data. These maps are often generated using machine learning (ML) algorithms that combine remote sensing products and field measurements. While these maps can produce estimates across large geographic regions at fine spatial resolutions, the estimates are prone to bias and do not have associated uncertainty estimates. Here, we assess one such map developed by the National Aeronautics and Space Administration's Carbon Monitoring System. We consider model-assisted (MA) and geostatistical model-based (GMB) estimators to address map bias and uncertainty quantification. The MA and GMB estimators use a sample of field observations as the response, and the ML-produced map as an auxiliary variable to achieve statistically defensible predictions. We compare MA and GMB estimator performance to DB and direct (DR) estimators. This assessment considers both counties and a small areal extent experimental forest, all within Oregon USA. Results suggest the MA and GMB estimators perform similar to the DB estimator at the state level and in counties containing many field plots. But in counties with moderate to small field sample sizes, the GMB and MA estimators are more precise than the DB estimator. As within-county sample sizes get smaller, the GMB estimator tends to outperform MA. Results also show the DR estimator's state-level estimates are substantially larger than the DB, MA and GMB estimates, indicating that that the DR estimator may be biased. When assessing the GMB estimator for the experimental forest, we find the GMB estimator has sufficient precision for stand-level carbon accounting even when no field observations are available within the stand. Plot-level GMB uncertainty interval coverage probabilities were estimated and showed adequate coverage. This suggests that the GMB estimator is producing statistically rigorous uncertainty estimates. © 2023 Elsevier Inc.",10.1016/j.rse.2023.113678,Bayesian hierarchical spatial modeling; Bias correction; Carbon monitoring; Design-based inference; Forest inventory; Machine learning; Model-based inference; Random forest; Remote sensing; Small area estimation,SCOPUS,"Combines model-assisted and geostatistical estimators with machine learning-generated biomass maps to accurately estimate forest biomass, addressing bias and uncertainty for improved carbon offset calculations.",❌,?,✔️,✔️
WOS:000642153700001,An efficient stock market prediction model using hybrid feature reduction method based on variational autoencoders and recursive feature elimination,"In this study, the hourly directions of eight banking stocks in Borsa Istanbul were predicted using linear-based, deep-learning (LSTM) and ensemble learning (LightGBM) models. These models were trained with four different feature sets and their performances were evaluated in terms of accuracy and F-measure metrics. While the first experiments directly used the own stock features as the model inputs, the second experiments utilized reduced stock features through Variational AutoEncoders (VAE). In the last experiments, in order to grasp the effects of the other banking stocks on individual stock performance, the features belonging to other stocks were also given as inputs to our models. While combining other stock features was done for both own (named as allstock_own) and VAE-reduced (named as allstock_VAE) stock features, the expanded dimensions of the feature sets were reduced by Recursive Feature Elimination. As the highest success rate increased up to 0.685 with allstock_own and LSTM with attention model, the combination of allstock_VAE and LSTM with the attention model obtained an accuracy rate of 0.675. Although the classification results achieved with both feature types was close, allstock_VAE achieved these results using nearly 16.67% less features compared to allstock_own. When all experimental results were examined, it was found out that the models trained with allstock_own and allstock_VAE achieved higher accuracy rates than those using individual stock features. It was also concluded that the results obtained with the VAE-reduced stock features were similar to those obtained by own stock features.",10.1186/s40854-021-00243-3,Stock market prediction; Variational autoencoder; Recursive feature elimination; Long-short term memory; Borsa Istanbul; LightGBM,WOS,"This study predicts the hourly directions of banking stocks using LSTM and LightGBM models with features reduced via Variational AutoEncoders and Recursive Feature Elimination, achieving high accuracy with fewer features.",✔️,Stock,✔️,❌
WOS:000901486600001,An image processing and machine learning solution to automate Egyptian cotton lint grading,"Egyptian cotton is one of the most important commodities for the Egyptian economy and is renowned globally for its quality, which is largely assessed and graded by manual inspection. This grading has several drawbacks, including significant labor requirements, low inspection efficiency, and influence from inspection conditions such as light and human subjectivity. This work proposes a low-cost solution to replace manual inspection with classification models to grade Egyptian cotton lint using images captured by a charge-coupled device camera. While this method has been evaluated for classifying US and Chinese upland cotton staples, it has not been tested on Egyptian cotton, which has unique characteristics and grading requirements. Furthermore, the methodology to develop these classification models has been expanded to include image processing techniques that remove the influence of trash on color measurements and extract features that capture the intra-sample variance of the cotton samples. Three different supervised machine learning algorithms were evaluated: artificial neural networks; random forest; and support vector machines. The highest accuracy models (82.13-90.21%) used a random forest algorithm. The models' accuracy was limited by the human error associated with labeling the cotton samples used to develop the classification models. Unsupervised machine learning methods, including k-means clustering, hierarchical clustering, and Gaussian mixture models, were used to indicate where labeling errors occurred.",10.1177/00405175221145571,Digital manufacturing; machine learning; Industry 4; 0; optical imaging; cotton lint; industrial crop,WOS,"An image processing and machine learning solution is developed to automate Egyptian cotton lint grading, achieving high accuracy with Random Forest algorithms and reducing human error in classification.",❌,,✔️,❌
10.1016/j.aej.2023.08.025,Analysis of bitcoin prices using a heavy-tailed version of Dagum distribution and machine learning methods,"Statistical modeling and forecasting are very important for decision-making in any field of life. This paper has two major objectives, namely, statistical modeling and forecasting of real phenomena. For covering the first aim (i.e., statistical modeling), we introduce a new probabilistic model. The new model is introduced by mixing the Dagum distribution with the weighted TX family approach. The proposed model is called the weighted TX Dagum distribution and possesses heavy-tailed characteristics. The new model is illustrated by analyzing real-life data related to Bitcoin prices. To cover the second aim (i.e., forecasting), we take into account six macroeconomic and financial indicators to investigate their impact on Bitcoin prices such as the Adaptive least absolute shrinkage and selection operator (Alasso), elastic net, and minimax concave penalty. After analyzing the data, it is found that Alasso and MCP have retained all the included predictors, except import, while Enet holds all the predictors. The root means square error and mean absolute error associated with MCP are lower than Alasso and Enet, which reveals that MCP fits the data very well as compared to rival methods. © 2023 The Author(s)",10.1016/j.aej.2023.08.025,Bitcoin prices; Dagum distribution; Heavy-tailed characteristics; Machine learning and robust regression methods; Macroeconomic variables,SCOPUS,"Presents a heavy-tailed probabilistic model for Bitcoin price analysis and employs machine learning techniques such as adaptive Lasso and elastic net for accurate forecasting, demonstrating MCP's superior performance.",✔️,Bitcoin,✔️,✔️
1947-5500,Analyzing Different Machine Learning Techniques for Stock Market Prediction,Stock market prediction is one of most challenging issue and attracted attention from many researches and stock market investors. With passing time these stock market prediction techniques are getting better with different machine learning algorithms and investors have started relying on these prediction model proposed by many researchers. Many machine learning techniques for stock market prediction are developed. There are no specifications available that which techniques are optimal or not. Also I will analyze and compare different techniques and will discuss their strength and weakness. I have analyzed how these technique works and compare these techniques with other stock market prediction techniques and explained how some techniques have advantage over others and perform better.,,,Proquest,"The article analyzes and compares various machine learning techniques for predicting stock market prices, discussing their strengths and weaknesses.",✔️,Stock,✔️,❌
10.1109/ACCESS.2023.3334260,Annotators' Selection Impact on the Creation of a Sentiment Corpus for the Cryptocurrency Financial Domain,"Well labeled natural language corpus data is essential for most natural language processing techniques, especially in specialized fields. However, cohort biases remain a significant challenge in machine learning. The narrow origin of data sampling or human annotators in cohorts is a prevalent issue for machine learning researchers due to its potential to induce bias in the final product. During the development of the CryptoLin corpus for another research project, the authors became concerned about the potential influence of cohort bias on the selection of annotators. Therefore, this paper addresses the question of whether cohort diversity improves the labeling result through the implementation of a repeated annotator process, involving two annotator cohorts and a statistically robust comparison methodology. The utilization of statistical tests, such as the Chi-Square Independence test for absolute frequency tables, and the construction of confidence intervals for Kappa point estimates, facilitates a rigorous analysis of the differences between Kappa estimates. Furthermore, the application of a two-proportion z-test to compare the accuracy scores of UTAD and IE annotators for various pre-trained models, including Vader Sentiment Analysis, TextBlob Sentiment Analysis, Flair NLP library, and FinBERT Financial Sentiment Analysis with BERT, contributes to the advancement of knowledge in this field. The paper utilizes Cryptocurrency Linguo (CryptoLin), a corpus containing 2683 cryptocurrency-related news articles spanning more than three years, and compares two different selection criteria for the annotators. CryptoLin was annotated twice with discrete values representing negative, neutral, and positive news respectively. The first annotation was done by twenty-seven annotators from the same cohort. Each news title was randomly assigned and blindly annotated by three human annotators. The second annotation was carried out by eighty-three annotators from three cohorts. Each news title was randomly assigned and blindly annotated by three human annotators, one in each different cohort. In both annotations, a consensus mechanism using simple voting was applied. The first annotation used the same cohort with students from the same nationality and background. The second used three cohorts with students from a very diverse set of nationalities and educational backgrounds. The results demonstrate that manual labeling done by both groups was acceptable according to inter-rater reliability coefficients Fleiss's Kappa, Krippendorff's Alpha, and Gwet's AC1. Preliminary analysis utilizing Vader, Textblob, Flair, and FinBERT confirmed the utility of the data set labeling for further refinement of sentiment analysis algorithms. Our results also highlight that the more diverse annotator pool performed better in all measured aspects. © 2013 IEEE.",10.1109/access.2023.3334260,Annotation; annotator selection criteria; cryptocurrency; labeled data set; news event; news sentiment corpus; NLP,SCOPUS,"Investigates how annotator diversity affects the creation of a sentiment corpus in the cryptocurrency financial domain, utilizing Bayesian methods and sentiment analysis models.",✔️,Cryptocurrency,✔️,✔️
WOS:001062957900001,Application of machine learning in algorithmic investment strategies on global stock markets,"The research undertakes the subject of machine learning based algorithmic investment strategies. Several technical analysis indicators were employed as inputs to machine learning models such as Neural Networks, K Nearest Neighbor, Regression Trees, Random Forests, Naive Bayes classifiers, Bayesian Generalized Linear Models, and Support Vector Machines. Models were used to generate trading signals on WIG20, DAX, S & P500, and selected CEE indices in the period between 200201-01 and 2023-03-31. Strategies were compared with each other and with the benchmark buyand-hold strategy in terms of achieved levels of risk and return. Sensitivity analysis was used to assess the quality of the estimation on independent subsets. The findings of the study showed that algorithmic strategies outperformed passive strategies in terms of risk-adjusted returns and that for the analyzed indices, Linear Support Vector Machine and Bayesian Generalized Linear Model were the best-performing models. The Linear Support Vector Machine was chosen as the model that, on average, produced the best results using a more thorough rank approach based on the outcomes for all examined models and indices.",10.1016/j.ribaf.2023.102052,Algorithmic investment strategies; Machine learning; Neural networks; Regression trees; Random forests; Support vector machine; Technical analysis; Equity stock indices; Developed and emerging markets; Information ratio,WOS,"Develops machine learning-based algorithmic trading strategies using various technical indicators, comparing models like Neural Networks, SVMs, Bayesian GLMs on global indices, finding Linear SVM and Bayesian GLMs as best performers.",✔️,Global Stock Indices,✔️,❌
WOS:000522489000109,Artificial Learning Dispatch Planning with Probabilistic Forecasts: Using Uncertainties as an Asset,"Weather forecast uncertainty is a key element for energy market volatility. By intelligently considering uncertainties on the schedule development, renewable energy systems with storage could improve dispatching accuracy, and therefore, effectively participate in electricity wholesale markets. Deterministic forecasts have been traditionally used to support dispatch planning, representing reduced or no uncertainty information about the future weather. Aiming at better representing the uncertainties involved, probabilistic forecasts have been developed to increase forecasting accuracy. For the dispatch planning, this can highly influence the development of a more precise schedule. This work extends a dispatch planning method to the use of probabilistic weather forecasts. The underlying method used a schedule optimizer coupled to a post-processing machine learning algorithm. This machine learning algorithm was adapted to include probabilistic forecasts, considering their additional information on uncertainties. This post-processing applied a calibration of the planned schedule considering the knowledge about uncertainties obtained from similar past situations. Simulations performed with a concentrated solar power plant model following the proposed strategy demonstrated promising financial improvement and relevant potential in dealing with uncertainties. Results especially show that information included in probabilistic forecasts can increase financial revenues up to 15% (in comparison to a persistence solar driven approach) if processed in a suitable way.",10.3390/en13030616,renewable systems; storage; dispatch; optimization; machine learning; probabilistic forecasts,WOS,"The paper extends dispatch planning methods by integrating probabilistic weather forecasts through machine learning calibration, enabling renewable energy systems to better manage uncertainties and increase financial revenues.",❌,?,✔️,✔️
WOS:000572871900002,Assess deep learning models for Egyptian exchange prediction using nonlinear artificial neural networks,"Financial analysis of the stock market using the historical data is the exigent demand in business and academia. This work explores the efficiency of three deep learning (Dl) techniques, namely Bayesian regularization (BE), Levenberg-Marquardt (lM), and scaled conjugate gradient (SCG), for training nonlinear autoregressive artificial neural networks (NARX) for predicting specifically the closing price of the Egyptian Stock Exchange indices (EGX-30, EGX-30-Capped, EGX-50-EWI, EGX-70, EGX-100, and NIlE). An empirical comparison is established among the experimented prediction models considering all techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. For performance evaluation, statistical measures such as mean squared error (MSE) and correlationRare used. From the simulation result, it can be clearly suggested that BR outperforms other models for short-term prediction especially for 3 days ahead. On the other hand, lM generates better prediction accuracy than BR- and SCG-based models for long-term prediction, especially for 7-day prediction.",10.1007/s00521-020-05374-9,Artificial neural networks; Autoregressive; Bayesian regularization; Deep learning; Egyptian stock market; Levenberg-Marquardt; Stock price prediction,WOS,"Evaluates the performance of various deep learning models, including Bayesian regularization and others, in predicting Egyptian Stock Exchange indices over different time horizons.",✔️,Egyptian Stock Exchange Indices,✔️,❌
18419836,Asymptotically Unbiased Estimation of A Nonsymmetric Dependence Measure Applied to Sensor Data Analytics and Financial Time Series,"A fundamental concept frequently applied to statistical machine learning is the detection of dependencies between unknown random variables found from data samples. In previous work, we have introduced a nonparametric unilateral dependence measure based on Onicescu’s information energy and a kNN method for estimating this measure from an available sample set of discrete or continuous variables. This paper provides the formal proofs which show that the estimator is asymptotically unbiased and has asymptotic zero variance when the sample size increases. It implies that the estimator has good statistical qualities. We investigate the performance of the estimator for data analysis applications in sensor data analysis and financial time series.",,,Proquest,The paper introduces an asymptotically unbiased estimator for a nonsymmetric dependence measure and applies it to sensor data analytics and financial time series.,❌,?,❌,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762322,Attention-Based Neural Bag-of-Features Learning for Sequence Data,"In this paper, we propose 2D-Attention (2DA), a generic attention formulation for sequence data, which acts as a complementary computation block that can detect and focus on relevant sources of information for the given learning objective. The proposed attention module is incorporated into the recently proposed Neural Bag of Feature (NBoF) model to enhance its learning capacity. Since 2DA acts as a plug-in layer, injecting it into different computation stages of the NBoF model results in different 2DA-NBoF architectures, each of which possesses a unique interpretation. We conducted extensive experiments in financial forecasting, audio analysis as well as medical diagnosis problems to benchmark the proposed formulations in comparison with existing methods, including the widely used Gated Recurrent Units. Our empirical analysis shows that the proposed attention formulations can not only improve performances of NBoF models but also make them resilient to noisy data.",10.1109/access.2022.3169776,Data models;Quantization (signal);Neural networks;Feature extraction;Histograms;Hidden Markov models;Visualization;Attention mechanism;neural bag-of-features;time-series analysis,IEEE,"Stock movement prediction using sentiment and financial signals is enhanced with Normalizing Flows, achieving state-of-the-art performance by learning flexible posterior distributions for Tweets and price signals.",✔️,Stock,✔️,✔️
WOS:000461762700005,BAYESIAN ESTIMATION OF STUDENT-T GARCH MODEL USING LINDLEY'S APPROXIMATION,"The dependency of conditional second moments of financial time series is modelled by Generalized Autoregressive conditionally heteroscedastic (GARCH) processes. The maximum likelihood estimation (MLE) procedure is most commonly used for estimating the unknown parameters of a GARCH model. In this study, the parameters of the GARCH models with student-t innovations are discussed for estimations using the Bayesian approach. It is assumed that the parameters of the GARCH model are random variables having known prior probability density functions. Lindley's approximation will be used to estimate the Bayesian estimators since they are not in a closed form. The Bayesian estimators are derived under squared error loss function. Finally, a simulation study is performed in order to compare the ML estimates to the Bayesian ones and in addition to simulations an example is given in order to illustrate the findings. MLE's and Bayesian estimates are compared according to the expected risks in the simulation study which shows that as the sample size increases the expected risks decrease and also it is observed that Bayesian estimates have performed better than MLE 's.",10.24818/18423264/53.1.19.05,GARCH; MLE; Lindley's Approximation; Bayesian Methods; Squared Error,WOS,"This paper presents a Bayesian estimation approach for Student-T GARCH models using Lindley's approximation, demonstrating improved performance over maximum likelihood estimates for financial time series data.",✔️,Various financial time series,❌,❌
WOS:000390831000014,BAYESIAN ESTIMATION OF THE PARAMETERS OF THE ARCH MODEL WITH NORMAL INNOVATIONS USING LINDLEY'S APPROXIMATION,"Autoregressive conditionally heteroscedastic (ARCH) models are used to analyze empirical financial data and capture various stylized facts in financial econometrics. The procedure that is most commonly used for estimating the unknown parameters of an ARCH model is the maximum likelihood estimation (MLE). In this study, it is assumed that the parameters of the ARCH model are random variables having known prior probability density functions, and therefore they will be estimated using Bayesian methods. The Bayesian estimators are not in a closed form, and thus Lindley's approximation will be used to estimate them. The Bayesian estimators are derived under squared error loss (SEL) and linear exponential (LINEX) loss functions. An example is given in order to illustrate the findings and furthermore, Monte Carlo simulations are performed in order to compare the ML estimates to the Bayesian ones. Finally, conclusions. on the findings are given.",,ARCH; QML method; Lindley's Approximation; Bayesian Methods; SEL; LINEX,WOS,"The study employs Bayesian methods, specifically Lindley's approximation, to estimate parameters of ARCH models for financial econometric analysis.",✔️,"Volatility (e.g., Stocks)",❌,✔️
WOS:000887773900001,Bayesian Aggregation Improves Traditional Single-Image Crop Classification Approaches,"Accurate information about growing crops allows for regulating the internal stocks of agricultural products and drawing strategies for negotiating agricultural commodities on financial markets. Machine learning methods are widely implemented for crop type recognition and classification based on satellite images. However, field classification is complicated by class imbalance and aggregation of pixel-wise into field-wise forecasting. We propose here a Bayesian methodology for the aggregation of classification results. We report the comparison of class balancing techniques. We also report the comparison of classical machine learning methods and the U-Net convolutional neural network for classifying crops using a single satellite image. The best result for single-satellite-image crop classification was achieved with an overall accuracy of 77.4% and a Macro F1-score of 0.66. Bayesian aggregation for field-wise classification improved the result obtained using majority voting aggregation by 1.5%. We demonstrate here that the Bayesian aggregation approach outperforms the majority voting and averaging strategy in overall accuracy for the single-image crop classification task.",10.3390/s22228600,crop classification; unbalanced classes problem; pixel-wise aggregation,WOS,"Proposes a Bayesian aggregation method to improve single-image crop classification, enhancing overall accuracy for agricultural forecasting.",❌,?,✔️,❌
10835547,Bayesian REIT Volatility Estimation and Institutional Portfolio Allocation,"Volatility estimation is an integral part of institutional finance with applications in risk management and portfolio allocation. Real estate investment trust volatility is examined using a Bayesian asymmetric GARCH model and is found to better estimate the true volatility series than does the traditional maximum likelihood approach. This paper discusses the shortfalls of maximum likelihood (ML) estimation and the advantages of the Bayesian estimation, particularly to real estate. Conditional variance estimation uncertainty is found to increase with volatility. A portfolio allocation problem highlights that the Bayesian approach performed better than the ML method in preserving capital. [PUBLICATION ABSTRACT]",,,Proquest,The paper utilizes a Bayesian asymmetric GARCH model to estimate real estate investment trust (REIT) volatility and demonstrates its superiority over traditional maximum likelihood methods for portfolio allocation.,✔️,REIT,❌,✔️
2-s2.0-58049216446,Bayesian REIT volatility estimation and institutional portfolio allocation,"Volatility estimation is an integral part of institutional finance with applications in risk management and portfolio allocation. Real estate investment trust volatility is examined using a Bayesian asymmetric GARCH model and is found to better estimate the true volatility series than does the traditional maximum likelihood approach. This paper discusses the shortfalls of maximum likelihood (ML) estimation and the advantages of the Bayesian estimation, particularly to real estate. Conditional variance estimation uncertainty is found to increase with volatility. A portfolio allocation problem highlights that the Bayesian approach performed better than the ML method in preserving capital.",,,SCOPUS,The paper utilizes a Bayesian asymmetric GARCH model to estimate real estate investment trust (REIT) volatility and demonstrates its superiority over traditional maximum likelihood methods for portfolio allocation.,✔️,REIT,❌,✔️
WOS:000073291400005,Bayesian analysis of a change-point in exponential families with applications,"A Bayesian analysis is used to detect a change-point in a sequence of independent random variables from exponential family distributions. The conjugate priors for the exponential families are considered in the analysis. The marginal posterior distribution of the change-point j is derived. Since some hyper-parameters are involved in the conjugate priors, the Type II maximum likelihood (ML-II) approach (cf. Berger, 1995) will be used to estimate these hyperparameters in applications. The method is simple and is easily applied to the Nile problem, Illinois traffic data, British coal-mining disasters, accident data and stock-market prices. (C) 1998 Elsevier Science B.V. All rights reserved.",10.1016/s0167-9473(98)00009-7,change-point; conjugate prior; ML-II approach; posterior distribution,WOS,"Introduces a Bayesian method to detect change-points in sequences from exponential family distributions, applied to stock-market prices among other datasets.",✔️,Stock Market Prices,❌,✔️
WOS:000937700000001,Bayesian bilinear neural network for predicting the mid-price dynamics in limit-order book markets,"The prediction of financial markets is a challenging yet important task. In modern electronically driven markets, traditional time-series econometric methods often appear incapable of capturing the true complexity of the multilevel interactions driving the price dynamics. While recent research has established the effectiveness of traditional machine learning (ML) models in financial applications, their intrinsic inability to deal with uncertainties, which is a great concern in econometrics research and real business applications, constitutes a major drawback. Bayesian methods naturally appear as a suitable remedy conveying the predictive ability of ML methods with the probabilistically oriented practice of econometric research. By adopting a state-of-the-art second-order optimization algorithm, we train a Bayesian bilinear neural network with temporal attention, suitable for the challenging time-series task of predicting mid-price movements in ultra-high-frequency limit-order book markets. We thoroughly compare our Bayesian model with traditional ML alternatives by addressing the use of predictive distributions to analyze errors and uncertainties associated with the estimated parameters and model forecasts. Our results underline the feasibility of the Bayesian deep-learning approach and its predictive and decisional advantages in complex econometric tasks, prompting future research in this direction.",10.1002/for.2955,Bayesian neural networks; bilinear neural network; financial time-series classification; limit-order book,WOS,"The study introduces a Bayesian bilinear neural network with temporal attention for predicting mid-price dynamics in limit-order book markets, providing uncertainty estimates alongside predictions.",✔️,Mid-price in limit-order book markets,✔️,✔️
WOS:000247439500009,Bayesian inference for the mixed conditional heteroskedasticity model,"We estimate by Bayesian inference the mixed conditional heteroskedasticity model of Haas et al. (2004a Journal of Financial Econometrics 2, 211-50). We construct a Gibbs sampler algorithm to compute posterior and predictive densities. The number of mixture components is selected by the marginal likelihood criterion. We apply the model to the SP500 daily returns.",10.1111/j.1368-423x.2007.00213.x,Bayesian inference; finite mixture; ML estimation; value at risk,WOS,The article estimates a mixed conditional heteroskedasticity model using Bayesian inference applied to SP500 daily returns.,✔️,S&P 500 Index,✔️,✔️
WOS:000668791400038,Bayesian neural networks for stock price forecasting before and during COVID-19 pandemic,"Recently, there has been much attention in the use of machine learning methods, particularly deep learning for stock price prediction. A major limitation of conventional deep learning is uncertainty quantification in predictions which affect investor confidence. Bayesian neural networks feature Bayesian inference for providing inference (training) of model parameters that provides a rigorous methodology for uncertainty quantification in predictions. Markov Chain Monte Carlo (MCMC) sampling methods have been prominent in implementing inference of Bayesian neural networks; however certain limitations existed due to a large number of parameters and the need for better computational resources. Recently, there has been much progress in the area of Bayesian neural networks given the use of Langevin gradients with parallel tempering MCMC that can be implemented in a parallel computing environment. The COVID-19 pandemic had a drastic impact in the world economy and stock markets given different levels of lockdowns due to rise and fall of daily infections. It is important to investigate the performance of related forecasting models during the COVID-19 pandemic given the volatility in stock markets. In this paper, we use novel Bayesian neural networks for multi-step-ahead stock price forecasting before and during COVID-19. We also investigate if the pre-COVID-19 datasets are useful of modelling stock price forecasting during COVID-19. Our results indicate due to high volatility in the stock-price during COVID-19, it is more challenging to provide forecasting. However, we found that Bayesian neural networks could provide reasonable predictions with uncertainty quantification despite high market volatility during the first peak of the COVID-19 pandemic.",10.1371/journal.pone.0253217,,WOS,"Utilizes Bayesian neural networks for multi-step-ahead stock price forecasting before and during the COVID-19 pandemic, emphasizing uncertainty quantification.",✔️,Stock,✔️,✔️
WOS:000502225300001,Bayesian predictive analysis for Weibull-Pareto composite model with an application to insurance data,"Aminzadeh and Deng, respectively provide Bayesian predictive models for Exponential-Pareto and Inverse Gamma-Pareto composite distributions which are one-parameter models. The purpose of this article is to develop an alternative Bayesian predictive model (two-parameter) which can be used to compute important risk measures that are not defined via the above predictive models. Bayesian predictive density for the Weibull-Pareto composite distribution is developed and is used to compute risk measures such as Value at Risk (VaR), Conditional Tail Expectation (CTE), Predictive Expectation (PE), Limited Predictive Expected value (LPE), Limited Predictive Variance (LPV), and Limited Predictive Tail-VaR (LPCTE). Accuracy of parameter estimates as well as the risk measures are assessed via simulation studies. It is shown that the informative Bayes estimates are consistently more accurate than ML and the non-informative Bayes estimates. Backtesting for the risk measures is performed and goodness-of-fit of Weibull-Pareto among other composite models to the Danish fire data is assessed.",10.1080/03610918.2019.1699572,Conditional tail expectation; Gamma and inverse-gamma priors; Predictive density; Value at risk; Weibull-Pareto composite model,WOS,"A Bayesian predictive analysis for Weibull-Pareto composite models is developed for insurance data, enabling the calculation of risk measures like VaR and CTE.",❌,Insurance Data,✔️,✔️
WOS:000398964300009,Bayesian regularisation neural network based on artificial intelligence optimisation,"Stock prediction is generally considered to be challenging and known for its high noise and strong nonlinearities in financial time series analysis. However, current forecasting models ignore the importance of model parameter optimisation and the use of recent data. In this article, a novel forecasting approach with a Bayesian-regularised artificial neural networks (BR-ANN) was proposed. The weight of the proposed model (BR-ANN) is determined by the particle swarm optimisation (PSO) algorithm. Daily market prices and financial technical indicators are utilised as inputs to predict the one day future closing price of the Shanghai (in China) composite index. The Bayesian-regularised network uses a probabilistic nature for the network weights and can reduce the potential for over-fitting and over-training. Our empirical study and the results of our K-line theory analysis indicate that PSO is determined to be an effective algorithm to optimise the parameters of the Bayesian neural network compared with other well-known prediction algorithms. In particular, the PSO model is more reliable than the simple Bayesian regularisation neural network near the local maximum value.",10.1080/00207543.2016.1237785,neural networks; Bayesian methods; PSO; over-fitting; local weights; K-line,WOS,"The article proposes a Bayesian-regularized neural network optimized via particle swarm optimization for forecasting the Shanghai Composite Index, demonstrating improved reliability over traditional methods.",✔️,Shanghai Composite Index,✔️,❌
WOS:000381841900007,Binomial Markov-Switching Multifractal model with Skewed t innovations and applications to Chinese SSEC Index,"This paper presents the Binomial Markov-switching Multifractal (BMSM) model of asset returns with Skewed t innovations (BMSM-Skewed t for short), which considers the fat tails, skewness and multifractality in asset returns simultaneously. The parameters of BMSM-Skewed t model can be estimated by Maximum Likelihood (ML) methods, and volatility forecasting can be accomplished via Bayesian updating. In order to evaluate the performance of BMSM-Skewed t model, BMSM model with Normal innovations (BMSM-N), BMSM model with Student-t innovations (BMSM-t) and GARCH(1,1) models (GARCH-N, GARCH-t and GARCH-Skewed t) are chosen for comparison. Through empirical studies on Shanghai Stock Exchange Composite Index (SSEC), we find that for sample estimation, BMSM models outperform the GARCH(1,1) models through BIC and AIC rules, and BMSM-Skewed t performs the best among all the models due to its fat tails, skewness and multifractality. In addition, BMSM-Skewed t model dominates other models at most forecasting horizons for out-of-sample volatility forecasts in terms of MSE, MAE and SPA test. (C) 2016 Elsevier B.V. All rights reserved.",10.1016/j.physa.2016.06.014,BMSM models; Volatility forecasting; Skewed t innovations,WOS,"This paper introduces a Binomial Markov-Switching Multifractal model with skewed t innovations for the Chinese SSEC Index, demonstrating superior in-sample and out-of-sample forecasting performance compared to traditional GARCH models through empirical analysis.",✔️,Chinese SSEC Index,❌,✔️
10.1002/sta4.70001,Bitcoin Price Prediction Using Deep Bayesian LSTM With Uncertainty Quantification: A Monte Carlo Dropout–Based Approach,"Bitcoin, being one of the most triumphant cryptocurrencies, is gaining increasing popularity online and is being used in a variety of transactions. Recently, research on Bitcoin price predictions is receiving more attention, and researchers have investigated the various state-of-the-art machine learning (ML) and deep learning (DL) models to predict Bitcoin price. However, despite these models providing promising predictions, they consistently exhibit uncertainty, which cannot be adequately quantified by classical ML models alone. Motivated by the enormous success of applying Bayesian approaches in several disciplines of ML and DL, this study aims to use Bayesian methods alongside Long Short-Term Memory (LSTM) to predict the closing Bitcoin price and consequently measure the uncertainty of the prediction model. Specifically, we adopted the Monte Carlo dropout (MC-Dropout) method with the Bayesian LSTM model to quantify the epistemic uncertainty of the model's predictions and provided confidence intervals for the predicted outputs. Experimental results showed that the proposed model is efficient and outperforms other state-of-the-art models in terms of root mean square error (RMSE), mean absolute error (MAE) and R2. Thus, we believe that these models may assist the investors and traders in making critical decisions based on short-term predictions of Bitcoin price. This study illustrates the potential benefits of utilizing Bayesian DL approaches in time series analysis to improve data prediction accuracy and reliability. © 2024 John Wiley & Sons Ltd.",10.1002/sta4.70001,Bayesian inference; Bitcoin; deep learning; LSTM; MC-Dropout,SCOPUS,"Develops a Deep Bayesian LSTM model with Monte Carlo dropout to predict Bitcoin prices, effectively quantifying uncertainty and surpassing state-of-the-art models in prediction accuracy and reliability.",✔️,Bitcoin price,✔️,✔️
10.1504/IJITST.2020.108130,Bitcoin price prediction using ARIMA model,"Bitcoin is a highly volatile cryptocurrency with rising popularity. It is a turning point in the way currency is seen. Now the currency, rather than being physical is becoming more and more digital. Due to high variance of solo mining, the number of users joining top most famous bitcoin mining pools is increasing due to the fact that users together under a bitcoin pool will have a higher chance of generating next block in the bitcoins blockchain by reducing the variance and earning the mining reward. In this research paper we are doing a survey on the technology lying underneath bitcoin's network and the various machine learning predictive algorithms. We collected the dataset on bitcoin blockchain from 28 April 2013 to 31 July 2017 which is publicly available on https://coinmarketcap.com and applied the ARIMA model for price prediction of bitcoin. Copyright © 2020 Inderscience Enterprises Ltd.",10.1504/ijitst.2020.108130,ARIMA model; Bayesian model; Bitcoin; Blockchain; Cryptocurrency; Mining; Neural network; Predictive analysis; Regression model; Support vector machine; SVM,SCOPUS,"Uses ARIMA model to predict Bitcoin prices, addressing volatility and comparing with machine learning methods.",✔️,Bitcoin,❌,✔️
2-s2.0-85177977642,Black-Litterman Portfolio Optimization Using Gaussian Process Regression,"The Black-Litterman portfolios based on the predictions provided by Gaussian Process are constructed in this study. Besides the expert views generated by the Gaussian Process, an customized algorithm quantifying the confidence level of the given investor opinions is also designed, which can be inputted into the Black-Litterman framework to revise the posterior parameters estimations. Low-risk anomaly is observed from the numerical experiments through the grouping method base on stock β, demonstrating the potential irrationality for even giant companies and brands on the advanced market. Empirical analysis shows that Gaussian Process is able to model the low β stock effectively, while not feasible for stocks with high volatility. Thus, the proposed BLGPlo portfolio outperform the benchmarks in terms of cumulative excess return and Sharpe ratio. Moreover, the BLGPlo performance can be further improved by allocating higher confidence level for the Gaussian Process-derived investor opinions. © (2023), (International Association of Engineers). All Rights Reserved.",,Black-Litterman; Gaussian Process; Machine learning; Portfolio selection,SCOPUS,"The study integrates Gaussian Process regression into the Black-Litterman portfolio optimization framework, enhancing portfolio performance in terms of cumulative excess return and Sharpe ratio.",✔️,Stocks,✔️,✔️
WOS:001247401200001,CAGTRADE: Predicting Stock Market Price Movement with a CNN-Attention-GRU Model,"Accurately predicting market direction is crucial for informed trading decisions to buy or sell stocks. This study proposes a deep learning based hybrid approach combining convolutional neural network (CNN), attention mechanism (AM), and gated recurrent unit (GRU) to predict short-term market trends (1 day, 3 days, 7 days, 10 days) across different stock indices (BSE, HSI, IXIC, NIFTY, N225, SSE). The architecture dynamically weights the input sequence with the AM model, captures local patterns through CNN and effectively models long-term dependencies with GRU thus aiming to accurately classify either ""buy"" or ""sell"" positions of stocks. The model is assessed using classification and financial evaluation metrics involving accuracy, precision, recall, f1-score, annualized returns, maximum drawdown, and return on investment. It outperforms benchmark models, and different technical indicators including average directional index, rate of change, moving average convergence divergence, and the buy-and-hold strategy, demonstrating its effectiveness in various market conditions. The proposed model achieves an average accuracy of 98% in predicting the 1 day-ahead direction, and an average accuracy of 88.53% across all prediction intervals. The model was also validated using the wilcoxon signed rank test that further supported its significance over the benchmark models. The CAG model presents a comprehensive and intuitive approach to stock market trend prediction, with potential applications in real-world asset decision-making.",10.1007/s10690-024-09463-w,Convolutional neural network (CNN); Deep learning (DL); Gated recurrent unit (GRU); Imbalanced dataset; Attention mechanism (AM); Stock market trend prediction,WOS,"Proposes a CNN-Attention-GRU hybrid deep learning model to accurately predict short-term stock market trend movements across various stock indices, outperforming benchmark models.",✔️,Stock Indices,✔️,❌
WOS:001061639000001,COVID-19 and commodity effects monitoring using financial & machine learning models,"This article focuses on examining the effects of the COVID-19 pandemic and gold prices on the stock market. It primarily analyzes the relationship between COVID-19 cases and stock market prices, along with the impact on various commodity elements such as gold, oil, Chinese RMB, and US Dollar prices. These commodity elements are considered essential indicators of a country's financial health, and the study investigates how the increase in COVID-19 cases affects these financial elements. The research incorporates financial models, machine learning algorithms, and a financial Gaussian mixture model for data analysis and comparison. The findings shed light on the correlation between the virus, trading outcomes, and the importance of Karachi Stock Exchange-100 index data in preventing market crashes. The study also explores the implications of emergencies on the finance sector and provides insights for future financial predictions and the impact of social disasters on the economy.",10.1016/j.sciaf.2023.e01856,VAR model; Machine learning; Commodity effect; Global financial analysis; COVID-19,WOS,"The study examines the impact of COVID-19 and commodity prices, such as gold and oil, on the stock market using financial models and machine learning algorithms, including a Gaussian mixture model.",✔️,"Stock market indices, Commodities (Gold, Oil), Currencies",✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612217,Can Deep Learning Improve Technical Analysis of Forex Data to Predict Future Price Movements?,"The foreign exchange market (Forex) is the world’s largest market for trading foreign money, with a trading volume of over 5.1 trillion dollars per day. It is known to be very complicated and volatile. Technical analysis is the observation of past market movements with the aim of predicting future prices and dealing with the effects of market movements. A trading system is based on technical indicators derived from technical analysis. In our work, a complete trading system with a combination of trading rules on Forex time series data is developed and made available to the scientific community. The system is implemented in two phases: In the first phase, each trading rule, both the AI-based rule and the trading rules from the technical indicators, is tested for selection; in the second phase, profitable rules are selected among the qualified rules and combined. Training data is used in the training phase of the trading system. The proposed trading system was extensively trained and tested on historical data from 2010 to 2021. To determine the effectiveness of the proposed method, we also conducted experiments with datasets and methodologies used in recent work by Hernandez-Aguila et al., 2021 and by Munkhdalai et al., 2019. Our method outperforms all other methodologies for almost all Forex markets, with an average percentage gain of 20.2%. A particular focus was on training our AI-based rule with two different architectures: the first is a widely used convolutional network for image classification, i.e. ResNet50; the second is an attention-based network Vision Transformer (ViT). The results provide a clear answer to the main question that guided our research and which is the title of this paper.",10.1109/access.2021.3127570,Currencies;Neural networks;Support vector machines;Predictive models;Optimization;Training;Genetic algorithms;Forex;expert advisor;genetic algorithm;metatrader;technical analysis;technical indicators;trading rules;trading system,IEEE,"Combines Bayesian approaches with LSTM deep learning models, using Monte Carlo dropout to predict Bitcoin closing prices and quantify prediction uncertainties, enhancing forecasting accuracy for investors.",✔️,Cryptocurrency (Bitcoin),✔️,✔️
WOS:001174986500001,China's inflation forecasting in a data-rich environment: based on machine learning algorithms,"Inflation forecasting stands as a central concern in macroeconomics. This paper focuses on predicting China's inflation within a data-rich environment. Specifically, we compile a large panel of China's monthly macroeconomic and financial variables, employing various machine learning models on this predictor panel to forecast China's inflation, encompassing both CPI and PPI, across various forecasting horizons extending up to 24 months. Our findings indicate the following: First, the machine learning models, when coupled with a large dataset of macroeconomic and financial predictors, demonstrate a superior ability to forecast China's inflation compared to benchmark time series models and principal component regression models. These advantages become even more notable at medium-to-long horizons and during periods of high inflation volatility, as well as CPI/PPI divergence periods. Second, our experiments reveal that penalized linear regression models, such as ridge and elastic net, consistently outperform the benchmarks and nonlinear machine learning methods in most cases. Lastly, variables related to price, stock, and money & credit are identified as the most crucial factors for forecasting inflation in China.",10.1080/00036846.2024.2322572,China's inflation; forecasting; machine learning; data-rich environment; C22; C53; E37,WOS,"This study employs machine learning algorithms on a comprehensive dataset of China's macroeconomic and financial variables to forecast inflation rates, outperforming traditional time series models and identifying key predictive factors.",✔️,"Inflation indices (CPI, PPI)",✔️,❌
07474938,Classical and Bayesian Analysis of Univariate and Multivariate Stochastic Volatility Models,"In this paper, efficient importance sampling (EIS) is used to perform a classical and Bayesian analysis of univariate and multivariate stochastic volatility (SV) models for financial return series. EIS provides a highly generic and very accurate procedure for the Monte Carlo (MC) evaluation of high-dimensional interdependent integrals. It can be used to carry out ML-estimation of SV models as well as simulation smoothing where the latent volatilities are sampled at once. Based on this EIS simulation smoother, a Bayesian Markov chain Monte Carlo (MCMC) posterior analysis of the parameters of SV models can be performed. [PUBLICATION ABSTRACT]",,,Proquest,The paper conducts classical and Bayesian analyses of univariate and multivariate stochastic volatility models for financial return series using efficient importance sampling and MCMC methods.,✔️,"Volatility (e.g., Stocks)",❌,✔️
WOS:000239059300008,Classical and Bayesian analysis of univariate and multivariate stochastic volatility models,"In this paper, efficient importance sampling (EIS) is used to perform a classical and Bayesian analysis of univariate and multivariate stochastic volatility (SV) models for financial return series. EIS provides a highly generic and very accurate procedure for the Monte Carlo (MC) evaluation of high-dimensional interdependent integrals. It can be used to carry out ML-estimation of SV models as well as simulation smoothing where the latent volatilities are sampled at once. Based on this EIS simulation smoother, a Bayesian Markov chain Monte Carlo (MCMC) posterior analysis of the parameters of SV models can be performed.",10.1080/07474930600713424,dynamic latent variables; Markov chain Monte Carlo; maximum likelihood; simulation smoother,WOS,"The article conducts classical and Bayesian analyses of univariate and multivariate stochastic volatility models using efficient importance sampling techniques, facilitating maximum likelihood estimation and posterior analysis for improved volatility forecasting.",✔️,Financial returns volatility,❌,✔️
https://doi.org/10.5120/ijca2015905413,Cloud based Financial Market Prediction through Genetic Algorithms: A Review,"This paper surveys recent literature in the area of stock market forecasting using advanced engineering based methods like Neural Network, fractal theory, Data Mining, Hidden Markov Model and Neuro-Fuzzy system. Neural Networks and Neuro-Fuzzy systems are emerging as an effective tool to be used in the forecasting of stock market especially in machine learning techniques. Due to chaotic behavior of the market, traditional techniques are insufficient to cover all the possible relation of the stock price fluctuations. Neural Network and Markov Model is being used exclusively in the forecasting of finance markets but in third world countries. In this paper, we will discuss the relevance of existing methods based on neural network and discussed gaps between these methods. We also propose a forecasting method to provide better an accuracy rather traditional method.",10.5120/ijca2015905413,,Proquest,"A review of genetic algorithms and cloud-based methods for financial market prediction is conducted, highlighting machine learning techniques for improved forecasting accuracy.",✔️,Financial Markets,✔️,❌
WOS:000612063900001,Combining Deep Learning and Multiresolution Analysis for Stock Market Forecasting,"Due to its complexity, financial time-series forecasting is regarded as one of the most challenging problems. During the past two decades, nonlinear modeling techniques, such as artificial neural networks, were commonly employed to solve a variety of time-series problems. Recently, however, deep neural network has been found to be more efficient than those in many application domains. In this article, we propose a model based on deep neural networks that improves the forecasting of stock prices. We investigate the impact of combining deep learning techniques with multiresolution analysis to improve the forecasting accuracy. Our proposed model is based on an empirical wavelet transform which is shown to outperform traditional stationary wavelet transform in capturing price fluctuations at different time scales. The proposed model is demonstrated to be substantially more effective than other models when evaluated on the S&P500 stock index and Mackey-Glass time series.",10.1109/access.2021.3051872,Predictive models; Forecasting; Multiresolution analysis; Hidden Markov models; Wavelet transforms; Data models; Transforms; Deep learning; multiresolution analysis; long-short term memory; financial time series; forecasting,WOS,"A deep neural network model combined with empirical wavelet transform is proposed for stock price forecasting, demonstrating superior performance on the S&P500 index and Mackey-Glass time series.",✔️,Stock,✔️,❌
WOS:001060633400002,Combining dimensionality reduction methods with neural networks for realized volatility forecasting,"The application of artificial neural networks to finance has recently received a great deal of attention from both investors and researchers, particularly as a forecasting tool. However, when dealing with a large number of predictors, these methods may overfit the data and provide poor out-of-sample forecasts. Our paper addresses this issue by employing two different approaches to predict realized volatility. On the one hand, we use a two-step procedure where several dimensionality reduction methods, such as Bayesian Model Averaging (BMA), Principal Component Analysis (PCA), and Least Absolute Shrinkage and Selection Operator (Lasso), are employed in the initial step to reduce dimensionality. The reduced samples are then combined with artificial neutral networks. On the other hand, we implement two single-step regularized neural networks that can shrink the input weights to zero and effectively handle high-dimensional data. Our findings on the volatility of different stock asset prices indicate that the reduced models outperform the compared models without regularization in terms of predictive accuracy.",10.1007/s10479-023-05544-7,Realized volatility; Artificial neural network; Machine-learning; PCA Method; Bayesian model averaging; C13; C14; G10,WOS,"This study combines dimensionality reduction techniques like PCA and Lasso with neural networks to forecast realized volatility, demonstrating that reduced models enhance predictive accuracy and mitigate overfitting in high-dimensional financial data.",✔️,Realized volatility,✔️,?
WOS:000466254600058,Combining humans and machines for the future: A novel procedure to predict human interest,"This paper proposes a method to quantify interest. In common terminology, when we engage with an object, e.g. Online Games, Social Networking Websites, Mobile Apps, etc., there is a degree of interest between us and the object. But, owing to the lack of a procedure that can quantify interest, we are unable to tell by how 'much' of a factor are we interested in the object. In other words, can we find a number for someone's interest? In this article, we propose a method that uses the principle of Bayesian Inference to tackle this issue. We formulate the ""interest estimation problem"" as a state estimation problem to deduce interest (in any object) indirectly from user activity. Activity caused by interest is computed through a subjective-objective weighted approach, then using indirect inference rules, we provide numerical estimates of interest. To do that, we model the dynamics of interest through the Ornstein-Uhlenbeck process. To further enhance the base performance, we draw inspiration from Stochastic Volatility models from Finance. Subsequently, drawing upon a self-adapting transfer function, we provide an avant-garde statistical procedure to model the transformation of interest into activity. The individual contributions are then combined and a solution is provided via Particle filters. Validation of the method is done in two ways. (1) Experimentation is performed on real datasets. Through numerical investigation we have found that the method shows good performance. (2) We implement the framework as a Web application and deploy it on an Enterprise Service Bus. The framework has been successfully hosted on a Cloud based Virtualized testbed consisting of several Virtual Machines constructed over XENServer as the underlying hypervisor. Through this experimental setup, we show the efficacy of the proposed algorithm in estimating interest, at much the same time, we demonstrate the viability of the method in practical cloud based deployment scenarios. (C) 2018 Elsevier B.V. All rights reserved.",10.1016/j.future.2018.01.043,Human machine systems; Data analytics; Interest modeling; Machine learning; Stochastic volatility models; Ornstein-Uhlenbeck process,WOS,"This paper introduces a Bayesian inference-based framework that combines human activity data with machine learning techniques to quantitatively predict individual interest in various objects, demonstrating its effectiveness through real-world datasets and cloud-based deployment scenarios.",❌,,✔️,✔️
10.3390/e24010092,Conducting Causal Analysis by Means of Approximating Probabilistic Truths,"The current paper develops a probabilistic theory of causation using measure-theoretical concepts and suggests practical routines for conducting causal inference. The theory is applicable to both linear and high-dimensional nonlinear models. An example is provided using random forest regressions and daily data on yield spreads. The application tests how uncertainty in short-and long-term inflation expectations interacts with spreads in the daily Bitcoin price. The results are contrasted with those obtained by standard linear Granger causality tests. It is shown that the suggested measure-theoretic approaches do not only lead to better predictive models, but also to more plausible parsimonious descriptions of possible causal flows. The paper concludes that researchers interested in causal analysis should be more aspirational in terms of developing predictive capabilities, even if the interest is in inference and not in prediction per se. The theory developed in the paper provides practitioners guidance for developing causal models using new machine learning methods that have, so far, remained relatively underutilized in this context. © 2022 by the author. Licensee MDPI, Basel, Switzerland.",10.3390/e24010092,Approximation theory; Bitcoin; Causality; Correct specification; Hellinger distance; Inflation; Kullback–Leibler divergence; Misspecified models; Yield spreads,SCOPUS,"Develops probabilistic Bayesian approaches for causal analysis using machine learning methods, improving predictive models over traditional Granger causality tests.",❌,?,✔️,✔️
10.1016/j.epsr.2024.110750,Conformal prediction for stochastic decision-making of PV power in electricity markets,"This paper studies the use of conformal prediction (CP), an emerging probabilistic forecasting method, for day-ahead photovoltaic power predictions to enhance participation in electricity markets. First, machine learning models are used to construct point predictions. Thereafter, several variants of CP are implemented to quantify the uncertainty of those predictions by creating CP intervals and cumulative distribution functions. Optimal quantity bids for the electricity market are estimated using several bidding strategies under uncertainty, namely: trust-the-forecast, worst-case, Newsvendor and expected utility maximization (EUM). Results show that CP in combination with k-nearest neighbors and/or Mondrian binning outperforms its corresponding linear quantile regressors. Using CP in combination with certain bidding strategies can yield high profit with minimal energy imbalance. In concrete, using conformal predictive systems with k-nearest neighbors and Mondrian binning after random forest regression yields the best profit and imbalance regardless of the decision-making strategy. Combining this uncertainty quantification method with the EUM strategy with conditional value at risk (CVaR) can yield up to 93% of the potential profit with minimal energy imbalance. © 2024 The Author(s)",10.1016/j.epsr.2024.110750,Conformal prediction; Electricity markets; Machine learning; Photovoltaic power; Stochastic optimization,SCOPUS,"The paper applies conformal prediction, a probabilistic forecasting method, to photovoltaic power predictions for electricity markets, enabling optimal bidding strategies under uncertainty.",✔️,Photovoltaic power (electricity markets),✔️,✔️
WOS:000915951700001,Constructing Equity Investment Strategies Using Analyst Reports and Regime Switching Models,"This study demonstrates whether analysts' sentiments toward individual stocks are useful for stock investment strategies. This is achieved by using natural language processing to create a polarity index from textual information in analyst reports. In this study, we performed time series forecasting for the created polarity index using deep learning, and clustered the forecasted values by volatility using a regime switching model. In addition, we constructed a portfolio from stock data and rebalanced it at each change point of the regime. Consequently, the investment strategy proposed in this study outperforms the benchmark portfolio in terms of returns. This suggests that the polarity index is useful for constructing stock investment strategies.",10.3389/frai.2022.865950,BERT; Hidden Markov Model; trading strategy; financial market; regime switching model,WOS,"This study leverages analysts' sentiments and regime switching models to construct equity investment strategies, demonstrating outperformance over benchmark portfolios.",✔️,Stocks,✔️,❌
WOS:000724596900014,Constructing a stock-price forecast CNN model with gold and crude oil indicators,"In this study, we propose algorithms to predict future stock market trends based on 8 different input features, including financial technology indicators, gold prices, a gold price volatility index, crude oil price, a crude oil price volatility index, and other characteristic data using two different labeling methods with separate classification algorithms of two and three output categories, respectively including predicted stock price changes (up and down) and recommended trading actions (buy, sell, and hold), and analyze the validity of these characteristic data in terms of their ability to predict future trends. The S&P 500 (GSPC) is the target of these forecasts. Sample data from 2010 to 2018 are divided 8:2, between training and verification data, while data from 2019 are used to test the proposed approach. CNN and LSTM models are used for comparison of classification accuracy and investment returns, respectively. Bayesian optimization (BO) hyperparameters are used to improve the accuracy of the model and increase the return on investment (ROI) of the output predictions. The purpose of this study is to verify whether using gold prices, a gold volatility index, crude oil price, and a crude oil price volatility indices as input features can enable a deep learning model accurately to predict future stock price trends, and to discuss separately the applicability of CNN and LSTM models to the abovementioned characteristics and financial indicators. We also present the results of experiments conducted to evaluate the proposed method in terms of classification accuracy and confusion matrix. In the case of three-category classification, the model takes feature data as input to outputs a predicted trading order on whether to buy, sell, or hold a given set of stocks tomorrow as well as the timing of entry and exit from each position, and also backtests the data outside the sample to find the combination of characteristics and indicators best maximizing ROI. Using this three-category method, we obtain a comprehensive ROI for a given set of individual stocks and assess whether each type of stock is suitable for the prediction model based on input features such as gold and crude oil or the fields that are suitable for the given feature. Experimental results show that the proposed approach as able to predict whether stock price will rise or fall in the next 10 days, and the model accuracy rate can reach 67%. The results of experiments on the proposed combined CNN model with eight features, referred to as CNN8, achieved an ROI on 2019 data outside the sample period of up to 13.23%, which was superior to the 12.08% and 11.06% obtained by the models designed CNN4 (CNN with four input features) and LSTM8(LSTM with eight input features), respectively. The F1 score increased from 0.75 0.79 as a result of applying BO. The results indicate that considering the price of gold, the gold volatility index, crude oil price, and crude oil price volatility index can help obtain better ROI for companies in certain fields, such as the semiconductor, petroleum, and automotive industries, rather than merely considering financial indicators. However, for companies related to apparel, fast food, and copy processing, the input characteristics of purely financial technical indicators were found to be suitable. (C) 2021 Elsevier B.V. All rights reserved.",10.1016/j.asoc.2021.107760,Stock price forecast; Deep learning; Convolutional neural networks; Long short-term memory; Bayesian optimization,WOS,"Proposes CNN and LSTM models with gold and crude oil indicators to predict S&P500 stock trends, using Bayesian optimization for model accuracy and ROI improvement.",✔️,S&P500 Stocks,✔️,❌
10.1016/j.rse.2021.112408,Corn yield prediction and uncertainty analysis based on remotely sensed variables using a Bayesian neural network approach,"As the world's leading corn producer, the United States supplies more than 30% of the global corn production. Accurate and timely estimation of corn yield is therefore essential for commodity trading and global food security. Recently, several deep learning models have been explored for corn yield forecasting. Despite success, most existing models only provide yield estimations without quantifying the uncertainty associated with the predictions. Also, the traditional deep learning approaches typically require a large training set and are easily prone to overfitting when the number of samples in the training set is relatively small. To address these limitations, in this study, we developed a county-level corn yield prediction model based on Bayesian Neural Network (BNN) using multiple data sources that are publicly available, including time-series satellite products, sequential climate observations, soil property maps, and historical corn yield records. Using preceding years since 2001 for model training, the developed BNN model achieved an average coefficient of determination (R2) of 0.77 for late-season prediction across the U.S. Corn Belt in testing years 2010–2019, and outperformed five other state-of-the-art machine learning models. Detailed evaluation in three representative testing years demonstrated that the proposed BNN model could accurately estimate corn yield not only in normal years but also in abnormal years when extreme weather events happened. Moreover, the timeliness of the prediction was evaluated within the growing season with an R2~0.75 achieved by middle August, which is about 2 months before the harvest. We also assessed the predictive uncertainty, and more than 84% of the observed yield records were successfully enveloped in the 95% confidence interval of the predictive yield distribution. Our results also showed that the uncertainty level decreased steadily as time proceeded and stabilized around early August. Uncertainties in yield prediction were mainly induced by the observation noise and also related to the interannual and seasonal variabilities of environmental stress such as heat and water stress. This paper provides a robust framework for the within-season prediction of crop yield and highlights the need to obtain a deeper understanding of the effects of environmental stress on agricultural productivity and crop yield estimation. © 2021 Elsevier Inc.",10.1016/j.rse.2021.112408,Bayesian neural network; Corn yield prediction; Deep learning; Remote sensing; Uncertainty estimation,SCOPUS,"Develops a Bayesian Neural Network model for county-level corn yield prediction, achieving high accuracy and uncertainty quantification.",✔️,Corn Yield,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861031,Cost-Sensitive Prediction of Stock Price Direction: Selection of Technical Indicators,"Stock market forecasting using technical indicators (TIs) is widely applied by investors and researchers. Using a minimal number of input features is crucial for successful prediction. However, there is no consensus about what constitutes a suitable collection of TIs. The choice of TIs suitable for a given forecasting model remains an area of active research. This study presents a detailed investigation of the selection of a minimal number of relevant TIs with the aim of increasing accuracy, reducing misclassification cost, and improving investment return. Fifty widely used TIs were ranked using five different feature selection methods. Experiments were conducted using nine classifiers, with several feature selection methods and various alternatives for the number of TIs. A proposed cost-sensitive fine-tuned naïve Bayes classifier managed to achieve better overall investment performance than other classifiers. Experiments were conducted on datasets consisting of daily time series of 99 stocks and the TASI market index.",10.1109/access.2019.2945907,Training;Stock markets;Investment;Forecasting;Predictive models;Classification algorithms;Feature extraction;Cost-sensitive;feature selection;machine learning;market trend;prediction;stock market;technical indicators,IEEE,"The study develops a cost-sensitive Naïve Bayes classifier to predict stock price directions based on selected technical indicators, enhancing investment performance by optimizing indicator selection.",✔️,"Stocks, TASI index",✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721191,Crop Prediction Based on Characteristics of the Agricultural Environment Using Various Feature Selection Techniques and Classifiers,"Agriculture is a growing field of research. In particular, crop prediction in agriculture is critical and is chiefly contingent upon soil and environment conditions, including rainfall, humidity, and temperature. In the past, farmers were able to decide on the crop to be cultivated, monitor its growth, and determine when it could be harvested. Today, however, rapid changes in environmental conditions have made it difficult for the farming community to continue to do so. Consequently, in recent years, machine learning techniques have taken over the task of prediction, and this work has used several of these to determine crop yield. To ensure that a given machine learning (ML) model works at a high level of precision, it is imperative to employ efficient feature selection methods to preprocess the raw data into an easily computable Machine Learning friendly dataset. To reduce redundancies and make the ML model more accurate, only data features that have a significant degree of relevance in determining the final output of the model must be employed. Thus, optimal feature selection arises to ensure that only the most relevant features are accepted as a part of the model. Conglomerating every single feature from raw data without checking for their role in the process of making the model will unnecessarily complicate our model. Furthermore, additional features which contribute little to the ML model will increase its time and space complexity and affect the accuracy of the model’s output. The results depict that an ensemble technique offers better prediction accuracy than the existing classification technique.",10.1109/access.2022.3154350,Crops;Zigbee;Monitoring;Soil;Temperature sensors;Security;Data models;Agriculture;classification;crop prediction;feature selection,IEEE,"Utilizes machine learning with feature selection techniques to predict crop yields based on agricultural environmental characteristics, enhancing model accuracy.",❌,?,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271718,CrowdFAB: Intelligent Crowd-Forecasting Using Blockchains and its Use in Security,"Crowdsourcing applications, such as Uber for ride-sharing, enable distributed problem-solving. A subset of these applications is intelligent crowd-forecasting applications, e.g., Virustotal, for malware detection. In crowd-forecasting applications, multiple agents respond with predictions about potential future event outcome(s). These responses are then combined to assess the events collaboratively and act accordingly. Unlike conventional crowdsourcing applications that only communicate information, crowd-forecasting applications need to additionally process information to achieve a collaborative assessment. Hence, they require knowledge-based systems instead of simple storage-based ones for crowdsourcing applications. Most existing crowd-forecasting systems are centralized, leading to the inherent single point of failure and inefficient collaborative assessment. This paper presents CrowdFAB, Crowdsourced Forecasting Applications using Blockchains. We deploy a knowledge-based blockchain paradigm that transforms blockchains from simple storage to knowledge-based systems, thereby achieving crowd-forecasting requirements without centralization. In addition, we formulate a novel reputation scheme that assigns reputations to agents based on their performance. We then use this scheme when making assessments. We implement and analyze CrowdFAB in terms of overhead and security features. Further, we evaluate CrowdFAB for a collaborative malware detection use case, where multiple detectors are involved for crowd forecasting. Results demonstrate CrowdFAB's superior accuracy and other metrics performance compared to other works with the same settings.",10.1109/tdsc.2023.3322038,Blockchains;Security;Knowledge based systems;Forecasting;Crowdsourcing;Smart contracts;Probabilistic logic;Blockchains;crowdsourcing;malware detection;security assessment,IEEE,"Introduces CrowdFAB, a decentralized crowd-forecasting system using blockchains and reputation schemes, applied to malware detection.",❌,?,✔️,❌
10.1080/00949655.2021.1899179,Cryptocurrency direction forecasting using deep learning algorithms,"Recently, the deep learning architecture has been used with an increasing rate for forecasting in financial markets. In this paper, the LSTM model is used to forecast the daily closing price direction of the BTC/USD. Both model accuracy and the profit or loss of the trades made based on the proposed model are analyzed. In addition, the effects of the MACD indicator and the input matrix dimension on forecasting accuracy are evaluated. The potential risks and actual risks encountered by the trader who trades based on the proposed model were also analyzed. The obtained results indicate that the optimization of the LSTM parameters using the Bayesian optimization model has enhanced the model’s accuracy. The results obtained from analyzing the drawdown and reward/risk resulting from the trades made based on the model show that the model enables the trader to trade with peace of mind due to the low level of actual risks and potential risks. © 2021 Informa UK Limited, trading as Taylor & Francis Group.",10.1080/00949655.2021.1899179,BPNN; BTC/USD forecasting; Cryptocurrency forecasting; deep learning,SCOPUS,"Utilizes Long Short-Term Memory (LSTM) deep learning models, optimized with Bayesian methods, to forecast BTC/USD price direction, enhancing accuracy and reducing trading risks.",✔️,Cryptocurrency (BTC/USD),✔️,✔️
WOS:000634143200001,Cryptocurrency price prediction using traditional statistical and machine-learning techniques: A survey,"Cryptocurrencies are decentralized electronic counterparts of government-issued money. The first and best-known cryptocurrency example is bitcoin. Cryptocurrencies are used to make transactions anonymously and securely over the internet. The decentralization behavior of a cryptocurrency has radically reduced central control over them, thereby influencing international trade and relations. Wide fluctuations in cryptocurrency prices motivate the urgent requirement for an accurate model to predict its price. Cryptocurrency price prediction is one of the trending areas among researchers. Research work in this field uses traditional statistical and machine-learning techniques, such as Bayesian regression, logistic regression, linear regression, support vector machine, artificial neural network, deep learning, and reinforcement learning. No seasonal effects exist in cryptocurrency, making it hard to predict using a statistical approach. Traditional statistical methods, although simple to implement and interpret, require a lot of statistical assumptions that could be unrealistic, leaving machine learning as the best technology in this field, being capable of predicting price based on experience. This article provides a comprehensive summary of the previous studies in the field of cryptocurrency price prediction from 2010 to 2020. The discussion presented in this article will help researchers to fill the gap in existing studies and gain more future insight.",10.1002/isaf.1488,cryptocurrency price prediction; bitcoin (BTC); machine learning (ML); reinforcement learning (RL); deep learning (DL),WOS,"Surveys cryptocurrency price prediction using traditional statistical and machine-learning techniques, highlighting ML's superiority due to lack of seasonal effects.",✔️,Cryptocurrencies,✔️,❌
10.15587/1729-4061.2023.281138,DEVELOPMENT NEURO-FUZZY MODEL TO PREDICT THE STOCKS OF COMPANIES IN THE ELECTRIC VEHICLE INDUSTRY,"Adaptive neuro-fuzzy inference system (ANFIS) it is a type of neural network that combines the strengths of both fuzzy logic and artificial neural networks. ANFIS is particularly useful in stock trading because it can handle uncertainty and imprecision in the data, which is common in stock market data. In stock trading, ANFIS can be used for a variety of purposes, such as predicting stock prices, identifying profitable trades, and detecting stock market trends. One of the key advantages of using ANFIS for stock trading is that it can handle both linear and non-linear relationships in the data. This is particularly useful in the stock market, where the relationships between different variables are often complex and non-linear. ANFIS can also be updated and retrained as new data becomes available, which allows it to adapt to changing market conditions. Therefore, the main hypothesis of this work is to understand whether it is possible to predict the dynamics of prices for stocks of companies in the electric vehicle (EV) sector using technical analysis indicators. The purpose of this work is to create a model for predicting the prices of companies in the EV sector. The technical analysis indicators were processed by several machine learning models. Linear models generally perform worse than more advanced techniques. Decision trees, whether fine or coarse, tend to yield poorer performance results in terms of RMSE, MSE and MAE. After conducting a data analysis, the ANFIS and Bayesian regularization back propagation Neural Network (BR-BPNN) models were seen to be the most effective. The ANFIS was trained for 2000 epochs which yielded a minimum RMSE of 5.90926 © 2023, Authors. This is an open access article under the Creative Commons CC BY license",10.15587/1729-4061.2023.281138,adaptive neuro-fuzzy inference system; correlation of technical indicators; electric vehicle sector; neural network; stock price forecasting,SCOPUS,The study develops a neuro-fuzzy model using ANFIS and Bayesian regularization neural networks to predict stock prices of companies in the electric vehicle industry.,✔️,Stocks (electric vehicle companies),✔️,❌
WOS:000818987300004,DIVIDENDS AND COMPOUND POISSON PROCESSES: A NEW STOCHASTIC STOCK PRICE MODEL,"This study introduces a stochastic multi-period dividend discount model (DDM) that includes (i) a compound nonhomogenous Poisson process for dividend growth and (ii) the probability of firm default. We obtain maximum likelihood (ML) estimators and confidence interval formulas of our model parameters. We apply the model to a set of firms from the S&P 500 index using historical dividend and price data over a 42-year period. Interestingly, stock price estimations calculated with the model are close to the observable prices. Overall, we prove that the model can be a useful tool for stock pricing.",10.1142/s0219024922500145,Stochastic dividend discount model; compound nonhomogeneous poisson process; random time of firm default; ML estimators,WOS,"A stochastic dividend discount model incorporating Poisson processes and default probabilities is introduced for stock pricing, demonstrating close estimations to actual prices.",✔️,Stocks,✔️,✔️
10.1016/j.petrol.2022.110352,"Data-driven EUR modeling and optimization in the liquid-rich Duvernay Formation, western Canada sedimentary basin, Canada","Estimated Ultimate Recovery (EUR) is one of the focuses of the feasibility assessment for oil and gas development projects. EUR is the utmost recoverable oil and gas volume under the current assumption of technology and economics. Many factors including geology, drilling, completion, operation, and commodity prices influence EUR, which makes the prediction a difficult task. Reservoir numerical simulation and production decline curve analysis (DCA) are two broadly accepted method to calculate EUR. However, the former requires substantial data and resources, while the latter is lack of causative mechanism to associate the fundamentals to productivity. This study proposes a machine learning (ML) procedure in EUR modeling, by which EUR is linked to fundamental variables from available data and the variation in EUR can be explained by various factors so that the results can be applied to optimize future projects. In the proposed procedure, the EUR was estimated using a probabilistic dual flow regime model and Markov Chain Monte Carlo (MCMC) simulation. The resulting EUR in each well was then modeled using a two-level stacked ensemble ML approach, while Shapley value was used to explain feature sensitivity in the trained model. In the last, the EUR is optimized by adjusting the most sensitive factors in the trained model. The trained ML model achieved high accuracy on EUR prediction, and the Shapley value analysis showed that completion length, condensate gas ratio and fracturing fluid volume are among the most important features to EUR. The EUR optimization result showed that there is large room for improvement by adjusting the key features. This proposed approach provides a new perspective to find associations between the fundamental factors and the well EUR which improves the understanding of oil and gas production in unconventional reservoirs. © 2022",10.1016/j.petrol.2022.110352,EUR; Machine learning; Shapley value; Stacked model,SCOPUS,"Utilizes machine learning, including stacked ensemble models and Shapley value analysis, to model and optimize Estimated Ultimate Recovery (EUR) in the liquid-rich Duvernay Formation, enhancing oil and gas project feasibility assessments.",✔️,Estimated Ultimate Recovery (EUR),✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10535174,Day-Ahead Electricity Price Forecasting in the Contemporary Italian Market,"In competitive electricity markets, prices are determined by the collective behaviour of suppliers and consumers. Hence, these systems rely on the balance between supply and demand, and sudden changes in the underlying conditions can lead to significant price fluctuations. In the face of the recent transformations in Italian electricity markets, which are driven by an increasing share of non-programmable renewables, energy crises, and geopolitical tensions, our study focuses on effective forecasting methodologies. We compare kernel and linear regression for predicting market equilibrium prices, both in point and probabilistic sense. We showcase the potential of both linear and non-linear models when carefully engineering the problem of interest, which involves properly selecting data and variables. The noteworthy outcome is that, while linear and non-linear models may differ in nature, their performance converges closely, attesting to the robustness of our approach in achieving reliable forecasts. We describe data sources and assumptions in exploratory univariate analyses, and the performance of the final multivariate model is evaluated over a test period on September 2023.",10.1109/access.2024.3403422,Forecasting;Electricity;Predictive models;Kernel;Data models;Electricity supply industry;Computational modeling;Economics;Statistics;Linear approximation;Probabilistic logic;Electricity supply industry;forecasting;economic forecasting;nonparametric statistics;linear approximation;probability;probability density function,IEEE,"Develops an automated Bayesian Support Vector Regression framework with Bayesian optimization for parameter selection and uncertainty estimation, enhancing financial time series prediction and market condition change detection.",✔️,"Equity Index, Credit Default Swaps, Bond Yields, Commodity Futures",✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847239,Decision Fusion for Stock Market Prediction: A Systematic Review,"Stock market prediction based on machine or deep learning is an essential topic in the financial community. Typically, models with different structures or initializations provide different forecasts of the same response variable. In such cases, better prediction is often achieved by combining forecasts from multiple models rather than using a single model in isolation. This combination of forecasts from the base learners is known as decision fusion. Furthermore, although decision fusion is typical and essential for making the best possible use of multiple forecasts, few studies have systematically summarized the studies that apply this technique. Therefore, there is an urgent need for a literature review reflecting the application of decision fusion in this field. To this end, this study systematically reviewed research related to decision fusion for stock market prediction, focusing on the characteristics of base learners and decision fusion methods. Specifically, the research trend on this topic, which has shifted over the past two decades, is discussed. This review also presents future directions in applying decision fusion to stock market prediction, such as the fusion of forecasts with different data types, using new algorithms as base learners, and integrating sentiment analysis with decision fusion techniques.",10.1109/access.2022.3195942,Stock markets;Forecasting;Predictive models;Market research;Systematics;Deep learning;Prediction algorithms;Base learner;decision fusion;ensemble;machine learning;review;stock market prediction,IEEE,"This systematic review examines the use of decision fusion methods in stock market prediction, analyzing various techniques and suggesting future directions for integrating multiple data types and algorithms.",❌,,❌,❌
WOS:000717914600001,Deep Nonlinear Ensemble Framework for Stock Index Forecasting and Uncertainty Analysis,"Stock index forecasting plays an important role in avoiding risk and increasing returns for financial regulators and investors. However, due to the volatility and uncertainty of the stock market, forecasting stock indices accurately is challenging. In this paper, a deep nonlinear ensemble framework is proposed for stock index forecasting and uncertainty analysis. (1) Singular spectrum analysis (SSA) is utilized to extract features from a raw stock index and eliminate the interference. (2) Enhanced weighted support vector machine (EWSVM) is proposed for forecasting each component that is decomposed, of which the penalty weights are based on the time order and the hyperparameters are optimized using the simulated annealing algorithm. (3) Recurrent neural network (RNN) is used to integrate the forecast of each component into the final point forecast. (4) Gaussian process regression (GPR) is applied to obtain the interval forecast of the original stock index. Two practical cases (Nikkei 225 Index, Japan and Hang Seng Index, Hong Kong, China) are utilized to evaluate the performance of the proposed model. In terms of the results of point forecasting, the MAE, R-2, MAPE, and RMSE of Nikkei 225 Index are 66.0745, 0.9972, 0.0066, and 80.0381, and those of Hang Seng Index are 79.2145,0.9968, 0.0073, and 96.7740. In terms of the results of interval forecasting, the CP95% , MWP95% , and MC95% of Nikkei 225 Index are 0.89979, 0.05746, and 0.06385, and those of Hang Seng Index are 0.97985, 0.28223, and 0.28803. Forecasting stock indices accurately is crucial for investment decision and risk management and is extremely meaningful to investors and financial regulators. In this paper, the SSA-EWSVM-RNN-GPR model is used to forecast the closing prices of stock indices, and compared with eight benchmark models, the proposed SSA-EWSVM-RNN-GPR model can be an effective tool for both point and interval forecasting of stock indices.",10.1007/s12559-021-09961-3,Stock forecasting; Singular spectrum analysis; Enhanced weighted support vector machine; Deep learning; Nonlinear ensemble,WOS,"Integrates copula functions with Hidden Markov Models and deep learning to enhance portfolio risk measurement, identifying interdependencies among financial industries and optimizing risk assessment.",✔️,Portfolio,✔️,✔️
WOS:000492797300038,Deep learning-based rolling horizon unit commitment under hybrid uncertainties,"Unit commitment is an optimization problem in power systems, which aims to satisfy future load at minimal cost by scheduling the on/off state and output of generation resources like thermal units. One challenge herein is the uncertainties that exist in both supply and demand sides of power systems, which becomes more severe with the growing penetration of renewable energy and the popularity of diversified loads. This paper proposes a rolling horizon model for unit commitment optimization under hybrid uncertainties. First, a probabilistic forecast approach for future load and wind power is given by exploiting the advanced deep learning structures, i.e. long short-term memory neural networks. Second, a Value-at-Risk-based unit commitment model is applied to decide the on/off state and output of thermal units in the next 24 h. Then at each time window, the distributions of future load and wind power are dynamically adjusted by a rolling forecast mechanism to involve the real-time collected data, whereafter a look-ahead economic dispatch model is applied to improve the output of units. Finally, the effectiveness of this research is demonstrated by a series of experiments. Generally, this study introduces a fundamental way to integrate forecast approaches into classical unit commitment optimization models. (C) 2019 Elsevier Ltd. All rights reserved.",10.1016/j.energy.2019.07.173,Rolling horizon unit commitment; Long short-term memory neural networks; Data-driven; Rolling forecast; Look-ahead economic dispatch,WOS,"Presents a deep learning-based rolling horizon unit commitment model for power systems under hybrid uncertainties, integrating LSTM forecasting and Value-at-Risk.",❌,?,✔️,✔️
10.1007/s00521-024-09916-3,DeepAR-Attention probabilistic prediction for stock price series,"Stock price prediction is a significant research domain, intersecting statistics, finance, and economics. Accurately forecasting stock price trends has always been a focal point for many researchers. However, traditional statistical methods for time series prediction still lack accuracy. The existing deep learning-based methods for stock price prediction have significantly enhanced the accuracy of predicting individual stock prices. However, they are not effective in forecasting the probability range of future stock price trends. In this paper, to address these limitations, we propose a novel DeepAR model based on the attention mechanism (DeepARA) for both single-point and probabilistic predictions of stock prices. This enhances the accuracy and flexibility of stock price forecasting. Although the attention mechanism was initially developed for natural language processing, it has now found applications in time series forecasting, including the dynamics of the stock market. Attention allocates different weights to time points of varying importance, thereby enhancing the model’s ability to capture fundamental market dynamics. We conducted multiple experiments in the Chinese stock market, involving 30 stocks across the top six sectors. Compared with baseline models, the DeepARA model demonstrates superior predictive capabilities. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.",10.1007/s00521-024-09916-3,Attention mechanism; Deep learning; DeepAR; Recurrent neural networks; Stock prediction,SCOPUS,"Proposes the DeepARA model, an attention-based DeepAR framework for both single-point and probabilistic stock price predictions, outperforming baseline models.",✔️,Stock Prices,✔️,✔️
https://doi.org/10.1007/s42521-022-00050-0,DeepVaR: a framework for portfolio risk assessment leveraging probabilistic deep neural networks.,"Determining and minimizing risk exposure pose one of the biggest challenges in the financial industry as an environment with multiple factors that affect (non-)identified risks and the corresponding decisions. Various estimation metrics are utilized towards robust and efficient risk management frameworks, with the most prevalent among them being the Value at Risk (VaR). VaR is a valuable risk-assessment approach, which offers traders, investors, and financial institutions information regarding risk estimations and potential investment insights. VaR has been adopted by the financial industry for decades, but the generated predictions lack efficiency in times of economic turmoil such as the 2008 global financial crisis and the COVID-19 pandemic, which in turn affects the respective decisions. To address this challenge, a variety of well-established variations of VaR models are exploited by the financial community, including data-driven and data analytics models. In this context, this paper introduces a probabilistic deep learning approach, leveraging time-series forecasting techniques with high potential of monitoring the risk of a given portfolio in a quite efficient way. The proposed approach has been evaluated and compared to the most prominent methods of VaR calculation, yielding promising results for VaR 99% for forex-based portfolios.Supplementary InformationThe online version contains supplementary material available at 10.1007/s42521-022-00050-0.",10.1007/s42521-022-00050-0,,Proquest,"Introduces DeepVaR, a probabilistic deep neural network framework for assessing portfolio risk by estimating Value at Risk, demonstrating improved performance during economic turmoil.",✔️,Portfolio,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146609,Detection of Stock Price Manipulation Using Kernel Based Principal Component Analysis and Multivariate Density Estimation,"Stock price manipulation uses illegitimate means to artificially influence market prices of several stocks. It causes massive losses and undermines investors' confidence and the integrity of the stock market. Several existing research works focused on detecting a specific manipulation scheme using supervised learning but lacks the adaptive capability to capture different manipulative strategies. This begets the assumption of model parameter values specific to the underlying manipulation scheme. In addition, supervised learning requires the use of labelled data which is difficult to acquire due to confidentiality and the proprietary nature of trading data. The proposed research establishes a detection model based on unsupervised learning using Kernel Principal Component Analysis (KPCA) and applied increased variance of selected latent features in higher dimensions. A proposed Multidimensional Kernel Density Estimation (MKDE) clustering is then applied upon the selected components to identify abnormal patterns of manipulation in data. This research has an advantage over the existing methods in overcoming the ambiguity of assuming values of several parameters, reducing the high dimensions obtained from conventional KPCA and thereby reducing computational complexity. The robustness of the detection model has also been evaluated when two or more manipulative activities occur within a short duration of each other and by varying the window length of the dataset fed to the model. Validation on multiple datasets and a comprehensive assessment of the model performance has been conducted without providing any prior information about the location of the manipulation. The results show a significant performance enhancement in terms of the F-measure values and a significant reduction in false alarm rate (FAR) has been achieved.",10.1109/access.2020.3011590,Stock markets;Kernel;Manipulators;Data models;Principal component analysis;Feature extraction;Computational modeling;Market abuse;stock price manipulation;anomaly detection;kernel principal component analyses;multi-dimensional kernel density estimate clustering,IEEE,"Develops an unsupervised machine learning model using Kernel PCA and Multivariate Kernel Density Estimation to detect stock price manipulation, overcoming parameter ambiguity and reducing computational complexity.",✔️,Stock Prices (Manipulation Detection),✔️,✔️
WOS:001297409100001,Developing a Novel Hybrid Model Double Exponential Smoothing and Dual Attention Encoder-Decoder Based Bi-Directional Gated Recurrent Unit Enhanced With Bayesian Optimization to Forecast Stock Price,"Financial market prediction has shown considerable potential in the past few years from the combination of contemporary Deep Learning (DL) techniques and traditional time series forecasting methodologies. To predict the stock prices of three distinct companies General Electric (GE), Microsoft (MSFT), and Amazon (AMZN) datasets. This study presents a novel hybrid model that combines the Double Exponential Smoothing (DES) method with a Deep Learning (DL) model Dual Attention Encoder-Decoder based Bi-directional GRU, optimized using Bayesian Optimization (DES-DA-ED-Bi-GRU-BO). By combining the best features of contemporary and old methods, the hybrid model seeks to efficiently identify patterns and trends in stock data. When handling time series data, the DES method offers a reliable and flexible mechanism that considers trends and seasonality in the data. The DA-ED-Bi-GRU added to the deep learning model further improves its comprehension of intricate patterns found in the stock data. The parameters are adjusted using Bayesian optimization (BO) to maximize the model's performance. Several performance indicators, such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-Square (R-2), and Theil's U-Statistics (TUS), are used to assess the effectiveness of the model. These measures offer thorough insights into the precision, dependability, and accuracy of the model's predictions. The experimental findings show that the proposed hybrid model has the ability to predict GE, MSFT, and AMZN stock values with reasonable accuracy. Along with the optimization framework, DL and conventional smoothing approaches combine to provide a potent forecasting tool that may help traders and investors make wise judgments.",10.1109/access.2024.3435683,Predictive models; Accuracy; Forecasting; Smoothing methods; Data models; Time series analysis; Measurement; Encoders; Stock markets; Pricing; Double exponential smoothing (DES); dual attention mechanism (DA); encoder-decoder (ED); bi-directional GRU (Bi-GRU); Bayesian optimization (BO); stock price prediction,WOS,"Develops a hybrid model combining Double Exponential Smoothing with a dual attention encoder-decoder Bi-GRU, optimized via Bayesian optimization, to accurately forecast stock prices for GE, MSFT, and AMZN.",✔️,Stock Prices,✔️,❌
10.20537/2076-7633-2023-15-1-185-195,Development of and research on machine learning algorithms for solving the classification problem in Twitter publications; [Разработка и исследование алгоритмов машинного обучения для решения задачи классификации в публикациях Twitter],"Posts on social networks can both predict the movement of the financial market, and in some cases even determine its direction. The analysis of posts on Twitter contributes to the prediction of cryptocurrency prices. The specificity of the community is represented in a special vocabulary. Thus, slang expressions and abbreviations are used in posts, the presence of which makes it difficult to vectorize text data, as a result of which preprocessing methods such as Stanza lemmatization and the use of regular expressions are considered. This paper describes created simplest machine learning models, which may work despite such problems as lack of data and short prediction timeframe. A word is considered as an element of a binary vector of a data unit in the course of the problem of binary classification solving. Basic words are determined according to the frequency analysis of mentions of a word. The markup is based on Binance candlesticks with variable parameters for a more accurate description of the trend of price changes. The paper introduces metrics that reflect the distribution of words depending on their belonging to a positive or negative classes. To solve the classification problem, we used a dense model with parameters selected by Keras Tuner, logistic regression, a random forest classifier, a naive Bayesian classifier capable of working with a small sample, which is very important for our task, and the k-nearest neighbors method. The constructed models were compared based on the accuracy metric of the predicted labels. During the investigation we recognized that the best approach is to use models which predict price movements of a single coin. Our model deals with posts that mention LUNA project, which no longer exist. This approach to solving binary classification of text data is widely used to predict the price of an asset, the trend of its movement, which is often used in automated trading. © 2023 Ivan S. Makarov, Ekaterina R. Bagantsova, Prokhor A. Iashin, Maria D. Kovaleva, Roman A. Gorbachev.",10.20537/2076-7633-2023-15-1-185-195,dense model; KNN; logistic regression; machine learning; naive Bayes classifier; natural language processing; random fores classifier; Twitter; vectorization; сryptocurrency,SCOPUS,"The paper develops machine learning models to classify Twitter posts related to cryptocurrency prices, using various classifiers to predict asset price movements and trends.",✔️,Cryptocurrency,✔️,❌
WOS:001208040700001,Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with Unmeasured Confounding,"We consider the problem of constructing bounds on the average treatment effect (ATE) when unmeasured confounders exist but have bounded influence. Specifically, we assume that omitted confounders could not change the odds of treatment for any unit by more than a fixed factor. We derive the sharp partial identification bounds implied by this assumption by leveraging distributionally robust optimization, and we propose estimators of these bounds with several novel robustness properties. The first is double sharpness: our estimators consistently estimate the sharp ATE bounds when one of two nuisance parameters is misspecified and achieve semiparametric efficiency when all nuisance parameters are suitably consistent. The second and more novel property is double validity: even when most nuisance parameters are misspecified, our estimators still provide valid but possibly conservative bounds for the ATE and our Wald confidence intervals remain valid even when our estimators are not asymptotically normal. As a result, our estimators provide a highly credible method for sensitivity analysis of causal inferences. Supplementary materials for this article are available online including a standardized description of the materials available for reproducing the work.",10.1080/01621459.2024.2335588,Conditional value at risk; Debiased machine learning; Double robustness; Partial identification; Marginal sensitivity model; Semiparametric efficiency,WOS,Develops doubly-valid and doubly-sharp sensitivity analysis estimators for causal inference with unmeasured confounding using Bayesian methods.,❌,?,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10649550,Dynamic Calibration Based on the Black-Scholes Option Pricing Model by Bayesian Method,"To improve the shortcomings of the classic Black-Scholes model, mainly on the constant volatility and normal distribution assumptions, this paper investigates the dynamic calibration method, which makes the expected return rate, volatility and interest rate become data-driven and time dependent. Based on the dynamic procedure, four distinct calibration models are proposed by using Bayesian method, among which Model I and Model II are used for comparison, Model III simultaneously uses the data of underlying asset, put and call options by introducing the bivariate normal distribution, and Model IV simplifies Model III by employing the put-call parity. The results of numerical experiments and empirical analysis illustrate that Model III is the most accurate but time consuming, while Model IV is the most efficient. Dynamic calibration method is also verified to be much more accurate in data fitting and option pricing than the commonly used global calibration. Overall, the dynamically calibrated Black-Scholes model can be regarded as an improvement on the classic Black-Scholes model, where model coefficients are functions of time. As a result, leptokurtic and negative skew distribution of log returns is regenerated, which makes the model more consistent with the data observed in real markets without an increase of the complexity.",10.1109/access.2024.3450602,Calibration;Data models;Pricing;Mathematical models;Computational modeling;Bayes methods;Solid modeling;Markov processes;Monte Carlo methods;Bayesian method;dynamic calibration;Black-Scholes model;Markov Chain Monte Carlo;volatility surface;leptokurtosis,IEEE,"This paper enhances the classic Black-Scholes option pricing model by introducing dynamic calibration using Bayesian methods, allowing key parameters to vary over time and better capturing real market behaviors such as leptokurtic and skewed return distributions.",✔️,Options,❌,✔️
978-1-392-07688-0,Dynamic Machine Learning with Least Square Objectives,"As of the writing of this thesis, machine learning has become one of the most active research fields. The interest comes from a variety of disciplines which include computer science, statistics, engineering, and medicine. The main idea behind learning from data is that, when an analytical model explaining the observations is hard to find—often in contrast to the models in physics such as Newton's laws—a statistical approach can be taken where one or more candidate models are tuned using data.Since the early 2000's this challenge has grown in two ways: (i) The amount of collected data has seen a massive growth due to the proliferation of digital media, and (ii) the data has become more complex. One example for the latter is the high dimensional datasets, which can for example correspond to dyadic interactions between two large groups (such as customer and product information a retailer collects), or to high resolution image/video recordings. Another important issue is the study of dynamic data, which exhibits dependence on time. Virtually all datasets fall into this category as all data collection is performed over time, however I use the term dynamic to hint at a system with an explicit temporal dependence. A traditional example is target tracking from signal processing literature. Here the position of a target is modeled using Newton's laws of motion, which relates it to time via the target's velocity and acceleration.Dynamic data, as I defined above, poses two important challenges. Firstly, the learning setup is different from the standard theoretical learning setup, also known as Probably Approximately Correct (PAC) learning. To derive PAC learning bounds one assumes a collection of data points sampled independently and identically from a distribution which generates the data. On the other hand, dynamic systems produce correlated outputs. The learning systems we use should accordingly take this difference into consideration. Secondly, as the system is dynamic, it might be necessary to perform the learning online. In this case the learning has to be done in a single pass. Typical applications include target tracking and electricity usage forecasting.In this thesis I investigate several important dynamic and online learning problems, where I develop novel tools to address the shortcomings of the previous solutions in the literature. The work is divided into three parts for convenience. The first part is about matrix factorization for time series analysis which is further divided into two chapters. In the first chapter, matrix factorization is used within a Bayesian framework to model time-varying dyadic interactions, with examples in predicting user-movie ratings and stock prices. In the next chapter, a matrix factorization which uses autoregressive models to forecast future values of multivariate time series is proposed, with applications in predicting electricity usage and traffic conditions. Inspired by the machinery we use in the first part, the second part is about nonlinear Kalman filtering, where a hidden state is estimated over time given observations. The nonlinearity of the system generating the observations is the main challenge here, where a divergence minimization approach is used to unify the seemingly unrelated methods in the literature, and propose new ones. This has applications in target tracking and options pricing. The third and last part is about cost sensitive learning, where a novel method for maximizing area under receiver operating characteristics curve is proposed. Our method has theoretical guarantees and favorable sample complexity. The method is tested on a variety of benchmark datasets, and also has applications in online advertising.",,,Proquest,"The thesis explores dynamic and online machine learning techniques, including matrix factorization and nonlinear Kalman filtering, for time series analysis and prediction tasks such as stock price forecasting.",✔️,Stock,✔️,✔️
WOS:000729809800019,Dynamic forecasting performance and liquidity evaluation of financial market by Econophysics and Bayesian methods,"In a complex financial system, what is the forecasting performance of macro and micro evolution models of Econophysics on asset prices? For this problem, from the perspective of machine learning, we study the dynamic forecasting and liquidity assessment of financial markets, based on econophysics and Bayesian methods. We establish eight dynamic prediction methods, based on our proposed likelihood estimation and Bayesian estimation methods of macro and micro evolution models of econophysics. Combined machine learning thinking and real data, we empirically study and simulate the out-of-sample dynamic forecasting analysis of eight proposed methods and compare with the benchmark GARCH model. A variety of loss functions, superior predictive ability test (SPA), Akaike and Bayesian information criterion (AIC and BIC) methods are introduced to further evaluate the forecasting performance of our proposed methods. The research of out of sample prediction shows that (1) the method of the simplified stochastic model with Bayesian method for only sample return has the best forecasting performance; (2) the method of the stochastic model with Bayesian method for only return samples has the worst forecasting performance. For the liquidity assessment problem, there is a strong correlation between the trading probability evaluated by the proposed eight methods and the real turnover rate, and an increase of liquidity is correspond to the increase of asset risk. In other words, it suggests that all proposed methods can well evaluate market liquidity. (C) 2021 Elsevier B.V. All rights reserved.",10.1016/j.physa.2021.126546,Econophysics; Agent-based model; Liquidity risk assessment; Machine learning thinking; Microcosmic evolution models,WOS,"Analyzes why existing machine learning and deep learning algorithms struggle to accurately predict stock prices, attributing it to the predominance of non-curve-shape features in financial time series data.",✔️,Stock Prices,✔️,❌
10.21003/EA.V187-17,Dynamics of Bitcoin trading on the Binance cryptocurrency exchange; [Динаміка розвитку торгів біткоїнами на криптовалютній біржі Binance]; [Динамика развития торгов биткоинами на криптовалютной бирже Binance],"Currently, there are a great number of platform-projects and frameworks based on blockchain technology. Consequently, it is necessary to define the most relevant blockchain platforms and analyze them taking into consideration a variety of features. Also, there is a need to investigate the logistics growth and the price of Bitcoin on the Binance cryptocurrency exchange. The authors have examined modern technologies used by manufacturing companies in the field of fintech in the context of the 2019-2024 period. The results show that sensors and automatic identification take the leading position both at present and in 2024. Artificial intelligence and blockchain are also in demand by manufacturers today, however in the nearest future their ranking positions will increase sixfold from 10% to 60%. In the current paper the authors review the largest companies that effectively use blockchain technology in their businesses. The conducted survey shows that 18% of companies use blockchain technology based on Bitcoin. The authors have analysed a number of Bitcoin transactions for the period from January 2017 to February 2021 and concluded that the COVID-19 pandemic has had a favourable effect on the indicator data. A maximum number of transactions equal to 10.15 million was carried out in July 2020. Using the method of the Ordinary Least Squares (OLS) and statistical estimation methods the authors have revealed an underestimation of the equilibrium state of the empirical distribution of price data and the volume of daily trading of Bitcoin on the Binance cryptocurrency exchange through the channel of the right-hand confidence interval. The blockchain technology based on Bitcoin has positively reacted to the macroeconomic factors such as the COVID-19 pandemics and further growth in Bitcoin transactions is expected. With the help of economic modelling, the authors have defined the predictable volume and the price of Bitcoin on the Binance cryptocurrency exchange. © Institute of Society Transformation, 2021.",10.21003/ea.v187-17,Bitcoin; Blockchain technology; Cryptocurrency; Financial market; Fintech,SCOPUS,"The study analyzes the growth and price dynamics of Bitcoin trading on the Binance exchange, using statistical models to predict trading volume and price.",✔️,Bitcoin,❌,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606099,EVORA: Deep Evidential Traversability Learning for Risk-Aware Off-Road Autonomy,"Traversing terrain with good traction is crucial for achieving fast off-road navigation. Instead of manually designing costs based on terrain features, existing methods learn terrain properties directly from data via self-supervision to automatically penalize trajectories moving through undesirable terrain, but challenges remain in properly quantifying and mitigating the risk due to uncertainty in the learned models. To this end, we present evidential off-road autonomy (EVORA), a unified framework to learn uncertainty-aware traction model and plan risk-aware trajectories. For uncertainty quantification, we efficiently model both aleatoric and epistemic uncertainty by learning discrete traction distributions and probability densities of the traction predictor's latent features. Leveraging evidential deep learning, we parameterize Dirichlet distributions with the network outputs and propose a novel uncertainty-aware squared Earth Mover's Distance loss with a closed-form expression that improves learning accuracy and navigation performance. For risk-aware navigation, the proposed planner simulates state trajectories with the worst-case expected traction to handle aleatoric uncertainty and penalizes trajectories moving through terrain with high epistemic uncertainty. Our approach is extensively validated in simulation and on wheeled and quadruped robots, showing improved navigation performance compared to methods that assume no slip, assume the expected traction, or optimize for the worst-case expected cost.",10.1109/tro.2024.3431828,Uncertainty;Navigation;Robots;Costs;Planning;Trajectory;Semantics;Autonomous robots;self-supervised learning;uncertainty quantification;off-road navigation,IEEE,"EVORA, an evidential deep learning framework, is proposed for traversability learning in autonomous driving, incorporating uncertainty-aware models for risk-aware navigation.",❌,?,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10029354,Effective Exploitation of Macroeconomic Indicators for Stock Direction Classification Using the Multimodal Fusion Transformer,"An enormous ripple effect can occur in financial data mining if it accurately predicts stock prices. However, predicting stock prices using only stock price data is difficult because of the random nature of stock price data. This paper attempts to fuse data to solve the stock price prediction problem. The following data affecting the stock price are added to the proposed method as an additional modality: macroeconomic indicators and the months and day of the week. The multimodal early fusion method is used, which learns the intermodality correlation of features. The proposed model in this paper outperformed the comparison models and achieved statistically significant results. Specifically, 27 out of 50 stocks achieved higher classification accuracy than the comparative model. In addition, the in-depth analysis indicates that the early fusion strategy achieved better classification accuracy in 30 of 50 datasets than the late fusion strategy for stock price prediction.",10.1109/access.2023.3240422,Hidden Markov models;Transformers;Predictive models;Macroeconomics;Correlation;Stock markets;Feature extraction;Stock price prediction;multimodal learning;information fusion;macroeconomic data;technical indicator,IEEE,"An adaptive SVR model with dynamic parameter optimization is introduced for high-frequency stock price forecasting, outperforming traditional SVR and neural networks across various time scales.",✔️,Stock,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10584081,Efficient Deep Q-Learning for Industrial Equipment Calibration in Elevator Manufacturing,"Industrial equipment calibration is an essential element for the proper functioning of any production plant. Without frequent and proper calibration, the quality and efficiency of the overall production process are threatened. Despite its significance, it is often performed manually based on qualitative measures that may lead to suboptimal behavior. In this article, we propose a deep reinforcement learning (RL)-based methodology to automate the calibration process and evaluate it in an elevator control use case. Moreover, to overcome data scarcity we develop a simulation environment based on generative modeling that creates synthetic RL episodes. The proposed methodology relies on a minimal set of sensors and actuators, i.e., a webcam, an Arduino board, three stepper motors, and an edge computational unit. Nevertheless, experimental evaluations indicate that it can perform in real-time applications achieving accurate calibration results.",10.1109/tii.2024.3417254,Calibration;Elevators;Webcams;Motors;Soft sensors;Q-learning;Feature extraction;Automatic calibration;deep Q-learning;parameter estimation;reinforcement learning (RL),IEEE,"Develops a deep reinforcement learning methodology to automate industrial equipment calibration in elevator manufacturing, demonstrating real-time accurate results.",❌,?,?,?
10.3390/su14105826,Emotional Artificial Neural Networks and Gaussian Process-Regression-Based Hybrid Machine-Learning Model for Prediction of Security and Privacy Effects on M-Banking Attractiveness,"With recent advances in mobile and internet technologies, the digital payment market is an increasingly integral part of people’s lives, offering many useful and interesting services, e.g., m-banking and cryptocurrency. The m-banking system allows users to pay for goods, services, and earn money via cryptotrading using any device such as mobile phones from anywhere. With the recent trends in global digital markets, especially the cryptocurrency market, m-banking is projected to have a brighter future. However, information stored or conveyed via these channels is more vulnerable to different security threats. Thus, the aim of this study is to examine the influence of security and confidentiality on m-banking patronage using artificial intelligence ensemble methods (ANFIS, GPR, EANN, and BRT) for the prediction of safety and secrecy effects. AI models were trained and tested using 745 datasets obtained from the study areas. The results indicated that AI models predicted the influence of security with high precision (NSE > 0.95), with the GPR model outperformed the other models. The results indicated that security and privacy were key influential parameters of m-payment system patronage (m-banking), followed by service and interface quali-ties. Unlike previous m-banking studies, the study results showed ease of use and culture to have no influence on m-banking patronage. These study results would assist m-payment system stake-holders, while the approach may serve as motivation for researchers to use AI techniques. The study also provides directions for future m-banking studies. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",10.3390/su14105826,artificial intelligence; ensemble techniques; m-banking; machine learning; privacy; security,SCOPUS,"Develops a hybrid machine learning model combining emotional artificial neural networks and Gaussian process regression to predict the impact of security and privacy on the attractiveness of mobile banking, with GPR showing superior performance.",❌,?,✔️,✔️
WOS:000873142500002,Encoded Value-at-Risk: A machine learning approach for portfolio risk measurement,"Measuring risk is at the center of modern financial risk management. As the world economy is becoming more complex and standard modelling assumptions are violated, the advanced artificial intelligence solutions may provide the right tools to analyse the global market. In this paper, we provide a novel approach for measuring market risk called Encoded Value-at-Risk (Encoded VaR), which is based on a type of artificial neural network, called Variational Auto-encoders (VAEs). Encoded VaR is a generative model which can be used to reproduce market scenarios from a range of historical cross-sectional stock returns, while increasing the signal-to-noise ratio present in the financial data, and learning the dependency structure of the market without any assumptions about the joint distribution of stock returns. We compare Encoded VaR out-of-sample results with twelve other methods and show that it is competitive to many other well-known VaR algorithms presented in the literature. (C) 2022 International Association for Mathematics and Computers in Simulation (IMACS). Published by Elsevier B.V. All rights reserved.",10.1016/j.matcom.2022.07.015,Value-at-risk; Financial risk management; Machine learning; Artificial neural networks; Variational autoencoders,WOS,"Encoded Value-at-Risk (Encoded VaR), a novel machine learning approach using Variational Auto-Encoders, is introduced for portfolio risk measurement, demonstrating competitive performance against established VaR methods.",❌,,✔️,✔️
WOS:001258447000001,Enhanced prediction of stock markets using a novel deep learning model PLSTM-TAL in urbanized smart cities,"Accurate predictions of stock markets are important for investors and other stakeholders of the equity markets to formulate profitable investment strategies. The improved accuracy of a prediction model even with a slight margin can translate into considerable monetary returns. However, the stock markets' prediction is regarded as an intricate research problem for the noise, complexity and volatility of the stocks' data. In recent years, the deep learning models have been successful in providing robust forecasts for sequential data. We propose a novel deep learning -based hybrid classification model by combining peephole LSTM with temporal attention layer (TAL) to accurately predict the direction of stock markets. The daily data of four world indices including those of U.S., U.K., China and India, from 2005 to 2022, are examined. We present a comprehensive evaluation with preliminary data analysis, feature extraction and hyperparameters' optimization for the problem of stock market prediction. TAL is introduced post peephole LSTM to select the relevant information with respect to time and enhance the performance of the proposed model. The prediction performance of the proposed model is compared with that of the benchmark models CNN, LSTM, SVM and RF using evaluation metrics of accuracy, precision, recall, F1 -score, AUC-ROC, PR-AUC and MCC. The experimental results show the superior performance of our proposed model achieving better scores than the benchmark models for most evaluation metrics and for all datasets. The accuracy of the proposed model is 96% and 88% for U.K. and Chinese stock markets respectively and it is 85% for both U.S. and Indian markets. Hence, the stock markets of U.K. and China are found to be more predictable than those of U.S. and India. Significant findings of our work include that the attention layer enables peephole LSTM to better identify the long-term dependencies and temporal patterns in the stock markets' data. Profitable and timely trading strategies can be formulated based on our proposed prediction model.",10.1016/j.heliyon.2024.e27747,Bayesian optimization; Contractive autoencoder; Ensemble empirical mode decomposition; Peephole LSTM; Stock market prediction; Temporal attention layer; Time series; Urban planing,WOS,"Proposes a novel deep learning hybrid model combining peephole LSTM with temporal attention layer to accurately predict the direction of stock markets for major indices in US, UK, China, and India.",✔️,Stock Indices,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10156850,Enhancing Cryptocurrency Price Forecasting Accuracy: A Feature Selection and Weighting Approach With Bi-Directional LSTM and Trend-Preserving Model Bias Correction,"A cryptocurrency is a digitized, encrypted, and decentralized virtual currency, which is impossible to counterfeit or double-spend. It is one of the very popular investment instruments and traded in blockchain based crypto exchanges on ever growing volume. It is quite volatile due to imbalance of supply and demand, government regulations, investor sentiment and above all media hype. Cryptocurrency price forecasting is an active area of research and several approaches have been proposed recently. This study proposed a price forecasting model based on three vital characteristics (i) a feature selection and weighting approach based on Mean Decrease Impurity(MDI) features. (ii) Bi-directional LSTM and (iii) with a trend preserving model bias correction (CUSUM control charts for monitoring the model performance over time) to forecast Bitcoin and Ethereum values for long and short term spans. The data for both currencies were analyzed in three different intervals: (i) April 01, 2013 to April 01, 2016 (ii) April 01, 2013 to April 01, 2017 and (iii) April 01, 2013 to December 31, 2019. Extensive series of experiments were performed and evaluated on Root Mean Square Errors (RMSE). For bitcoin forecasting, the model achieved RMSE values 3.499 for interval 1, 5.070 for interval 2 and 6.642 for interval 3. Similarly, for Ethereum RSME of 0.094, 0.332, 3.027 are obtained for the three intervals respectively, On a new test-set collected from January 01, 2020 to January 01, 2022 for the two cryptocurrencies we obtained an average RSME of 9.17, with model bias correction, Comparing with the prevalent forecasting models we report a new state of the art in cryptocurrency forecasting.",10.1109/access.2023.3287888,Predictive models;Bitcoin;Forecasting;Data models;Long short term memory;Machine learning;Blockchains;Blockchain;cryptocurrency;machine learning,IEEE,"The study presents a cryptocurrency price forecasting model combining feature selection, bidirectional LSTM, and bias correction, achieving state-of-the-art accuracy for Bitcoin and Ethereum predictions.",✔️,"Bitcoin, Ethereum",✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919398,Enhancing Stock Portfolios for Enterprise Management and Investment in Energy Industry,"Renewable energy is critical to the energy industry, even more so given the recent surge in oil and gas prices. As a result, the oil and gas sector is constantly preparing for the coming energy transition. This raises the question of when the oil and gas industry should invest in renewable energy sources. This article examines the history of oil company involvement in renewable energy to address this question. It also establishes and quantifies a relationship between renewable energy investment and oil and gas prices, followed by a projection of renewable energy investment based on oil and gas prices. A decision support system based on crude oil prices and renewable energy stocks is developed to predict renewable energy investment decisions. According to the experiments, the prediction model used provides favorable mean square values compared to other models. An algorithm based on the price of oil determines whether to invest in shares of renewable energy companies. The performance of a company is evaluated based on its expected profitability.",10.1109/tii.2022.3214518,Oils;Renewable energy sources;Forecasting;Predictive models;Companies;Portfolios;Probabilistic logic;Classification;decision support system;forecasting;portfolio management;renewable energy,IEEE,"Integrates GARCH models with LSTM networks using non-linear filtering to adjust volatility distributions, enhancing prediction accuracy for S&P 500 volatility.",✔️,Stock Market Volatility (S&P 500),✔️,✔️
WOS:000574481400002,Enhancing profit from stock transactions using neural networks,"Financial time-series forecasting, and profit maximization is a challenging task, which has attracted the interest of several researchers and is immensely important for investors. In this paper, we present a deep learning system, which uses a variety of data for a subset of the stocks on the NASDAQ exchange to forecast the stock price. Our framework allows the use of a variational autoencoder (VAE) to remove noise and time-series data engineering to extract higher-level features. A Stacked LSTM Autoencoder is used to perform multi-step-ahead prediction of the stock closing price. This prediction is used by two profit-maximization strategies that include greedy approach and short selling. Besides, we use reinforcement learning as a third profit-enhancement strategy and compare these three strategies to offline strategies that use the actual future prices. Results show that the proposed methods outperform the state-of-the-art time-series forecasting approaches in terms of predictive accuracy and profitability.",10.3233/aic-200629,Financial time series prediction; stock price; LSTM autoencoder; feature engineering; reinforcement learning,WOS,A deep learning system utilizing variational autoencoders and LSTM autoencoders is proposed for stock price forecasting and profit maximization through various trading strategies.,✔️,Stocks,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10073955,Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning With Applications in Autonomous Driving,"Reinforcement learning (RL) can be used to create a decision-making agent for autonomous driving. However, previous approaches provide black-box solutions, which do not offer information on how confident the agent is about its decisions. An estimate of both the aleatoric and epistemic uncertainty of the agent’s decisions is fundamental for real-world applications of autonomous driving. Therefore, this paper introduces the Ensemble Quantile Networks (EQN) method, which combines distributional RL with an ensemble approach, to obtain a complete uncertainty estimate. The distribution over returns is estimated by learning its quantile function implicitly, which gives the aleatoric uncertainty, whereas an ensemble of agents is trained on bootstrapped data to provide a Bayesian estimation of the epistemic uncertainty. A criterion for classifying which decisions that have an unacceptable uncertainty is also introduced. The results show that the EQN method can balance risk and time efficiency in different occluded intersection scenarios, by considering the estimated aleatoric uncertainty. Furthermore, it is shown that the trained agent can use the epistemic uncertainty information to identify situations that the agent has not been trained for and thereby avoid making unfounded, potentially dangerous, decisions outside of the training distribution.",10.1109/tits.2023.3251376,Uncertainty;Autonomous vehicles;Training;Decision making;Reinforcement learning;Bayes methods;Neural networks;Reinforcement learning;aleatoric uncertainty;epistemic uncertainty;autonomous driving;decision-making,IEEE,"Develops a Bayesian Neural Network with latent factors (LFBNN) for predicting used car prices, incorporating uncertainty estimation and noise reduction, and implemented on a cloud platform for improved accuracy and performance.",❌,Used Car Prices,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405660,Ensemble Technique With Optimal Feature Selection for Saudi Stock Market Prediction: A Novel Hybrid Red Deer-Grey Algorithm,"The forecast of the stock price attempts to assess the potential movement of the financial exchange's stock value. The exact estimation of the movement of share price would contribute more to investors' profit. This paper introduces a new stock market prediction model that includes three major phases: feature extraction, optimal feature selection, and prediction. Initially, statistical features like mean, standard deviation, variance, skewness, and kurtosis is extracted from the collected stock market data. Further, the indexed data collected are also computed concerning standard indicators like Average True Range (ATR), Exponential Moving Average (EMA), Relative Strength Index (RSI), and Rate of Change (ROC). To acquire best-predicted results, it is more crucial to select the most relevant features. Such that, the optimal features are selected from the extracted features (technical indicators based features, statistical features) by a new hybrid model referred to Red Deer Adopted Wolf Algorithm (RDAWA). Further, the selected features are subjected to the ensemble technique for predicting the stock movement. The ensemble technique involves the classifiers like Support Vector Machine (SVM), Random Forest1 (RF1), Random Forest2 (RF2), and optimized Neural Network (NN), respectively. The final predicted results are acquired from the Optimized Neural Network (NN). To make the precise prediction, the training of NN is carried out by the proposed RDAWA via fine-tuning the optimal weight. Finally, the performance of the proposed work is compared over other conventional models with respect to certain measures.",10.1109/access.2021.3073507,Hidden Markov models;Forecasting;Stock markets;Feature extraction;Support vector machines;Predictive models;Indexes;Saudi stock market prediction;close price;second order technical indicators;pre classifier,IEEE,"An ensemble technique with a hybrid Red Deer-Grey Algorithm is developed for Saudi stock market prediction, utilizing optimal feature selection and ensemble classifiers to achieve high prediction accuracy.",✔️,Saudi Stock Market,✔️,❌
WOS:000185922400015,Estimation of dynamic bivariate mixture models: Comments on Watanabe (2000),"This note compares a Bayesian Markov chain Monte Carlo approach implemented by Watanabe with a maximum likelihood ML approach based on an efficient importance sampling procedure to estimate dynamic bivariate mixture models. In these models, stock price volatility and trading volume are jointly directed by the unobservable number of price-relevant information arrivals, which is specified as a serially correlated random variable. It is shown that the efficient importance sampling technique is extremely accurate and that it produces results that differ significantly from those reported by Watanabe.",10.1198/073500103288619287,Bayesian posterior means; efficient importance sampling; latent variable; Markov chain Monte Carlo; maximum likelihood,WOS,"Compares Bayesian MCMC approach with maximum likelihood approach for estimating dynamic bivariate mixture models related to stock price volatility and trading volume, finding importance sampling accurate.",✔️,Stock Prices,❌,✔️
WOS:000701133500001,Estimation with Uncertainty via Conditional Generative Adversarial Networks,"Conventional predictive Artificial Neural Networks (ANNs) commonly employ deterministic weight matrices; therefore, their prediction is a point estimate. Such a deterministic nature in ANNs causes the limitations of using ANNs for medical diagnosis, law problems, and portfolio management in which not only discovering the prediction but also the uncertainty of the prediction is essentially required. In order to address such a problem, we propose a predictive probabilistic neural network model, which corresponds to a different manner of using the generator in the conditional Generative Adversarial Network (cGAN) that has been routinely used for conditional sample generation. By reversing the input and output of ordinary cGAN, the model can be successfully used as a predictive model; moreover, the model is robust against noises since adversarial training is employed. In addition, to measure the uncertainty of predictions, we introduce the entropy and relative entropy for regression problems and classification problems, respectively. The proposed framework is applied to stock market data and an image classification task. As a result, the proposed framework shows superior estimation performance, especially on noisy data; moreover, it is demonstrated that the proposed framework can properly estimate the uncertainty of predictions.",10.3390/s21186194,generative adversarial network; deep learning; adversarial learning; probability estimation; risk estimation; portfolio management,WOS,"Introduces a predictive probabilistic neural network model using conditional GANs to estimate stock prices with uncertainty quantification, showing superior performance especially on noisy data.",✔️,Stock Prices,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335921,Examining the Forecasting Movement of Palm Oil Price Using RBFNN-2SATRA Metaheuristic Algorithms for Logic Mining,"RBFNN with different algorithms and the logic mining method for forecasting constitute the most significant tools and techniques, which are used to demonstrate the economic growth in the country. Upon using monthly data spanning from Jan 2016 to March 2020 for the manufacturing of palm oil, the results mainly revealed that RBFNN-2SATRAAIS is the most accurate and efficient model compared to RBFNN-2SATRAPSO and RBFNN-2SATRAGA in forecasting the price of palm oil. RBFNN-2SATRAAIS had the highest average overall accuracy (90.476190%), followed by RBFNN-2SATRAPSO (85.71%), and RBFNN-2SATRAGA (76.19%). The results also showed that the spot price of palm oil is highly influenced by the total exports and imports, as well as the production of palm oil, its end-stocks, and Malaysia’s real, effective exchange rate. By using the data mining technique based on the energy minimization technique, the logical mining task was carried out. The empirical findings provided useful insights into decision-making and policy implementations, including the formulation of strategies to help the industry in dealing with constant price fluctuations and, thereby, enabling the Malaysian palm oil industry to continue its domination over the international market.",10.1109/access.2021.3054816,Oils;Data mining;Forecasting;Prediction algorithms;Petroleum industry;Neurons;Genetic algorithms;Palm oil prices;economic growth;forecasting;artificial immune system;particle swarm optimization;genetic algorithm;radial basis functions neural network;2 satisfiability;2 satisfiability reverse;Analysis;logic mining,IEEE,"Utilizes RBFNN-based metaheuristic algorithms to forecast palm oil prices, showing high accuracy and efficiency compared to other models.",✔️,Commodity (Palm Oil),✔️,❌
WOS:001097165900021,Exploiting Data Science for Measuring the Performance of Technology Stocks,"The rise or fall of the stock markets directly affects investors' interest and loyalty. Therefore, it is necessary to measure the performance of stocks in the market in advance to prevent our assets from suffering significant losses. In our proposed study, six supervised machine learning (ML) strategies and deep learning (DL) models with long short-term memory (LSTM) of data science was deployed for thorough analysis and measurement of the performance of the technology stocks. Under discussion are Apple Inc. (AAPL), Microsoft Corporation (NVDA), and Avigilon Corporation (AVGO). The datasets were taken from the Yahoo Finance API from 06-052005 to 06-05-2022 (seventeen years) with 4280 samples. As already noted, multiple studies have been performed to resolve this problem using linear regression, support vector machines, deep long short-term memory (LSTM), and many other models. In this research, the Hidden Markov Model (HMM) outperformed other employed machine learning ensembles, tree-based models, the ARIMA (Auto Regressive Integrated Moving Average) model, and long short-term memory with a robust mean accuracy score of 99.98. Other statistical analyses and measurements for machine learning ensemble algorithms, the Long Short-Term Model, and ARIMA were also carried out for further investigation of the performance of advanced models for forecasting time series data. Thus, the proposed research found the best model to be HMM, and LSTM was the second-best model that performed well in all aspects. A developed model will be highly recommended and helpful for early measurement of technology stock performance for investment or withdrawal based on the future stock rise or fall for creating smart environments.",10.32604/cmc.2023.036553,Machine learning; data science; smart environments; stocks movement; deep learning; stock marketing,WOS,"Machine learning models, including Hidden Markov Models, are employed to predict the performance of technology stocks, achieving high accuracy and aiding investment decisions.",✔️,Technology Stocks,✔️,❌
10.1007/s10796-018-9859-2,Extracting Knowledge from Technical Reports for the Valuation of West Texas Intermediate Crude Oil Futures,"This paper proposes and demonstrates an approach for the often-attempted problem of market prediction, framed as classification task. We restrict our study to a widely purchased and well recognized commodity, West Texas Intermediate crude oil, which experiences significant volatility. For this purpose, nine learners using features extracted from monthly International Energy Agency (IEA) reports to predict undervalued, overvalued, and accurate valuation of the oil futures between 2003 and 2015. The often touted “Efficient Market Hypothesis” (EMH) suggests that it is impossible for individual investors to “beat the market” as market and external forces, such as geopolitical crises and natural disasters, are nearly impossible to predict. However, four algorithms were statistically better at the 95% confidence interval than “Zero-Rule” and “Random-Guess” strategies which are expected to pseudo-reflect the EMH. Furthermore, the addition of text features can significantly improve performance compared to only using price history from the oil futures data, challenging the validity of the semi-strong versions of the EMH in the crude oil market. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.",10.1007/s10796-018-9859-2,Crude oil market; Machine learning; Text mining,SCOPUS,"The paper presents machine learning classifiers that use technical report features to classify West Texas Intermediate crude oil futures as undervalued, overvalued, or accurately valued, outperforming baseline methods.",✔️,West Texas Intermediate crude oil futures,✔️,❌
10.1016/j.jpdc.2020.09.002,FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures,"This paper presents a novel leaderless protocol (FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures) with a low communicational complexity and which allows a set of nodes to come to a consensus on a value of a single bit. The paper makes the assumption that part of the nodes are Byzantine, and are thus controlled by an adversary who intends to either delay the consensus, or break it (this defines that at least a couple of honest nodes come to different conclusions). We prove that, nevertheless, the protocol works with high probability when its parameters are suitably chosen. Along this the paper also provides explicit estimates on the probability that the protocol finalizes in the consensus state in a given time. This protocol could be applied to reaching consensus in decentralized cryptocurrency systems. A special feature of it is that it makes use of a sequence of random numbers which are either provided by a trusted source or generated by the nodes themselves using some decentralized random number generating protocol. This increases the overall trustworthiness of the infrastructure. A core contribution of the paper is that it uses a very weak consensus to obtain a strong consensus on the value of a bit, and which can relate to the validity of a transaction. © 2020 Elsevier Inc.",10.1016/j.jpdc.2020.09.002,Consensus; Decentralized cryptocurrency systems; Decentralized randomness; Voting,SCOPUS,"The paper introduces a fast probabilistic consensus protocol for Byzantine infrastructures, potentially applicable to decentralized cryptocurrency systems for secure and efficient consensus.",❌,,❌,✔️
WOS:000730914100009,Failure in Stock Price Prediction: A Comparison between the Curve-Shape-Feature and Non-Curve-Shape-Feature Modes of Existing Machine Learning Algorithms,"In the era of artificial intelligence, machine learning methods are successfully used in various fields. Machine learning has attracted extensive attention from investors in the financial market, especially in stock price prediction. However, one argument for the machine learning methods used in stock price prediction is that they are black-box models which are difficult to interpret. In this paper, we focus on the future stock price prediction with the historical stock price by machine learning and deep learning methods, such as support vector machine (SVM), random forest (RF), Bayesian classifier (BC), decision tree (DT), multilayer perceptron (MLP), convolutional neural network (CNN), bi-directional long-short term memory (BiLSTM), the embedded CNN, and the embedded BiLSTM. Firstly, we manually design several financial time series where the future price correlates with the historical stock prices in pre-designed modes, namely the curve-shape-feature (CSF) and the non-curve-shape-feature (NCSF) modes. In the CSF mode, the future prices can be extracted from the curve shapes of the historical stock prices. Conversely, in the NCSF mode, they can't. Secondly, we apply various algorithms to those pre-designed and real financial time series. We find that the existing machine learning and deep learning algorithms fail in stock price prediction because in the real financial time series, less information of future prices is contained in the CSF mode, and perhaps more information is contained in the NCSF. Various machine learning and deep learning algorithms are good at handling the CSF in historical data, which are successfully applied in image recognition and natural language processing. However, they are inappropriate for stock price prediction on account of the NCSF. Therefore, accurate stock price prediction is the key to successful investment, and new machine learning algorithms handling the NCSF series are needed.",10.15837/ijccc.2021.6.4549,stock price prediction; financial time series; machine learning method; deep learn-ing method,WOS,"Analyzes why existing machine learning and deep learning algorithms struggle to accurately predict stock prices, attributing it to the predominance of non-curve-shape features in financial time series data.",✔️,Stock Prices,✔️,❌
WOS:001153279000001,Fin-GAN: forecasting and classifying financial time series via generative adversarial networks,"We investigate the use of Generative Adversarial Networks (GANs) for probabilistic forecasting of financial time series. To this end, we introduce a novel economics-driven loss function for the generator. This newly designed loss function renders GANs more suitable for a classification task, and places them into a supervised learning setting, whilst producing full conditional probability distributions of price returns given previous historical values. Our approach moves beyond the point estimates traditionally employed in the forecasting literature, and allows for uncertainty estimates. Numerical experiments on equity data showcase the effectiveness of our proposed methodology, which achieves higher Sharpe Ratios compared to classical supervised learning models, such as LSTMs and ARIMA.",10.1080/14697688.2023.2299466,GANs; Financial returns; Time series forecasting; Classification; G17; C15; C22; C32; C45; C53,WOS,"The paper introduces Fin-GAN, a Generative Adversarial Network-based model for probabilistic forecasting and classification of financial time series, producing conditional probability distributions and uncertainty estimates.",✔️,Equity data,✔️,✔️
WOS:000471974900001,Financial Latent Dirichlet Allocation (FinLDA): Feature Extraction in Text and Data Mining for Financial Time Series Prediction,"News has been an important source for many financial time series predictions based on fundamental analysis. However, digesting a massive amount of news and data published on the Internet to predict a market can be burdensome. This paper introduces a topic model based on latent Dirichlet allocation (LDA) to discover features from a combination of text, especially news articles and financial time series, denoted as Financial LDA (FinLDA). The features from FinLDA are served as additional input features for any machine learning algorithm to improve the prediction of the financial time series. We provide posterior distributions used in Gibbs sampling for two variants of the FinLDA and propose a framework for applying the FinLDA in a text and data mining for financial time series prediction. The experimental results show that the features from the FinLDA empirically add value to the prediction and give better results than the comparative features including topic distributions from the common LDA.",10.1109/access.2019.2919993,Bayesian method; data mining; data preparation; data processing; feature extraction; financial time series; information processing; latent Dirichlet allocation; news; prediction; stock market; text mining; topic modeling,WOS,"Develops Financial LDA (FinLDA), a latent Dirichlet allocation-based feature extraction method combining text and data mining, to enhance machine learning models in predicting financial time series.",✔️,Financial Time Series,✔️,✔️
WOS:000604846000002,Financial risk assessment in shipping: a holistic machine learning based methodology,"Corporate financial distress (FD) prediction models are of great importance to all stakeholders, including regulators and banks, who rely on acceptable estimates of default risk, for both individual borrowers and bank loan portfolios. Whilst this subject has been covered extensively in finance research, its application to international shipping companies has been limited while the focus has mainly been on the application of traditional linear modelling, using sparse, cross-sectional financial statement data. Insufficient attention has been paid to the noisy and incomplete nature of shipping company financial statement information. This study contributes to the literature through the design, development and testing of a novel holistic machine learning methodology which integrates predictor evaluation and missing data analysis into the distress prediction process. The model was validated using a longitudinal dataset of over 5000 company year-end financial statements combined with macroeconomic and market predictors. We applied this methodology first for individual company level distress prediction before testing the models' ability to provide accurate confidence intervals by backtesting conditional value-at-risk estimations of the distress rates for bank portfolios. We conclude that, by adopting a holistic approach, our methodology can enhance financial monitoring of company loans and bank loan portfolios thereby providing a practical ""early warning system"" for financial distress.",10.1057/s41278-020-00183-2,Financial distress; Machine learning; Multivariate imputation; Random forest; Extreme gradient boosting; Generalised additive modelling; Conditional value-at-risk,WOS,"Develops a machine learning methodology to predict corporate financial distress in shipping, serving as an early warning system, validated with large datasets.",✔️,Corporate Financial Distress,✔️,❌
10.1515/jafio-2023-0043,Food Price Inflation in the United States as a Complex Dynamic Economic System,"The issue of volatile food prices is a consistent problem for American consumers, as rising prices make it challenging to afford nutritious food that meets dietary standards. Various complex factors influence this price volatility, including economic conditions, weather patterns, global trade, energy prices, and more. Notably, the impact of food price increases is not equal for everyone. Low-income individuals and those in rural areas are disproportionately affected. A comprehensive understanding of the driving factors is essential to tackle this issue effectively. We employ advanced time-series techniques such as Vector Error Correction Models (VECM) and modern causal inference methods such as probabilistic graphical models implemented via machine learning and artificial intelligence approaches on monthly data from 2000 to 2021 to investigate the U.S. food price inflation issue. These methods help unravel the intricate dynamics among key variables driving food price inflation. The study aims to achieve several objectives. It intends to (1) clarify how factors influencing food price inflation in the U.S. change over time using VECM models, (2) establish causal relationships among interconnected variables to develop probabilistic graphical models using innovative search algorithms, and (3) create and validate forecasts related to U.S. food price inflation. The end goal is to provide actionable insights for policy design. Results show that food price inflation is heavily tied to commodity pricing and pricing for medical services. Additionally, historical decompositions for COVID-19 show ties between food price inflation and energy inflation. © 2024 Walter de Gruyter GmbH, Berlin/Boston 2024.",10.1515/jafio-2023-0043,directed acyclic graphs; food price inflation; innovation accounting; time-series analysis; vector error correction model,SCOPUS,"Analyzes food price inflation in the U.S. using machine learning and causal inference methods, identifying key factors like commodity and energy prices.",✔️,Food Prices,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580751,Forecast-Driven Stochastic Scheduling of a Virtual Power Plant in Energy and Reserve Markets,"Virtual power plants (VPPs) offer a cost-effective solution to incentivize coordination between different resources participating in joint energy and reserve markets. However, emerging technologies such as storage and demand response cannot deliver flexibility over long periods due to inherent energy limitations. In this article, we, therefore, inform the day-ahead scheduling of VPPs with forecast scenarios of the balancing stage, which are complemented with information on nonshiftable load, renewable generation, and electricity prices. These multivariate scenarios (incorporating both time and cross-variable dependencies) are obtained using a machine learning framework in which probabilistic forecasts are converted into time trajectories using a copula-based sampling. The model is enriched with a detailed representation of the intraday decision stage wherein all flexible resources are dynamically allocated over the daily horizon. To ensure the reliability of the solution, we take into full consideration the revenues and unit-specific costs related to the activation of reserves. Outcomes show that improving the representation of the intraday dispatch stage while relying on representative balancing uncertainties are two complementary components for increasing the quality of the VPP day-ahead strategy, which ultimately fosters its economic value.",10.1109/jsyst.2021.3114445,Uncertainty;Costs;Real-time systems;Probabilistic logic;Predictive models;Renewable energy sources;Trajectory;Power generation;Long short term memory;Bidirectional long short-term memory (BLSTM);machine learning;renewable generation;virtual power plant (VPP),IEEE,"Develops an unsupervised machine learning model using Kernel PCA and Multivariate Kernel Density Estimation to detect stock price manipulation, overcoming parameter ambiguity and reducing computational complexity.",✔️,Stock Prices (Manipulation Detection),✔️,✔️
WOS:001244822200275,Forecasting Bitcoin Prices Using Deep Learning for Consumer-Centric Industrial Applications,"As cryptocurrencies become more popular as investment vehicles, bitcoin draws interest from businesses, consumers, and computer scientists all across the world. Bitcoin is a computer file stored in digital wallet applications where each transaction is secured using strong cryptographic algorithms. It was challenging to forecast the future price of bitcoin due to its nonlinearity and extreme volatility. Several recent classic parametric models have been found with limited accuracy. To address the limitations and fill the existing research gaps, there is a need for a good prediction model which will provide the desired accuracy in the case of uncertainty and dynamism. This research suggested a deep learning-based framework for predicting and forecasting Bitcoin price. The research will be helpful for worldwide consumers and industries to take their decision on whether to invest or not. The research utilizes Yahoo! finance dataset for the period of 01-03-2016 to 26-02-2021 having 1828 samples. The experimental outcomes of the proposed Long Short-Term Memory (LSTM) model outperformed similar deep learning models by securing minimum loss and confirming that it can be used for future price prediction of the cryptocurrencies, which is helpful for the buyer to take their decision.",10.1109/tce.2023.3321653,Bitcoin; Predictive models; Hidden Markov models; Deep learning; Data models; Analytical models; Training; cryptocurrency; bitcoin; GRU; LSTM; machine learning,WOS,"A deep learning-based framework using LSTM is developed to forecast Bitcoin prices, outperforming similar models and providing valuable insights for investment decisions based on historical price data.",✔️,Bitcoin,✔️,❌
WOS:000846325900001,"Forecasting Crude Oil Prices with Major S&P 500 Stock Prices: Deep Learning, Gaussian Process, and Vine Copula","This paper introduces methodologies in forecasting oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. We also apply Bayesian variable selection and nonlinear principal component analysis (NLPCA) for data dimension reduction. With a reduced number of important covariates, we also forecast oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. To apply real data to the proposed methods, we select monthly log returns of 2 oil prices and 74 large-cap, major S&P 500 stock prices across the period of February 2001-October 2019. We conclude that vine copula regression with NLPCA is superior overall to other proposed methods in terms of the measures of prediction errors.",10.3390/axioms11080375,oil prices; S&P 500; multivariate time series; Gaussian process model; vine copula; Bayesian variable selection; functional principal component analysis; nonlinear principal component analysis,WOS,"Forecasts Brent and WTI oil prices using Gaussian processes, deep learning, and vine copula regression with dimension reduction techniques, finding vine copula with NLPCA superior.",✔️,Brent and WTI Oil Prices,✔️,✔️
9798664751994,"Forecasting State Tax Revenues, Recessions and Their Uncertainties Using Mixed-Frequency Data, Model Averaging, Bootstrap, ROC Analysis and Machine Learning","In recent years models with mixed frequency have been extensively used to forecast low-frequency variables such as GDP and inflation, but we are one of the first to use this framework in state government revenue forecasting. New York State had a record of passing late budgets before. In order to facilitate budget negotiations, which often center on forecasts, we develop a Mixed-Data Sampling (MIDAS) model for revenue forecasting using jagged edge data sets in the first chapter. We forecast yearly tax revenues using monthly data on tax receipts and also two dynamic factors extracted from a set of selected monthly and quarterly indicators specific to the New York State and the U.S. economy separately. These three models are combined with optimal weights to generate monthly multi-period forecasts. The weights of the two dynamic factors are high at horizons more than 11 months, after which the monthly tax revenue variable picks up in its contribution as uncertainty is resolved. By combining we gain forecast efficiency at all horizons. Our sample covers fiscal years 1986–2020; and data till FY 2007 is used in estimation to generate and evaluate out-of-sample forecasts over FY 2008–2020. To coincide with the budget process, our forecasts start 18 months, and are continuously updated monthly till the end of the fiscal year. Our model allows for identification of reasons for forecast revisions as new information arrives on a monthly basis in a transparent manner. We document significant gains in forecast accuracy. The relative gain in forecasting efficiency is particularly significant during the cyclical downturns, including COVID-19 in 2020. Counterfactual analysis is implemented to study the marginal contribution of data at each horizon. We estimate the variances of combined out-of-sample forecasts with blocking-based residual bootstrap methodology. With the variance estimates, we provide fan charts for each fixed target fiscal year showing the underlying forecast uncertainty.In the second chapter, we study the role of the components of Conference Board Leading Economic Indicator (LEI). LEI has ten monthly variables. Out of the ten variables, S&P 500 stock price index, Initial Claims and Interest Rate Spread can be observed at frequencies higher than monthly. We explore if there are further improvements when the three variables are used in terms of higher frequencies. In our analysis, MIDAS regression is integrated with probit model (Probit-MIDAS). We find data at higher frequencies can perform at least as well as data at monthly frequency. Even if forecasts from high-frequency data do not outperform their monthly counterparts significantly, the high-frequency data still have timing advantages at some particular horizons as the recession forecasts are updated daily or weekly. Finally, we also find efficiency gain from the probability forecast combination in terms of receiver operating characteristic (ROC) curves.Even though many studies have established the existence of structural breaks and declining predictability in the relationship between GDP growth and yield spreads, business analysts continue to watch for the inversion of the spread as a leading indicator for recessions. In the third chapter, we reestablish the enduring power of spread to forecast recessions, notwithstanding the temporal instabilities. We use daily data on 10-year minus 3-month Treasury rates and other spreads to find the threshold value that produces the highest discriminatory power as measured by the ROC curve, and its functionals such as the hit rate, false alarm rate, area under the curve (AUC), and the Youden's index. Based on data from January 2, 1962 to July 16, 2020, we find that the threshold value has slowly drifted upwards from zero since the recessions of 1980, and was at 0.89% for 12-month-ahead forecasts as the recession of 2020 approached. Once the threshold is adjusted to its optimal value recursively in real time, the type I and II errors associated with each 10-month ahead forecasts for the six recent recessions remained unchanged around 80% hit rate accompanied by a false alarm rate of 20%. To account for the sampling variability, we use a circular block bootstrap procedure to construct the confidence intervals for these statistics. We also studied a modified interest rate spread where the 10-year rate was replaced by its near-term historical minimum value (Iqbal et al. 2019). It produced slightly better ROC curves, but the qualitative results remained the same.In the fourth chapter, we forecast New York State tax revenues with mixed-frequency data using newly evolving machine learning techniques. We experiment different options such as boosting, LASSO, sparse-group LASSO and a few other options. State tax revenues can be affected by recession, which is a rare event without large size of data for training. Thus we suggest boosting with restricted lags of macro variables as our final model. The role of monthly or quarterly data releases in annual state tax revenues is discussed by studying variables/lags selected by boosting. Forecast after COVID-19 in 2020 shows a negative tax revenue growth in the next fiscal year.",,,Proquest,"The paper develops mixed-data sampling (MIDAS) models integrated with machine learning techniques to forecast state tax revenues and recessions, demonstrating improved forecast accuracy and uncertainty estimation.",❌,?,✔️,✔️
https://doi.org/10.7906/indecs.18.4.7,Forecasting Stock Market Indices using Machine Learning Algorithms,"In recent years machine learning algorithms have become a very popular tool for analysing financial data and forecasting stock prices. The goal of this article is to forecast five major stock market indexes (DAX, Dow Jones, NASDAQ, Nikkei 225 and S&P 500) using machine learning algorithms (Linear regression, Gaussian Processes, SMOreg and neural network Multilayer Perceptron) on historical data covering the period February 1, 2010, to January 31, 2020. The forecasts were made by using historical data in different base period lengths and forecasting horizons. The precision of machine learning algorithms was evaluated with the help of error metrics. The results of the analysis have shown that machine learning algorithms achieved highly accurate forecasting performance. The overall precision of all algorithms was better for shorter base period lengths and forecast horizons. The results obtained from this analysis could help investors in determining their optimal investment strategy. Stock price prediction remains, however, one of the most complex issues in the field of finance.",10.7906/indecs.18.4.7,,Proquest,"Employs machine learning algorithms to forecast major stock market indices, demonstrating high accuracy especially for shorter periods.",✔️,"Stock Market Indices (DAX, Dow Jones, NASDAQ, Nikkei 225, S&P 500)",✔️,❌
WOS:001246495900002,Forecasting VIX using Bayesian deep learning,"Recently, deep learning techniques are gradually replacing traditional statistical and machine learning models as the first choice for price forecasting tasks. In this paper, we leverage probabilistic deep learning for inferring the volatility index VIX. We employ the probabilistic counterpart of WaveNet, Temporal Convolutional Network (TCN), and Transformers. We show that TCN outperforms all models with an RMSE around 0.189. In addition, it has been well known that modern neural networks provide inaccurate uncertainty estimates. For solving this problem, we use the standard deviation scaling to calibrate the networks. Furthermore, we found out that MNF with Gaussian prior outperforms Reparameterization Trick and Flipout models in terms of precision and uncertainty predictions. Finally, we claim that MNF with Cauchy and LogUniform prior distributions yield well-calibrated TCN, and Transformer and WaveNet networks being the former that best infer the VIX values for one and five-step-ahead forecasting, and the probabilistic Transformer model yields an adequate forecasting for the COVID-19 pandemic period.",10.1007/s41060-024-00562-5,Volatility index; Bayesian neural networks; Forecasting; Calibration,WOS,"This study employs probabilistic deep learning models, such as Bayesian WaveNet, Temporal Convolutional Networks, and Transformers, to forecast the VIX volatility index, incorporating uncertainty estimates to enhance prediction accuracy and reliability.",✔️,VIX,✔️,✔️
02522667,Forecasting classification of operating performance of enterprises by probabilistic neural network,"Classification of operating performance of the enterprises is not only a hot issue emphasized by the management, but it is even the important reference by investors in their decision-making. In general, the analysis of its performance is usually undertaken by models of financial prediction or credit rating. This paper address a lot of models to analyze it through the financial ratio from 287 private enterprises of traditional industry public listed in Taiwan's stock market and OTC as sample data. A hybrid methodology that combines both data mining and artificial intelligence is proposed to take advantage of the unique strength of single one model. First, we use the data mining technique, such as traditional principal components analysis, to select network input variables. Second, the various different models, including the Probabilistic Neural Network are also considered. Third, this paper shows that the classification ability of the Probabilistic Neural Network model, after the parameter adjusted by genetic algorithm, does significantly outperform other simple methods-back-propagation network, decision tree, and logistic regression model. In conclusion, experimental results with real data sets indicate that combined model can be an effective way to improve forecasting classification accuracy achieved by either of the one single models. [PUBLICATION ABSTRACT]",,,Proquest,"The paper proposes a hybrid methodology combining data mining and artificial intelligence, specifically utilizing a Probabilistic Neural Network optimized by genetic algorithms, to classify the operating performance of enterprises with improved accuracy.",❌,?,✔️,✔️
10.1016/j.neucom.2015.04.071,Forecasting exchange rate using deep belief networks and conjugate gradient method,"Forecasting exchange rates is an important financial problem. In this paper, an improved deep belief network (DBN) is proposed for forecasting exchange rates. By using continuous restricted Boltzmann machines (CRBMs) to construct a DBN, we update the classical DBN to model continuous data. The structure of DBN is optimally determined through experiments for application in exchange rates forecasting. Also, conjugate gradient method is applied to accelerate the learning for DBN. In the experiments, three exchange rate series are tested and six evaluation criteria are adopted to evaluate the performance of the proposed method. Comparison with typical forecasting methods such as feed forward neural network (FFNN) shows that the proposed method is applicable to the prediction of foreign exchange rate and works better than traditional methods. © 2015 Elsevier B.V.",10.1016/j.neucom.2015.04.071,Conjugate gradient; Continuous restricted Boltmann machines; Deep belief networks; Exchange rate forecasting,SCOPUS,"The paper presents an enhanced deep belief network model using continuous RBMs and conjugate gradient optimization for forecasting exchange rates, outperforming traditional methods.",✔️,Exchange rates,✔️,❌
WOS:001164585300001,Forecasting realized volatility of crude oil futures prices based on machine learning,"Extending the popular HAR model with additional information channels to forecast realized volatility of WTI futures prices, we show that machine learning-generated forecasts provide better forecasting quality and that portfolios that are constructed with these forecasts outperform their competing models resulting in economic gains. Analyzing the selection process, we show that information channels vary across forecasting horizon. Variable selection produces clusters and provides evidence that there are structural changes with regard to the significance of information channels.",10.1002/for.3077,crude oil; exogenous predictors; forecasting; machine learning; realized volatility,WOS,"The research extends the HAR model by integrating machine learning techniques to forecast the realized volatility of WTI crude oil futures, demonstrating improved forecasting quality and economic gains over traditional models.",✔️,Crude oil futures,✔️,✔️
WOS:000432501900002,Forecasting stock market index daily direction: A Bayesian Network approach,"In this work, we investigate the feasibility of Bayesian Networks as a way to verify the extent to which stock market indices from around the globe influence iBOVESPA - the main index at the Sao Paulo Stock Exchange, Brazil. To do so, index directions were input to a network designed to reflect some intuitive dependencies amongst continental markets, moving through 24 and 48 h cycles, and outputting iBOVESPA's next day closing direction. Two different network topologies were tested, with different numbers of stock indices used in each test. Best results were obtained with the model that accounts for a single index per continent, up to 24 h before iBOVESPA's closing time. Mean accuracy with this configuration was around 71% (with almost 78% top accuracy). With results comparable to those of the related literature, our model has the further advantage of being simpler and more tractable for its users. Also, along with the fact that it not only gives the next day closing direction, but also furnishes the set of indices that influence iBovespa the most, the model lends itself both to academic research purposes and as one of the building blocks in more robust decision support systems. (C) 2018 Elsevier Ltd. All rights reserved.",10.1016/j.eswa.2018.03.039,Stock direction prediction; Bayesian Networks; Machine learning; Applied artificial intelligence,WOS,"Employs Bayesian Networks to predict the daily closing direction of the iBOVESPA index based on global stock market indices, achieving around 71% accuracy with interpretable dependencies.",✔️,iBOVESPA Index,✔️,✔️
WOS:000976124800001,Forecasting the Stock Price of Listed Innovative SMEs Using Machine Learning Methods Based on Bayesian optimization: Evidence from China,"Innovative SMEs have had an important impact on the economies of emerging countries in recent years. In particular, the volatility of their share prices is closely related to economic development and investor behaviors. Therefore, this study takes the Chinese market as an example, after constructing 34 determinants that affect the stock price, the RF, DNN, GBDT, and Adaboost models under Bayesian optimization are employed to forecast the next day's closing price of listed innovative SMEs. The number of samples is 78,708 from 337 SMEs listed on the Chinese SSE STAR market, from July 22, 2019, to September 10, 2021 period. The experimental results show the RF and DNN models perform at a better prediction level than the GBDT and Adaboost models, in terms of the evaluation indicators of R-2, RMSE, MAPE, and DA. Then K-fold method and t-tests as robustness checks ensure our experimental results are more reliable and robust.",10.1007/s10614-023-10393-4,Innovative SMEs; Stock price; Bayesian optimization; Machine learning; K-fold method,WOS,"Uses machine learning models optimized by Bayesian optimization to forecast next day's closing price of listed innovative SMEs in China's SSE STAR market, showing RF and DNN outperform others.",✔️,Listed Innovative SMEs Stocks,✔️,❌
WOS:000279657800023,"Forecasting volatility under fractality, regime-switching, long memory and student-<i>t</i> innovations","The Markov-switching Multifractal model of asset returns with Student-t innovations (MSM-t henceforth) is introduced as an extension to the Markov-switching Multifractal model of asset returns (MSM). The MSM-t can be estimated via Maximum Likelihood (ML) and Generalized Method of Moments (GMM) and volatility forecasting can be performed via Bayesian updating (ML) or best linear forecasts (GMM). Monte Carlo simulations show that using GMM plus linear forecasts leads to minor losses in efficiency compared to optimal Bayesian forecasts based on ML estimates. The forecasting capability of the MSM-t model is evaluated empirically in a comprehensive panel forecasting analysis with three different cross-sections of assets at the country level (all-share equity indices, bond indices and real estate security indices). Empirical forecasts of the MSM-t model are compared to those obtained from its Gaussian counterparts and other volatility models of the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) family. In terms of mean absolute errors (mean squared errors), the MSM-t (Gaussian MSM) dominates all other models at most forecasting horizons for the various asset classes considered. Furthermore, forecast combinations obtained from the MSM and (Fractionally Integrated) GARCH models provide an improvement upon forecasts from single models. (C) 2010 Elsevier B.V. All rights reserved.",10.1016/j.csda.2010.03.005,Multiplicative volatility models; Long memory; Student-t innovations; International volatility forecasting,WOS,"Applies a scalable sparse formulation of the multidimensional nonstationary Maximum Entropy Principle to model and predict stock market indices, demonstrating superior performance compared to traditional GARCH models.",✔️,Stock Market Indices,❌,✔️
10.1007/s00521-024-09531-2,Forecasting wholesale prices of yellow corn through the Gaussian process regression,"For market players and policy officials, commodity price forecasts are crucial problems that are challenging to address due to the complexity of price time series. Given its strategic importance, corn crops are hardly an exception. The current paper evaluates the forecasting issue for China’s weekly wholesale price index for yellow corn from January 1, 2010 to January 10, 2020. We develop a Gaussian process regression model using cross validation and Bayesian optimizations over various kernels and basis functions that could effectively handle this sophisticated commodity price forecast problem. The model provides precise out-of-sample forecasts from January 4, 2019 to January 10, 2020, with a relative root mean square error, root mean square error, and mean absolute error of 1.245%, 1.605, and 0.936, respectively. The models developed here might be used by market players for market evaluations and decision-making as well as by policymakers for policy creation and execution. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.",10.1007/s00521-024-09531-2,Commodity price; Corn; Forecasting; Gaussian process regression; Machine learning,SCOPUS,"The paper develops a Gaussian process regression model to forecast China's weekly wholesale price index for yellow corn, providing precise out-of-sample forecasts useful for market players and policymakers.",✔️,Commodity (Yellow Corn),✔️,✔️
WOS:000275920800001,Foreign Exchange Market Prediction with Multiple Classifiers,"Foreign exchange market prediction is attractive and challenging. According to the efficient market and random walk hypotheses, market prices should follow a random walk pattern and thus should not be predictable with more than about 50% accuracy. fit this article, we investigate the predictability of foreign exchange spot rates of the US dollar against the British pound to show that not all periods are equally random. WC used the Hurst exponent to select a period with great predictability. Parameters for generating training patterns were determined heuristically by auto-mutual information and false nearest-neighbor methods. Some inductive machine-learning classifiers-artificial neural network, decision tree, k-nearest neighbor, and naive Bayesian classifier-were then trained with these generated patterns. Though appropriate collaboration of these models, we achieved a prediction accuracy of up to 67%. Copyright (C) 2009 John Wiley & Sons, Ltd.",10.1002/for.1124,foreign exchange market prediction; efficient market hypothesis; Hurst exponent; machine learning; model ensemble,WOS,"This study investigates the predictability of USD/GBP exchange rates using multiple machine learning classifiers, achieving up to 67% prediction accuracy.",✔️,Foreign Exchange (USD/GBP),✔️,❌
02776693,Foreign exchange market prediction with multiple classifiers,"Foreign exchange market prediction is attractive and challenging. According to the efficient market and random walk hypotheses, market prices should follow a random walk pattern and thus should not be predictable with more than about 50% accuracy. In this article, we investigate the predictability of foreign exchange spot rates of the US dollar against the British pound to show that not all periods are equally random. We used the Hurst exponent to select a period with great predictability. Parameters for generating training patterns were determined heuristically by auto-mutual information and false nearest-neighbor methods. Some inductive machine-learning classifiers - artificial neural network, decision tree, k-nearest neighbor, and naive Bayesian classifier - were then trained with these generated patterns. Through appropriate collaboration of these models, we achieved a prediction accuracy of up to 67%. [PUBLICATION ABSTRACT]",,,Proquest,"The article investigates the predictability of foreign exchange rates using multiple machine learning classifiers, achieving up to 67% prediction accuracy, thereby challenging the efficient market hypothesis.",✔️,Foreign Exchange,✔️,❌
WOS:001232701300001,Fossil energy market price prediction by using machine learning with optimal hyper-parameters: A comparative study,"Fossil energy markets are important commodities, and their price fluctuations impact worldwide economy and financial markets. Hence, it is essential to forecast the prices of fossil energy commodities. In this study, various machine learning systems are optimized by using Bayesian optimization method and implemented to forecast prices in 12 different fossil energy markets including crude oil, natural gas, propane, kerosene, gasoline, heating oil, and coal based on price information from all fossil energy markets. The optimized machine learning systems considered in modeling and simulations are Gaussian regression process, support vector regression, regression trees, k -nearest neighbor algorithm, and deep feedforward neural networks. The simulation results show that Gaussian regression process is the best system to forecast fossil energy markets. In addition, the deep learning feedforward neural networks system yields to stable forecasts. Furthermore, the prediction of the prices in natural gas, coal, and propane markets is a difficult task compared to the prediction of the prices in crude oil markets. The understanding of the effectiveness of machine learning systems in pricing different fossil energy markets can help international economic agents establish appropriate investment strategies.",10.1016/j.resourpol.2024.105008,Fossil energy market price; Machine learning; Gaussian regression process; Support vector regression; Regression trees; K -nearest neighbors; Deep feedforward neural networks; Bayesian optimization,WOS,"Compares ML systems optimized with Bayesian optimization to predict prices in 12 fossil energy markets, finding Gaussian regression process best.",✔️,Fossil Energy Commodities,✔️,❌
WOS:001227476100001,Fractional gaussian noise: Spectral density and estimation methods,"The fractional Brownian motion (fBm) process, governed by a fractional parameter H is an element of(0,1), is a continuous-time Gaussian process with its increment being the fractional Gaussian noise (fGn). This article first provides a computationally feasible expression for the spectral density of fGn. This expression enables us to assess the accuracy of a range of approximation methods, including the truncation method, Paxson's approximation, and the Taylor series expansion at the near-zero frequency. Next, we conduct an extensive Monte Carlo study comparing the finite sample performance and computational cost of alternative estimation methods for H under the fGn specification. These methods include two semi-parametric methods (based on the Taylor series expansion), two versions of the Whittle method (utilising either the computationally feasible expression or Paxson's approximation of the spectral density), a time-domain maximum likelihood (ML) method (employing a recursive approach for its likelihood calculation), and a change-of-frequency method. Special attention is paid to highly anti-persistent processes with H close to zero, which are of empirical relevance to financial volatility modelling. Considering the trade-off between statistical and computational efficiency, we recommend using either the Whittle ML method based on Paxson's approximation or the time-domain ML method. We model the log realized volatility dynamics of 40 financial assets in the US market from 2012 to 2019 with fBm. Although all estimation methods suggest rough volatility, the implied degree of roughness varies substantially with the estimation methods, highlighting the importance of understanding the finite sample performance of various estimation methods.",10.1111/jtsa.12750,Fractional Brownian motion; fractional Gaussian noise; semi-parametric method; maximum likelihood; Whittle likelihood; change-of-frequency; realised volatility,WOS,"The article provides computational methods for estimating spectral density and the Hurst parameter of fractional Gaussian noise, applying these to model log realized volatility of US financial assets, supporting the rough volatility hypothesis.",✔️,Realized volatility,❌,❌
0015198X,Fuzzy Neural Systems for Stock Selection,"Artificial neural systems suffer from an inability to explain the steps by which they reach decisions and from an inability to incorporate rules into their structure.  Fuzzy neural systems (FNS) address some of the shortcomings of artificial intelligence tools.  An FNS uses a new concept called neural gates, which are similar to the processing elements of artificial neural systems but can handle a broader range of information.  Neural gates can be applied to forecasting stock market returns, assessing country risk, and rating stocks based on fuzzy rules and probabilistic and Boolean logic.  An intelligent stock selection (ISS) system incorporating neural gates is presented.  The ISS combines the various advantages of expert systems, artificial neural systems, and fuzzy reasoning.  A stock selection application is provided.",,,Proquest,The paper presents an Intelligent Stock Selection (ISS) system that integrates fuzzy neural systems with expert systems to forecast stock market returns and facilitate stock selection based on fuzzy rules and probabilistic logic.,✔️,Stock,✔️,✔️
10.3772/j.issn.1006-6748.2023.02.002,GHM-FKNN: A generalized Heronian mean based fuzzy k-nearest neighbor classifier for the stock trend prediction,"Stock trend prediction is a challenging problem because it involves many variables. Aiming at the problem that some existing machine learning techniques, such as random forest (RF), probabilistic random forest (PRF), k-nearest neighbor (KNN), and fuzzy KNN (FKNN), have difficulty in accurately predicting the stock trend (uptrend or downtrend) for a given date, a generalized Heronian mean (GHM) based FKNN predictor named GHM-FKNN was proposed. GHM-FKNN combines GHM aggregation function with the ideas of the classical FKNN approach. After evaluation, the comparison results elucidated that GHM-FKNN outperformed the other best existing methods RF, PRF, KNN and FKNN on independent test datasets corresponding to three stocks, namely AAPL, AMZN and NFLX. Compared with RF, PRF, KNN and FKNN, GHM-FKNN achieved the best performance with accuracy of 62. 37% for AAPL, 58. 25% for AMZN, and 64. 10% for NFLX. © 2023 Inst. of Scientific and Technical Information of China. All rights reserved.",10.3772/j.issn.1006-6748.2023.02.002,fuzzy k-nearest neighbor (FKNN); Heronian mean; stock trend prediction,SCOPUS,"The paper presents GHM-FKNN, a generalized Heronian mean-based fuzzy k-nearest neighbor classifier, achieving superior accuracy in predicting stock trends for various companies.",✔️,"Stocks (AAPL, AMZN, NFLX)",✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976203,GIN: Graph-Based Interaction-Aware Constraint Policy Optimization for Autonomous Driving,"Applying reinforcement learning to autonomous driving entails particular challenges, primarily due to dynamically changing traffic flows. To address such challenges, it is necessary to quickly determine response strategies to the changing intentions of surrounding vehicles. This letter proposes a new policy optimization method for safe driving using graph-based interaction-aware constraints. In this framework, the motion prediction and control modules are trained simultaneously while sharing a latent representation that contains a social context. To reflect social interactions, we illustrate the movements of agents in graph form and filter the features with the graph convolution networks. This helps preserve the spatiotemporal locality of adjacent nodes. Furthermore, we create feedback loops to combine these two modules effectively. As a result, this approach encourages the learned controller to be safe from dynamic risks and renders the motion prediction robust to abnormal movements. In the experiment, we set up a navigation scenario comprising various situations with CARLA, an urban driving simulator. The experiments show state-of-the-art performance on navigation strategy and motion prediction compared to the baselines.",10.1109/lra.2022.3227862,Costs;Vehicle dynamics;Safety;Planning;Dynamics;Spatiotemporal phenomena;Roads;Integrated planning and learning;reinforcement learning;robot safety,IEEE,"Introduces a graph-based policy optimization method for safe autonomous driving, enhancing motion prediction and control modules with reinforcement learning.",❌,?,?,?
WOS:000336054200005,Gaussian Process-Mixture Conditional Heteroscedasticity,"Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.",10.1109/tpami.2013.183,Gaussian process; Pitman-Yor process; mixture model; conditional heteroscedasticity; copula; volatility modeling,WOS,"A nonparametric Bayesian Gaussian process-mixture model is introduced for volatility modeling in financial returns, capturing heavy tails and skewness effectively.",✔️,Financial Returns,✔️,✔️
WOS:000463062900004,Generative Bayesian neural network model for risk-neutral pricing of American index options,"Financial models with stochastic volatility or jumps play a critical role as alternative option pricing models for the classical Black-Scholes model, which have the ability to fit different market volatility structures. Recently, machine learning models have elicited considerable attention from researchers because of their improved prediction accuracy in pricing financial derivatives. We propose a generative Bayesian learning model that incorporates a prior reflecting a risk-neutral pricing structure to provide fair prices for the deep ITM and the deep OTM options that are rarely traded. We conduct a comprehensive empirical study to compare classical financial option models with machine learning models in terms of model estimation and prediction using S&P 100 American put options from 2003 to 2012. Results indicate that machine learning models demonstrate better prediction performance than the classical financial option models. Especially, we observe that the generative Bayesian neural network model demonstrates the best overall prediction performance.",10.1080/14697688.2018.1490807,American index option market; Generative Bayesian learning; Machine Learning; Financial option models; Option pricing,WOS,"The paper presents a generative Bayesian neural network model incorporating risk-neutral pricing for American index options, outperforming classical financial option models in estimation and prediction accuracy.",✔️,American index options,✔️,✔️
WOS:000610728400001,Global Stock Selection with Hidden Markov Model,"Hidden Markov model (HMM) is a powerful machine-learning method for data regime detection, especially time series data. In this paper, we establish a multi-step procedure for using HMM to select stocks from the global stock market. First, the five important factors of a stock are identified and scored based on its historical performances. Second, HMM is used to predict the regimes of six global economic indicators and find the time periods in the past during which these indicators have a combination of regimes that is similar to those predicted. Then, we analyze the five stock factors of the All country world index (ACWI) in the identified time periods to assign a weighted score for each stock factor and to calculate the composite score of the five factors. Finally, we make a monthly selection of 10% of the global stocks that have the highest composite scores. This strategy is shown to outperform those relying on either ACWI, any single stock factor, or the simple average of the five stock factors.",10.3390/risks9010009,global stocks; trading; machine learning; hidden Markov model; economics; regimes; stock ranking; stocks&#8217; factors; economics indicators,WOS,"Utilizes Hidden Markov Model to select stocks from the global market by predicting economic indicator regimes and scoring stock factors, outperforming various benchmarks.",✔️,Global Stocks,✔️,✔️
WOS:000075842000003,Graded forecasting using an array of bipolar predictions: application of probabilistic neural networks to a stock market index,"To an increasing extent over the past decade, software learning methods including neural networks have been used for prediction in financial markets and other areas. By far the most popular type of neural network has been backpropagation. However, the advantages of other learning techniques such as the swift response of the probabilistic neural network (PNN) suggest the desirability of adapting other models to the predictive function. Unfortunately, the conventional architecture for probabilistic neural networks yields only a bipolar output corresponding to Yes or No; Up or Down. This limitation may be circumvented in part by using a graded forecast of multiple discrete values. More specifically, the approach involves an architecture comprising an array of elementary PNNs with bipolar output. This paper explores a number of interrelated topics: (1) presentation of a new architecture for graded forecasting using an arrayed probabilistic network (APN); (2) use of a ""mistake chart"" to compare the accuracy of learning systems against default performance based on a constant prediction; and (3) evaluation of several backpropagation models against a recurrent neural network (RNN) as well as PNN, APN, and case based reasoning. These concepts are investigated against the backdrop of a practical application involving the prediction of a stock market index. (C) 1998 Elsevier Science B.V. All rights reserved.",10.1016/s0169-2070(98)00003-x,forecasting system; artificial intelligence; financial market forecasting,WOS,"Develops an array of probabilistic neural networks to perform graded forecasting for stock market indices, enhancing predictive accuracy by utilizing multiple discrete prediction values.",✔️,Stock Market Index,✔️,✔️
10.1007/s11063-022-10904-8,Graph-Based LSTM for Anti-money Laundering: Experimenting Temporal Graph Convolutional Network with Bitcoin Data,"Elliptic data—one of the largest Bitcoin transaction graphs—has admitted promising results in many studies using classical supervised learning and graph convolutional network models for anti-money laundering. Despite the promising results provided by these studies, only few have considered the temporal information of this dataset, wherein the results were not very satisfactory. Moreover, there is very sparse existing literature that applies active learning to this type of blockchain dataset. In this paper, we develop a classification model that combines long-short-term memory with GCN—referred to as temporal-GCN—that classifies the illicit transactions of Elliptic data using its transaction’s features only. Subsequently, we present an active learning framework applied to the large-scale Bitcoin transaction graph dataset, unlike previous studies on this dataset. Uncertainties for active learning are obtained using Monte-Carlo dropout (MC-dropout) and Monte-Carlo based adversarial attack (MC-AA) which are Bayesian approximations. Active learning frameworks with these methods are compared using various acquisition functions that appeared in the literature. To the best of our knowledge, MC-AA method is the first time to be examined in the context of active learning. Our main finding is that temporal-GCN model has attained significant success in comparison to the previous studies with the same experimental settings on the same dataset. Moreover, we evaluate the performance of the provided acquisition functions using MC-AA and MC-dropout and compare the result against the baseline random sampling model. © 2022, The Author(s).",10.1007/s11063-022-10904-8,Active learning; Anti-money laundering; Bitcoin data; Temporal GCN; Uncertainty estimation,SCOPUS,"The paper presents a temporal graph-based LSTM model with active learning for anti-money laundering efforts using Bitcoin transaction data, enhancing classification of illicit transactions.",❌,,✔️,✔️
WOS:000795156400005,Hidden Markov Model and multifractal method-based predictive quantization complexity models vis-a-vis the differential prognosis and differentiation of Multiple Sclerosis' subgroups,"Hidden Markov Model (HMM) is a stochastic process where implicit or latent stochastic processes can be inferred indirectly through a sequence of observed states. HMM as a mathematical model for uncertain phenomena is applicable for the description and computation of complex dynamical behaviours enabling the mathematical formulation of neural dynamics across spatial and temporal scales. The human brain with its fractal structure demonstrates complex dynamics and fractals in the brain are characterized by irregularity, singularity and self-similarity in terms of form at different observation levels, making detection difficult as observations in real-time occurrences can be time variant, discrete, continuous or noisy. Multiple Sclerosis (MS) is an autoimmune degenerative disease with time and space related dissemination, leading to neuronal apoptosis, coupled with some subtle features that could be overlooked by physicians. This study, through the proposed integrated approach with multi-source complex spatial data, aims to attain accurate prediction, diagnosis and prognosis of MS subgroups by HMM with Viterbi algorithm and Forward-Backward algorithm as the dynamic and efficient products of knowledge-based and Artificial Intelligence (AI)-based systems within the framework of precision medicine. Multifractal Bayesian method (MFM) accordingly applied to identify and eliminate ""insignificant ""irregularities while maintaining ""significant ""singularities. An efficient modelling of HMM is proposed to diagnose and predict the course of MS while using MFM method. Unlike the methods employed in previous studies, our proposed integrated novel method encompasses the subsequent approaches based on reliable MS dataset ((X) over cap) collected: (i) MFM method was applied ((X) over cap) to MS dataset to characterize the irregular, self-similar and significant attributes, thus, attributes with ""insignificant "" irregularities were eliminated and ""significant "" singularities were maintained. MFM-MS dataset ((X) over cap) was generated. (ii) The continuous values in the MS dataset ((X) over cap) and MFM-MS dataset ((X) over cap) were converted into discrete values through vector quantization method of the HMM (iii) Through transitional matrices, different observation matrices were computed from the both datasets. (v) Computational complexity has been computed for both datasets. (vi) The results of the HMM models based on observation matrices obtained from both datasets were compared. In terms of the integrated HMM model proposed and the MS dataset handled, no earlier work exists in the literature. The experimental results demonstrate the applicability and accuracy of our novel proposed integrated method, HMM and Multifractal (HMM-MFM) method, for the application to the MS dataset (X). Compared with conventional methods, our novel method has achieved more superiority regarding extracting subtle and hidden details, which are significant for distinguishing different dynamic and complex systems including engineering and other related applied sciences. Thus, we have aimed at pointing a new frontier by providing a novel alternative mathematical model to facilitate the critical decision-making, management and prediction processes among the related areas in chaotic, dynamic complex systems with intricate and transient states. (C)2022 Elsevier B.V. All rights reserved.",10.1016/j.knosys.2022.108694,Hidden Markov Model; Viterbi algorithm; Forward-Backward algorithm; Multifractal analysis; Nonlinear stochastic processes; Computational dynamic complexityanalyses; Multiple Sclerosis' subgroups,WOS,Integrates Hidden Markov Models and multifractal Bayesian methods for accurate prediction and diagnosis of Multiple Sclerosis subgroups.,❌,?,✔️,✔️
10.1016/j.asoc.2024.111557,Hidden Markov guided Deep Learning models for forecasting highly volatile agricultural commodity prices,"Predicting agricultural commodity prices accurately is of utmost importance due to various factors such as perishability, seasonality, production uncertainty etc. Moreover, the substantial volatility that may be exhibited in time series further adds to the complexity and constitutes a significant challenge. In this paper, a Hidden Markov (HM) guided Deep Learning (DL) models has been developed on nonlinear and nonstationary price data of agricultural commodities for forecasting by considering technical indicators viz., Moving Average (MA), Bollinger Bands (BB), Moving Average Convergence Divergence (MACD), Exponential MA (EMA) and Fast Fourier Transformation (FFT). HM Models (HMMs) can effectively handle the sequential dependencies and hidden states, while DL approach can learn complex patterns and relationships within the price series and thus the drawback of lack of generalization capability in the DL model has been overcome by HMM. In this study, the Potato price data of the Champadanga district of West Bengal, India has been utilized to assess the performance of the proposed technique. HMM has been combined with six baseline DL models viz., Recurrent Neural Networks (RNN), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Bidirectional LSTM (BiLSTM) and Bidirectional GRU (BiGRU) for forecast modeling. Performance evaluation metrics viz., Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE) and the insightful Diebold–Mariano (DM) test revealed that Hidden Markov hybridized with DL models surpassed baseline DL models in forecasting accuracy for 1-week, 4-week, 8-week and 12-week ahead DL predictions. The proposed approach holds significant promise for enhancing the precision of agricultural commodity price forecasting with far-reaching implications for various stakeholders such as farmers and planners. © 2024 Elsevier B.V.",10.1016/j.asoc.2024.111557,Bollinger Bands; Fourier transform; Gated Recurrent Unit (GRU)/ Bidirectional GRU (BiGRU); Long Short-Term Memory (LSTM)/ Bidirectional LSTM (BiLSTM); Recurrent Neural Network (RNN)/ Convolutional Neural Networks (CNN),SCOPUS,"Hidden Markov guided deep learning models are developed to forecast highly volatile agricultural commodity prices, achieving higher accuracy than baseline models for potato price predictions.",✔️,Agricultural Commodity (Potato),✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8640116,High-Dimensional Multiple Bubbles Prediction Based on Sparse Constraints,"Many bubble test methods do not have the ability to predict multiple bubbles in a high dimensional space now. Therefore, we propose a data-driven, self-adaptive evolutionary bubble prediction algorithm named WSADF. First, according to the invariance principle, we speculate that if there are inherent degrees of freedom for high dimensional time series, then comovement causality analysis (CCA) can be improved to select the decisive high dimensional time series that must reflect the prominent comovement causality. The optimization problem of the high dimensional space can be solved in the low dimensional space and maintain the inherent relationships among the time series by using CCA. Second, the learning parameters of hidden neurons have the ability of self-adaptive differential evolution. The neurons in the network are used to model the individuals’ signals from the perspective of evolution. Third, a self-adaptive evolutionary neural network can be used to simulate the operation of the entire market’s signals. The generalized sup augmented Dickey–Fuller test is improved to suit changing market environmental conditions. Thus, the WSADF algorithm has the ability to predict multiple bubbles in high dimensional space. An empirical application of the methodology is conducted on different types of markets (e.g., the USDCNH and CSI300 closing prices), which has successfully identified and forecasted multiple bubbles from 2015 to 2017.",10.1109/access.2019.2893929,Time series analysis;Neurons;Biological neural networks;Prediction algorithms;Training data;Adaptation models;Optimization;Sparse and compressible signals;self-adaptive evolutionary;machine learning;multiple bubbles;GSADF test;high-dimensional space,IEEE,"We propose a data-driven evolutionary algorithm WSADF to predict multiple market bubbles in high-dimensional financial markets, successfully applied to USDCNH and CSI300 indices.",✔️,"Currency, Stock Index",✔️,❌
WOS:000456228800001,High-order Hidden Markov Model for trend prediction in financial time series,"Financial price series trend prediction is an essential problem which has been discussed extensively using tools and techniques of economic physics and machine learning. Time dependence and volatility issues in this problem have made Hidden Markov Model (HMM) a useful tool in predicting the states of stock market. In this paper, we present an approach to predict the stock market price trend based on high-order HMM. Different from the commonly used first-order HMM, short and long-term time dependence are both considered in the high order HMM. By introducing a dimension reduction method which could transform the high-dimensional state vector of high-order HMM into a single one, we present a dynamic high-order HMM trading strategy to predict and trade CSI 300 and S&P 500 stock index for the next day given historical data. In our approach, we make a statistic of the daily returns in the history to demonstrate the relationship between hidden states and the price change trend. Experiments on CSI 300 and S&P 500 index illustrate that high-order HMM has preferable ability to identify market price trend than first-order one. Thus, the high-order HMM has higher accuracy and lower risk than the first-order model in predicting the index price trend. (C) 2018 Elsevier B.V. All rights reserved.",10.1016/j.physa.2018.10.053,High-order HMM; Trend prediction; Trading algorithm,WOS,"This article presents a high-order Hidden Markov Model for predicting stock market price trends, demonstrating improved accuracy and lower risk compared to first-order models.",✔️,"Stock indices (CSI 300, S&P 500)",✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494511,HyBiLSTM: Multivariate Bitcoin Price Forecasting Using Hybrid Time-Series Models With Bidirectional LSTM,"Despite their growing popularity in recent research, most hybrid models that harness the strengths of both classical time-series analysis and deep learning models have been explored within the univariate forecasting context. In the econometric domain, where exogenous factors play a crucial role; there is a pressing need for more studies focusing on multivariate forecasting. This paper introduces a novel hybrid model, HyBiLSTM. It integrates an ARIMAX GARCHX model for initial forecasting, followed by a second forecasting phase that addresses the residuals using a bidirectional long short-term memory model optimized through grey wolf optimization algorithm. The final forecast is a composite derived from both models. Three quantitative metrics (mean absolute error, root mean square error, and mean absolute percentage error) assessed the model performance using data that spanned social and economic variables from July 1, 2019, to December 31, 2022. The results revealed several key findings: 1) The addition of exogenous factors improved the performance of the ARIMA and GARCH models. 2) The BiLSTM variant outperformed other LSTM variants when combined with the ARIMAX GARCHX model. 3) An analysis using Shapley additive explanations indicated that bitcoin price was influenced by stock prices, Twitter volume, gold prices, and the Twitter sentiment index. 4) The presence of a structural break had a significant effect on the model’s forecasting accuracy. Beyond expanding the academic literature on hybrid models within a multivariate context, this offers valuable practical insights for investors. Specifically, it analyzes various factors that could serve as early indicators of bitcoin price fluctuations.",10.1109/access.2024.3386029,Biological system modeling;Predictive models;Long short term memory;Forecasting;Bitcoin;Data models;Time series analysis;LSTM;ARIMAX;GARCHX;bitcoin;SHAP;bidirectional LSTM,IEEE,"The paper introduces HyBiLSTM, a hybrid time-series model combining ARIMAX GARCHX and bidirectional LSTM for multivariate Bitcoin price forecasting, utilizing social and economic indicators to enhance prediction accuracy.",✔️,Bitcoin,✔️,✔️
WOS:000781289000001,Hybrid Feature Reduction Using <i>PCC</i>-Stacked Autoencoders for Gold/Oil Prices Forecasting under COVID-19 Pandemic,"The financial markets have been influenced by the emerging spread of Coronavirus disease, COVID-19. The oil, and gold as well have experienced a downward trend due to the increased rate in the number of confirmed COVID-19 cases. Lately, the published COVID data comprised new variables that may influence the accuracy of the oil/gold prices forecasting models including the Stringency index, Reproduction rate, Positive Rate, and Vaccinations. In this study, Deep Autoencoders are introduced and combined with the well-known approach: Pearson Correlation Coefficient, PCC, analysis in selecting the key features that affect the accuracy of the forecasting models of gold and oil prices with respect to COVID-19 pandemic. We have utilized a hybrid approach of PCC along with a 2-Stage Stacked Autoencoder, SA, to extract the latent features which are then submitted to Neural Network, NN, regression model. The NN regressor has been trained using the Bayesian Regularization-backpropagation algorithm which provides a good generalization for small noisy datasets. The hybrid approach has yielded the minimum MSE values of 8.97 x 10(-3) and 5.356 x 10(-2) on the oil/gold validation set, respectively. Compared to the existing approaches, the proposed approach has outperformed the ARIMA, ML based regression models in forecasting the oil/gold prices. In addition, the introduced framework has yielded lower Mean Absolute Error, MAE, than the Recurrent Neural Network, RNN, and the Principal Component Analysis, PCA, for dimension reduction. The retrieved results showed that the hybrid method produced more robust features by considering the relationship between the input features.",10.3390/electronics11070991,stacked autoencoders; neural network; forecasting models,WOS,"The study develops a hybrid feature reduction approach combining Pearson Correlation Coefficient and stacked autoencoders with neural networks to forecast gold and oil prices during the COVID-19 pandemic, achieving superior accuracy compared to traditional models like ARIMA.",✔️,Gold and oil,✔️,❌
WOS:001139596200001,Hybrid machine learning models for aboveground biomass estimations,"Forest biomass provides a quantitative assessment for carbon stock marketing on a national or regional scale. Some countries have committed to net zero carbon emissions, so proper biomass estimations are essential. This study investigates the uses of machine learning (LightGBM, XGBoost), in which hyperparameters were tuned by Bayesian-based Optimisers and a novel Tasmanian Devil Optimisation algorithm for estimates of aboveground biomass (AGB) using Sentinel 1A, Landsat images, and ground survey data. A province in the northern part of Vietnam was selected as a case study since the change in land cover has been considered crucial. The models were optimized/trained and validated using statistical indicators, namely, root mean square error (RMSE), coefficient of determination (R2), and mean absolute error (MAE). The trained models were further explained using SHAP values to understand better how they perform and the contribution of each feature to the overall estimates. The results showed that the three indicators of the proposed model were statistically better than those of the reference methods. Specifically, the hybrid model ended up at RMSE -13.87, MAE - 10.62, and R2 - 0.79 for the estimation of AGB. Based on the experience, such hybrid integration can be recommended as an alternative solution for biomass estimation. In a broader context, the fast growth of machine learning and optimization algorithms has created new scientifically sound solutions for a better analysis of forest cover.",10.1016/j.ecoinf.2023.102421,Aboveground biomass; Gradient boosting; Bayesian optimisations; Meta-heuristic optimisation,WOS,"Uses machine learning models (LightGBM, XGBoost) optimized by Bayesian-based and Tasmanian Devil Optimization algorithms to estimate aboveground biomass using satellite data, outperforming reference methods.",❌,?,✔️,❌
WOS:001139673000001,IACPPO: A deep reinforcement learning-based model for warehouse inventory replenishment,"Inventory cost is a significant factor in Supply Chain Management (SCM), and an effective replenishment strategy can reduce warehouse operation costs. However, traditional replenishment strategies often struggle to meet the complex and ever-changing demands of real-world warehouse scenarios. Moreover, the spatiotemporal heterogeneity of commodity demand and inventory cost poses significant challenges to time series prediction models, as individual training strategies for different commodities significantly increase modeling and time costs. To address these issues, we propose a replenishment model called IACPPO, which incorporates the Advantage ActorCritic (A2C) algorithm with the Proximal Policy Optimization (PPO) algorithm. Firstly, we introduce gated recurrent unit (GRU) and Attention Mechanisms into the Actor-Critic network to analyze data state spaces for probabilistic modeling and extracting valid information from environmental state sequences by memory reasoning and focusing on critical state sequences; additionally, we fuse the A2C algorithm with the PPO algorithm to train the whole network simultaneously to obtain the replenishment strategy. Finally, experimental results on two different real-world inventory datasets show that using the IACPPO model has achieved the best cost control strategies in most experimental validations of replenishment strategies.",10.1016/j.cie.2023.109829,Inventory cost management; Replenishment strategy; Markov decision process; Supply chain,WOS,"Proposes the IACPPO model, a deep reinforcement learning-based approach for warehouse inventory replenishment, achieving optimal cost control strategies.",❌,?,✔️,❌
978-1-109-88417-3,Identification and prediction of economic regimes to guide decision making in multi-agent marketplaces,"Supply chain management is commonly employed by businesses to improve organizational processes by optimizing the transfer of goods, information, and services between buyers and suppliers. Traditionally, supply chains have been created and maintained through the interactions of human representatives of the various companies involved. However, the recent advent of autonomous software agents opens new possibilities for automating and coordinating the decision making processes between the various parties involved. Autonomous agents participating in supply chain management must typically make their decisions in environments of high complexity, high variability, and high uncertainty since only limited information is visible. We present an approach whereby an autonomous agent is able to make tactical decisions, such as product pricing, as well as strategic decisions, such as product mix and production planning, in order to maximize its profit despite the uncertainties in the market. The agent predicts future market conditions and adapts its decisions on procurement, production, and sales accordingly. Using a combination of machine learning and optimization techniques; the agent first characterizes the microeconomic conditions, such as over-supply or scarcity, of the market. These conditions are distinguishable statistical patterns that we call economic regimes. They are learned from historical data by using a Gaussian Mixture Model to model the price density of the different products and by clustering price distributions that recur across days. In real-time the agent identifies the current dominant market condition and forecasts market changes over a planning horizon. Methods for the identification of regimes are explored in detail, and three different algorithms are presented. One is based on exponential smoothing, the second on a Markov prediction process, and the third on a Markov correction-prediction process. We examine a wide range of tuning options for these algorithms, and show how they can be used to predict prices, price trends, and the probability of receiving a customer order. We validate our methods by presenting experimental results from the Trading Agent Competition for Supply Chain Management, an international competition of software agents that has provided inspiration for this work. We also show how the same approach can be applied to the stock market.",,,Proquest,"The study develops nonparametric Bayesian models to identify and predict economic regimes in multi-agent marketplaces, including applications to stock markets, enabling agents to make informed tactical and strategic decisions.",✔️,Stock,✔️,✔️
0419-4217,Identification and prediction of economic regimes to guide decision making in multi-agent marketplaces.,"Supply chain management is commonly employed by businesses to improve organizational processes by optimizing the transfer of goods, information, and services between buyers and suppliers. Traditionally, supply chains have been created and maintained through the interactions of human representatives of the various companies involved. However, the recent advent of autonomous software agents opens new possibilities for automating and coordinating the decision making processes between the various parties involved. Autonomous agents participating in supply chain management must typically make their decisions in environments of high complexity, high variability, and high uncertainty since only limited information is visible. We present an approach whereby an autonomous agent is able to make tactical decisions, such as product pricing, as well as strategic decisions, such as product mix and production planning, in order to maximize its profit despite the uncertainties in the market. The agent predicts future market conditions and adapts its decisions on procurement, production, and sales accordingly. Using a combination of machine learning and optimization techniques; the agent first characterizes the microeconomic conditions, such as over-supply or scarcity, of the market. These conditions are distinguishable statistical patterns that we call economic regimes. They are learned from historical data by using a Gaussian Mixture Model to model the price density of the different products and by clustering price distributions that recur across days. In real-time the agent identifies the current dominant market condition and forecasts market changes over a planning horizon. Methods for the identification of regimes are explored in detail, and three different algorithms are presented. One is based on exponential smoothing, the second on a Markov prediction process, and the third on a Markov correction-prediction process. We examine a wide range of tuning options for these algorithms, and show how they can be used to predict prices, price trends, and the probability of receiving a customer order. We validate our methods by presenting experimental results from the Trading Agent Competition for Supply Chain Management, an international competition of software agents that has provided inspiration for this work. We also show how the same approach can be applied to the stock market.",,,Proquest,"The study develops nonparametric Bayesian models to identify and predict economic regimes in multi-agent marketplaces, including applications to stock markets, enabling agents to make informed tactical and strategic decisions.",✔️,Stock,✔️,✔️
WOS:000979768700001,Identifying dominant industrial sectors in market states of the S&P 500 financial data,"Understanding and forecasting changing market conditions in complex economic systems like the financial market is of great importance to various stakeholders such as financial institutions and regulatory agencies. Based on the finding that the dynamics of sector correlation matrices of the S&P 500 stock market can be described by a sequence of distinct states via a clustering algorithm, we try to identify the industrial sectors dominating the correlation structure of each state. For this purpose, we use a method from explainable artificial intelligence (XAI) on daily S&P 500 stock market data from 1992 to 2012 to assign relevance scores to every feature of each data point. To compare the significance of the features for the entire data set we develop an aggregation procedure and apply a Bayesian change point analysis to identify the most significant sector correlations. We show that the correlation matrix of each state is dominated only by a few sector correlations. Especially the energy and IT sector are identified as key factors in determining the state of the economy. Additionally we show that a reduced surrogate model, using only the eight sector correlations with the highest XAI-relevance, can replicate 90%",10.1088/1742-5468/accce0,econophysics; finance; explainable AI; clustering; market states,WOS,"Uses explainable AI and Bayesian change point analysis to identify dominant industrial sectors influencing market states within the S&P 500, revealing key sector correlations like energy and IT.",❌,S&P 500 Sectors,✔️,❌
WOS:000731136600001,Impact of Hyperparameter Tuning on Machine Learning Models in Stock Price Forecasting,"Stock price forecasting has been reported as a challenging task in the scientific and financial communities due to stock prices' nonlinear and dynamic nature. Machine learning models exhibit capabilities that allow them to handle nonlinear data and be candidate tools for stock price forecasting. In this study, an empirical evaluation of eight conventional machine learning models' is conducted to forecast the stock price of eleven companies belonging to the Saudi Stock Exchange. Moreover, the optimal configuration of hyperparameters in each machine learning model is identified. Forecasting performance is evaluated by two well-known error metrics: Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). Wilcoxson effect size is utilized to determine the impact of hyperparameter tuning by comparing tuned and un-tuned machine learning models' forecasting performance. Empirical results indicate there are varying impacts of hyperparameter tuning of machine learning models in forecasting stock price. After tuning the hyperparameters, Support Vector Regression outperforms other forecasting models with a significant statistical difference. In contrast, Kernel Ridge Regression shows noteworthy forecasting performance without hyperparameter tuning with respect to other un-tuned forecasting models. However, Decision Tree and K-Nearest Neighbour are the poor-performing models which demonstrate inadequate forecasting performance even after hyperparameter tuning.",10.1109/access.2021.3134138,Forecasting; Predictive models; Machine learning; Tuning; Biological system modeling; Time series analysis; Training; Gaussian process regression; hyperparameter tuning; kernel ridge regression; LASSO; machine learning; stock price forecasting; support vector regression; time series analysis,WOS,"Examines the influence of hyperparameter tuning on the forecasting performance of various machine learning models for stock price prediction, highlighting that optimized models like Support Vector Regression outperform others.",✔️,Stock Prices,✔️,❌
WOS:000751704800148,Implementation of a Commitment Machine for an Adaptive and Robust Expected Shortfall Estimation,"This study proposes a metaheuristic for the selection of models among different Expected Shortfall (ES) estimation methods. The proposed approach, denominated ""Commitment Machine"" (CM), has a strong focus on assets cross-correlation and allows to measure adaptively the ES, dynamically evaluating which is the most performing method through the minimization of a loss function. The CM algorithm compares four different ES estimation techniques which all take into account the interaction effects among assets: a Bayesian Vector autoregressive model, Stochastic Differential Equation (SDE) numerical schemes with Exponential Weighted Moving Average (EWMA), a Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) volatility model and a hybrid method that integrates Dynamic Recurrent Neural Networks together with a Monte Carlo approach. The integration of traditional Monte Carlo approaches with Machine Learning technologies and the heterogeneity of dynamically selected methodologies lead to an improved estimation of the ES. The study describes the techniques adopted by the CM and the logic behind model selection; moreover, it provides a market application case of the proposed metaheuristic, by simulating an equally weighted multi-asset portfolio.",10.3389/frai.2021.732805,expected shortfall; monte carlo methods; stochastic differential equation; bayesian vector autoregressive; dynamic neural networks; nonlinear auto-regressive networks; artificial intelligence; commitment machine,WOS,"Proposes Commitment Machine, a metaheuristic to select ES estimation models using Bayesian, GARCH, neural networks, improving ES estimation.",✔️,Portfolio ES,✔️,✔️
WOS:001201108800001,Improved Financial Predicting Method Based on Time Series Long Short-Term Memory Algorithm,"With developments in global economic integration and the increase in future economic uncertainty, it is imperative to have the ability to predict future capital in relation to financial capital inflow and outflow predictions to ensure capital optimization is within a controllable range within the current macroeconomic environment and situation. This paper proposes an automated capital prediction strategy for the capital supply chain using time series analysis artificial intelligence methods. Firstly, to analyze the fluctuation and tail risk of the financial characteristics, the paper explores the financial characteristics for measuring the dynamic VaR from the perspectives of volatility, tail, and peak with the Bayesian peaks over threshold (POT) model. Following this, in order to make the modeling more refined, the forecast targets are split before modeling with seasonal Autoregressive Integrated Moving Average (ARIMA) models and Prophet models. Finally, the time series modeling of the wavelet Long Short-Term Memory (LSTM) model is carried out using a two-part analysis method to determine the linear separated wavelet and non-linear embedded wavelet parts to predict strong volatility in financial capital. Taking the user capital flow of the Yu'e Bao platform, the results prove the feasibility and prediction accuracy of the innovative model proposed.",10.3390/math12071074,financial capital; artificial intelligence; Bayesian POT; time series,WOS,"The paper presents an advanced capital prediction method utilizing a wavelet-based LSTM model and Bayesian approaches to forecast financial capital flows, demonstrating high prediction accuracy on the Yu'e Bao platform's capital data.",✔️,Financial capital flows,✔️,✔️
WOS:001316679800001,Improving Stock Price Forecasting Accuracy with Stochastic Multilayer Perceptron,"The stock market operates in a stochastic environment, making accurate price forecasting challenging. To address this issue, a stochastic multilayer perceptron (S-MLP) model has been developed to simulate the stock market's stochastic nature. By incorporating a Gaussian process into the sigmoid activation function, this model incorporates stochasticity into the traditional multilayer perceptron (MLP). As the perturbation factor, a stochastic sigmoid activation function (SAF) with a volatility estimator is used. Although S-MLP has demonstrated superiority over MLP, there is still room for improvement in terms of forecasting precision. In this study, we propose S-MLP with a trainable perturbation factor (S-MLPT), an improved variant of SMLP. SAF employs the Yang-Zhang volatility estimator as the perturbation factor. The proposed model first employed MLP, and all the parameters were trained. After freezing the parameters, SMLP is used to train the perturbation factor in the SAF. To evaluate the predictive performance of the models, MLP, S-MLP, and S-MLPT are used to predict the one day ahead highest stock price of four counters listed in Bursa Malaysia. As an evaluation metric, the coefficient of determination is utilised, and the relative percentage improvement of the models is calculated to determine their superiority. The results demonstrated that S-MLP outperforms MLP by effectively minimizing the loss function and converging towards a better local or global minimum during training. In conclusion, S-MLPT exhibits even better performance than S-MLP, with relative percentage improvements of 0.14%, 15.45%, and 0.48% for counters 0166.KL, 2445.KL, and 4707.KL, respectively.",10.11113/mjfas.v20n4.3497,Forecasting stock price; deep learning; multilayer perceptron; stochastic multilayer perceptron,WOS,"The article introduces an improved stochastic multilayer perceptron model (S-MLPT) for enhancing the accuracy of stock price forecasting, demonstrating its superiority over traditional MLP models.",✔️,Stock,✔️,✔️
WOS:000663221100001,Industrial Forecasting with Exponentially Smoothed Recurrent Neural Networks,"Time series modeling has entered an era of unprecedented growth in the size and complexity of data which require new modeling approaches. While many new general purpose machine learning approaches have emerged, they remain poorly understand and irreconcilable with more traditional statistical modeling approaches. We present a general class of exponential smoothed recurrent neural networks (RNNs) which are well suited to modeling nonstationary dynamical systems arising in industrial applications. In particular, we analyze their capacity to characterize the nonlinear partial autocorrelation structure of time series and directly capture dynamic effects such as seasonality and trends. Application of exponentially smoothed RNNs to forecasting electricity load, weather data, and stock prices highlight the efficacy of exponential smoothing of the hidden state for multistep time series forecasting. The results also suggest that popular, but more complicated neural network architectures originally designed for speech processing are likely over-engineered for industrial forecasting and light-weight exponentially smoothed architectures, trained in a fraction of the time, capture the salient features while being superior and more robust than simple RNNs and autoregressive models. Additionally, uncertainty quantification of Bayesian exponential smoothed RNNs is shown to provide improved coverage.",10.1080/00401706.2021.1921035,Exponential smoothing; Forecasting; Nonstationarity; Partial autocorrelations; Quantification; Uncertainty,WOS,"Presents exponentially smoothed RNNs for forecasting nonstationary dynamical systems like electricity load and stock prices, showing improved forecasting performance and uncertainty quantification.",✔️,Stock Prices,✔️,✔️
WOS:001281386400001,Integrating spotted hyena optimization technique with generative artificial intelligence for time series forecasting,"Generative artificial intelligence (AI) has developed as an effective tool for time series predicting, revolutionizing the typical methods of prediction. Different classical approaches that depend on existing approaches and assumptions, generative AI controls advanced deep learning (DL) approaches like generative adversarial networks (GANs) and recurrent neural networks (RNNs), to identify designs and connections in time series data. DL has accomplished major success in optimizing performances connected with AI. In the financial area, it can be extremely utilized for the stock market predictive, trade implementation approaches, and set of optimizers. Stock market predictive is the most important use case in this field. GANs with advanced AI approaches have become more significant in recent times. However, it can be utilized in image-image-translation and other computer vision (CV) conditions. GANs could not utilized greatly for stock market prediction because of their effort to establish the proper set of hyperparameters. This study develops an integrated spotted hyena optimization algorithm with generative artificial intelligence for time series forecasting (SHOAGAI-TSF) technique. The purpose of the SHOAGAI-TSF technique is to accomplish a forecasting process for the utilization of stock price prediction. The SHOAGAI-TSF technique uses probabilistic forecasting with a conditional GAN (CGAN) approach for the prediction of stock prices. The CGAN model learns the data generation distribution and determines the probabilistic prediction from it. To boost the prediction results of the CGAN approach, the hyperparameter tuning can be performed by the use of the SHOA. The simulation result analysis of the SHOAGAI-TSF technique takes place on the stock market dataset. The experimental outcomes determine the significant solution of the SHOAGAI-TSF algorithm with other compared methods in terms of distinct metrics.",10.1111/exsy.13681,artificial intelligence; generative adversarial network; spotted hyena optimization; stock market prediction; time series forecasting,WOS,"Develops an integrated spotted hyena optimization algorithm with conditional GANs for probabilistic stock price time series forecasting, achieving superior prediction results compared to benchmark methods.",✔️,Stock Prices,✔️,✔️
WOS:000520892300030,Intelligent forecasting with machine learning trading systems in chaotic intraday Bitcoin market,"Due to the remarkable boost in cryptocurrency trading on digital blockchain platforms, the utilization of advanced machine learning systems for robust prediction of highly nonlinear and noisy data, gains further popularity by individual and institutional market agents. The purpose of our study is to comparatively evaluate a plethora of Artificial Intelligence systems in forecasting high frequency Bitcoin price series. We employ three different sets of models, i.e., statistical machine learning approaches including support vector regressions (SVR) and Gaussian Poisson regressions (GRP), algorithmic models such as regression trees (RT) and the k-nearest neighbours (kNN) and finally artificial neural network topologies such as feedforward (FFNN), Bayesian regularization (BRNN) and radial basis function networks (RBFNN). To the best of our knowledge, this is the first time an extensive empirical investigation of the comparative predictability of various machine learning models is implemented in high-frequency trading of Bitcoin. The entropy analysis of training and testing samples reveals long memory traits, high levels of stochasticity, and topological complexity. The presence of inherent nonlinear dynamics of Bitcoin time series fully rationalizes the use of advanced machines learning techniques. The optimal parameter values for SVR, GRP and kNN are found via Bayesian optimization. Based on diverse performance metrics, our results show that the BRNN renders an outstanding accuracy in forecasting, while its convergence is unhindered and remarkably fast. The overall superiority of artificial neural networks is due to parallel processing features that efficiently emulate human decision-making in the presence of underlying nonlinear input-output relationships in noisy signal environments. (C) 2020 Elsevier Ltd. All rights reserved.",10.1016/j.chaos.2020.109641,Machine learning; Intraday trading; Bitcoin; Forecasting; 90.01 Social Phenomena,WOS,"Compares various machine learning models for high-frequency Bitcoin price forecasting, finding Bayesian regularization neural networks as top performers.",✔️,Bitcoin,✔️,❌
10.1007/s42452-021-04162-x,IoT-based group size prediction and recommendation system using machine learning and deep learning techniques,"In an open source software development environment, it is hard to decide the number of group members required for resolving software issues. Developers generally reply to issues based totally on their domain knowledge and interest, and there are no predetermined groups. The developers openly collaborate on resolving the issues based on many factors, such as their interest, domain expertise, and availability. This study compares eight different algorithms employing machine learning and deep learning, namely—Convolutional Neural Network, Multilayer Perceptron, Classification and Regression Trees, Generalized Linear Model, Bayesian Additive Regression Trees, Gaussian Process, Random Forest and Conditional Inference Tree for predicting group size in five open source software projects developed and managed using an open source development framework GitHub. The social information foraging model has also been extended to predict group size in software issues, and its results compared to those obtained using machine learning and deep learning algorithms. The prediction results suggest that deep learning and machine learning models predict better than the extended social information foraging model, while the best-ranked model is a deep multilayer perceptron((R.M.S.E. sequelize—1.21, opencv—1.17, bitcoin—1.05, aseprite—1.01, electron—1.16). Also it was observed that issue labels helped improve the prediction performance of the machine learning and deep learning models. The prediction results of these models have been used to build an Issue Group Recommendation System as an Internet of Things application that recommends and alerts additional developers to help resolve an open issue. © 2021, The Author(s).",10.1007/s42452-021-04162-x,Deep learning; Edge computing; Internet of things; Machine learning; Open source software development; Software repositories,SCOPUS,"Uses machine learning algorithms to predict moisture ratio and drying rate of orange slices, demonstrating high accuracy with k-NN models.",❌,?,✔️,❌
WOS:000598059300002,Is Inflation a Monetary Phenomenon in the East European Economies? - Multifrequency Bayesian Quantile Inference,"This paper tries to determine how growth of money supply affects inflation in different time-horizons and under different inflation levels in the Czech Republic, Poland, Hungary and Russia. The research is done by using two innovative methodologies - the wavelet approach and Bayesian quantile regression. By observing these four countries, we can assess whether inflation targeting (IT) plays significant role in curbing inflation, because three Visegrad group countries adopted IT almost two decades ago, while Russia started to conduct IT relatively recently. Estimated quantiles suggest that money supply growth does not influence inflation in the Czech Republic and Hungary, whatsoever. We find that money growth impacts inflation in Poland, but very modestly. On the other hand, in the case of Russia, the transmission effect from money to inflation is much higher, and it goes around 40% in low inflation conditions, when Ml aggregate is observed, and around 78% in low inflation conditions, when M3 aggregate is analysed. The overall results clearly indicate that the adoption of the IT framework as a disinflation strategy proved to be successful in the Visegrad group countries, since excessive money growth has little or no effect at all on inflation in these countries.",10.31577/ekoncas.2020.08.02,money; inflation; wavelet; Bayesian quantiles; Central and Eastern European countries,WOS,"Multifrequency Bayesian quantile inference is used to assess the monetary phenomenon of inflation in East European economies, indicating successful inflation targeting.",❌,Inflation Indicators,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9652123,Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction,"Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution StockNF by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines.",10.1109/lsp.2021.3135793,Predictive models;Time series analysis;Stochastic processes;Data models;Noise measurement;Task analysis;Social networking (online);Stock movement prediction;Fintech;normalizing flow;variational inference;generative models,IEEE,"Attention-Based Neural Bag-of-Features learning is proposed for sequence data in financial forecasting, outperforming traditional methods and making models more resilient to noisy data.",✔️,Financial Time Series,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6942194,Learning the Information Divergence,"Information divergence that measures the difference between two nonnegative matrices or tensors has found its use in a variety of machine learning problems. Examples are Nonnegative Matrix/Tensor Factorization, Stochastic Neighbor Embedding, topic models, and Bayesian network optimization. The success of such a learning task depends heavily on a suitable divergence. A large variety of divergences have been suggested and analyzed, but very few results are available for an objective choice of the optimal divergence for a given task. Here we present a framework that facilitates automatic selection of the best divergence among a given family, based on standard maximum likelihood estimation. We first propose an approximated Tweedie distribution for the β-divergence family. Selecting the best β then becomes a machine learning problem solved by maximum likelihood. Next, we reformulate α-divergence in terms of β-divergence, which enables automatic selection of α by maximum likelihood with reuse of the learning principle for β-divergence. Furthermore, we show the connections between γ- and β-divergences as well as Renyi- and α-divergences, such that our automatic selection framework is extended to non-separable divergences. Experiments on both synthetic and real-world data demonstrate that our method can quite accurately select information divergence across different learning problems and various divergence families.",10.1109/tpami.2014.2366144,Medals;Approximation methods;Tensile stress;Maximum likelihood estimation;Stochastic processes;Standards;Brain modeling;information divergence;Tweedie distribution;maximum likelihood;nonnegative matrix factorization;stochastic neighbor embedding;Information divergence;tweedie distribution;maximum likelihood;nonnegative matrix factorization;stochastic neighbor embedding,IEEE,"Presents a framework for automatic selection of information divergences in machine learning tasks, improving model selection through maximum likelihood estimation.",❌,?,✔️,❌
10.1109/TGRS.2024.3448205,Leveraging satellite data with machine and deep learning techniques for corn yield and price forecasting,"This research introduces a new method for predicting changes in corn yield and price, critical for food security. Instead of relying on difficult-to-access pre-harvest production data, our approach uses satellite-derived Gross Primary Production (GPP) data and dimension-reduction techniques to forecast national corn yield and price changes. We conducted case studies in the US, Malawi, and South Africa to validate this approach, analyzing predictors from annual GPP variations during peak growing seasons. We applied dimension reduction strategies, such as spatial averaging and Empirical Orthogonal Functions (EOFs). Additionally, we used deep learning techniques like Autoencoders (AEs) and Variational Autoencoders (VAEs) to extract meaningful features from the high-dimensional GPP datasets. These features were then used as predictors in yield and price classification models based on Generalized Linear Models and ElasticNet. We also considered a neural network model trained to predict yield and price variations from GPP input data directly. We evaluated the model performances using metrics such as Area Under Curve, Brier Skill Score, and Matthew&#x2019;s Correlation Coefficient. Our results indicate that dimension-reduction techniques based on AEs and VAEs provided better predictive capabilities across all three countries compared to EOF, particularly in Malawi, where the Brier Skill Score increased from 0.26 with EOF to 0.81 with AE for yield and from -0.004 with EOF to 0.77 with VAE for price. This study demonstrates that integrating open-access satellite data with dimension-reduction techniques can significantly improve crop forecast accuracy, providing an accessible tool to enhance agricultural management and food security. IEEE",10.1109/tgrs.2024.3448205,Autoencoder; Biological system modeling; Classification; Commodity price; Crop yield; Crop yield; Dimension reduction; Forecasting; Land surface; Neural network; Predictive models; Production; Remote sensing; Remote sensing,SCOPUS,"A machine and deep learning approach using satellite-derived data and dimension-reduction techniques is introduced for forecasting corn yield and price, significantly improving prediction accuracy across multiple countries.",✔️,Corn,✔️,❌
WOS:001168597500001,Localized Debiased Machine Learning: Efficient Inference on Quantile Treatment Effects and Beyond,"We consider estimating a low-dimensional parameter in an estimating equation involving high-dimensional nuisance functions that depend on the target parameter as an input. A central example is the efficient estimating equation for the (local) quantile treatment effect ((L)QTE) in causal inference, which involves the covariate-conditional cumulative distribution function evaluated at the quantile to be estimated. Existing approaches based on flexibly estimating the nuisances and plugging in the estimates, such as debiased machine learning (DML), require we learn the nuisance at all possible inputs. For (L)QTE, DML requires we learn the whole covariate-conditional cumulative distribution function. We instead propose localized debiased machine learning (LDML), which avoids this burdensome step and needs only estimate nuisances at a single initial rough guess for the target parameter. For (L)QTE, LDML involves learning just two regression functions, a standard task for machine learning methods. We prove that under lax rate conditions demonstrate in empirical studies.",,Causal Inference; Neyman Orthogonality; Cross-fitting; Instrumental Variables; Conditional Value at Risk; Expectiles,WOS,"Introduces localized debiased machine learning (LDML) for efficient inference on quantile treatment effects, simplifying existing ML approaches.",❌,?,✔️,❌
WOS:001223046600008,"Long-term financial predictions based on Feynman-Dirac path integrals, deep Bayesian networks and temporal generative adversarial networks","This paper presents a new deep learning framework, QuantumPath, for long-term stock price prediction, which is of great significance in portfolio management and risk mitigation, especially when the market becomes volatile due to unpredictable circumstances such as a pandemic. Our approach is based on stochastic equations, the Feynman-Dirac path integral, deep Bayesian networks, and temporal generative adversarial neural networks (t-GAN). The expected financial trajectory is evaluated with a Feynman-Dirac path integral. The latter involves summing all possible financial trajectories that could have been taken by the financial instrument. These trajectories are generated with a t-GAN. A probability is attributed to each point of each path. The probability is a function of the Lagrangian, which is derived from a stochastic equation describing the temporal evolution of the stock. The drift and the volatility at each point, which are required in order to evaluate the Lagrangian, are predicted with a deep Bayesian neural network. Given that the evolution of a stock's price is isomorphic to a time series, our temporal GAN consists of long short-term memory (LSTM) neural networks, which introduce a memory mechanism, and temporal convolutional neural networks (TCN), which ensure causality. Stock prices are predicted over periods of twenty and thirty days for nine stocks, eight of which are included in the S&P 500 index. Our experimental results clearly demonstrate the efficiency of our approach.",10.1016/j.mlwa.2022.100255,Temporal generative adversarial network; Time series; Financial predictions; Long short-term memory; Temporal convolutional network,WOS,"Introduces a deep learning framework integrating Feynman-Dirac path integrals, deep Bayesian networks, and temporal GANs for long-term prediction of stock prices, demonstrating high efficiency on S&P 500 stocks.",✔️,Stock Prices (S&P 500),✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538097,Machine Learning Algorithms for Forecasting and Categorizing Euro-to-Dollar Exchange Rates,"Forecasting changes in foreign exchange rates is a well-explored and widely recognized area within finance. Numerous research endeavors have delved into the utilization of methods in machine learning to analyze and predict movements in the foreign exchange market. This work employed several machine-learning techniques such as Adaboost, logistic regression, gradient boosting, random forest classifier, bagging, Gaussian naïve Bayes, extreme gradient boosting classifier, decision tree classifier, and our approach (we have combined three models: logistic regression, random forest classifier, and Gaussian naive Bayes). Our objective is to predict the most advantageous times for purchasing and selling the euro about the dollar. We integrated a range of technical indicators into the training dataset to enhance the precision of our techniques and strategy. The outcomes of our experiment demonstrate that our approach outperforms alternative methods, achieving superior prediction performance. Our methodology yielded an accuracy of 0.948. This study will empower investors to make informed decisions about their future EUR/USD transactions, helping them identify the most advantageous times to buy and sell within the market.",10.1109/access.2024.3404824,Machine learning;Forecasting;Currencies;Classification algorithms;Training;Random forests;Machine learning algorithms;Finance;Logistic regression;Foreign exchange;prediction;logistic regression;random forest;Naïve Bayes,IEEE,"The paper utilizes various machine learning algorithms to forecast and categorize EUR/USD exchange rates, identifying optimal times for buying and selling based on technical indicators.",✔️,EUR/USD exchange rates,✔️,❌
WOS:000606999100001,Machine Learning Predictions of Housing Market Synchronization across US States: The Role of Uncertainty,"We analyze the role of macroeconomic uncertainty in predicting synchronization in housing price movements across all the United States (US) states plus District of Columbia (DC). We first use a Bayesian dynamic factor model to decompose the house price movements into a national, four regional (Northeast, South, Midwest, and West), and state-specific factors. We then study the ability of macroeconomic uncertainty in forecasting the comovements in housing prices, by controlling for a wide-array of predictors, such as factors derived from a large macroeconomic dataset, oil shocks, and financial market-related uncertainties. To accommodate for multiple predictors and nonlinearities, we take a machine learning approach of random forests. Our results provide strong evidence of forecastability of the national house price factor based on the information content of macroeconomic uncertainties over and above the other predictors. This result also carries over, albeit by a varying degree, to the factors associated with the four census regions, and the overall house price growth of the US economy. Moreover, macroeconomic uncertainty is found to have predictive content for (stochastic) volatility of the national factor and aggregate US house price. Our results have important implications for policymakers and investors.",10.1007/s11146-020-09813-1,Machine learning; Random forests; Bayesian dynamic factor model; Forecasting; Housing markets synchronization; United States,WOS,"The research employs random forests, a machine learning technique, to predict synchronization in housing price movements across US states, highlighting the significant role of macroeconomic uncertainty in enhancing forecastability of housing market trends.",✔️,Housing prices,✔️,?
WOS:000778317400001,Machine Learning Regularization Methods in High-Dimensional Monetary and Financial VARs,"Vector autoregressions (VARs) and their multiple variants are standard models in economic and financial research due to their power for forecasting, data analysis and inference. These properties are a consequence of their capabilities to include multiple variables and lags which, however, turns into an exponential growth of the parameters to be estimated. This means that high-dimensional models with multiple variables and lags are difficult to estimate, leading to omitted variables, information biases and a loss of potential forecasting power. Traditionally, the existing literature has resorted to factor analysis, and specially, to Bayesian methods to overcome this situation. This paper explores the so-called machine learning regularization methods as an alternative to traditional methods of forecasting and impulse response analysis. We find that regularization structures, which allow for high dimensional models, perform better than standard Bayesian methods in nowcasting and forecasting. Moreover, impulse response analysis is robust and consistent with economic theory and evidence, and with the different regularization structures. Specifically, regarding the best regularization structure, an elementwise machine learning structure performs better in nowcasting and in computational efficiency, whilst a componentwise structure performs better in forecasting and cross-validation methods.",10.3390/math10060877,VAR; machine learning; LASSO (Least Absolute Shrinkage and Selection Operator); regularization methods; sparsity; monetary economics; financial economics,WOS,"The paper investigates machine learning regularization techniques as alternatives to traditional Bayesian methods for forecasting and impulse response analysis in high-dimensional Vector Autoregressions (VARs), demonstrating enhanced forecasting performance and robustness.",✔️,Multiple financial variables via VAR,✔️,?
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627654,Machine Learning in Financial Market Surveillance: A Survey,"The use of machine learning for anomaly detection is a well-studied topic within various application domains. However, the detection problem for market surveillance remains challenging due to the lack of labeled data and the nature of anomalous behaviors, which are often contextual and spread over a sequence of anomalous instances. This paper provides a comprehensive review of state-of-the-art machine learning methods used, particularly in financial market surveillance. We discuss the research challenges and progress in this field, mainly applied in other related application domains. In particular, we present a case of machine learning-based surveillance system design for a physical power trading market and discuss how the nature of input data affects the effectiveness of the methods on detecting anomalous market behaviors. Overall, our findings indicate that the regression tree-based ensemble algorithms robustly and effectively predict day-ahead future prices, showing their capability to detect abnormal price changes.",10.1109/access.2021.3130843,Surveillance;Machine learning;Anomaly detection;Power markets;Instruments;Time series analysis;Statistical analysis;Anomaly detection;financial market surveillance;machine learning;time series,IEEE,"The survey reviews machine learning methods for anomaly detection in financial market surveillance, highlighting regression tree-based ensembles in predicting day-ahead prices and detecting abnormal price changes.",✔️,Power trading prices,✔️,❌
10.3390/jrfm15020071,Machine Learning the Carbon Footprint of Bitcoin Mining,"Building on an economic model of rational Bitcoin mining, we measured the carbon footprint of Bitcoin mining power consumption using feed-forward neural networks. We found associated carbon footprints of 2.77, 16.08 and 14.99 MtCO2 e for 2017, 2018 and 2019 based on a novel bottom-up approach, which (i) conform with recent estimates, (ii) lie within the economic model bounds while (iii) delivering much narrower prediction intervals and yet (iv) raise alarming concerns, given recent evidence (e.g., from climate–weather integrated models). We demonstrate how machine learning methods can contribute to not-for-profit pressing societal issues, such as global warming, where data complexity and availability can be overcome. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",10.3390/jrfm15020071,Bitcoin mining; CO<sub>2</sub>; dropout methods; machine learning; neural networks,SCOPUS,"Estimates drying characteristics of apple slices using various machine learning models, achieving high correlation coefficients and aiding in the optimization of drying processes.",❌,?,✔️,❌
WOS:001126988800002,Machine Learning-Based Time Series Prediction at Brazilian Stocks Exchange,"This study proposes a novel method for forecasting the returns of assets comprising the Ibovespa from January 1, 2016, to December 30, 2020, by integrating machine learning algorithms-Gradient Boosting Machine, k-Nearest Neighbor, and Bayesian Regularized Neural Networks. Employing an ensemble strategy with diverse data modeling approaches, the method includes a pre-processing stage for variable selection, ranking their importance using statistical techniques such as OneR, Information Gain, and Chi-Square. This approach aims to overcome common challenges such as overfitting, high dimensionality, and computational efficiency, thus enhancing the robustness of the machine learning model and reducing susceptibility to biases and fluctuations. Empirical results demonstrate that, compared to the ARIMA model, the machine learning algorithm shows superior performance in forecast error and forecast hit rate and precision (R2, Willmott, and Kurtosis). Furthermore, the results suggest that the proposed algorithm can significantly improve predictive precision when applied to the ARIMA model and generalized to various datasets that include various markets and assets.",10.1007/s10614-023-10529-6,Machine learning; Financial time series; Prediction; Hybrid intelligent algorithm; Ensemble,WOS,"This study introduces a machine learning ensemble method integrating Gradient Boosting Machine, kNN, and Bayesian Regularized Neural Networks to forecast returns of assets on the Brazilian Ibovespa stock exchange.",✔️,Stocks in the Brazilian Ibovespa,✔️,❌
10.1111/jfpp.16496,Machine learning algorithms to estimate drying characteristics of apples slices dried with different methods,"In this study, three different apple cultivars were dried using five different drying methods and moisture ratio (MR), moisture content (MC) and drying rate values were determined. Then, different machine learning algorithms (artificial neural network, k-nearest neighbors, random forest, gaussian processes, and support vector regression) were used to estimate MR, MC and drying rate. For MR estimation of Golden Delicious, Oregon Spur and Granny Smith cultivars, Random Forest was most successful algorithm with correlation coefficients (R) of 0.9800, 0.9873, and 0.9841, respectively. This was followed by SVR with R: 0.9323 for Golden Delicious, ANN with R: 0.9766 for Oregon Spur and 5-NN with R: 0.9827 for Granny Smith. MC and drying rate estimation results showed that RF, SVR, and k-NN achieved higher R for all cultivars. It was concluded that machine learning algorithms are an effective approach for the accurate estimation of the drying characteristics of apple slices. Practical applications: Machine learning-like precise modeling techniques are used to estimate the drying characteristics of agricultural commodities. Models should be assessed and compared for optimization of drying conditions and operational costs. Machine learning models predictions agreed well with testing data sets and they could be useful for understanding and controlling the factors affecting drying behaviors. © 2022 Wiley Periodicals LLC.",10.1111/jfpp.16496,,SCOPUS,"Machine learning algorithms are applied to estimate the drying characteristics of apple slices, demonstrating high accuracy in predicting moisture ratio and drying rate using various ML models.",❌,?,✔️,❌
WOS:000444498300002,"Machine learning for quantitative finance: fast derivative pricing, hedging and fitting","In this paper, we show how we can deploy machine learning techniques in the context of traditional quant problems. We illustrate that for many classical problems, we can arrive at speed-ups of several orders of magnitude by deploying machine learning techniques based on Gaussian process regression. The price we have to pay for this extra speed is some loss of accuracy. However, we show that this reduced accuracy is often well within reasonable limits and hence very acceptable from a practical point of view. The concrete examples concern fitting and estimation. In the fitting context, we fit sophisticated Greek profiles and summarize implied volatility surfaces. In the estimation context, we reduce computation times for the calculation of vanilla option values under advanced models, the pricing of American options and the pricing of exotic options under models beyond the Black-Scholes setting.",10.1080/14697688.2018.1495335,Machine learning; Gaussian processes; Derivative pricing; Hedging; Volatility surface,WOS,"The article demonstrates the application of machine learning methods, particularly Gaussian process regression, to accelerate derivative pricing, hedging, and fitting tasks in quantitative finance, achieving significant computational speedups with acceptable accuracy loss.",✔️,Derivatives,✔️,✔️
10.1080/01431161.2021.1998714,Machine learning modelling of crop structure within the Maize Triangle of South Africa,"Maize has been identified as a strategic commodity for the reduction of poverty and enhancement of food security in the African continent. Climate variability and difficult economic conditions are pressuring farmers to produce higher (maize) yields with fewer inputs, per hectare. The remote sensing of crop specific structural parameters are essential in identifying the particular growth stages of the maize crop which require specific tasks from the farmer (e.g. weed control, top dressing, pesticide application for disease and borer control and critical moisture phase). This study sought to assess the performance of multiple linear regression (LR), Random Forest (RF) and Gaussian Process Regression (GPR) in the estimation of four maize crop structural parameters in a study area in the Vereeniging region of the Maize Triangle of South Africa. These parameters were leaf area index (LAI), stem height (HT), stem diameter (DIA) and stem density (SD). An additional aim was to investigate whether the combination of selected spectral vegetation indices (red-edge, chlorophyll, senescence and greenness) with Sentinel-2 reflectance bands as modelling predictors yielded improved results over the individual spectral bands alone. Combining reflectance bands and vegetation indices as modelling predictors yielded the highest validation accuracy, over other scenarios, for only one out of the four crop structural parameters (DAI). The reflectance bands only scenario yielded the highest validation accuracies for two crop structural parameters (HT and SD). The use of spectral vegetation indices alone as modelling predictors yielded the highest modelling accuracies for the LAI crop parameter than the other scenarios. These trends indicate that the combination of Sentinel-2 reflectance bands and derived vegetation indices do not always yield improved modelling results for the four crop structural parameters under investigation. As a result, reflectance bands (mostly) or indices alone could suffice for nearly all of the parameters. With respect to the modelling algorithms, LR yielded the highest accuracies for DIA and SD (Standard Error of Prediction or SEP values of 22.40%±4.65 and 34.15%±2.72 respectively). GPR yielded the highest accuracies for LAI and HT (SEP values of 28.69%±3.84 and 23.19%±2.27 respectively) while RF did not yield the highest validation accuracy for any of the crop structural parameters. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",10.1080/01431161.2021.1998714,,SCOPUS,"Applies machine learning models, including linear regression and Gaussian Process Regression, to estimate structural parameters of maize crops in South Africa, improving agricultural monitoring and management.",❌,?,✔️,✔️
10.1371/journal.pone.0249136,Machine learning models based on remote and proximal sensing as potential methods for in-season biomass yields prediction in commercial sorghum fields,"Crop yield monitoring demonstrated the potential to improve agricultural productivity through improved crop breeding, farm management and commodity planning. Remote and proximal sensing offer the possibility to cut crop monitoring costs traditionally associated with surveys and censuses. Fraction of absorbed photosynthetically active radiation (fAPAR), chlorophyll concentration (CI) and normalized difference vegetation (NDVI) indices were used in crop monitoring, but their comparative performances in sorghum monitoring is lacking. This work aimed therefore at closing this gap by evaluating the performance of machine learning modelling of in-season sorghum biomass yields based on Sentinel-2-derived fAPAR and simpler high-throughput optical handheld meters-derived NDVI and CI calculated from sorghum plants reflectance. Bayesian ridge regression showed good cross-validated performance, and high reliability (R2 = 35%) and low bias (mean absolute prediction error, MAPE = 0.4%) during the validation step. Hand-held optical meter-derived CI and Sentinel-2- derived fAPAR showed comparable effects on machine learning performance, but CI outperformed NDVI and was therefore considered as a good alternative to Sentinel-2's fAPAR. The best times to sample the vegetation indices were the months of June (second half) and July. The results obtained in this work will serve several purposes including improvements in plant breeding, farming management and sorghum biomass yield forecasting at extension services and policy making levels. © 2021 Habyarimana, Baloch. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",10.1371/journal.pone.0249136,,SCOPUS,"Evaluates machine learning models for predicting in-season biomass yields in sorghum fields using remote and proximal sensing data, achieving reliable predictions with Bayesian ridge regression.",❌,?,✔️,✔️
10.1007/s13563-024-00457-8,Machine learning price index forecasts of flat steel products,"Investors and authorities have always placed a high emphasis on commodity price forecasting. In this study, the issue of daily price index forecasting for flat steel products on the Chinese market between June 15, 2011, and April 15, 2021 is examined. There hasn’t been enough focus in the literature on anticipating this important commodity price indicator. Cross-validation and Bayesian optimizations are used to train our models, and Gaussian process regressions are used to support our conclusions. With an out-of-sample relative root mean square error of 0.1293%, the created models correctly forecasted the price indices between April 26, 2019, and April 15, 2021. The developed models may be used for policy research and decision-making by investors and policymakers. When creating similar commodity price indices with reference data on the price trends predicted by the models, the forecasting findings may prove helpful. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.",10.1007/s13563-024-00457-8,Bayesian optimization; Cross validation; Flat steel product; Gaussian process regression; Price prediction,SCOPUS,"The article presents machine learning models for daily price index forecasting of flat steel products in the Chinese market, achieving high accuracy and useful for investors and policymakers.",✔️,Commodity (flat steel products),✔️,✔️
WOS:000448496200008,Machine learning versus econometric jump models in predictability and domain adaptability of index options,"Econometric jump models dealing with key stylized facts in financial option markets have an explicit underlying asset process based on stochastic differential equations. Machine learning models with improved prediction accuracy have elicited considerable attention from researchers in the field of financial application. An intensive empirical study is conducted to compare two methods in terms of model estimation, prediction, and domain adaptation using S&P 100 American/European put options. Results indicated that econometric jump models demonstrate better prediction performance than the best-performing machine learning models, and the estimation results of the former are similar to those of the latter. The former also exhibited significantly better domain adaptation performance than the latter regardless of domain adaptation techniques in machine learning. (C) 2018 Elsevier B.V. All rights reserved.",10.1016/j.physa.2018.08.091,Financial time series; Levy process; Bayesian neural network; Neural network; Support vector regression; Gaussian process regression; Domain adaptation,WOS,"Comparatively assesses econometric jump models against machine learning approaches in predicting index options, demonstrating that traditional econometric models outperform ML models in prediction and domain adaptability.",✔️,Index Options (S&P 100),✔️,❌
10.1016/j.crad.2018.05.015,"Machine learning “red dot”: open-source, cloud, deep convolutional neural networks in chest radiograph binary normality classification","Aim: To develop a machine learning-based model for the binary classification of chest radiography abnormalities, to serve as a retrospective tool in guiding clinician reporting prioritisation. Materials and methods: The open-source machine learning library, Tensorflow, was used to retrain a final layer of the deep convolutional neural network, Inception, to perform binary normality classification on two, anonymised, public image datasets. Re-training was performed on 47,644 images using commodity hardware, with validation testing on 5,505 previously unseen radiographs. Confusion matrix analysis was performed to derive diagnostic utility metrics. Results: A final model accuracy of 94.6% (95% confidence interval [CI]: 94.3–94.7%) based on an unseen testing subset (n=5,505) was obtained, yielding a sensitivity of 94.6% (95% CI: 94.4–94.7%) and a specificity of 93.4% (95% CI: 87.2–96.9%) with a positive predictive value (PPV) of 99.8% (95% CI: 99.7–99.9%) and area under the curve (AUC) of 0.98 (95% CI: 0.97–0.99). Conclusion: This study demonstrates the application of a machine learning-based approach to classify chest radiographs as normal or abnormal. Its application to real-world datasets may be warranted in optimising clinician workload. © 2018 The Royal College of Radiologists",10.1016/j.crad.2018.05.015,,SCOPUS,"A machine learning model using deep convolutional neural networks is developed for binary classification of chest radiographs, achieving high accuracy in normality detection.",❌,Chest Radiographs,✔️,❌
WOS:000965365700061,Machine learning-based probabilistic profitable model in algorithmic trading,"Machine learning models are nowadays becoming ubiquitous in algorithmic trading and investment management. These models are mostly used in the pre-trade analysis phase to determine the buy or sell decisions using various machine learning techniques. We aim to implement a machine learning-driven approach using various technical indicators to predict stock market prices and then accordingly make a decision about buying or selling. First, an effective trading strategy is discussed that selects the potentially profitable stocks, and then the technical indicators such as simple moving average (SMA), exponential moving average (EMA), relative strength index (RSI), and moving average convergence divergence (MACD) are calculated for those potentially profitable stocks. Then supervised machine learning algorithms such as multiple linear regression, support vector machine regression, and decision tree regression are applied, where the close price of the stock is predicted using technical indicators for the next day, and based on that buy or sell signals are generated. The model is then tested on 12 different SNP500 stocks, one for every month in 2018, with the mean squared error (MSE) varying between 30.33 and 48.16 and the root MSE varying between 5.51 and 6.93, where the error is calculated on the difference in the number of days when the stock price actually increases and the predicted number of days for various models.",10.1117/1.jei.32.1.013039,algorithmic trading; machine learning; technical analysis; trading strategy,WOS,"Develops machine learning models using technical indicators to predict S&P500 stock prices and inform buy/sell decisions in algorithmic trading, tested on 12 SNP500 stocks.",✔️,S&P500 Stocks,✔️,❌
WOS:000685167900003,Market efficiency analysis using Al models based on Investors' Mood,"The Efficient Market Hypothesis assumes that stock prices in financial markets incorporate all the historical information in any of its forms (weak, semi-strong and strong). The aim of this study is to validate this hypothesis. This study uses artificial intelligence models designed to predict IBEX trends, based on investor mood, extracting information from the big data and using natural language processing algorithms. The results of the study show that the success rate of a system that trains for only 6 months is higher than a system that uses all the available historical information. Investment strategies can also be based on the forecasts of the artificial intelligence models, which can beat the market, by setting up different trading systems for different degrees of risk, depending on the probability threshold provided by the model considered. These results imply that the Spanish financial market has a short-term memory, and does not include older information and therefore does not fulfill the efficient market hypothesis assumptions.",10.16967/23898186.649,Big data; IBEX; Bayesian Networks; investors' mood; trading systems; market efficiency,WOS,"Uses AI models based on investor mood extracted via NLP from big data to predict IBEX trends, achieving higher accuracy than systems trained on full historical data, implying short-term memory in the market.",✔️,IBEX,✔️,❌
WOS:001133356400001,Meta-Heuristic-Based Hybrid Resnet with Recurrent Neural Network for Enhanced Stock Market Prediction,"This paper is to design a new hybrid deep learning model for stock market prediction. Initially, the collected stock market data from the benchmark sources are pre-processed using empirical wavelet transform (EWT). This pre-processed data is subjected to the prediction model based on hybrid deep learning approach by adopting Resnet and recurrent neural network (RNN). Here, the fully connected layer of Resnet is replaced with the RNN. In both the Resnet and RNN structures, the parameter is optimized using the probabilistic spider monkey optimization (P-SMO) for attaining accurate prediction. When analyzing the proposed P-SMO-ResRNN, it secures 6.27%, 12.26%, 15.13%, 13.61%, and 14.10% more than RNN, DNN, NN, KNN, and SVM, respectively, regarding the MASE analysis. Hence, the proposed model shows enhanced performance. With the elaborated model and estimation of prediction term based on several analyses, this work supports the stock analysis research community.",10.4018/ijdst.307152,Hybrid Deep Learning; Probabilistic Spider Monkey Optimization; Recurrent Neural Network; Resnet,WOS,"Designs a hybrid deep learning model combining ResNet and Recurrent Neural Networks, optimized with probabilistic spider monkey optimization, to enhance stock market prediction accuracy.",✔️,Stock Market,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4049819,Model Risk for European-Style Stock Index Options,"In empirical modeling, there have been two strands for pricing in the options literature, namely the parametric and nonparametric models. Often, the support for the nonparametric methods is based on a benchmark such as the Black-Scholes (BS) model with constant volatility. In this paper, we study the stochastic volatility (SV) and stochastic volatility random jump (SVJ) models as parametric benchmarks against feedforward neural network (FNN) models, a class of neural network models. Our choice for FNN models is due to their well-studied universal approximation properties of an unknown function and its partial derivatives. Since the partial derivatives of an option pricing formula are risk pricing tools, an accurate estimation of the unknown option pricing function is essential for pricing and hedging. Our findings indicate that FNN models offer themselves as robust option pricing tools, over their sophisticated parametric counterparts in predictive settings. There are two routes to explain the superiority of FNN models over the parametric models in forecast settings. These are nonnormality of return distributions and adaptive learning",10.1109/tnn.2006.883005,Pricing;Stochastic processes;Neural networks;Feedforward neural networks;Predictive models;Parametric statistics;Councils;Computer crashes;Robustness;Tail;Extreme tail events;feedforward neural networks (FNNs);nonparametric methods;option pricing;risk exposure,IEEE,"The paper compares parametric models and feedforward neural network models for pricing European-style stock index options, demonstrating the superiority of neural networks in predictive settings.",✔️,European-style stock index options,✔️,❌
WOS:000876112600001,"Modeling Bitcoin Prices using Signal Processing Methods, Bayesian Optimization, and Deep Neural Networks","Bitcoin is a volatile financial asset that runs on a decentralized peer-to-peer Blockchain network. Investors need accurate price forecasts to minimize losses and maximize profits. Extreme volatility, speculative nature, and dependence on intrinsic and external factors make Bitcoin price forecast challenging. This research proposes a reliable forecasting framework by reducing the inherent noise in Bitcoin time series and by examining the predictive power of three distinct types of predictors, namely fundamental indicators, technical indicators, and univariate lagged prices. We begin with a three-step hybrid feature selection procedure to identify the variables with the highest predictive ability, then use Hampel and Savitzky-Golay filters to impute outliers and remove signal noise from the Bitcoin time series. Next, we use several deep neural networks tuned by Bayesian Optimization to forecast short-term prices for the next day, three days, five days, and seven days ahead intervals. We found that the Deep Artificial Neural Network model created using technical indicators as input data outperformed other benchmark models like Long Short Term Memory, Bi-directional LSTM (BiLSTM), and Convolutional Neural Network (CNN)-BiLSTM. The presented results record a high accuracy and outperform all existing models available in the past literature with an absolute percentage error as low as 0.28% for the next day forecast and 2.25% for the seventh day for the latest out of sample period ranging from Jan 1, 2021, to Nov 1, 2021. With contributions in feature selection, data-preprocessing, and hybridizing deep learning models, this work contributes to researchers and traders in fundamental and technical domains.",10.1007/s10614-022-10325-8,Time series forecasting; Deep learning; Bayesian optimization; Savitzky-Golay Filter; Outlier detection,WOS,"The study presents a comprehensive framework combining signal processing, Bayesian optimization, and deep neural networks to forecast Bitcoin prices, outperforming existing models with high accuracy and low error rates during out-of-sample periods.",✔️,Bitcoin,✔️,❌
WOS:000783091400003,"Modeling and prediction of KSE-100 index closing based on news sentiments: an applications of machine learning model and ARMA (p, q) model","The main financial markets of every country are stock exchange and consider as an imperative cause for the corporations to increase capital. The novelty of this study to explore machine learning techniques when applied to financial stock market data, and to understand how machine learning algorithms can be applied and compare the result with time series analysis to real lifetime series data and helpful for any investor. Investors are constantly reviewing past pricing history and using it to influence their future investment decisions. The another novelty of this study, using news sentiments, the values will be processed into lists displaying and representing the stock and predicting the future rates to describe the market, and to compare investments, which will help to avoid uncertainty amongst the investors regarding the stock index. Using artificial neural network technique for prediction for KSE 100 index data on closing day. In this regard, six months' data cycle trained the data and apply the statistical interference using a ARMA (p, q) model to calculate numerical result. The novelty of this study to find the relation between them either they are strongly correlated or not, using machine learning techniques and ARMA (p, q) process to forecast the behavior KSE 100 index cycles. The adequacy of model describes via least values Akaike information criterion (AIC), Bayesian Schwarz information criterion (SIC) and Hannan Quinn information criterion (HIC). Durbin- Watson (DW) test is also applied. DW values (< 2) shows that all cycles are strongly correlated. Most of the KSE-100 index cycles expresses that the appropriate model is ARMA (2,1). Cycle's 2nd,3rd,4th and 5th shows that ARMA (3,1) is best fitted. Cycle 8th is shows ARMA (1,1) best fit and cycle 12th shows that the most appropriate model is ARMA (4,1). Diagnostic checking tests like Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Theil's U-Statistics are used to predict KSE-100 index cycles. Theil's U-Statistics demonstrate that each cycle is strongly correlated to previous one.",10.1007/s11042-022-13052-2,KSE-100 index; ARMA (p; Q); RMSE; MAE; Theil's U-statistics,WOS,"Combines news sentiments with machine learning models and ARMA models to predict KSE-100 index closing prices, using ANN and ARMA models with evaluation via various error metrics.",✔️,KSE-100 Index,✔️,❌
10.1109/JSAIT.2024.3397741,Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing,"Machine learning (ML) models used in prediction and classification tasks may display performance disparities across population groups determined by sensitive attributes (e.g., race, sex, age). We consider the problem of evaluating the performance of a fixed ML model across population groups defined by multiple sensitive attributes (e.g., race and sex and age). Here, the sample complexity for estimating the worst-case performance gap across groups (e.g., the largest difference in error rates) increases exponentially with the number of group-denoting sensitive attributes. To address this issue, we propose an approach to test for performance disparities based on Conditional Value-at-Risk (CVaR). By allowing a small probabilistic slack on the groups over which a model has approximately equal performance, we show that the sample complexity required for discovering performance violations is reduced exponentially to be at most upper bounded by the square root of the number of groups. As a byproduct of our analysis, when the groups are weighted by a specific prior distribution, we show that R&#x00E9;nyi entropy of order 2/3 of the prior distribution captures the sample complexity of the proposed CVaR test algorithm. Finally, we also show that there exists a non-i.i.d. data collection strategy that results in a sample complexity independent of the number of groups. IEEE",10.1109/jsait.2024.3397741,Complexity theory; Entropy; hypothesis testing; Information theory; intersectional fairness; intersectionality; Measurement; multi-group fairness; Sociology; Statistics; Testing,SCOPUS,"Introduces a Conditional Value-at-Risk-based test for evaluating multi-group fairness in ML models, reducing sample complexity significantly.",❌,?,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887150,Multi-Layer Coupled Hidden Markov Model for Cross-Market Behavior Analysis and Trend Forecasting,"The frequent global financial crisis indicates the increasing importance and challenge to analyze and forecast the future trends of stock market for investors and trading agents. Especially with the globalization of the world economy and integration of international financial markets, the complex relationships between markets from different countries should be considered in forecasting market trends, involving multi-layered, interactive, evolutionary, and heterogeneous financial variables and the couplings between variable sets from different countries. A variety of methods have been proposed and implemented for forecasting stock market trends, but there is very limited work reported on predicting a market's movement based on analyzing the multi-layered, hidden coupling relationships between various markets in different countries. This involves the analysis of hierarchical coupled behaviors and their relationships across multiple markets, and the nonlinear market dynamics. To address this critical issue, this paper proposes a new approach Multi-layer Coupled Hidden Markov Model (MCHMM) for Hierarchical Cross-market Behavior Analysis (HCBA), namely exploring the complex coupling relationships between variables of markets from a country (Layer-1 coupling) and couplings between markets from various countries (Layer-2 coupling), to forecast a stock market's movements. Toward capturing the hierarchical coupled market behaviors, a Multi-layered Coupled Hidden Markov Model (MCHMM) is built to infer movements of a stock market in a target country by forecasting its price return probabilities. The experimental results on 11 years of data from two types of markets (stock market and currency market) of 13 countries show that our proposed approach outperforms other four benchmarks from technical and business perspectives.",10.1109/access.2019.2950437,Hidden Markov models;Couplings;Forecasting;Market research;Stock markets;Time series analysis;Currencies;Cross-market behavior analysis;MCHMM;trend forecasting;financial market,IEEE,"[Duplicate or similar entry] A Multi-Layer Coupled Hidden Markov Model is proposed for hierarchical cross-market behavior analysis and trend forecasting, effectively capturing relationships between markets across countries.",✔️,Stock Market Indices,✔️,✔️
WOS:000870513100007,Multi-Model Generative Adversarial Network Hybrid Prediction Algorithm (MMGAN-HPA) for stock market prices prediction,"Deep learning has achieved greater success in optimizing solutions associated with Artificial Intelligence (AI). In the financial domain, it is widely used for stock market prediction, trade execution strategies and portfolio optimization. Stock market prediction is a very significant use case in this domain. Generative Adversarial Networks (GANs) with advanced AI models have gained significance of late. However, it is used in image-image-translation and other computer vision scenarios. GANs are not used much for stock market prediction due to its difficulty in setting the right set of hyperparameters. In this paper, overcome this problem with reinforcement learning and Bayesian optimization. A deep learning framework based on GAN, named Stock-GAN, is implemented with generator and discriminator. The former is realized with LSTM, a variant of Recurrent Neural Network (RNN), while the latter uses Convolutional Neural Network. An algorithm named Generative Adversarial Network based Hybrid Prediction Algorithm (GAN-HPA) is proposed. An empirical study revealed that Stock-GAN achieves promising performance in stock price prediction when compared with the state of the art model known as Multi-Model based Hybrid Prediction Algorithm (MM-HPA). Afterwards, MM-HPA and GAN-HPA combined to form yet another hybrid model known as MMGAN-HPA for improved performance over MM-HPA and GAN-HPA.(c) 2021 The Authors. Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).",10.1016/j.jksuci.2021.07.001,Deep learning; Generative Adversarial Network (GAN); Recurrent Neural Network (RNN); Convolutional Neural Network (CNN); Stock market analysis,WOS,"Implements a multi-model GAN-based hybrid prediction algorithm using reinforcement learning and Bayesian optimization to accurately predict stock market prices, outperforming state-of-the-art models.",✔️,Stock Prices,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138373,Multi-Stage Volt/VAR Support in Distribution Grids: Risk-Aware Scheduling With Real-Time Reinforcement Learning Control,"The ever-increasing penetration of intermittent renewable resources in low-voltage power grids necessitates efficient operational strategies for voltage regulation as well as power scheduling of the available resources. In this paper, a risk-aware Volt/VAR support framework followed by a real-time reinforcement learning controller is presented for three-phase distribution systems. In the risk-aware stochastic scheduling stage, the legacy voltage regulating assets along with inverter-based photovoltaics (PVs) and energy storage system (ESS) are optimized considering day-ahead and intra-day markets. Moreover, demand response (DR) and voltage reduction plans are included in the proposed scheduling framework. By incorporating voltage-dependent load modeling in this study, the implementation of the voltage reduction plan reduces energy consumption in feeders by running the network at lower permissible voltage limits. The shiftable loads under the DR program are employed for peak shaving and to reduce operational costs. The result shows that DR implementation also reduces dependencies on the operation of traditional devices. The stochasticity of abrupt changes in PV generations is represented as the Gaussian Mixture Model (GMM), indicating a non-unimodal probability distribution in day-ahead PV forecasting errors. The scenario sets for uncertain variables are then reduced using a fuzzy clustering technique. Decisions made in the scheduling, associated with PV inverters and ESS operation, are revised with a real-time controller, i.e., Deep Deterministic Policy Gradient (DDPG) reinforcement learning. The DDPG is adopted in the control stage of the framework considering the detailed modeling of unbalanced three-phase distribution grids to minimize the voltage deviation and power ramping of ESS. The performance of the proposed multi-stage scheme is verified using a three-phase active distribution grid under different scenarios.",10.1109/access.2023.3280558,Voltage control;Real-time systems;Optimization;Uncertainty;Stochastic processes;Load modeling;Inverters;Reactive power;Demand response;Gaussian processes;Reinforcement learning;Demand response program;Gaussian mixture model;reinforcement learning;risk-aware scheduling;Volt/VAR support,IEEE,"A graph-aware Gaussian process model with generalized Gaussian likelihood is introduced for portfolio selection, enhancing mean-variance analysis with uncertainty capture.",✔️,Portfolio (Various Assets),✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894113,Multimarket Trading Strategy of a Hydropower Producer Considering Active-Time Duration: A Distributional Regression Approach,"This article presents a new approach for finding the optimal multimarket trading strategy of cascaded hydropower plants (HPPs) in the sequential electricity markets. These markets are day-ahead energy market, the market for frequency containment reserve in normal mode (FCR-N), and manual frequency restoration reserve markets for both energy production and capacity reserve. The active-time duration (ATD) of an mFRR energy offer is an important required parameter and it is uncertain at the time of day-ahead offer-function submission. Hence, we suggest a distributional regression approach for ATD modeling in an optimal multimarket setup. Also, a modified machine learning approach is proposed to generate price scenarios for the mFRR energy market taking into account uncertain ATD parameters. To illustrate our proposed approach, various numerical experiments are performed. Our numerical results show how proper modeling of ATD parameters can lead to a more realistic multimarket offer-function for cascaded HPPs. Furthermore, the results show how the inclusion of FCR-N and mFRR capacity markets change the optimal day-ahead offer-function.",10.1109/jsyst.2022.3205142,Hydroelectric power generation;Electricity supply industry;Real-time systems;Europe;Deep learning;Production;Predictive models;Cascaded hydropower plants (HPPs);distributional regression;electricity market;machine learning,IEEE,"Presents a machine learning-based distributional regression framework for optimal trading strategies in electricity markets, incorporating uncertainty in active-time duration.",✔️,Electricity (Energy Markets),✔️,✔️
WOS:000549854400025,Multivariate Financial Time-Series Prediction With Certified Robustness,"The futures market's forecasts are significant to investors and policymakers, where the application of deep learning approaches to finance has received a great deal of attention. In this study, we propose a multivariate financial time-series forecasting method. Our model addresses the long- and short-term features, multimodal and non-stationarity nature of multivariate time-series by incorporating the improved deep neural networks and certified noise injection. Specifically, multimodal variational autoencoder is used to extract deep high-level features of multivariate time-series, Long- and Short- Term recurrent neural network is applied for multivariate time-series forecasting, and certified noise injection mechanism, inspired by differential privacy, is proposed to improve the robustness and accuracy of prediction. Extensive empirical results on real-world agricultural commodity futures price time series and relevant external data demonstrate that our model achieves better performance over that of several state-of-the-art baseline methods.",10.1109/access.2020.3001287,Time series analysis; Feature extraction; Differential privacy; Logic gates; Sensitivity; Robustness; Predictive models; Futures prices; deep neural networks; prediction; multivariate; Gaussian noise,WOS,"A multivariate financial time-series forecasting method using variational autoencoders and reinforced with noise injection is proposed, demonstrating superior performance on commodity futures.",✔️,Agricultural Commodity Futures,✔️,✔️
WOS:000380081200006,Negation scope detection in sentiment analysis: Decision support for news-driven trading,"Decision support for financial news using natural language processing requires robust methods that process all sentences correctly, including those that are negated. To predict the corresponding negation scope, related literature commonly utilizes rule-based algorithms and generative probabilistic models. In contrast, we propose the use of a tailored reinforcement learning method, since it can conquer learning task of arbitrary length. We then perform a thorough comparison with a two-pronged evaluation. First, we compare the predictive performance using a manually-labeled dataset. Here, reinforcement learning outperforms common approaches from the related literature, leading to a balanced classification accuracy of up to 70.17%. Second, we examine how detecting negation scopes can improve the accuracy of sentiment analysis for financial news, leading to an improvement of up to 10.63% in the correlation between news sentiment and stock market returns. This reveals negation scope detection as a crucial leverage in decision support from sentiment. (C) 2016 Elsevier B.V. All rights reserved.",10.1016/j.dss.2016.05.009,Decision support; Machine learning; Sentiment analysis; Negation scope detection; Financial news,WOS,"Proposes a reinforcement learning-based method for detecting negation scopes in sentiment analysis to enhance the accuracy of news-driven trading decisions, improving the correlation between sentiment and stock returns.",❌,Stock Returns,✔️,❌
2-s2.0-79957931366,Neural networks and investor sentiment measures for stock market trend prediction,"Soft computing methods and various sentiment indicators are employed to conduct out-of-sample predictions of the future sign of the stock market returns. In particular, we assess the performance of the probabilistic neural network (PNN) against the back-propagation neural network (BPNN) in predicting technology stocks and NYSE up and down moves. Genetic algorithms (GA) are employed to optimize the topologies of the BPNN. Our results from Granger causality tests show strong evidence that all stock returns are strongly related to at least one of the sentiment variables. In addition, the results from simulations show that the GA-BPNN is more capable of distinguishing between market ups and downs than the PNN. Finally, the simulations show that trading given decision rules (for example; buy stock if predicted return is higher than a given threshold) yields to higher accuracy than predicting the stock market ups and downs. © 2005-2011 JATT & LLs All rights reserved.",,Artificial intelligence; Classification; Stock market,SCOPUS,The article compares Probabilistic Neural Networks and Back-Propagation Neural Networks in predicting stock market trends and demonstrates that GA-optimized BPNN outperforms PNN and other models in distinguishing market movements.,✔️,Stock,✔️,✔️
9798382067292,Nonparametric Bayesian Models for Learning Network Coupling Relationships,"As the traditional machine learning setting assumes that the data are identically and independently distributed (i.i.d), this is quite like a perfect conditioned vacuum and seldom a real case in practical applications. Thus, the non-i.i.d learning (Cao, Ou, Yu & Wei 2010)(Cao, Ou & Yu 2012)(Cao 2014) has emerged as a powerful tool in describing the fundamental phenomena in the real world, as more factors to be well catered in this modelling. One critical factor in the non-i.i.d. learning is the relations among the data, ranging from the feature information, node partitioning to the correlation of the outcome, which is referred to as the coupling relation in the non-i.i.d. learning. In our work, we aim at uncovering this coupling relation with the nonparametric Bayesian relational models, that is, the data points in our work are supposed to be coupled with each other, and it is this coupling relation we are interested in for further investigation. The coupling relation is widely seen and motivated in real world applications, for example, the hidden structure learning in social networks for link prediction and structure understanding, the fraud detection in the transactional stock market, the protein interaction modelling in biology.In this thesis, we are particularly interested in the learning and inferencing on the relational data, which is to further discover the coupling relation between the corresponding points. For the detail modelling perspective, we have focused on the framework of mixed-membership stochastic blockmodel, in which membership indicator and mixed-membership distributionare noted to represent the nodes’ belonging community for one relation and the histogram of all the belonging communities for one node. More specifically, we are trying to model the coupling relation through three different aspects: 1) the mixed-membership distributions’ coupling relation across the time. In this work, the coupling relation is reflected in the sticky phenomenon between the mixed-membership distributions in two consecutive time; 2) the membership indicators’ coupling relation, in which the Copula function is utilized to depict the coupling relation; 3) the node information and mixed-membership distribution’s coupling relation. This is achieved by the new proposal transform for the node information’s integration. As these three aspects describe the critical parts of the nodes’ interaction with the communities, we are hoping the complex hidden structures can thus be well studied.In all of the above extensions, we set the number of the communities in a nonparametric Bayesian prior (mainly Hierarchical Dirichlet Process), instead of fixing it as in the previous classical models. In such a way, the complexity of our model can grow along with the data size. That is to say, while we have more data, our model can have a larger amount of communities to account for them. This appealing property enables our models to fit the data better. Moreover, the nice formalization of the Hierarchical Dirichlet Process facilitates us to some benefits, such as the conjugate prior. Thus, this nonparametric Bayesian prior has introduced new elements to the coupling relations’ learning.Under this varying backgrounds and scenarios, we have shown our proposed models and frameworks for learning the coupling relations are evidenced to outperform the state-of-the-art methods via literature explanation and empirical results. The outcomes are sequentially accepted by top journals. Therefore, the nonparametric Bayesian models in learning the coupling relations presents high research value and would still be attractive opportunities for further exploration and exploit.",,,Proquest,"The thesis develops nonparametric Bayesian models to learn coupling relationships in network data, with applications including stock market analysis, enhancing understanding of complex interactions among financial variables.",❌,?,✔️,✔️
WOS:000619190000002,ON A COMPUTATIONALLY SCALABLE SPARSE FORMULATION OF THE MULTIDIMENSIONAL AND NONSTATIONARY MAXIMUM ENTROPY PRINCIPLE,"Data-driven modeling and computational predictions based on the maximum entropy principle (MaxEnt principle) aim to find as simple as possible-but not simpler than necessary-models that allow one to avoid the data-overfitting problem. We derive a multivariate nonparametric and nonstationary formulation of the MaxEnt principle and show that its solution can be approximated through a numerical maximization of the sparse constrained optimization problem with regularization. Application of the resulting algorithm to popular financial benchmarks reveals memoryless models allowing for simple and qualitative descriptions of data of the major stock market indices. We compare the obtained MaxEnt models to the heteroscedastic models from computational econometrics (GARCH, GARCH-GJR, MS-GARCH, and GARCH-PML4) in terms of the model fit, complexity, and prediction quality. We compare the resulting model log-likelihoods, the values of the Bayesian information criterion, posterior model probabilities, the quality of the data autocorrelation function fits, as well as the value-at-risk prediction quality. We show that all of the seven considered major financial benchmark time series (DJI, SPX, FTSE, STOXX, SMI, HSI, and N225) are better described by conditionally memoryless MaxEnt models with nonstationary regime-switching than by the common econometric models with finite memory. This analysis also reveals a sparse network of statistically significant temporal relations for the positive and negative latent variance changes among different markets. The code is provided for open access.",10.2140/camcos.2020.15.129,machine learning; financial time series; maximum entropy; heteroscedasticity; sparsity,WOS,"Develops a multivariate nonparametric formulation of the MaxEnt principle and applies it to financial benchmarks, comparing to econometric models, showing better description with probabilistic measures.",✔️,"Financial Indices (DJI, SPX, etc.)",❌,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10645704,On Confidence Sequences for Bounded Random Processes via Universal Gambling Strategies,"This paper considers the problem of constructing a confidence sequence, which is a sequence of confidence intervals that hold uniformly over time, for estimating the mean of bounded real-valued random processes. This paper revisits the gambling-based approach established in the recent literature from a natural two-horse race perspective, and demonstrates new properties of the resulting algorithm induced by Cover (1991)’s universal portfolio. The main result of this paper is a new algorithm based on a mixture of lower bounds, which closely approximates the performance of Cover’s universal portfolio with constant per-round time complexity. A higher-order generalization of a lower bound on a logarithmic function in (Fan et al., 2015), which is developed as a key technique for the proposed algorithm, may be of independent interest.",10.1109/tit.2024.3448461,Vectors;Games;Portfolios;Stochastic processes;Complexity theory;Stock markets;Standards;Confidence sequences;time-uniform confidence intervals;gambling;universal portfolios,IEEE,The paper develops a new algorithm for constructing confidence sequences in bounded random processes using universal gambling strategies and portfolio approaches.,❌,?,?,?
10.1073/pnas.2214972120,On cheap entropy-sparsified regression learning,"Regression learning is one of the long-standing problems in statistics, machine learning, and deep learning (DL). We show that writing this problem as a probabilistic expectation over (unknown) feature probabilities, increasing the number of unknown parameters and seemingly making the problem more complex-actually leads to a simplification, allowing to incorporate the physical principle of entropy maximization. It helps decompose a very general setting of this learning problem (including discretization, feature selection, and learning multiple piece-wise linear regressions) into an iterative sequence of simple substeps, which are either analytically solvable or cheaply computable through an efficient second-order numerical solver with a sublinear cost scaling. This leads to the computationally cheap and robust non- DL second-order Sparse Probabilistic Approximation for Regression Task Analysis (SPARTAn) algorithm, that can be efficiently applied to problems with millions of feature dimensions on a commodity laptop, when the state-of-the-art learning tools would require supercomputers. SPARTAn is compared to a range of commonly used regression learning tools on synthetic problems and on the prediction of the El Niño Southern Oscillation, the dominant interannual mode of tropical climate variability. The obtained SPARTAn learners provide more predictive, sparse, and physically explainable data descriptions, clearly discerning the important role of ocean temperature variability at the thermocline in the equatorial Pacific. SPARTAn provides an easily interpretable description of the timescales by which these thermocline temperature features evolve and eventually express at the surface, thereby enabling enhanced predictability of the key drivers of the interannual climate.  © 2022 the Author(s).",10.1073/pnas.2214972120,climate prediction; entropy; numerics; supervised learning,SCOPUS,"Introduces the SPARTAn algorithm, a non-deep learning probabilistic regression method for large-scale feature problems, applied to climate and El Niño prediction.",✔️,El Niño Southern Oscillation,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731844,On the Economic Significance of Stock Market Prediction and the No Free Lunch Theorem,"Forecasting of stock market returns is a challenging research activity that is now expanding with the availability of new data sources, markets, financial instruments, and algorithms. At its core, the predictability of prices still raises important questions. Here, we discuss the economic significance of the prediction accuracy. To develop this question, we collect the daily series prices of almost half of the publicly traded companies around the world over a period of ten years and formulate some trading strategies based on their prediction. Proper visualization of these data together with the use of the No Free Lunch theoretical framework gives some unexpected results that show how the a priori less accurate algorithms and inefficient strategies can offer better results than the a priori best alternatives in some particular subsets of data that have a clear interpretation in terms of economic sectors and regions.",10.1109/access.2019.2921092,Prediction algorithms;Companies;Support vector machines;Databases;Stock markets;Data visualization;Stock market;economic significance;forecasting;prediction algorithm;trading strategies;extended Bayesian framework;no free lunch theorem;support vector machines;big data;visualization,IEEE,"The paper explores the economic implications of stock market prediction accuracy, demonstrating through trading strategies that even less accurate algorithms can be profitable under certain conditions, aligning with the No Free Lunch theorem.",✔️,Stocks,❌,❌
WOS:001157113100001,On the pricing of capped volatility swaps using machine learning techniques,"A capped volatility swap is a forward contract on an asset's capped, annualized, realized volatility, over a predetermined period of time. This paper presents data-driven machine learning techniques for pricing such capped volatility swaps, using unique data sets comprising both the strike price of contracts at initiation and the daily observed prices of running contracts. Additionally, the developed model can serve as a validation tool for external volatility swap prices, flagging prices that deviate significantly from the estimated value. In order to predict the capped, future, realized volatility, we explore distributional information on the underlying asset, specifically by extracting information from the implied volatilities and market-implied moments of the asset. The pricing performance of tree-based machine learning techniques and a Gaussian process regression model is evaluated in a validation setting tailored to the use of financial data.",10.1080/14697688.2024.2305643,Capped volatility swaps; Pricing; Implied volatility; Market-implied moments; Gaussian process regression; Tree-based machine learning,WOS,"The paper introduces machine learning methods, including tree-based techniques and Gaussian process regression, for pricing capped volatility swaps and validating external swap prices, demonstrating improved predictive performance in financial derivatives pricing.",✔️,Capped volatility swaps,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320514,Online Sequential Extreme Learning Machine Algorithm for Better Predispatch Electricity Price Forecasting Grids,"The predispatch price forecast plays a key element in the electricity market. However, such a forecast usually depends on the traditional offline batch-learning technologies, which cannot respond in time to the unexpected changes in the local power system environment. Further, the predispatch local price forecast is often affected by the dynamic price changes from the neighboring regions. This article proposes a novel online learning forecast approach to overcome the above issues to provide a better predispatch price forecast by using the online sequential extreme learning machine (OS-ELM) algorithm. The article proposes a novel data structure in the form of a 2-D orthogonal list and two corresponding OS-ELM modules. One module provides the rolling day-ahead price prediction and prediction intervals using the day-by-day online training update, while the other provides the rolling 30-min prediction using the 2-h-by-2-h online training update. The proposed approach can continuously perceive any unexpected events and any price fluctuations from the neighboring regions in the nonlinear patterns. The proposed approach is validated using simulation studies based on the data from the Australian electricity market, and the simulation results show that the proposed approach can help in improving the forecast accuracy, especially when unexpected changes occur both locally and in the neighboring area.",10.1109/tia.2021.3051105,Training;Forecasting;Electricity supply industry;Uncertainty;Prediction algorithms;Extreme learning machines;Artificial neural networks;Electricity market;electricity price;extreme learning machine;online training;regression analysis,IEEE,"Develops a Bayesian Regularized Neural Network for analyzing Bitcoin trends, integrating uncertainty estimation to enhance forecasting reliability.",✔️,Cryptocurrency (Bitcoin),✔️,✔️
WOS:000530547900016,Online sequential pattern mining and association discovery by advanced artificial intelligence and machine learning techniques,"With the advances in information science, vast amounts of financial time series data can been collected and analyzed. In modern time series analysis, sequential pattern mining (SPM) and association discovery (AD) are the most important techniques to predict the future trends. This study aims at developing advanced SPM and AD for financial data by cutting edge techniques from artificial intelligence and machine learning. The nonlinearity and non-stationarity of financial time series dynamics pose a major challenge for SPM and AD. This study employs time-frequency analysis to extract features for SPM. Then, a sparse multi-manifold clustering (SMMC) is used to partition the feature space into several disjointed regions for better AD. Finally, local relevance vector machines (RVMs) are employed for AD and perform the forecasting. Different from traditional methods, the novel forecasting system operates on multiple resolutions and multiple dynamic regimes. SMMC finds both the neighbors and the weights automatically by a sparse solution, which approximately spans a low-dimensional affine subspace at that point. RVM, the Bayesian kernel machines, can produce parsimonious models with excellent generalization properties. Taking multiple time series data from financial markets as an example, the empirical results demonstrate that the proposed model outperforms traditional models and significantly reduces the forecasting errors. The framework is effective and suitable for other time series forecasting.",10.1007/s00500-019-04100-5,Multi-scale representation; Manifold clustering; Local modeling; Kernel machine; Time-frequency analysis,WOS,The study develops advanced sequential pattern mining and association discovery methods using AI and machine learning techniques for forecasting financial time series across multiple resolutions and dynamic regimes.,✔️,Financial markets data,✔️,❌
WOS:000346281800008,Operational risk modelling and organizational learning in structured finance operations: a Bayesian network approach,"This paper describes the development of a tool, based on a Bayesian network model, that provides posteriori predictions of operational risk events, aggregate operational loss distributions, and Operational Value-at-Risk, for a structured finance operations unit located within one of Australia's major banks. The Bayesian network, based on a previously developed causal framework, has been designed to model the smaller and more frequent, attritional operational loss events. Given the limited availability of risk factor event information and operational loss data, we rely on the elicitation of subjective probabilities, sourced from domain experts. Parameter sensitivity analysis is performed to validate and check the model's robustness against the beliefs of risk management and operational staff. To ensure that the domain's evolving risk profile is captured through time, a formal approach to organizational learning is investigated that employs the automatic parameter adaption features of the Bayesian network model. A hypothetical case study is then described to demonstrate model adaption and the application of the tool to operational loss forecasting by a business unit risk manager.",10.1057/jors.2013.49,banking; finance; operational risk; probabilistic methods; artificial intelligence; Bayesian networks,WOS,?,?,?,?,
WOS:001137843200001,Optimal model description of finance and human factor indices,"Economists have conducted research on several empirical phenomena regarding the behavior of individual investors, such as how their emotions and opinions influence their decisions. All those emotions and opinions are described by the word Sentiment. In finance, stochastic changes might occur according to investors sentiment levels. In this study, our main goal is to apply several operational research techniques and analyze these techniques' accurance. Firstly, we represent the mutual effects between some financial process and investors sentiment with multivariate adaptive regression splines (MARS) model. Furthermore, we consider to extend this model by using distinct data mining techniques and compare the gain in accuracy and computational time with its strong alternatives applied in the analyses of the financial data. Hence, the goal of this study is to compare the forecasting performance of sentiment index by using two-stage MARS-NN (neural network), MARS-RF (random forest), RF-MARS, RF-NN, NN-MARS, and NN-RF hybrid models. Furthermore, we aim to classify the peoples' feelings about economy according to their confidence levels. Moreover, to forecast the underlying state change of the consumer confidence index (CCI) and to observe the relationship with some macroeconomic data (CPI, GDP and currency rate) at a monthly interval, we apply hidden Markov model (HMM). The aim is to detect the switch between these states and to define a path of these states. We also aim to use volatility models for mainly sentiment index, consumer confidence index, and other indices so that we can get better forecasting results from those datasets.",10.1007/s10100-023-00897-7,Investor sentiment; Consumer confidence index; Sentiment index; Machine learning; HMM; Volatility model; Operational research,WOS,"The study applies multivariate adaptive regression splines and hidden Markov models to forecast consumer confidence indices, incorporating sentiment analysis and macroeconomic data.",✔️,"Consumer Confidence Index, Macroeconomic Indicators",✔️,❌
WOS:000998898300002,Optimization of mixture models on time series networks encoded by visibility graphs: an analysis of the US electricity market,We propose a fully unsupervised network-based methodology for estimating Gaussian Mixture Models on financial time series by maximum likelihood using the Expectation-Maximization algorithm. Visibility graph-structured information of observed data is used to initialize the algorithm. The proposed methodology is applied to the US wholesale electricity market. We will demonstrate that encoding time series through Visibility Graphs allows us to capture the behavior of the time series and the nonlinear interactions between observations well. The results reveal that the proposed methodology outperforms more established approaches.,10.1007/s10287-023-00460-4,Visibility graph; Markov transition field; Graph embedding; Graph machine learning; Topological data analysis,WOS,"A network-based methodology using Gaussian Mixture Models and visibility graphs is proposed for analyzing the US electricity market, showing superior performance over established approaches.",❌,?,✔️,✔️
WOS:001207315000004,Optimized Ensemble Support Vector Regression Models for Predicting Stock Prices with Multiple Kernels,"Stock forecasting is a complicated and daily challenge for investors because of the non -linearity of the market and the high volatility of financial assets such as stocks, bonds and other commodities. There is a need for a powerful and adaptive stock prediction model that handles complexities and provides accurate predictions. The support vector regression (SVR) model is one of the most prominent machine learning models for forecasting time series data. An ensemble hyperbolic tangent kernel SVR (HTK-SVR-BO) is proposed in this paper, combining Tanh and inverse Tanh kernels with Bayesian optimization. Combining the strengths of multiple kernels using the ensemble technique and then using optimization to identify the optimal values for each SVR model to enhance the ensemble model performance is possible. Our proposed model is compared with an ensemble SVR model (LPR-SVR-BO), which uses well-known SVR kernel types, including linear, polynomial and radial basis function (RBF). We apply the proposed models to Microsoft Corporation (MSFT) stock prices. The mean absolute error (MAE), mean squared error (MSE), root mean squared error (RMSE), R2 score (model accuracy) and mean absolute percentage error (MAPE) are the regression metrics used to compare the effectiveness of each ensemble model. In our comparison, HTK-SVR-BO performs better in terms of regression metrics compared to LPR-SVR-BO and achieves results of 0.27424, 0.13392, 0.36595, 0.99997 and 5.2331 respectively. According to the analysis, the proposed model is more predictive and may generalize to previously unknown data more effectively, so it can be accurate when forecasting future stock prices.",10.18267/j.aip.226,Microsoft corporation (MSFT); Stock forecast; SVR; Hyperbolic tangent kernels (HTK); Linear polynomial RBF kernels (LPR); Ensemble model; Bayesian optimization (BO); Regression metrics,WOS,"Proposes an ensemble SVR model combining multiple kernels optimized via Bayesian optimization to predict Microsoft stock prices, outperforming traditional SVR models.",✔️,Microsoft Stock,✔️,❌
WOS:001286763200095,PMANet: a time series forecasting model for Chinese stock price prediction,"Forecasting stock movements is a crucial research endeavor in finance, aiding traders in making informed decisions for enhanced profitability. Utilizing actual stock prices and correlating factors from the Wind platform presents a potent yet intricate forecasting approach. While previous methodologies have explored this avenue, they encounter challenges including limited comprehension of interrelations among stock data elements, diminished accuracy in extensive series, and struggles with anomaly points. This paper introduces an advanced hybrid model for stock price prediction, termed PMANet. PMANet is founded on Multi-scale Timing Feature Attention, amalgamating Multi-scale Timing Feature Convolution and Ant Particle Swarm Optimization. The model elevates the understanding of dependencies and interrelations within stock data sequences through Probabilistic Positional Attention. Furthermore, the Encoder incorporates Multi-scale Timing Feature Convolution, augmenting the model's capacity to discern multi-scale and significant features while adeptly managing lengthy input sequences. Additionally, the model's proficiency in addressing anomaly points in stock sequences is enhanced by substituting the optimizer with Ant Particle Swarm Optimization. To ascertain the model's efficacy and applicability, we conducted an empirical study using stocks from four pivotal industries in China. The experimental outcomes demonstrate that PMANet is both feasible and versatile in its predictive capability, yielding forecasts closely aligned with actual values, thereby fulfilling application requirements more effectively.",10.1038/s41598-024-69303-9,Stock price prediction; Informer; Deep learning; Time series forecasting model,WOS,"Introduces PMANet, a multi-scale timing feature attention-based neural network optimized with ant particle swarm optimization, for accurately forecasting Chinese stock prices across key industries.",✔️,Chinese Stock Prices,✔️,❌
WOS:001260917700002,PROPOSED BAYESIAN OPTIMIZATION BASED LSTM-CNN MODEL FOR STOCK TREND PREDICTION,"Stock prediction is prominent in the field of Artificial Intelligence. Stock prediction problems are handled either as a regression or classification task. Studies in the literature have also shown success for hybrid learning to stock prediction. But little attention is paid to finding out the effect of spatial feature extraction/distortion over the temporal effect of the deep neural network and vice versa for the problem under study. The paper, therefore, proposes a hybrid long shortterm memory (LSTM) network over a convolutional neural network (CNN) called LSTM-CNN as against the popular CNN-LSTM model. The daily price movement of the S & P 500 index data is utilized. A sliding window technique is considered to obtain a balanced data of 20 -days window data from the S & P 500. The proposed stock prediction model is investigated further for an optimal set of hyperparameters using the Bayesian optimization (Bo) technique. In addition, the proposed model is compared with optimized CNN, LSTM, and CNN-LTSM models. The optimized LSTM-CNN model is found to outperform the other models with accuracy, precision, and recall values of 0.9741, 0.9684, and 0.9800, respectively. The proposed model is established to provide a better stock trend prediction.",10.31577/cai_2024_1_38,Stock management; hybrid learning; deep learning; optimization; pre- diction,WOS,"The paper introduces a Bayesian optimization-enhanced LSTM-CNN hybrid model for predicting stock trends, demonstrating superior performance on S&P 500 data.",✔️,S&P 500 index,✔️,❌
WOS:000336191800020,Parametric models and non-parametric machine learning models for predicting option prices: Empirical comparison study over KOSPI 200 Index options,"We investigated the performance of parametric and non-parametric methods concerning the in-sample pricing and out-of-sample prediction performances of index options. Comparisons were performed on the KOSPI 200 Index options from January 2001 to December 2010. To verify the statistical differences between the compared methods, we tested the following null hypothesis: two series of forecasting errors have the same mean-squared value. The experimental study reveals that non-parametric methods significantly outperform parametric methods on both in-sample pricing and out-of-sample pricing. The outperforming non-parametric method is statistically different from the other models, and significantly different from the parametric models. The Gaussian process model delivers the most outstanding performance in forecasting, and also provides the predictive distribution of option prices. (C) 2014 Elsevier Ltd. All rights reserved.",10.1016/j.eswa.2014.01.032,Option pricing; Gaussian processes; Support vector machines; Artificial neural network; Black-Scholes model; Heston model; Merton model,WOS,"This empirical study compares parametric and non-parametric machine learning models for predicting KOSPI 200 index option prices, finding that non-parametric models, particularly Gaussian processes, significantly outperform parametric approaches in both in-sample and out-of-sample forecasting.",✔️,KOSPI 200 Index options,✔️,✔️
10.1371/journal.pone.0308488,Period-aggregated transformer for learning latent seasonalities in long-horizon financial time series,"Fluctuations in the financial market are influenced by various driving forces and numerous factors. Traditional financial research aims to identify the factors influencing stock prices, and existing works construct a common neural network learning framework that learns temporal dependency using a fixed time window of historical information, such as RNN and LSTM models. However, these models only consider the short-term and point-to-point relationships within stock series. The financial market is a complex and dynamic system with many unobservable temporal patterns. Therefore, we propose an adaptive period-aggregation model called the Latent Period-Aggregated Stock Transformer (LPAST). The model integrates a variational autoencoder (VAE) with a period-to-period attention mechanism for multistep prediction in the financial time series. Additionally, we introduce a self-correlation learning method and routing mechanism to handle complex multi-period aggregations and information distribution. Main contributions include proposing a novel period-aggregation representation scheme, introducing a new attention mechanism, and validating the model’s superiority in long-horizon prediction tasks. The LPAST model demonstrates its potential and effectiveness in financial market prediction, highlighting its relevance in financial research and predictive analytics. © 2024 Tang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",10.1371/journal.pone.0308488,,SCOPUS,"A period-aggregated transformer model is developed to learn latent seasonalities in long-horizon financial time series, demonstrating effectiveness in financial market prediction.",✔️,Financial Time Series,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10083301,Portfolio Selection via Graph-Aware Gaussian Processes With Generalized Gaussian Likelihood,"Portfolio selection aims to manage the allocation of wealth among different assets, which remains to be a fundamental and challenging financial task. Markowitz's mean-variance analysis is one of the most well-known and widely adopted techniques for this problem. However, it requires accurate estimations of both the mean and variance of the return, while predicting the variance is particularly difficult. In this article, we propose a novel portfolio selection strategy based on a graph-aware Gaussian process model equipped with generalized Gaussian distribution (GGD) likelihood. Our method unleashes the potential of mean-variance analysis by exploiting the Gaussian process model's ability in capturing uncertainty, and the graph information is also incorporated so that correlation among different assets can be utilized. We notice that most existing financial models assume the returns follow the log-normal distribution, whereas we observe that it cannot perfectly explain real-world market data. Based on this discovery, we introduce the GGD as the likelihood function. We further improve our method by proposing a passive variant to address transaction fees, and designing the mean function of the Gaussian process with the mean reversion principle. Thorough experiments were performed on synthetic and real-world financial datasets to verify the effectiveness of our method.",10.1109/tai.2023.3262456,Portfolios;Gaussian processes;Task analysis;Machine learning;Gaussian distribution;Uncertainty;Data models;Artificial intelligence in finance;Bayesian learning;statistical inference,IEEE,"Proposes a graph-aware Gaussian process model with generalized Gaussian likelihood for portfolio selection, effectively capturing uncertainty and asset correlations.",✔️,portfolio,✔️,✔️
WOS:001045509800001,Portfolio optimization using predictive auxiliary classifier generative adversarial networks,"In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. Despite numerous studies on shallow learning models, they have shown limited success in analyzing the complex nature of massive stock data, a task where recent deep learning models excel. However, the deterministic nature of conventional deep learning models impedes their consideration of portfolio risk due to an inherent lack of uncertainty quantification in their predictions. This paper proposes a novel portfolio weighting strategy, incorporating both risk and return considerations within a deep learning framework. We propose the Predictive Auxiliary Classifier Generative Adversarial Networks (PredACGAN), a probabilistic deep learning model, to measure prediction uncertainty. The PredACGAN generator leverages latent vectors and historical stock prices to predict future returns. The model synthesizes predictive distributions from various latent vectors and past prices. The associated risk is produced via the entropy of these distributions, facilitating portfolio optimization through both return and risk considerations. The proposed algorithm removes high-risk assets from the investment universe at rebalancing moments, enabling PredACGAN to optimize portfolios considering both return and risk. We evaluated PredACGAN and the accompanying algorithm with S & P 500 stocks from 1990 to 2020, with portfolios rebalanced monthly based on PredACGAN predictions and risk measures. The PredACGAN portfolios yielded 9.123% annual returns and a 1.054 Sharpe ratio, outperforming a risk-agnostic portfolio yielding 1.024% annual returns and a 0.236 Sharpe ratio. The PredACGAN portfolio also exhibited lower maximum drawdowns, highlighting its effectiveness.",10.1016/j.engappai.2023.106739,Portfolio optimization; Uncertainty; Generative adversarial network; Deep learning; Risk estimation,WOS,"Proposes PredACGAN, a probabilistic deep learning model using GANs for portfolio optimization considering both return and risk, outperforming risk-agnostic portfolios in S&P500.",✔️,S&P500 Stocks,✔️,✔️
WOS:000885089700001,Portfolio rebalancing based on a combined method of ensemble machine learning and genetic algorithm,"Purpose - This paper presents a combined method of ensemble learning and genetics to rebalance the corporate portfolio. The primary purpose of this paper is to determine the amount of investment in each of the shares of the listed company and the time of purchase, holding or sale of shares to maximize total return and reduce investment risk. Design/methodology/approach - To achieve the goals of the problem, a two-level combined intelligent method, such as a support vector machine, decision tree, network Bayesian, k-nearest neighbors and multilayer perceptron neural network as heterogeneous basic models of ensemble learning in the first level, was applied. Then, the majority vote method (weighted average) in the second stage as the final model of learning was collectively used. Therefore, the data collected from 208 listed companies active in the Tehran stock exchange () from 2011 to 2015 have been used to teach the data. For testing and analysis, the data of the same companies between 2016 and 2020 have been used. Findings - The results showed that the method of combined ensemble learning and genetics has the highest total stock portfolio yield of 114.12%, with a risk of 0.905%. Also, by examining the rate of return on capital, it was observed that the proposed method has the highest average rate of return on investment of 110.64%. As a result, the proposed method leads to higher returns with lower risk than the purchase and maintenance method for fund managers and companies and predicts market trends. Research limitations/implications - In the forthcoming research, there were no limitations to obtain research data were easily extracted from the site of Tehran Stock Exchange Technology Management Company and Rahvard Novin software, and simulation was performed in MATLAB software. Practical implications - In this paper, using combined machine learning methods, companies' stock prices are predicted and stock portfolio optimization is optimized. As companies and private organizations are trying to increase their rate of return, so they need a way to predict stock prices based on specific indicators. It turned out that this algorithm has the highest stock portfolio return with reasonable investment risk, and therefore, investors, portfolio managers and market timers can be used this method to optimize the stock portfolio. Social implications - The homogeneous and heterogeneous two-level hybrid model presented in the research can be used to predict market trends by market timers and fund managers. Also, adjusting the portfolio with this method has a much higher return than the return on buying and holding, and with controlled risk, it increases the security of investors' capital, and investors invest their capital in the funds more safely. And will achieve their expected returns. As a result, the psychological security gained from using this method for portfolio arrangement will eventually lead to the growth of the capital market. Originality/value - This paper tries to present the best combination of stock portfolios of active companies of the Tehran Stock Exchange by using the two-level combined intelligent method and genetic algorithm.",10.1108/jfra-11-2021-0413,Portfolio balancing; Ensemble learning; Market timing; Combined learning methods,WOS,"Uses ensemble learning and genetic algorithms to rebalance stock portfolios of Tehran Stock Exchange companies, achieving high returns with low risk compared to buy and hold.",✔️,Tehran Stock Exchange Stocks,✔️,❌
WOS:000407472100007,Practical Bayesian support vector regression for financial time series prediction and market condition change detection,"Support vector regression (SVR) has long been proven to be a successful tool to predict financial time series. The core idea of this study is to outline an automated framework for achieving a faster and easier parameter selection process, and at the same time, generating useful prediction uncertainty estimates in order to effectively tackle flexible real-world financial time series prediction problems. A Bayesian approach to SVR is discussed, and implemented. It is found that the direct implementation of the probabilistic framework of Gao et al. returns unsatisfactory results in our experiments. A novel enhancement is proposed by adding a new kernel scaling parameter mu to overcome the difficulties encountered. In addition, the multi-armed bandit Bayesian optimization technique is applied to automate the parameter selection process. Our framework is then tested on financial time series of various asset classes (i.e. equity index, credit default swaps spread, bond yields, and commodity futures) to ensure its flexibility. It is shown that the generalization performance of this parameter selection process can reach or sometimes surpass the computationally expensive cross-validation procedure. An adaptive calibration process is also described to allow practical use of the prediction uncertainty estimates to assess the quality of predictions. It is shown that the machine-learning approach discussed in this study can be developed as a very useful pricing tool, and potentially a market condition change detector. A further extension is possible by taking the prediction uncertainties into consideration when building a financial portfolio.",10.1080/14697688.2016.1267868,Support vector machines regression; Kernel scaling; Machine learning; Bayesian inference; Multi-armed bandit Bayesian optimization; Gaussian process; C44; C45; C61,WOS,"This study develops a Bayesian support vector regression framework for financial time series prediction and market condition detection, providing prediction uncertainty estimates and automated parameter selection.",✔️,"Equity index, credit default swaps spread, bond yields, commodity futures",✔️,✔️
10.1109/TMC.2023.3339384,Predicting IoT Distributed Ledger Fraud Transactions With a Lightweight GAN Network,"Decision-making and consensus in traditional blockchain protocols is formulated as a repeated Bernoulli trial that solves a computationally-intense lottery puzzle, called Proof-of-Work (PoW) in Bitcoin. This approach has shown robustness through practice, but does not scale with increasing network size and generation of new transactions. Resource constrained Internet of Things (IoT) networks are incompatible with full computation of schemes like Bitcoin's PoW. Our effort proposes a first step towards an alternative consensus using machine learning-based decision-making with prediction of fraud transactions to alleviate need for intense computation. To improve base approval probabilities for fraud detection in an ideal security setting, Vector GAN (VecGAN) is proposed to augment blockchain data in classifier training, which combines error-driven learning with Bayesian estimation to alleviate calculations. This two-step approach with augmentation and classification on new transactions is proposed as a novel approach to blockchain decision-making. Experimental prediction accuracy using VecGAN improved up to 3% on simplistic classifiers compared to other state-of-the-art augmentation techniques. Resource consumption in a realistic blockchain setting was reduced while improving block throughput by 50% compared to PoW. Future work will explore Sybil-spam defensive measures for realistic protocol implementation with this approach.  © 2002-2012 IEEE.",10.1109/tmc.2023.3339384,Blockchain; data augmentation; generative adversarial network; Internet of Things (IoT),SCOPUS,"The paper introduces a lightweight GAN-based model (VecGAN) to predict fraud transactions in IoT distributed ledger systems, improving prediction accuracy and reducing resource consumption.",❌,,✔️,✔️
WOS:000371424200031,Predicting Market Impact Costs Using Nonparametric Machine Learning Models,"Market impact cost is the most significant portion of implicit transaction costs that can reduce the overall transaction cost, although it cannot be measured directly. In this paper, we employed the state-of-the-art nonparametric machine learning models: neural networks, Bayesian neural network, Gaussian process, and support vector regression, to predict market impact cost accurately and to provide the predictive model that is versatile in the number of variables. We collected a large amount of real single transaction data of US stock market from Bloomberg Terminal and generated three independent input variables. As a result, most nonparametric machine learning models outperformed a-state-of-the-art benchmark parametric model such as I-star model in four error measures. Although these models encounter certain difficulties in separating the permanent and temporary cost directly, nonparametric machine learning models can be good alternatives in reducing transaction costs by considerably improving in prediction performance.",10.1371/journal.pone.0150243,,WOS,"Employs nonparametric machine learning models, including neural networks and Gaussian processes, to accurately predict market impact costs, outperforming traditional parametric models and aiding in reducing transaction expenses.",✔️,Market Impact Costs,✔️,❌
https://doi.org/10.18488/journal.aefr.2019.92.243.256,Predicting Stock Market Indices Using Classification Tools,"Increasing interest has been shown in the use of classifiers to extract informative patterns from time series data generated by monitoring financial phenomena. This paper investigates data mining and pattern recognition methods in forecasting the movement of the Standard & Poor?s 500 index. We use functional forms of varying classifiers to predict financial time series data and to evaluate the performance of different classifiers. By using the time series ARIMA model, we forecast the Standard & Poor?s 500 index. Additionally, with the AdaBoost algorithm and its extensions, we compare the classifying accuracy rates of bagging and boosting models with several classifiers, such as support vector machines, k-nearest neighbor, the probabilistic neural network, and the classification and regression tree. Results indicate that the boosting classifier with real AdaBoost (exponential loss) best forecast the Standard & Poor?s 500 index movements. This result should be relevant to firms that want to predict the stock prices.",10.18488/journal.aefr.2019.92.243.256,,Proquest,"Compares classification machine learning tools for predicting S&P 500 index movements, finding AdaBoost with real AdaBoost best performing.",✔️,S&P 500 Index,✔️,❌
10.15849/IJASCA.231130.03,Predicting Stock Prices using Artificial Intelligence: A Comparative Study of Machine Learning Algorithms,"The prediction of stock prices poses an intricate and demanding challenge within the realm of finance. The emergence of artificial intelligence (AI) and machine learning (ML) methodologies has escalated the significance of stock price prediction for investors, traders, and financial experts. This study unveils a comparative examination of diverse ML algorithms intended for stock price prediction through AI mechanisms. We assess the efficacy of multiple algorithms, encompassing Linear Regression, Ridge Regression, Lasso Regression, Random Forest Regression, and Gradient Boosting Regression, employing a dataset of historical stock prices sourced from Yahoo Finance. Our findings demonstrate that the Gaussian Process Regressor surpasses other algorithms, boasting an impeccable R-squared value of 1.00. Moreover, we delve into the pivotal role played by feature engineering and preprocessing techniques in augmenting the precision of prediction models. This investigation furnishes valuable insights into the integration of AI in the financial domain, with the potential to enlighten investment and trading strategies. © Al-Zaytoonah University of Jordan (ZUJ).",10.15849/ijasca.231130.03,Artificial Intelligence; Machine Learning; prediction; Stock Prices,SCOPUS,"Conducts a comparative analysis of various machine learning algorithms for predicting stock prices, identifying the Gaussian Process Regressor as the top performer with a perfect R-squared value.",✔️,Stock,✔️,✔️
WOS:000737351200001,Predicting Volatility Index According to Technical Index and Economic Indicators on the Basis of Deep Learning Algorithm,"The Volatility Index (VIX) is a real-time index that has been used as the first measure to quantify market expectations for volatility, which affects the financial market as a main actor of the overall economy that is sensitive to the environmental and social aspects of investors and companies. The VIX is calculated using option prices for the S&P 500 Index (SPX) and is expressed as a percentage. Taking into account that VIX only shows the implicit volatility of the S&P 500 for the next 30 days, the authors develop a model for a near-optimal state trying to avoid uncertainty and insufficient accuracy. The researchers are trying to make a contribution to the theory of socially responsible portfolio management. The developed approach allows potential investments to make decisions regarding such important topics as ethical investing, performance analysis, as well as sustainable investment strategies. The approach of this research allows to use deep probabilistic convolutional neural networks based on conditional variance as a linear function of errors with the aim of estimating and predicting the VIX. For this purpose, the use of technical indicators and economic indexes such as Chicago Board Options Exchange (CBOE) VIX and S&P 500 is considered. The results of estimating and predicting the VIX with the proposed method indicate high precision and create a certainty in modeling to achieve the goals.",10.3390/su132414011,sustainable financial markets; volatility index; deep neural network; convolution of probability,WOS,"A deep probabilistic convolutional neural network model is developed to predict the Volatility Index (VIX) using technical and economic indicators, achieving high prediction precision.",✔️,Volatility Index (VIX),✔️,✔️
2-s2.0-85073325015,Predicting a stock portfolio with the multivariate bayesian structural time series model: Do news or emotions matter?,"In this paper, we provide methods for creatively incorporating information from financial news and Twitter feeds into predicting the prices of a portfolio of stocks, using the framework of the Multivariate Bayesian Structural Time Series (MBSTS) model. MBSTS is a Bayesian machine learning model designed to capture correlations among multiple target time series, while using a number of contemporaneous predictors. As an illustration of the current model, we use data on two leading online commerce companies, namely Amazon and eBay, and run extensive empirical experiments to examine which if any, text mining predictors would add to the predictability of a stock price. Evaluation of competing models such as the autoregressive integrated moving average (ARIMA) model, and the recurrent neural network (RNN) model with long short term memory (LSTM), in terms of their performances with respect to cumulative one-step-ahead forecast errors with and without sentimental predictors, were carried out. Our contributions are threefold: Firstly, our model is the first one that successfully incorporated the online text mining to an advanced multivariate Bayesian machine learning time series model, which opens the door of applying both text mining and machine learning simultaneously in modern quantitative finance research; Secondly, under the presence of both modern and classical predictors in both fundamental and technical sense, the polarity of news still adds on a complementary effect; Thirdly, we discover that all models under investigation with sentimental predictors do outperform models without these sentimental predictors, and the MBSTS model with sentimental predictors outperforms all the other models. © 2019 [International Journal of Artificial Intelligence].",,Feature Selection; Sentiment Analysis; Text Mining; Time Series Forecast,SCOPUS,"The paper integrates text mining from financial news and Twitter into a Multivariate Bayesian Structural Time Series model to predict stock portfolio prices, outperforming traditional ARIMA and RNN models.",✔️,Stock,✔️,✔️
WOS:000412613900012,Predicting economic growth with stock networks,"Networks derived from stock prices are often used to model developments on financial markets and are tightly intertwined with crises. Yet, the influence of changing market topologies on the broader economy (i.e. GDP) is unclear. In this paper, we propose a Bayesian approach that utilizes individual-level network measures of companies as lagged probabilistic features to predict national economic growth. We use a comprehensive data set consisting of Standard and Poor's 500 corporations from January 1988 until October 2016. The final model forecasts correctly all major recession and prosperity phases of the U.S. economy up to one year ahead. By employing different network measures on the level of corporations, we can also identify which companies' stocks possess a key role in a changing economic environment and may be used as indication of critical (and prosperous) developments. More generally, the proposed approach allows to predict probabilities for different overall states of social entities by using local network positions and could be applied on various phenomena. (C) 2017 Elsevier B.V. All rights reserved.",10.1016/j.physa.2017.07.022,Econophysics; Stock networks; Naive Bayes classifier; Machine learning; Economic growth,WOS,"Proposes a Bayesian approach using stock network measures as lagged features to predict national economic growth (GDP), showing correct forecasts of recessions and prosperity.",✔️,GDP,✔️,✔️
2-s2.0-85111270345,Predicting sovereign credit ratings for portfolio stress testing,"This paper analyses the relationship between macroeconomic and credit cycles. It is not a straightforward relationship, particularly in sovereign credit assessment. Modelling such a relationship requires blending scenario analysis and stress testing, together with dynamic modelling of macroeconomic and credit variables. The novelty of the presented approach is its ability to cross-pollinate machine learning and Monte Carlo (MC) simulation as part of a process that overcomes the challenges faced by risk managers. The result is a probabilistic forward-looking view of credit risk scenarios that can guide action. Sovereign credit ratings are expert opinions based on relevant macroeconomic, financial and policy information. We introduce a predictive machine learning model of sovereign credit ratings that lends itself naturally to MC simulations and stress testing. The Least Absolute Shrinkage and Selection Operator (LASSO) allows considering many variables simultaneously in a nonlinear fashion as candidates for predicting sovereign ratings. The portfolio stress testing capability comes in by augmenting the set of variables used in the MC simulations to include external shock variables common to the sovereigns in the portfolio, for example, relevant global commodity prices. The resulting rating distribution can be used to calculate different relevant risk metrics, including credit-sensitive measures of risk-weighted assets. © Henry Stewart Publications.",,Capital adequacy; Credit rating; LASSO; Machine learning; Monte Carlo simulation; Sovereign risk; Stress testing,SCOPUS,"The study employs LASSO-based machine learning models to predict sovereign credit ratings, facilitating portfolio stress testing and risk assessment through Monte Carlo simulations and scenario analysis.",❌,?,✔️,❌
WOS:001248864800002,Predicting stock price of construction companies using weighted ensemble learning,"Modeling the behavior of stock price data has always been one of the challenging applications of Artificial Intelligence (AI) and Machine Learning (ML) due to its high complexity and dependence on various conditions. Recent studies show that this will be difficult to do with just one learning model. The problem can be more complex for companies in the construction sector, due to the dependency of their behavior on more conditions. This study aims to provide a hybrid model for improving the accuracy of prediction for the stock price index of companies in the construction section. The contribution of this paper can be considered as follows: First, a combination of several prediction models is used to predict stock prices so that learning models can cover each other's errors. In this research, an ensemble model based on Artificial Neural Network (ANN), Gaussian Process Regression (GPR), and Classification and Regression Tree (CART) is presented for predicting the stock price index. Second, the optimization technique is used to determine the effect of each learning model on the prediction result. For this purpose, first, all three mentioned algorithms process the data simultaneously and perform the prediction operation. Then, using the Cuckoo Search (CS) algorithm, the output weight of each algorithm is determined as a coefficient. Finally, using the ensemble technique, these results are combined and the final output is generated through weighted averaging on optimal coefficients. The proposed system was implemented, and its efficiency was evaluated by real stock data of construction companies. The results showed that using CS optimization in the proposed ensemble system is highly effective in reducing prediction error. According to the results, the proposed system can predict the price index with an average accuracy of 96.6 %, which shows a reduction of at least 2.4 % in prediction error compared to the previous methods. Comparing the evaluation results of the proposed system with similar algorithms indicates that our model is more accurate and can be useful for predicting the stock price index in real-world scenarios.",10.1016/j.heliyon.2024.e31604,Ensemble learning; Forecasting stock price of construction; companies; Artificial Intelligence; Machine Learning,WOS,"Develops a weighted ensemble learning model combining ANN, Gaussian Process Regression, and CART optimized with Cuckoo Search to accurately predict stock prices of construction companies, achieving high accuracy and reduced prediction errors.",✔️,Stock Prices (Construction Companies),✔️,❌
9798380382243,Prediction and Statistical Inference in Feedback Loops,"Classical machine learning and statistics are built on the paradigm that there is a fixed quantity that we want to learn about a population, such as the best predictor of outcomes from features or the average effect of a treatment. In modern practices, however, predictions and inferences beget other predictions and inferences, causing the quantity of interest to change over time and drift away in a feedback loop. The feedback poses challenges for traditional methods, calling for new solutions. This thesis introduces new principles for prediction and inference in the presence of feedback loops.The first part focuses on performative prediction. Performative prediction formalizes the phenomenon that predictive models—by means of being used to make consequential downstream decisions—often influence the outcomes they aim to predict in the first place. For example, travel time estimates on navigation apps influence traffic patterns and thus realized travel times, stock price predictions influence trading activity and hence prices. We examine common heuristics such as retraining, as well as more refined optimization strategies for dealing with performative feedback. At the end of the first part, we identify important scenarios where the act of prediction triggers feedback loops that are not explained by the framework of performativity, and we develop theory to describe and study such feedback.The second part discusses principles for valid statistical inference, i.e., valid p-values and confidence intervals, in the presence of feedback. We consider two types of feedback: the first is due to data snooping, i.e., the practice of choosing which results to report only after seeing the data; the second arises when machine-learning systems are used to supply cheap predictions to augment or supplant high-quality data in future scientific analyses. In both cases, ignoring the feedback and naively applying classical statistical methods leads to inflated error rates and false discoveries; we provide alternative approaches that guarantee valid inferences in the face of feedback.",,,Proquest,"The thesis introduces novel principles for prediction and statistical inference in scenarios involving feedback loops, such as performative prediction, addressing challenges in traditional methods and ensuring valid inferences amidst dynamic data dependencies.",❌,?,❌,❌
10.1080/24751839.2023.2250113,Prediction of Ethereum gas prices using DeepAR and probabilistic forecasting,"Ethereum is a major public blockchain. Besides being the second-largest digital currency by market capitalization for its cryptocurrency, the Ether (Ξ), it is also the foundation of Web3 and decentralized applications, or DApps, that are fuelled by Smart Contracts. At the time of this writing, Ethereum still uses Proof of Work (PoW) consensus algorithm to ensure the integrity of the blockchain and to prevent double spend. PoW requires the participation of miners, who are incentivized to assemble blocks of transactions by being rewarded with cryptocurrency paid by transaction originators and by the blockchain network itself via newly minted Ξ. Network fees for transaction submissions are called gas, by analogy to the fuel used by cars, and are negotiable. They are also highly volatile and hence it is critical to predict the direction they are heading into, so that one can time transaction submissions, when feasible. There have been several efforts to predict gas prices, including usage of large Mempools, analysis of committed blocks, and more recent ones using Facebook's Prophet model [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2]. In this study, we introduce an innovative approach that employs the DeepAR [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001] model, known for its superior forecasting accuracy over conventional methods by virtue of its ability to learn from multiple related time series. This methodology not only offers immediate advantages but also holds promise for ongoing enhancements. We substantiate our claims through empirical testing, utilizing data extracts from the Ethereum blockchain and cryptocurrency price feeds. This document is an extended version of our ICCS 2022 paper on the same topic. In this paper, we dive deeper into the internals of DeepAR forecasting algorithm [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001], analyse the correlation between the on-chain/off-chain sample data, and describe additional experiments that empirically prove our findings and, finally, perform a comparison of our outputs with those from the Prophet [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2] model. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.",10.1080/24751839.2023.2250113,blockchain; DeepAR; Ethereum; gas price; machine learning; prediction; probabilistic forecasting; proof of work,SCOPUS,"Implements DeepAR, a probabilistic forecasting model, to predict Ethereum gas prices, demonstrating superior accuracy over traditional models like Prophet, aiding in optimal transaction timing.",✔️,Ethereum gas price,✔️,✔️
https://doi.org/10.18187/pjsor.v19i1.4214,Prediction of KLCI Index Through Economic LASSO Regression Model and Model Averaging,"The Financial Times Stock Exchange (FTSE) Bursa Malaysia KLCI Index is a key component in the development of Malaysia's economic growth and the complexity in terms of identifying the factors that have a substantial impact on the Malaysian stock market has always been a contentious issue. In this study, the macroeconomic factors of exchange rate, interest rate, gold price, consumer price index, money supply Ml, М2, and М3, industrial production, and oil price were discussed by using economic LASSO regression and Bayesian Model Averaging (BMA) with monthly average and monthly end time-series data spanning from January 2015 to June 2021, with a total of 78 observations by using the R Studio. The findings demonstrate that month-end data is better suited for stock market prediction than month-average data and that the BMA model is more suitable than the LASSO model, as seen by lower Mean Square Error of Prediction, MSE(P) and Residual Mean Square Error of Prediction, RMSE(P) values. The exchange rate, gold price, and money supply have a negative association with the dependent variables, while the consumer price index has a positive relationship associated with the dependent variables. The consumer price index is the most significant contributing factor, whereas gold price is the least significant. The result depicted that the KLCI index has no significant relationship with the variables interest rate, money supply М2, Ml, industrial production index, and oil price. In conclusion, investors could specifically focus on the positive contributor and put lesser attention on improving their portfolio return.",10.18187/pjsor.v19i1.4214,,Proquest,"Examines why existing ML and DL algorithms fail in stock price prediction, attributing it to their reliance on curve-shape features, highlighting the need for models handling non-curve-shape features.",✔️,Stock Prices,✔️,❌
https://doi.org/10.1109/ICCPEIC.2014.6915414,Prediction of events based on Complex Event Processing and Probabilistic Fuzzy Logic,"This paper proposes a prediction system named as PECEP. PECEP is based on Complex Event Processing (CEP) and Probabilistic Fuzzy Logic (PFL). CEP is event processing that combines data from multiple sources to infer events or patterns that suggest more complicated circumstances. The main aim of CEP is to identify meaningful events such as opportunities or threats and respond to them as quickly as possible. A PFL is a type of logic that recognizes more than simple truth values. Fuzzy logic can be represented with degrees of truthfulness and falsehood. The event data are downloaded and updated dynamically from the online data source. PECEP consists of three steps namely Collection of Data Set, Feature Processing and Machine Learning. PECEP is validated using Esper in the stock market domain. A stock market or equity market is a public entity for the trading of company stock and derivatives at an agreed price. The output of the PECEP provides a guideline about the future price of stock. The performance of PECEP is compared with the existing system in terms of the four parameters- Accuracy, Error Rate Analysis, Processing Time and Throughput.",10.1109/iccpeic.2014.6915414,,Proquest,"Proposes PECEP, a prediction system using Complex Event Processing and Probabilistic Fuzzy Logic, applied to the stock market to guide future stock price predictions.",✔️,Stock Prices,✔️,✔️
10.1111/jfpp.17011,Prediction of moisture ratio and drying rate of orange slices using machine learning approaches,"In order to improve the drying characteristics and to optimization of drying conditions, machine learning (ML) and response surface methodology (RSM) were applied in air-convective drying of orange slices (Washington Navel and Valencia cultivars). Interactions of temperature (T, 50–60°C), sample thickness (ST, 5–9 mm), and drying time (DT, 8–10 h) like independent variables with specific moisture extraction rate, effective moisture diffusivity, energy efficiency, and energy consumption like dependent variables were determined. In addition, five machine learning algorithms (random forest-RF; artificial neural network-ANN; gaussian processes-GP support vector regression-SVR, and k-nearest neighbors-kNN) were used to predict moisture ratio and drying rate. In Washington Navel and Valencia cultivars, the greatest correlation coefficients (R) for prediction of moisture ratio were obtained k-NN algorithm with values of 0.9944 and 0.9898, respectively. Also, drying rate prediction results showed that k-NN achieved higher R with values of 1.0000 and 0.9954, respectively. Experimental findings were adapted by a second-degree polynomial model through variance analysis to identify model fitness and optimal drying conditions. Combined desirability value was calculated as 0.8812 for Valencia and 0.8564 for Washington. Increasing energy consumption was encountered with increasing drying time and sample thickness. Besides, energy consumption had a decreasing trend at higher temperatures. Practical applications: Machine learning models are novelty and rapid methods that have been successfully utilized to solve such challenges agricultural commodities. Drying is common process to preserve the food quality. This study provides optimum conditions for drying orange slices in single unit air-convective dryer and improves the effect of drying system on some drying characteristics energy aspects. In addition, this study can be able to present a technical knowledge for orange slice drying and related equipment design. © 2022 Wiley Periodicals LLC.",10.1111/jfpp.17011,,SCOPUS,"Uses machine learning algorithms to predict moisture ratio and drying rate of orange slices, demonstrating high accuracy with k-NN models.",❌,?,✔️,❌
WOS:001216335500001,Prediction of realized volatility and implied volatility indices using AI and machine learning: A review,"In this systematic literature review, we examine the existing studies predicting realized volatility and implied volatility indices using artificial intelligence and machine learning. We survey the literature in order to discover whether the proposed methods provide superior forecasts compared to traditional econometric models, how widespread the application of explainable AI is, and to outline potential areas for further research. Generally, we find the efficacy of AI and ML methods for volatility prediction to be highly promising, often providing comparative or better results than their econometric counterparts. Neural networks employing memory, such as Long-Short Term Memory and Gated Recurrent Units, consistently rank among the top performing models. However, traditional econometric models are still highly relevant, commonly yielding similar results as more advanced ML and AI models. In light of the success with ensemble methods, a promising area of research is the use of hybrid models, combining machine learning and econometric models. In spite of the common critique of many machine learning models being of a black -box nature, we find that very few papers apply XAI to analyze and support their empirical results. Thus, we recommend that researchers strive harder to employ XAI in future work. Similarly, we see potential for applications of probabilistic machine learning, effectively quantifying uncertainty in volatility forecasts from machine learning models.",10.1016/j.irfa.2024.103221,Volatility forecasting; Machine learning; Explainable artificial intelligence,WOS,"This systematic review examines existing AI and machine learning approaches for predicting realized and implied volatility indices, highlighting their effectiveness compared to traditional econometric models and suggesting areas for future research.",✔️,Volatility indices,✔️,?
WOS:000636288300001,Predictions of bitcoin prices through machine learning based frameworks,"The high volatility of an asset in financial markets is commonly seen as a negative factor. However short-term trades may entail high profits if traders open and close the correct positions. The high volatility of cryptocurrencies, and in particular of Bitcoin, is what made cryptocurrency trading so profitable in these last years. The main goal of this work is to compare several frameworks each other to predict the daily closing Bitcoin price, investigating those that provide the best performance, after a rigorous model selection by the so-called k-fold cross validation method. We evaluated the performance of one stage frameworks, based only on one machine learning technique, such as the Bayesian Neural Network, the Feed Forward and the Long Short Term Memory Neural Networks, and that of two stages frameworks formed by the neural networks just mentioned in cascade to Support Vector Regression. Results highlight higher performance of the two stages frameworks with respect to the correspondent one stage frameworks, but for the Bayesian Neural Network. The one stage framework based on Bayesian Neural Network has the highest performance and the order of magnitude of the mean absolute percentage error computed on the predicted price by this framework is in agreement with those reported in recent literature works.",10.7717/peerj-cs.413,Machine learning; Cryptocurrencies; Technical indicators; Bayesian neural network,WOS,"Compares machine learning frameworks, including Bayesian Neural Networks, FFNN, LSTM, with Bayesian optimization to predict Bitcoin prices, finding Bayesian Neural Networks best.",✔️,Bitcoin,✔️,❌
10.1007/s00521-024-10270-7,Predictions of steel price indices through machine learning for the regional northeast Chinese market,"Projections of commodity prices have long been a significant source of dependence for investors and the government. This study investigates the challenging topic of forecasting the daily regional steel price index in the northeast Chinese market from January 1, 2010, to April 15, 2021. The projection of this significant commodity price indication has not received enough attention in the literature. The forecasting model that is used is Gaussian process regressions, which are trained using a mix of cross-validation and Bayesian optimizations. The models that were built precisely predicted the price indices between January 8, 2019, and April 15, 2021, with an out-of-sample relative root mean square error of 0.5432%. Investors and government officials can use the established models to study pricing and make judgments. Forecasting results can help create comparable commodity price indices when reference data on the price trends suggested by these models are used. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.",10.1007/s00521-024-10270-7,Bayesian optimization; Cross-validation; Gaussian process regression; Regional steel price index; Time series forecast,SCOPUS,"Researchers employ Gaussian process regressions with cross-validation and Bayesian optimizations to predict the regional steel price index in Northeast China, achieving high forecasting accuracy.",✔️,Commodity (Steel),✔️,✔️
WOS:000853367800001,Prevalence of money laundering and terrorism financing through stock market: a comprehensive conceptual review paper,"Purpose This paper aims to provide a comprehensive conceptual framework and strong arguments with an intent to examine the stock market variables (predictors) indicating the money laundering (ML) and terrorism financing (FT) proceeds. Design/methodology/approach This paper provides a comprehensive review of ML/FT through the stock market across developed, developing and emerging jurisdictions, sheds light on the existing literature and critically evaluates the gap in the relevant studies. Moving forward, this paper develops the conceptual framework and formulates hypotheses to explore the empirical relationship. Findings This paper advocates and finds a basis to carry out much-needed empirical research between the ML/FT and stock market keeping in view the growing criminal cases in the developing countries. This paper suggests mining proxies from the publically available stock market data and the results of existing seminal research as variables of the study. These data and results carry information about the ML determinants. After developing hypothetical research providing concepts, this paper also finds that using a suitable methodology, preferable Bayesian logistic and linear regression models, it is possible to find the typologies and factors that can indicate and endorse the use of the stock market for ML/FT. Broadly, it is found that the significance of this study will be two-pronged: empirical development and policy implications. Research limitations/implications This paper mainly focuses on the developing region, a newly emerging market and, peculiarly, a grey-listed region by the Financial Action Task Force (FATF). Practical implications In light of the existing literature and to the best of the researchers' knowledge, this study will bring into focus the new age of the action research on the ML regime in the securities markets of the developing countries, hence, the emerging markets. Moreover, this research shall have a sheer significance for the policy measures on FATF recommendations on ML and FT, especially for the countries listed as ""grey"". Social implications The research based on comprehensive review will help in controlling the social behaviours aiding the proceeds of ML. Originality/value This research is extremely novel to the best of the researcher's knowledge.",10.1108/jmlc-06-2022-0094,Money laundering; FATF; Stock market; Terrorism financing; Due diligence; Insider trading,WOS,"A comprehensive review explores the relationship between stock market variables and money laundering/terrorism financing, proposing Bayesian logistic and linear regression models for detection.",❌,Stock Market Variables,✔️,✔️
WOS:001139557000002,Probabilistic Life-Cycle Connectivity Assessment of Transportation Networks Using Deep Learning,"Bridges and pavements are two major infrastructure components of a transportation network providing mobility of freight and commodities for economic vitality and access to a range of users as social benefits. However, the lack of a comprehensive infrastructure management system incorporating bridges and pavements inhibits accurate performance prediction, optimal maintenance actions, and the associated use of shrinking budgets. This paper presents an integrated probabilistic life-cycle connectivity framework for the performance analysis of transportation networks containing bridges and asphalt pavements by considering flexural and shear failure modes for prestressed concrete and steel bridges and four failure modes, including international roughness index, rut depth, alligator cracking, and transverse cracking, for asphalt pavements. In this framework, neural network-based deep learning models are used to assess the probabilistic performance of transportation networks and to provide guidance for the associated maintenance strategies. An existing transportation network consisting of bridges and asphalt pavement segments is selected to investigate its life-cycle connectivity reliability and component importance using the matrix-based system reliability method. Results show that the consideration of asphalt pavement failure probability has a significant effect on the probability of transportation network connectivity.",10.1061/jbenf2.beeng-6149,Transportation network; Connectivity; Bridge; Asphalt pavement; System reliability; Neural networks; Deep learning,WOS,Introduces a probabilistic life-cycle connectivity framework for transportation networks using deep learning to assess infrastructure performance and maintenance strategies.,❌,?,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684197,Probabilistic Risk Assessment in Power Systems With High Wind Energy Penetration,"Power systems are increasingly confronted with operational uncertainties. These stem from the integration of wind and solar energy sources with inherently stochastic generation behavior. The ensuing risks include power plant curtailments or grid imbalances. The deterministic approaches that currently underpin most planning have proven insufficient to manage these risks. This paper presents an alternative in the form of a data-driven probabilistic approach with direct relevance for transmission system operators. The models present a novel methodology that is independent of the common boundary conditions, e.g. case-specific models. First, we compare several data-driven algorithms and assign the forecasting task to the best-performing one. Second, the resulting forecast serves as an input for three optimal power flow (OPF) problems we tailor to the German power system. These problems minimize energy import volumes, energy import costs, and overall power losses. Third, based on the OPF results, we perform a risk assessment for operational instability, power loss, financial losses, and renewable energy waste. The results show that neural networks slightly outperform traditional machine learning algorithms in forecasting accuracy. However, linear-quadratic regulators remain attractive for their simplicity-performance ratio. Our probabilistic OPF approach can reduce power losses and identify frequency and line loading irregularities that deterministic methods do not. The data-driven approach we propose is superior to existing approaches in terms of its performance, usability, and applicability to complex power systems.",10.1109/access.2024.3463882,Uncertainty;Probabilistic logic;Costs;Wind energy;Forecasting;Wind power generation;Power system stability;Machine learning;Power system reliability;Risk management;Machine learning;power systems reliability;power forecasting;uncertain optimization;risk assessment,IEEE,"A probabilistic risk assessment framework is proposed for power systems with high wind energy penetration, utilizing neural networks and stochastic models to reduce power losses.",❌,Power Systems,✔️,✔️
10.17586/2226-1494-2023-23-1-105-111,Probabilistic criteria for time-series predictability estimation,"Assessing the time series predictability is necessary for forecasting models validating, for classifying series to optimize the choice of the model and its parameters, and for analyzing the results. The difficulties in assessing predictability occur due to large heteroscedasticity of errors obtained when predicting several series of different nature and characteristics. In this work, the internal predictability of predictive modeling objects is investigated. Using the example of time series forecasting, we explore the possibility of quantifying internal predictability in terms of the probability (frequency) of obtaining a forecast with an error greater than some certain level. We also try to determine the relationship of such a measure with the characteristics of the time series themselves. The idea of the proposed method is to estimate the internal predictability by the probability of an error exceeding a predetermined threshold value. The studies were carried out on data from open sources containing more than seven thousand time series of stock market prices. We compare the probability of errors which exceed the allowable value (miss probabilities) for the same series on different forecasting models. We show that these probabilities differ insignificantly for different forecasting models with the same series, and hence, the probability can be a measure of predictability. We also show the relationship of the miss probability values with entropy, the Hurst exponent, and other characteristics of the series according to which the predictability can be estimated. It has been established that the resulting measure makes it possible to compare the predictability of time series with pronounced heteroscedasticity of forecast errors and when using different models. The measure is related to the characteristics of the time series and is interpretable. The results can be generalized to any objects of predictive modeling and forecasting quality scores. It can be useful to developers of predictive modeling algorithms, machine learning specialists in solving practical problems of forecasting. © 2023, ITMO University. All rights reserved.",10.17586/2226-1494-2023-23-1-105-111,forecasting error; intrinsic predictability; misprediction,SCOPUS,"Introduces probabilistic criteria for assessing the predictability of time-series data, specifically applied to stock market prices, by evaluating the probability of forecast errors exceeding certain thresholds and linking to series characteristics.",✔️,Stock,❌,✔️
WOS:001259187000001,Probabilistic deep learning and transfer learning for robust cryptocurrency price prediction,"Forecasting the price of Bitcoin (BTC) with precision is a complex endeavor, given the market's inherent uncertainty and volatility, influenced by a diverse range of parameters. This research is driven by the central goal of introducing a specialized deep learning model tailored to predict digital currency prices, with a specific emphasis on BTC. To address this challenge, a pioneering strategy has been established, leveraging probabilistic gated recurrent units (P-GRU). This approach integrates probabilistic attributes into the model, facilitating the generation of probability distributions for projected values. The effectiveness of this method is assessed using one year of BTC price history, sampled at a five-minute interval. In parallel, a comparative analysis is conducted against alternative models, including GRU, long short-term memory (LSTM), and variants thereof (time-distributed, bidirectional, and simple models). In pursuit of optimizing model efficacy, a bespoke callback mechanism is deployed. This callback, driven by R2-score tracking, captures optimal model weights based on validation data. Moreover, a transfer learning paradigm is adopted to broaden the study's horizons. A pre-trained model on BTC data is harnessed to predict prices for six other prominent cryptocurrencies: Ethereum, Litecoin, Tron, Polkadot, Cardano, and Stellar. Consequently, a distinct model is tailored for each cryptocurrency. The outcomes of this investigation conclusively underscore the superior performance of the proposed methodology. In the midst of a volatile and uncertain market landscape, the proposed approach outshines its counterparts, showcasing an enhanced ability for cryptocurrency price forecasting.",10.1016/j.eswa.2024.124404,BTC price prediction; Cryptocurrency prediction; Probabilistic gated recurrent units (P-GRU); Bayesian neural networks (BNNs); Transfer learning,WOS,"Develops a probabilistic deep learning model with transfer learning to predict Bitcoin and other cryptocurrencies, showing superior performance in volatile markets.",✔️,Bitcoin and other Cryptocurrencies,✔️,✔️
WOS:000377733300006,Probabilistic forecasting of the solar irradiance with recursive ARMA and GARCH models,"Forecasting of the solar irradiance is a key feature in order to increase the penetration rate of solar energy into the energy grids. Indeed, the anticipation of the fluctuations of the solar renewables allows a better management of the production means of electricity and a better operation of the grid-connected storage systems. If numerous methods for forecasting the mean of the solar irradiance were recently developed, there are only few works dedicated to the evaluation of prediction intervals associated to these point forecasts. Time series of solar irradiance and more specifically of clear sky index show some similarities with that of financial time series. The aim of this paper is to assess the performances of a commonly used combination of two linear models (ARMA and GARCH) in econometrics in order to provide probabilistic forecasts of solar irradiance. In addition, a recursive estimation of the parameters of the models has been set up in order to provide a framework that can be applied easily in an operational context. A comprehensive testing procedure has been used to assess both point forecasts and probabilistic forecasts. Using only the past records of the solar irradiance, the proposed model is able to perform point forecasts as accurately as other methods based on machine learning techniques. Moreover, the recursive ARMA GARCH model is easier to set-up and it gives additional information about the uncertainty of the forecasts. Even if some strong assumption has been made regarding the statistical distribution of the error, the reliability of the probabilistic forecasts stands in the same order of magnitude as other works done in the field of solar forecasting. (C) 2016 Elsevier Ltd. All rights reserved.",10.1016/j.solener.2016.03.064,Probabilistic solar forecasts; Clear sky index; ARMA; GARCH; Operational framework; Recursive least square,WOS,"The paper evaluates recursive ARMA and GARCH econometric models for probabilistic forecasting of solar irradiance, drawing parallels with financial time series.",❌,?,❌,❌
WOS:000753670800002,Probabilistic machine learning for local volatility,"The local volatility model is widely used for pricing and hedging financial derivatives. While its main appeal is its capability of reproducing any given surface of observed option prices - it provides a perfect fit - the essential component is a latent function that can be uniquely determined only in the limit of infinite data. To (re)construct this function, numerous calibration methods have been suggested that involve steps of interpolation and extrapolation, most often of parametric form and with point-estimate representations. We use probabilistic machine learning to look at the calibration problem in a probabilistic framework based on Gaussian processes. This immediately gives a way of encoding prior beliefs about the local volatility function and a hypothesis model that is highly flexible yet not prone to overfitting. Besides providing a method for calibrating a (range of) point estimate(s), we draw posterior inference from the distribution over local volatility. This leads to a better understanding of uncertainty associated with the model in general, and with the calibration in particular. Further, we infer dynamical properties of local volatility by augmenting the hypothesis space with a time dimension. Ideally, this provides predictive distributions not only locally, but also for entire surfaces forward in time. We apply our approach to S&P 500 market data.",10.21314/jcf.2021.012,option pricing; local volatility; probabilistic inference; Gaussian processes; machine learning,WOS,"The article applies probabilistic machine learning, specifically Gaussian processes, to calibrate local volatility models for financial derivatives, enabling posterior inference and uncertainty quantification in volatility predictions over time.",✔️,Local volatility models for financial derivatives,✔️,✔️
WOS:001096941900002,Probability rough set and portfolio optimization integrated three-way predication decisions approach to stock price,"In the stock market, accurate trend judgment and reasonable asset distribution are effective ways to obtain ideal return. However, the real stock market is affected by the objective economic environment, investors' expected return and other potential factors, which makes the classical portfolio strategy face more challenges and pressures. How to build a reliable portfolio strategy in an uncertain environment will be a scientific problem worthy of in-depth discussion. To address this issue, this paper combines machine learning with rough set to establish a new rough set theory prediction model, quantitatively dividing the stock data into three categories and targetedly predicting the future trend according to the complexity. Based on the proposed prediction model, a new portfolio strategy is proposed by integrating the mean-variance model. Firstly, for reducing the volatility and noise of the original data of stock price, outlier processing (OP) and wavelet denoising (WD) are utilized. Secondly, for the sake of pertinently forecasting the future trend of different characteristic stock price, a three-way prediction (TWP) decisions approach is constructed based on multiscale permutation entropy (MPE), probabilistic rough set (PRS), variational modal decomposition (VMD) and deep learning. Finally, 20 stocks of Shanghai and Shenzhen stock exchanges are taken as research samples to verify the scientificity and rationality of the portfolio strategy. The results show that the proposed approach not only provides scientific support and reference for investors' investment decisions, but also provides a new investment strategy theory and method for the investment decisions of the stock market.",10.1007/s10489-023-05085-3,Probability rough set; Bidirectional gated recurrent unit; Mean-variance model; Stock price forecasting,WOS,"Combines machine learning with rough set theory to classify stock data into three categories and integrates mean-variance portfolio optimization, enhancing prediction accuracy and investment strategies for stock markets.",✔️,Stock Prices,✔️,❌
10.1109/JIOT.2018.2819706,Profit Maximization Mechanism and Data Management for Data Analytics Services,"With the advancement and emergence of new network services, such as social network, Internet of Things, and crowdsensing, large volume of diverse data is collected, shared, and leveraged to develop analytics services. The data analytics service has become a key commodity that can be traded among various economic entities. In this paper, we address the optimal pricing mechanisms and data management for data analytics services and further discuss the perishable services in the time varying environment. We first propose a data market model and define the data utility based on the impact of data size on the performance of data analytics, e.g., prediction and verification accuracy. For perishable services, we study the perishability of data that affects the service quality and provide a quality decay function. The data analytics services are considered as digital goods and uniquely characterized by 'unlimited supply' compared to conventional goods. Therefore, we apply the Bayesian profit maximization mechanism in selling data analytics services, which is truthful, rational, and computationally efficient. The optimal service price, data amount, and service update interval are obtained to maximize the profit under different customer's valuation distributions. Finally, experimental results on real-world datasets show that our data market model and pricing mechanism effectively solve the profit maximization problem and provide useful strategies for the data analytics service provider. © 2014 IEEE.",10.1109/jiot.2018.2819706,Data analytics; deep learning; digital goods auction; Internet of Things (IoT); optimal pricing; perishable service,SCOPUS,"Develops a data market model and Bayesian profit maximization mechanism for data analytics services, applied to S&P500 stocks.",✔️,S&P500 Stocks,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10689666,Prospective Portfolio Optimization With Asset Preselection Using a Combination of Long and Short Term Memory and Sharpe Ratio Maximization,"This research presents a novel portfolio optimization model that incorporates asset preselection. This model aims to demonstrate how using Long and Short-Term Memory and Sharpe Ratio Maximization can enhance the efficiency of portfolios.The suggested approach consists of three stages, each with practical applications. During the initial phase, the data is gathered. In the second phase, the LSTM network, a commonly employed tool in predicting stock price movements, is utilized to anticipate the time series of stock closing prices. The third stage of the process focuses on stock selection and determining the appropriate weighting for each stock in the portfolio. The proposed approach is tested and carefully validated using the daily closing prices of ten equities from the FTSE 100. The results demonstrate the model’s resilience and efficacy, as the portfolios generated using the anticipated and validation data exhibit high similarity. Given the importance of selecting the right stocks for portfolio optimization, this study will combine asset preselection with portfolio weighting. Furthermore, this study utilized a Long Short-Term Memory network to forecast the optimization model’s parameters accurately and introduced a novel portfolio optimization model.",10.1109/access.2024.3466829,Portfolios;Optimization;Long short term memory;Predictive models;Investment;Forecasting;Data models;Stock markets;Asset pre-selection;long short-term memory;stock prediction;portfolio optimization;Sharpe ratio;cardinality,IEEE,This research presents a novel portfolio optimization model using Long Short-Term Memory networks and Sharpe Ratio Maximization to enhance portfolio efficiency.,✔️,stock,✔️,❌
WOS:001302798700001,Quantifying credit portfolio sensitivity toasset correlations with interpretablegenerative neural networks,"We propose a novel approach for quantifying the sensitivity of credit portfolio value-at-risk to asset correlations with the use of synthetic financial correlation matrixesgenerated with deep learning models. In previous work, generative adversarial net-works (GANs) were employed to demonstrate the generation of plausible correlationmatrixes that capture the essential characteristics observed in empirical correlationmatrixes estimated on asset returns. Instead of GANs, we employ variational autoen-coders (VAEs) to achieve a more interpretable latent space representation and toobtain a generator of plausible correlation matrixes by sampling the VAE's latentspace. Through our analysis, we reveal that the VAE's latent space can be a use-ful tool to capture the crucial factors impacting portfolio diversification, particularlyin relation to the sensitivity of credit portfolios to changes in asset correlations. AVAE trained on the historical time series of correlation matrixes is used to generatesynthetic correlation matrixes that satisfy a set of expected financial properties. Our analysis provides clear indications that the capacity for realistic data augmentationprovided by VAEs, combined with the ability to obtain model interpretability, canprove useful for risk management, enhancing the resilience and accuracy of modelswhen backtesting, as past data may exhibit biases and might not contain the essentialhigh-stress events required for evaluating diverse risk scenarios.",10.21314/jrmv.2024.002,variational autoencoder (VAE); credit portfolio model; concentration risk; generativeneural network; interpretable generative neural network; explainable artificial intelligence (XAI),WOS,"A variational autoencoder-based approach is introduced to quantify credit portfolio sensitivity to asset correlations, enhancing risk management through interpretable generative models.",✔️,Credit Portfolios,✔️,✔️
10.1016/j.fbio.2022.101670,"Rapid detection of total phenolics, antioxidant activity and ascorbic acid of dried apples by chemometric algorithms","Multivariate approaches like machine learning are commonly used in estimation of biochemical traits from spectral and color characteristics of foodstuffs and agricultural commodities. In present study, windfall apples of Golden Delicious, Oregon Spur and Granny Smith cultivars were dried in open-sun, controlled greenhouse, microwave oven (200W), hybrid system (100W + 60°C), convective dryer (70°C) and freeze-dryer (−55°C). Spectral, chromatic and biochemical characteristics of dried apples were determined and assessed through machine learning algorithms. Total phenolic matter, DPPH (2,2-Diphenyl-1-picrylhydrazyl), FRAP (Ferric Reducing Antioxidant Power) and ascorbic acid content were estimated with the use of five different machine learning algorithms (artificial neural networks, k-nearest neighbor, random forest, gaussian processes and support vector regression). The most successful results were achieved in estimation of total phenolic content (R ≥ 0.85). Additionally, Multilayer Perceptron, Support Vector Regression and Gaussian Processes were identified as the best machine learning algorithms in estimation of biochemical compositions of dried apples. © 2022 Elsevier Ltd",10.1016/j.fbio.2022.101670,Apple; Biochemical composition; Drying; Machine learning; VIS/NIR spectra,SCOPUS,"The study utilizes machine learning algorithms to estimate biochemical compositions of dried apples, identifying the most effective models for predicting total phenolics, antioxidant activity, and ascorbic acid.",❌,?,✔️,❌
10.1016/j.neucom.2021.03.111,Recurrent dictionary learning for state-space models with an application in stock forecasting,"In this work, we introduce a new modeling and inferential tool for dynamical processing of time series. The approach is called recurrent dictionary learning (RDL). The proposed model reads as a linear Gaussian Markovian state-space model involving two linear operators, the state evolution and the observation matrices, that we assumed to be unknown. These two unknown operators (that can be seen interpreted as dictionaries) and the sequence of hidden states are jointly learnt via an expectation–maximization algorithm. The RDL model gathers several advantages, namely online processing, probabilistic inference, and a high model expressiveness which is usually typical of neural networks. RDL is particularly well suited for stock forecasting. Its performance is illustrated on two problems: next day forecasting (regression problem) and next day trading (classification problem), given past stock market observations. Experimental results show that our proposed method excels over state-of-the-art stock analysis models such as CNN-TA, MFNN, and LSTM. © 2021 Elsevier B.V.",10.1016/j.neucom.2021.03.111,Dynamical modeling; Expectation-minimization; Kalman filter; Recurrent dictionary learning; Stock forecasting; Uncertainty quantification,SCOPUS,"Introduces the recurrent dictionary learning model for stock forecasting, leveraging probabilistic inference and state-space models to outperform existing stock analysis models.",✔️,Stock,✔️,✔️
10.1504/IJMME.2024.140697,Regional steel price index predictions for North China through machine learning,"Projections of commodity prices have long been heavily relied upon by investors and the government. This study examines the challenging task of estimating the daily regional steel price index in the north Chinese market for the period of 1 January 2010 to 15 April 2021. The projection of this significant commodity price indication has not received enough attention in the literature. After training our models with cross-validation and Bayesian optimisations, we apply Gaussian process regressions to verify our findings. The models that were built properly predicted the price indices between 8 January 2019 and 15 April 2021, with an out-of-sample relative root mean square error of 0.5871%. Investors and government officials can utilise the generated models for price analysis and decision-making. Forecasting results can help create comparable commodity price indices when reference data on the price trends suggested by these models are used. © 2024 Inderscience Enterprises Ltd.",10.1504/ijmme.2024.140697,Bayesian optimisation; China; cross validation; Gaussian process regression; GPR; regional steel price index; time-series forecast,SCOPUS,"Forecasts daily steel price indices in North China using Gaussian process regressions, demonstrating high accuracy and supporting investment and policy-making decisions.",✔️,Commodity (Steel),✔️,✔️
WOS:000773704100006,Research on HMM-Based Efficient Stock Price Prediction,"Stock market is one of the most important parts of the investment market. Compared with other industries, the stock market not only has a higher rate of return on investment but also has a higher risk, and stock price prediction has always been a close concern of investors. Therefore, the research on stock price prediction methods and how to reduce the error of stock price prediction has become a hot topic for many scholars at home and abroad. In recent years, the development of computer technology such as machine learning and econometric method makes the stock price prediction more reliable. Due to the hidden Markov nature of stock price, this paper proposes a stock price prediction method based on hidden Markov model (HMM). To be specific, since the data of stock price have continuity in time series, it is necessary to extend the discrete HMM to the continuous HMM, and then put forward the up and down trend prediction model based on the continuous HMM. The first-order continuous HMM is extended to the second-order continuous HMM, and the stock price is predicted by combining the prediction method of fluctuation range. As a result, the proposed second-order continuous HMM-based stock price prediction model is simulated on Hang Seng Index (HSI), one of the earliest stock market indexes in Hong Kong. The evaluation results on six months HSI show that the predicted value of the proposed model is very close to the actual value and outperforms three benchmarks in terms of RMSE, MAE, and R-2.",10.1155/2022/8124149,,WOS,"The research introduces a continuous high-order Hidden Markov Model for efficient stock price prediction, outperforming benchmarks in accuracy and error reduction on the Hang Seng Index.",✔️,Stock indices (Hang Seng Index),✔️,❌
WOS:000829767000001,Research on Risk Features and Prediction of China's Crude Oil Futures Market Based on Machine Learning,"Facing the rapidly changing domestic and foreign futures markets, how to accurately and immediately predict the price trend of crude oil futures in order to avoid the risks caused by price fluctuations is very important for all participants in the crude oil futures market. Based on the 5-min high-frequency trading data of China's crude oil futures market in recent 3 years, this paper uses the EMD-MFDFA model combined with multifractal detrended fluctuation analysis (MF-DFA) and empirical mode decomposition unsupervised K-means clustering and Gaussian mixture model (GMM) to identify the risk status of each trading day. Further, Support vector machine (SVM), extreme gradient lifting (XGBoost) and their improved algorithms are used to predict the risk state of China's crude oil futures market. The empirical results are as follows: first, There are obvious multifractal features in the return rate series of China's crude oil futures market and its single trading day; Second, compared with the traditional SVM model, the improved Twin Support Vector Machine (TWSVM) based on solving the sample imbalance issue has better prediction ability for China's crude oil futures risk.; Third, The XGBoost has a great impact on the prediction of China's crude oil risk, and the Focal-XGBoost with focal loss function performs the best in predicting the risk of China's crude oil futures market.",10.3389/fenrg.2022.741018,Chinas crude oil futures; multifractal; clustering; sample imbalance; risk prediction,WOS,"The paper uses machine learning techniques to predict risk states in China's crude oil futures market, incorporating models like SVM and XGBoost for enhanced prediction accuracy.",✔️,Crude Oil Futures,✔️,✔️
10.1016/j.apenergy.2024.123885,Research on optimization strategy of futures hedging dependent on market state,"Considering the dynamic nature of market conditions, this paper introduces a state-dependent futures hedging optimization model and methodology. This approach dynamically adjusts the traditional model-driven hedging strategy, effectively balancing the pursuit of returns with the imperative of risk mitigation. Empirical evidence shows that integrating Hidden Markov Model (HMM) with machine learning techniques, as demonstrated in this study, improves the accuracy of market state forecasts. Compared to the traditional model-driven hedging strategy, the innovative state-dependent hedging strategy introduced here significantly enhances the return-to-risk ratio, and revenue, without increasing hedging risks. Moreover, the hedging portfolio developed under this strategy achieves an average hedging efficiency of 0.76, highlighting the effectiveness of the proposed methodology. Additional robustness tests indicate that this market state-dependent hedging optimization strategy is promising under various conditions, including different position adjustment ratios, volatility benchmarks, evaluation periods, types of crude oil, and transaction costs. The research conducted in this paper not only contributes to and expands traditional hedging theories but also provides a practical risk management solution for market participants. © 2024 Elsevier Ltd",10.1016/j.apenergy.2024.123885,Futures hedging; HMM; Machine learning; Model-driven; State dependence,SCOPUS,"A state-dependent futures hedging optimization model using Hidden Markov Models and machine learning techniques is proposed, enhancing return-to-risk ratios and hedging efficiency without increasing risks.",❌,,✔️,✔️
1350486X,Return and Value at Risk using the Dirichlet Process,"There exists a wide variety of models for return, and the chosen model determines the tool required to calculate the value at risk (VaR). This paper introduces an alternative methodology to model-based simulation by using a Monte Carlo simulation of the Dirichlet process. The model is constructed in a Bayesian framework, using properties initially described by Ferguson. A notable advantage of this model is that, on average, the random draws are sampled from a mixed distribution that consists of a prior guess by an expert and the empirical process based on a random sample of historical asset returns. The method is relatively automatic and similar to machine learning tools, e.g. the estimate is updated as new data arrive. [PUBLICATION ABSTRACT]",,,Proquest,"The paper presents a Bayesian approach using Dirichlet processes and Monte Carlo simulation for estimating asset returns and calculating value at risk (VaR), offering an automatic and data-updatable method for financial risk assessment.",✔️,Value at Risk (VaR) for financial assets,❌,✔️
10.1080/13504860701718448,Return and value at risk using the Dirichlet process,"There exists a wide variety of models for return, and the chosen model determines the tool required to calculate the value at risk (VaR). This paper introduces an alternative methodology to model-based simulation by using a Monte Carlo simulation of the Dirichlet process. The model is constructed in a Bayesian framework, using properties initially described by Ferguson. A notable advantage of this model is that, on average, the random draws are sampled from a mixed distribution that consists of a prior guess by an expert and the empirical process based on a random sample of historical asset returns. The method is relatively automatic and similar to machine learning tools, e.g. the estimate is updated as new data arrive. © 2008 Taylor & Francis.",10.1080/13504860701718448,Bayes estimates; Dirichlet process; Quantiles; Value at risk,SCOPUS,Introduces a Bayesian Monte Carlo simulation using the Dirichlet process to calculate Value at Risk (VaR) by combining expert priors with historical asset returns.,✔️,Value at Risk (VaR),❌,✔️
WOS:001194900200001,Risk Forecasting Comparisons in Decentralized Finance: An Approach in Constant Product Market Makers,"This study leverages decentralized liquidity pool data sourced from UNISWAP-V2 to forecast Value-at-Risk (VaR) and Expected Shortfall (ES) employing the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model with varied error distributions and the deep learning probabilistic forecasting algorithm known as DeepAR. Performance evaluations of these distinct forecasting methodologies are conducted using an appropriate loss function. Results indicate that the GARCH model with a normal distribution consistently outperforms other models, particularly when forecasting VaR. Conversely, the DeepAR model exhibits limited effectiveness in VaR forecasting across all scenarios, except for liquidity pools involving at least one stablecoin. However, it demonstrates greater reliability in predicting most ES risk measures and associated data. Our findings underscore that in a subset of the data, providing liquidity to pairs involving at least one stablecoin entails statistically significant lower risk compared to holding an equivalent amount of crypto assets. Furthermore, this research contributes to the advancement of novel risk management tools and strategies tailored for liquidity providers.",10.1007/s10614-024-10585-6,DeFi; Risk forecasting; Cryptocurrency; Liquidity pool,WOS,"Uses GARCH and DeepAR models to forecast Value-at-Risk and Expected Shortfall in decentralized finance markets, finding GARCH better for VaR, DeepAR better for ES.",✔️,DeFi Liquidity Pools,✔️,✔️
10.1109/TMC.2023.3321306,RoSeFi: A Robust Sedentary Behavior Monitoring System With Commodity WiFi Devices,"Sedentary behaviors are shown to be hazardous to human health. Detecting sedentary behaviors in a ubiquitous way can be realized by the promising WiFi sensing technique. The accurate detection of sedentary behaviors is determined by the accurate recognition of sit-stand postural transition (SPT). However, according to our findings, SPT recognition errors are inevitable even with advanced machine-learning methods, because different SPTs may result in a similar change in WiFi channel state information (CSI). To effectively reduce SPT recognition errors, in this paper we propose RoSeFi, a robust sedentary behavior monitoring system. We first classify the errors in SPT recognition results into two categories: the errors violating SPT's consistency and the errors violating SPTs' symmetry. To correct the above errors, we reveal two inherent features in the CSI data of SPTs, i.e., contextual association and waveform mirror symmetry. Then a novel metric named WMSF is defined to quantify the degree of waveform mirror symmetry between two SPTs' CSI data. Integrating the above features, the problem of recognition error correction can be modeled as a constrained nonlinear optimization problem (CNOP). To solve the problem, we design a unified error detection/correction scheme, named UEDC, which converts the CNOP into a sequence decoding problem in Hidden Markov Model (HMM). A tailored Viterbi algorithm combined with WMSF is proposed to detect and correct the errors simultaneously. The experimental results show that RoseFi reduces 60-82% SPT recognition errors, gains 15-20% relative improvement in the accuracy of SPT recognition, and eventually reduces the sedentary time estimation errors by 10%-20%, compared with typical existing systems. In addition, our error correction method can be adapted to most existing machine learning based human action recognition methods, effectively improving their performance. © 2023 IEEE.",10.1109/tmc.2023.3321306,channel state information; recognition error correction; Sedentary behavior monitoring; sit-stand transition recognition; WiFi,SCOPUS,"RoSeFi, a robust sedentary behavior monitoring system using commodity WiFi devices, is proposed to accurately detect and correct recognition errors in sedentary behavior classification.",❌,,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400748,Robust Resource Allocation for Vehicular Communications With Imperfect CSI,"The resource allocation in vehicle-to-everything (V2X) communications face a great challenge for satisfying the heterogeneous quality of service (QoS) requirements of the ultra-reliable safety-related services and the minimum throughput required entertainment services, due to the channel uncertainties caused by high mobility. In this paper, we first consider an optimistic scenario where the distribution of uncertain channel state information (CSI) can be deterministic and accurately known at the eNB. Then, a low-complexity resource allocation approach is developed, in which the probabilistic QoS constraint of V2V is transformed into a computable optimization constraint. To deal with the scenario with unknown uncertain CSI distribution, we develop a distributionally robust resource allocation approach for converting the intractable chance constraint of V2V into a deterministic semidefinite constraint based only on the first- and second-order moments of uncertain CSI. For alleviating the conservatism of above approach, a support-based distributionally robust resource allocation approach is developed to tighten the semidefinite constraint by utilizing the support information of uncertain CSI. Finally, we conduct simulations to show that the effectiveness of the proposed approaches outperforms other state-of-art approaches.",10.1109/twc.2021.3070894,Resource management;Quality of service;Channel estimation;Optimization;Interference;Signal to noise ratio;Fading channels;V2X communications;resource allocation;distributionally robust optimization;chance constraint;uncertain channel,IEEE,"The paper develops robust resource allocation methods for vehicle-to-everything communications under channel uncertainties, enhancing quality of service through advanced optimization techniques.",❌,?,❌,❌
10.1088/0026-1394/60/1A/08020,"SIM.QM-S17 Ethanol in Aqueous Matrix: Supplement Key Comparison, Model 1","Main text To establish international measurement capabilities for the determination of ethanol in aqueous matrices, the CCQM Organic Analysis Working Group (OAWG) has performed three ethanol Key comparisons (2002: CCQM-K27a for forensic aqueous ethanol and CCQM-K27b for ethanol in wine as a commodity; 2005: CCQM-K27 subsequent studies - four levels of ethanol in water; 2007: CCQM-K27.2 Subsequent 2 for forensic levels). To provide an opportunity for the NMIs and DIs within the RMOs, three Key comparisons has been conducted within SIM (SIM.QM-K1, SIM.QM-K27) and AFRIMETS (AFRIMETS.QM-K27). In addition, for the NMIs to support their ethanol in aqueous matrices measurements capabilities, a Track A Model 2 (formerly known as Track B) Key comparison CCQM-K79 (2010) has been completed to compare aqueous ethanol certified reference material (CRM) solutions certified by the participant NMIs and DIs. The current comparison is important to NMIs and DIs to maintain their ethanol in water measurement capabilities, to claim it as a new one as well as to complement their existing measurement capabilities, mainly within the range where the alcohol meter (breathalyzer) needs to be calibrated and verified. In 2017, several NMIs and DIs in SIM expressed their interest in a complementary SIM.QM-K27 comparison, therefore CENAM and INMETRO agreed to collaborate for the realization of a SIM supplement comparison, which was identified as SIM.QM-K27.2019 by the OAWG, and the final assigned name by SIM was SIM.QM-S17. The main purpose of this comparison was to offer to SIM countries and other regions an additional opportunity for the NMI and DIs to evaluate their measurements capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. Fourteen laboratories were registered to take part in this comparison, and thirteen sent their results. This report presents the results of the SIM Key comparison SIM.QM-S17. The measurements capabilities demonstrated by the participants in SIM.QM-S17, underpin their ability to assign reference values of ethanol content in aqueous samples for both forensic and commodities applications. Successful participation in SIM.QM-S17 demonstrates the laboratories measurement capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. The study material was two batches of solutions of ethanol in water prepared gravimetrically at concentrations between 0.1 mg/g - 5 mg/g by CENAM, dispensed in glass bottles of 50 mL sealed with tear off aluminum crimp seals, with rubber stoppers. In previous SIM.QM.K27 comparison, the purity-corrected gravimetric value of the aqueous ethanol solutions assigned by the coordinating NMI was used to link SIM.QM-K27 to the CCQM-K27 Key comparison reference value (KCRV), where 1 % uncertainty was assigned to the KCRV to have the same uncertainty from the CCQM-K27.2. For this comparison, SIM.QM-S17 two levels aqueous ethanol solutions, the purity assigned by CENAM was not used for KCRV as was informed initially in the protocol, instead in 5-June-2020 at the OAWG, CENAM gravimetric values were presented, as well as the participants results evaluated by four different statistical approaches to assess the candidate KCRV. For both levels of ethanol in aqueous matrix solutions, the DerSimonian-Laird Weighted mean and the Hierarchical Bayes mean methods seem to give a better estimation of the KCRV ± KCRU95 candidate and was agreed by OAWG to use the Hierarchical Bayesian mean, from where the KCRV for SIM.QM-S17 Level 1 (Low-level) and Level 2 (high-level) were (240.92 ± 1.28) mg/kg (k =2) and (389.87 ± 1.52) mg/kg (k =2), respectively. All the thirteen participants in the SIM.QM-S17, including both coordinators, demonstrated their capability to measure ethanol in aqueous matrix in the mass fraction range of 0.1 mg/g to 5 mg/g. To reach the main text of this paper, click on Final Report. Note that this text is that which appears in Appendix B of the BIPM key comparison database https://www.bipm.org/kcdb/. The final report has been peer-reviewed and approved for publication by the CCQM, according to the provisions of the CIPM Mutual Recognition Arrangement (CIPM MRA). © 2023 BIPM & IOP Publishing Ltd.",10.1088/0026-1394/60/1a/08020,,SCOPUS,"The paper reports on a comparison study for measuring ethanol in aqueous solutions, ensuring accurate determination of ethanol mass fractions by national measurement institutes.",❌,,❌,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265235,SNoRe: Scalable Unsupervised Learning of Symbolic Node Representations,"Learning from complex real-life networks is a lively research area, with recent advances in learning information-rich, low-dimensional network node representations. However, state-of-the-art methods are not necessarily interpretable and are therefore not fully applicable to sensitive settings in biomedical or user profiling tasks, where explicit bias detection is highly relevant. The proposed SNoRe (Symbolic Node Representations) algorithm is capable of learning symbolic, human-understandable representations of individual network nodes, based on the similarity of neighborhood hashes which serve as features. SNoRe's interpretable features are suitable for direct explanation of individual predictions, which we demonstrate by coupling it with the widely used instance explanation tool SHAP to obtain nomograms representing the relevance of individual features for a given classification. To our knowledge, this is one of the first such attempts in a structural node embedding setting. In the experimental evaluation on eleven real-life datasets, SNoRe proved to be competitive to strong baselines, such as variational graph autoencoders, node2vec and LINE. The vectorized implementation of SNoRe scales to large networks, making it suitable for contemporary network learning and analysis tasks.",10.1109/access.2020.3039541,Task analysis;Signal processing algorithms;Prediction algorithms;Convolution;Classification algorithms;Sparse matrices;Convolutional neural networks;Node embedding;feature construction;symbolic learning;interpretable machine learning,IEEE,"Presents SNoRe, an algorithm for scalable and interpretable symbolic node representations in networks, with competitive performance on real-life datasets.",❌,?,?,?
WOS:000902044600001,Safe Reinforcement Learning Using Wasserstein Distributionally Robust MPC and Chance Constraint,"In this paper, we address the chance-constrained safe Reinforcement Learning (RL) problem using the function approximators based on Stochastic Model Predictive Control (SMPC) and Distributionally Robust Model Predictive Control (DRMPC). We use Conditional Value at Risk (CVaR) to measure the probability of constraint violation and safety. In order to provide a safe policy by construction, we first propose using parameterized nonlinear DRMPC at each time step. DRMPC optimizes a finite-horizon cost function subject to the worst-case constraint violation in an ambiguity set. We use a statistical ball around the empirical distribution with a radius measured by the Wasserstein metric as the ambiguity set. Unlike the sample average approximation SMPC, DRMPC provides a probabilistic guarantee of the out-of-sample risk and requires lower samples from the disturbance. Then the Q-learning method is used to optimize the parameters in the DRMPC to achieve the best closed-loop performance. Wheeled Mobile Robot (WMR) path planning with obstacle avoidance will be considered to illustrate the efficiency of the proposed method.",10.1109/access.2022.3228922,Safe reinforcement learning; model predictive control; distributionally robust optimization; chance constraint; conditional value at risk; Q-learning,WOS,A safe reinforcement learning framework using Wasserstein distributionally robust MPC and chance constraints is developed for risk-aware autonomous systems like wheeled robots.,❌,?,✔️,✔️
WOS:000555358600001,Selecting data adaptive learner from multiple deep learners using Bayesian networks,"A method to predict time series using multiple deep learners and a Bayesian network is proposed. In this study, the input explanatory variables are Bayesian network nodes that are associated with learners. Training data are divided usingK-means clustering, and multiple deep learners are trained depending on the cluster. A Bayesian network is used to determine which deep learner is in charge of predicting a time series. We determine a threshold value and select learners with a posterior probability equal to or greater than the threshold value, which could facilitate more robust prediction. The proposed method is applied to financial time-series data, and the predicted results for the Nikkei 225 index are demonstrated.",10.1007/s00521-020-05234-6,Time-series forecasting; Deep learning; Bayesian network; Mixture of experts,WOS,"This study proposes a Bayesian network-based method for selecting adaptive deep learners to predict financial time series, demonstrated on the Nikkei 225 index.",✔️,Nikkei 225 index,✔️,❌
10.1109/JIOT.2017.2764957,Self-evolving trading strategy integrating Internet of Things and big data,"In the era of Internet of Things (IoT) and big data, data has increased dramatically. Computers have been used in various fields. Algorithmic trading is beginning to develop rapidly in the trading market, more and more algorithms begin to be used in the transaction market. As a form of machine learning, neural network can fully reveal the complex trading market. Based on the characteristics of commodity futures market, this paper chooses back propagation neural network to establish price forecasting model. And then, according to the rules of futures market, a self-evolving commodity futures trading strategy is proposed. We also use the data of the Shanghai Futures Exchange and the Dalian Futures Exchange to back-testing the strategy. Finally, we compare the proposed strategies and traditional strategies, and illustrate the evolution of our strategy. Experiments show that our strategies are superior to other compared strategies in the proposed evaluation indicator. Our strategy has a good performance both in yield and risk. It also proves the feasibility of the model and the strategy. The research of this paper is significant to the research of the futures market, and it also provides a new idea for the application of machine learning in algorithmic trading. © 2017 IEEE.",10.1109/jiot.2017.2764957,,SCOPUS,"An adaptive Support Vector Regression model with dynamic parameter optimization is developed for high-frequency futures price forecasting, outperforming traditional SVR and neural network methods.",✔️,Futures,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643777,Sell or HODL Cryptos: Cryptocurrency Short-to-Long Term Projection Using Simultaneous Classification-Regression Deep Learning Framework,"Decentralized cryptocurrencies like Bitcoin are digital assets with a price volatility nature, that allow for blockchain-based, peer-to-peer monetary transactions. Due to the price volatility problem with decentralized cryptocurrencies, research into the underlying pricing mechanism is required. Additionally, the behavior of Bitcoin prices is non-stationary, meaning that the statistical distribution of data varies over time. The proposed framework demonstrates the use of sophisticated machine learning models in predicting the short and medium-term trends and actual values of Bitcoin prices. This research goes beyond previous work that has only looked at machine learning-based categorization for a single day by instead using such models to forecast price changes seven, thirty, and ninety days into the future. The generated models are useful and work admirably, with the classification models reaching a maximum accuracy enhancement up to 31.48% for a 90-day prediction and a 11.76% F1-score for a forecast extending to the thirtieth day. In the case of regression the margin of error shifts from the one-time horizon for price projections to the next. A significant notable downfall occurs in different error metrics. These findings suggest that the models given here outperform those already found in the literature.",10.1109/access.2024.3448234,Predictive models;Bitcoin;Long short term memory;Data models;Forecasting;Computational modeling;Support vector machines;Machine learning;Deep learning;Artificial neural networks;Bitcoin;machine learning;support vector machine (SVM);deep learning;long short-term memory (LSTM);artificial neural network (ANN),IEEE,"Combines CNN and BiLSTM with attention mechanisms to forecast short-term Bitcoin price correlations, improving prediction accuracy for investment strategies.",✔️,Cryptocurrency (Bitcoin),✔️,✔️
10.1016/j.knosys.2019.03.029,Sentiment-aware volatility forecasting,"Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled using Variational Bayes via the data generation and inference operations. We benchmark our model with 9 other popular ones in terms of the likelihood of forecasts given the observed sequence. Experimental results suggest that our model not only outperforms pure statistical models, e.g., GARCH and its variants, Gaussian-process volatility model, but also outperforms the state-of-the-art autoregressive deep neural nets architectures, such as the variational recurrent neural network and the neural stochastic volatility model. © 2019 Elsevier B.V.",10.1016/j.knosys.2019.03.029,Financial text mining; Sentiment knowledge; Time series analysis; Variational neural networks; Volatility modeling,SCOPUS,"The paper introduces the SAVING model, a sentiment-aware volatility forecasting framework that integrates market sentiment with machine learning techniques, utilizing Variational Bayes to capture interactions between asset price movements and sentiment, and achieving superior performance over traditional models like GARCH.",✔️,Volatility indices,✔️,✔️
WOS:000462781900001,Sequential Design and Spatial Modeling for Portfolio Tail Risk Measurement,"We consider calculation of capital requirements when the underlying economic scenarios are determined by simulatable risk factors. In the respective nested simulation framework, the goal is to estimate portfolio tail risk, quantified via value-at-risk (VaR) or tail value-at-risk (TVaR), of portfolio losses in a given collection of future economic scenarios represented by factor levels at the risk horizon. Traditionally, evaluating portfolio losses in an outer scenario is done by computing a conditional expectation via inner-level Monte Carlo simulations and is computationally expensive. We introduce several inter-related machine learning techniques to speed up this computation, in particular by properly accounting for the simulation noise. Our main workhorse is an advanced Gaussian process (GP) regression approach that uses nonparametric spatial modeling to efficiently learn the relationship between the stochastic factors defining scenarios and corresponding portfolio values. Leveraging this emulator, we develop sequential algorithms that adaptively allocate inner simulation budgets to target the quantile region. The GP framework also yields better uncertainty quantification for the resulting VaR/TVaR estimators which reduce bias and variance compared to existing methods. We illustrate the proposed strategies with two case-studies in two and six dimensions.",10.1137/17m1158380,value-at-risk estimation; Gaussian process regression; sequential design; nested simulation; portfolio tail risk,WOS,"Uses Gaussian processes and sequential algorithms to forecast VaR and TVaR for portfolios, improving risk measurement.",✔️,Portfolio,✔️,✔️
https://doi.org/10.2299/jsp.24.113,Short-Term Prediction of Foreign Exchange Rates by Collective Knowledge of Counterparty Banks,"Foreign-exchange (FX) brokers have some risk factors such as price fluctuation risk and latency of data transmission. To reduce these risks in FX brokerage services, we propose a short-term prediction of exchange rates quoted by counter-party banks. We consider that these exchange rates are generated by the knowledge of each counter-party bank, and therefore try to extract the knowledge by using a machine learning method. As a result, we could predict the direction of exchange rates with a prediction accuracy of about 80% if the prediction interval is 100[ms]. Furthermore, by integrating the knowledge of counterparty banks by the ensemble learning, we could improve not only prediction accuracy but also profitability of foreign-exchange brokers. These improvements can be considered as an effect of collective knowledge based on the diversity prediction theorem, but this effect might be limited by extremely short-term prediction of foreign-exchange rates after 100[ms]~200[ms].",10.2299/jsp.24.113,,Proquest,"Short-term prediction of foreign exchange rates using machine learning models achieves approximately 80% accuracy, enhancing profitability for FX brokers through ensemble learning.",✔️,Foreign Exchange (FX),✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10444524,Short-Term Stock Correlation Forecasting Based on CNN-BiLSTM Enhanced by Attention Mechanism,"This study utilizes a new approach for short-term stock correlation forecasting using a combination of convolutional neural networks (CNN), bi-directional long and short-term memory (BiLSTM), and attention mechanisms to address the issue of information loss due to excessively long input time series data. The objective is to improve the accuracy of short-term equity correlation forecasts, which is essential for the efficient management of financial asset portfolios. The existing time series models usually only take into account the effect of stock historical data characteristics on stock correlation but ignore the fact that stock correlation is affected by multiple factors and undergoes an unknown unstable trend. More efficient methods or algorithms need to be devised to deal with financial data. This paper explores stock metrics and introduces a multi-factor model to quantify the factors affecting stock returns in order to calculate the correlation between stocks. Meanwhile, to cope with the problem of incomplete input data, this paper simultaneously incorporates stock return data that is directly related to the correlation data. In the CNN-BiLSTM-Attention (CLATT) model, the role of the CNN module is to obtain high-dimensional features from the input time series data, and the role of the BiLSTM module is to process the time series information to capture the time-series features in the stock return data and correlation data in the sample. In order to acquire the inherent correlation between the input stock return data and correlation data and to enhance the prediction accuracy of the model, the attention mechanism is finally implemented and used to optimize the weights of the BiLSTM output. In this paper, mean square error (MSE), root mean square error (RMSE), mean absolute error (MAE) metrics, mean absolute percentage of error (MAPE), and the coefficient of determination  $R^{2}$ , as well as four benchmark models, are used to evaluate the performance of the proposed model. The result shows that the CLATT model has 57.32% and 33% improvement in the correlation prediction accuracy of different stock portfolios compared to the single LSTM model, and the model prediction accuracy has been improved. Compared with the benchmark CNN-BiLSTM, it also has 56.06% and 28.87% improvement.",10.1109/access.2024.3369419,Correlation;Data models;Predictive models;Time series analysis;Mathematical models;Deep learning;Forecasting;Convolutional neural networks;Stock markets;Financial industry;Time series analysis;Asset management;Financial services;Mean square error methods;Portfolios;Multiple factor;stock correlation prediction;time series prediction;attention mechanism;CNN;BiLSTM,IEEE,"Introduces Ensemble Quantile Networks combining distributional reinforcement learning with ensemble methods to provide uncertainty estimates for autonomous driving decisions, improving safety and reliability.",❌,Autonomous Vehicles,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329994,Stochastic Optimization in a Cumulative Prospect Theory Framework,"Cumulative prospect theory (CPT) is a popular approach for modeling human preferences. It is based on probabilistic distortions and generalizes the expected utility theory. We bring the CPT to a stochastic optimization framework and propose algorithms for both estimation and optimization of CPT-value objectives. We propose an empirical distribution function-based scheme to estimate the CPT value, and then, use this scheme in the inner loop of a CPT-value optimization procedure. We propose both gradient based as well as gradient-free CPT-value optimization algorithms that are based on two well-known simulation optimization ideas: simultaneous perturbation stochastic approximation and model-based parameter search, respectively. We provide theoretical convergence guarantees for all the proposed algorithms and also illustrate the potential of CPT-based criteria in a traffic signal control application.",10.1109/tac.2018.2822658,Optimization;Stochastic processes;Random variables;Approximation algorithms;Convergence;Complexity theory;Cumulative prospect theory (CPT);reinforcement learning;simultaneous perturbation stochastic approximation (SPSA);stochastic optimization,IEEE,"The paper integrates stochastic optimization methods within a Cumulative Prospect Theory framework, developing algorithms for parameter estimation and objective optimization to model human decision-making under uncertainty.",❌,,❌,✔️
WOS:000337860600006,Stochastic nonlinear time series forecasting using time-delay reservoir computers: Performance and universality,"Reservoir computing is a recently introduced machine learning paradigm that has already shown excellent performances in the processing of empirical data. We study a particular kind of reservoir computers called time-delay reservoirs that are constructed out of the sampling of the solution of a time-delay differential equation and show their good performance in the forecasting of the conditional covariances associated to multivariate discrete-time nonlinear stochastic processes of VEC-GARCH type as well as in the prediction of factual daily market realized volatilities computed with intraday quotes, using as training input daily fog-return series of moderate size. We tackle some problems associated to the lack of task-universality for individually operating reservoirs and propose a solution based on the use of parallel arrays of time-delay reservoirs. (C) 2014 Elsevier Ltd. All rights reserved.",10.1016/j.neunet.2014.03.004,Reservoir computing; Echo state networks; Neural computing; Time-delay reservoir; Time series forecasting; Universality; VEC-GARCH model; Volatility forecasting; Realized volatility; Parallel reservoir computing,WOS,"This study employs time-delay reservoir computers, a type of machine learning model, for stochastic nonlinear time series forecasting of financial covariances and realized volatilities, showcasing their performance and universal applicability in financial data analysis.",✔️,Realized volatilities,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653278,Stock Market Trend Prediction Using High-Order Information of Time Series,"Given a financial time series such as  $S\&P~500$ , or any historical data in stock markets, how can we obtain useful information from recent transaction data to predict the ups and downs at the next moment? Recent work on this issue shows initial evidence that machine learning techniques are capable of identifying (non-linear) dependency in the stock market price sequences. However, due to the high volatility and non-stationary nature of the stock market, forecasting the trend of a financial time series remains a big challenge. In this paper, we introduced a new method to simplify noisy-filled financial temporal series via sequence reconstruction by leveraging motifs (frequent patterns), and then utilize a convolutional neural network to capture spatial structure of time series. The experimental results show the efficiency of our proposed method in feature learning and outperformance with 4%–7% accuracy improvement compared with the traditional signal process methods and frequency trading patterns modeling approach with deep learning in stock trend prediction.",10.1109/access.2019.2901842,Time series analysis;Market research;Hidden Markov models;Predictive models;Feature extraction;Stock markets;Forecasting;Trend prediction;convolutional neural network;financial time series;motif extraction,IEEE,"A new method using convolutional neural networks on motif-reconstructed financial time series is introduced for stock market trend prediction, achieving 4-7% accuracy improvements over traditional methods.",✔️,Stock Index,✔️,❌
10.30630/joiv.7.4.1640,Stock Price Movement Classification Using Ensembled Model of Long Short-Term Memory (LSTM) and Random Forest (RF),"Stock investing is known worldwide as a passive income available for everyone. To increase the profit possibly gained, many researchers and investors brainstorm to gain a strategy with the most profit. Machine learning and deep learning are two of these approaches to predicting the stock's movement and deciding the strategy to gain as much as possible. To reach this goal, the researcher experiments with Random Forest (RF) and Long Short-Term Memory (LSTM) by trying them individually and merging them into an ensembled model. The researcher used RF to classify the results from LSTM models obtained throughout the Hyperparameter Optimization (HPO) process. This idea is implemented to lessen the time needed to train and optimize each LSTM model inside the ensembled model. Another anticipation done in this research to overcome the time needed to train the model is classifying the return for longer periods. The dataset used in this model is 45 stocks listed in LQ45 as of August 2021 This research results in showing that LSTM gives better results than RF model especially when using Bayesian Optimization as the HPO method, and that the ensembled model can return better precision in predicting stocks in comparison to the LSTM model itself. Future improvement can focus on the model structure, additional model types as the ensemble model estimator, improvement on the model efficiency, and datasets research to be used in predicting the stock movement prediction. © 2023, Politeknik Negeri Padang. All rights reserved.",10.30630/joiv.7.4.1640,bayesian optimization; classification; deep learning; ensembled model; long short-term memory; Machine learning; random forest; random search; stock investing,SCOPUS,"Develops an ensembled model combining Long Short-Term Memory (LSTM) and Random Forest (RF) to classify stock price movements, demonstrating improved prediction accuracy over individual models.",✔️,Stock,✔️,❌
WOS:000724824100012,"Stock index prediction and uncertainty analysis using multi-scale nonlinear ensemble paradigm of optimal feature extraction, two-stage deep learning and Gaussian process regression","Reliable prediction of stock indexes can be highly valuable for financial decision-making and risk management. The stock market is a highly complicated nonlinear system which makes it difficult to present accurate predictors. In this paper, an innovative multi-scale nonlinear ensemble paradigm is proposed for stock index prediction and uncertainty analysis, which consists of an optimal feature extraction including variational mode decomposition and auto-encoder, a two-stage deep learning based on recurrent neural network and long short-term memory, and Gaussian process regression. The optimal feature extraction is proposed to extract the optimal features of stock index fluctuations and eliminate the disturbance of illusive components. The two-stage deep learning is developed to conduct the prediction of each feature sub-signal and implement its nonlinear integration. The Gaussian process regression is utilized to construct the interval prediction of the original stock signal and analyze the uncertainties of stock market. The validity of the developed model is verified by the data from S&P 500, Dow Jones index and NASDAQ. After a series of comparisons, the mean absolute percentage errors of the proposed model in S&P 500, Dow Jones index and NASDAQ are 0.55%, 0.65% and 1.11%, respectively. These results fully verify the effectiveness of proposed model. (C) 2021 Elsevier B.V. All rights reserved.",10.1016/j.asoc.2021.107898,Stock index prediction; Optimal feature extraction; Two-stage deep learning; Gaussian process regression; Multi-scale nonlinear ensemble paradigm,WOS,"Introduces a multi-scale nonlinear ensemble framework combining optimal feature extraction, deep learning, and Gaussian process regression for stock index prediction and uncertainty analysis, demonstrating high accuracy on major indices.",✔️,"S&P 500, Dow Jones, NASDAQ",✔️,✔️
2-s2.0-84874513449,Stock market forecasting techniques: A survey,"This paper surveys recent literature in the area of Neural Network, Data Mining, Hidden Markov Model and Neuro-Fuzzy system used to predict the stock market fluctuation. Neural Networks and Neuro-Fuzzy systems are identified to be the leading machine learning techniques in stock market index prediction area. The Traditional techniques are not cover all the possible relation of the stock price fluctuations. There are new approaches to known in-depth of an analysis of stock price variations. NN and Markov Model can be used exclusively in the finance markets and forecasting of stock price. In this paper, we propose a forecasting method to provide better an accuracy rather traditional method. © 2005 - 2012 JATIT & LLS. All rights reserved.",,And time series analysis; Data mining; Forecasting techniques; Markov model; Neuro-fuzzy systems; Stock market prediction,SCOPUS,"This survey reviews recent machine learning techniques, including neural networks, data mining, and hidden Markov models, used for stock market forecasting, and proposes a novel forecasting method aimed at improving prediction accuracy.",✔️,Stock,✔️,❌
WOS:001306875600008,Stock movement prediction model based on gated orthogonal recurrent units,"Stock movement prediction has received growing interest in the deep learning community. However, the generalization ability of some existing prediction models is weak due to the highly stochastic property of stock market, and some models suffer from the problem of gradient explosion or gradient vanishing in the training process. To solve the above issues, in this paper, we propose a novel stock movement prediction model based on gated orthogonal recurrent units (GORU) and variational auto-encoder (VAE). Specifically, GORU encodes the text information, and then VAE infers and decodes the market information formed by concatenating encoded text information with normalized historical price information. Meanwhile, orthogonality introduced by GORU can alleviate the problem of gradient explosion or gradient vanishing and enhance the generalization ability of the model. We evaluate the relative contributions of text information and historical prices with respect to prediction accuracy by the results of an ablation study. The experimental results on publicly available datasets show that the proposed model is better than several state-of-the-art models, which indicates that the GORU and VAE can effectively improve the model's generalization ability and accuracy for predicting stock trends.",10.1016/j.iswa.2022.200156,Stock movement prediction; Deep neural network; Gated orthogonal recurrent unit; Text information encoding; Variational inference,WOS,"A novel stock movement prediction model based on Gated Orthogonal Recurrent Units (GORU) and Variational Auto-Encoder (VAE) is proposed, enhancing generalization and accuracy for predicting stock trends.",✔️,Stock,✔️,✔️
WOS:000392285600027,Stock trend prediction based on a new status box method and AdaBoost probabilistic support vector machine,"Stock trend prediction is regarded as one of the most challenging tasks of financial time series prediction. Conventional statistical modeling techniques are not adequate for stock trend forecasting because of the non-stationarity and non-linearity of the stock market. With this regard, many machine learning approaches are used to improve the prediction results. These approaches mainly focus on two aspects: regression problem of the stock price and prediction problem of the turning points of stock price. In this paper, we concentrate on the evaluation of the current trend of stock price and the prediction of the change orientation of the stock price in future. Then, a new approach named status box method is proposed. Different from the prediction issue of the turning points, the status box method packages some stock points into three categories of boxes which indicate different stock status. And then, some machine learning techniques are used to classify these boxes so as to measure whether the states of each box coincides with the stock price trend and forecast the stock price trend based on the states of the box. These results would support us to make buying or selling strategies. Comparing with the turning points prediction that only considered the features of one day, each status box contains a certain amount of points which represent the stock price trend in a certain period of time. So, the status box reflects more information of stock market. To solve the classification problem of the status box, a special features construction approach is presented. Moreover, a new ensemble method integrated with the AdaBoost algorithm, probabilistic support vector machine (PSVM), and genetic algorithm (GA) is constructed to perform the status boxes classification. To verify the applicability and superiority of the proposed methods, 20 shares chosen from Shenzhen Stock Exchange (SZSE) and 16 shares from National Association of Securities Dealers Automated Quotations (NASDAQ) are applied to perform stock trend prediction. The results show that the status box method not only have the better classification accuracy but also effectively solve the unbalance problem of the stock turning points classification. In addition, the new ensemble classifier achieves preferable profitability in simulation of stock investment and remarkably improves the classification performance compared with the approach that only uses the PSVM or back-propagation artificial neural network (BPN). (C) 2016 Elsevier B.V. All rights reserved.",10.1016/j.asoc.2016.08.026,Stock trend prediction; Status box method; Piecewise linear representation; AdaBoost; Probabilistic support vector machine,WOS,"Introduces the status box method combined with AdaBoost probabilistic support vector machines to classify and predict stock price trends, demonstrating higher classification accuracy and investment profitability.",✔️,Stock Trends,✔️,✔️
10.1007/s13042-019-01041-1,Study on the prediction of stock price based on the associated network model of LSTM,"Stock market has received widespread attention from investors. It has always been a hot spot for investors and investment companies to grasp the change regularity of the stock market and predict its trend. Currently, there are many methods for stock price prediction. The prediction methods can be roughly divided into two categories: statistical methods and artificial intelligence methods. Statistical methods include logistic regression model, ARCH model, etc. Artificial intelligence methods include multi-layer perceptron, convolutional neural network, naive Bayes network, back propagation network, single-layer LSTM, support vector machine, recurrent neural network, etc. But these studies predict only one single value. In order to predict multiple values in one model, it need to design a model which can handle multiple inputs and produces multiple associated output values at the same time. For this purpose, it is proposed an associated deep recurrent neural network model with multiple inputs and multiple outputs based on long short-term memory network. The associated network model can predict the opening price, the lowest price and the highest price of a stock simultaneously. The associated network model was compared with LSTM network model and deep recurrent neural network model. The experiments show that the accuracy of the associated model is superior to the other two models in predicting multiple values at the same time, and its prediction accuracy is over 95%. © 2019, The Author(s).",10.1007/s13042-019-01041-1,Associated network; Deep learning; Deep recurrent neural network; Long short-term memory (LSTM); Machine learning,SCOPUS,"The study develops an LSTM-based network model to simultaneously predict multiple stock prices (opening, lowest, highest), achieving over 95% accuracy.",✔️,Stocks,✔️,❌
WOS:000497715600001,Systematic analysis and review of stock market prediction techniques,"Prediction of stock market trends is considered as an important task and is of great attention as predicting stock prices successfully may lead to attractive profits by making proper decisions. Stock market prediction is a major challenge owing to non-stationary, blaring, and chaotic data, and thus, the prediction becomes challenging among the investors to invest the money for making profits. Several techniques are devised in the existing techniques to predict the stock market trends. This work presents the detailed review of 50 research papers suggesting the methodologies, like Bayesian model, Fuzzy classifier, Artificial Neural Networks (ANN), Support Vector Machine (SVM) classifier, Neural Network (NN), Machine Learning Methods and so on, based on stock market prediction. The obtained papers are classified based on different prediction and clustering techniques. The research gaps and the challenges faced by the existing techniques are listed and elaborated, which help the researchers to upgrade the future works. The works are analyzed using certain datasets, software tools, performance evaluation measures, prediction techniques utilized, and performance attained by different techniques. The commonly used technique for attaining effective stock market prediction is ANN and the fuzzy-based technique. Even though a lot of research efforts, the current stock market prediction technique still have many limits. From this survey, it can be concluded that the stock market prediction is a very complex task, and different factors should be considered for predicting the future of the market more accurately and efficiently. (C) 2019 Published by Elsevier Inc.",10.1016/j.cosrev.2019.08.001,Stock market prediction; Bayesian model; Fuzzy classifier; ANN; Classification; Clustering,WOS,"Comprehensive review of 50 research papers on stock market prediction techniques, highlighting methodologies like Bayesian models, ANN, SVM, and identifying research gaps.",✔️,Stock,✔️,?
10.1038/s41467-024-48024-7,Task-oriented machine learning surrogates for tipping points of agent-based models,"We present a machine learning framework bridging manifold learning, neural networks, Gaussian processes, and Equation-Free multiscale approach, for the construction of different types of effective reduced order models from detailed agent-based simulators and the systematic multiscale numerical analysis of their emergent dynamics. The specific tasks of interest here include the detection of tipping points, and the uncertainty quantification of rare events near them. Our illustrative examples are an event-driven, stochastic financial market model describing the mimetic behavior of traders, and a compartmental stochastic epidemic model on an Erdös-Rényi network. We contrast the pros and cons of the different types of surrogate models and the effort involved in learning them. Importantly, the proposed framework reveals that, around the tipping points, the emergent dynamics of both benchmark examples can be effectively described by a one-dimensional stochastic differential equation, thus revealing the intrinsic dimensionality of the normal form of the specific type of the tipping point. This allows a significant reduction in the computational cost of the tasks of interest. © The Author(s) 2024.",10.1038/s41467-024-48024-7,,SCOPUS,"A machine learning framework combining manifold learning, neural networks, and Gaussian processes is proposed to detect tipping points and quantify uncertainty in agent-based models of financial markets and epidemics.",✔️,Financial Market,✔️,✔️
10.1504/ijebr.2023.127271,Technical analysis forecasting and evaluation of stock markets: the probabilistic recovery neural network approach,"The market efficiency theory suggests that stock market pricing reflects all publicly available information regarding a given stock. To outperform the market, a shareholder must study the market’s price volume patterns and predict human behaviour and tendencies. Except for conventional approaches based on fundamental or technical analysis, new tools are currently proposed using big data and artificial intelligence. This publication analyses and evaluates four commonly used deep-learning artificial neural network models. Then, it proposes a new method by adopting the ‘probabilistic recovery’ algorithmic approach. The dataset used consists of 501 unique company names based on real data derived from US Dow Jones. This method closely follows the market’s behaviour, providing daily upwards-downwards data trends. The proposed system can be used as a tool for technical analysis regarding the prediction accuracy of trading strategies, providing approximately 60% future movements’ accuracy, over 90% relative price prediction and annual investment return slightly over 60%. Copyright © 2023 Inderscience Enterprises Ltd.",10.1504/ijebr.2023.127271,algorithmic trading; CNNs; decision making; finance convolutional neural networks; finance generative adversarial networks; fully connected neural networks; neural networks; probablistic neural network; recurrent neural networks; RNNs; stock market dynamics; stock market forecast; stock market neural networks forecasting; stock market prediction; technical analysis; technical indicators; trading strategies,SCOPUS,"Evaluates deep-learning neural network models for stock market forecasting and introduces a probabilistic recovery algorithm, achieving significant prediction accuracies in market trends and price movements.",✔️,Stock market,✔️,✔️
WOS:000683624300001,Temporal mixture ensemble models for probabilistic forecasting of intraday cryptocurrency volume,"We study the problem of the intraday short-term volume forecasting in cryptocurrency multi-markets. The predictions are built by using transaction and order book data from different markets where the exchange takes place. Methodologically, we propose a temporal mixture ensemble, capable of adaptively exploiting, for the forecasting, different sources of data and providing a volume point estimate, as well as its uncertainty. We provide evidence of the clear outperformance of our model with respect to econometric models. Moreover our model performs slightly better than Gradient Boosting Machine while having a much clearer interpretability of the results. Finally, we show that the above results are robust also when restricting the prediction analysis to each volume quartile.",10.1007/s10203-021-00344-9,Econometrics; Machine learning; Cryptocurrency markets; Temporal mixture ensemble,WOS,"Proposes a temporal mixture ensemble for probabilistic forecasting of intraday cryptocurrency volume, showing better performance than GARCH and other ML models.",✔️,Cryptocurrency Volume,✔️,✔️
WOS:000915922500001,"The British Stock Market, currencies, brexit, and media sentiments: A big data analysis","In this study, we use a machine learning framework and draw on an extensive body of media articles on Brexit to provide evidence of cointegration and causality between the sentiments of the media and the movement of British currency. Our contribution to the literature is novel. In addition to applying lexicons commonly used in sentiment analysis, we devise a method using Bayesian learning to create a more context-aware and informative lexicon for Brexit. By leveraging and extending this method, we reveal the relationship between original media senti-ment and related economic and financial variables. Our method is a distinct improvement over existing methods and can better predict out-of-sample outcomes than conventional ones.",10.1016/j.najef.2022.101861,Media sentiment; British Stock Market; British currency; Brexit; Machine learning,WOS,Utilizes a machine learning framework and sentiment analysis of Brexit-related media articles to establish causality and cointegration between media sentiments and British currency movements.,✔️,British Currency,✔️,❌
WOS:000745983600001,The Influence of Cognitive Biases and Financial Factors on Forecast Accuracy of Analysts,"The objective of this study was to jointly analyze the importance of cognitive and financial factors in the accuracy of profit forecasting by analysts. Data from publicly traded Brazilian companies in 2019 were obtained. We used text analysis to assess the cognitive biases from the qualitative reports of analysts. Further, we analyzed the data using statistical regression learning methods and statistical classification learning methods, such as Multiple Linear Regression (MRL), k-dependence Bayesian (k-DB), and Random Forest (RF). The Bayesian inference and classification methods allow an expansion of the research line, especially in the area of machine learning, which can benefit from the examples of factors addressed in this research. The results indicated that, among cognitive biases, optimism had a negative relationship with forecasting accuracy while anchoring bias had a positive relationship. Commonality, to a lesser extent, also had a positive relationship with the analyst's accuracy. Among financial factors, the most important aspects in the accuracy of analysts were volatility, indebtedness, and profitability. Age of the company, fair value, American Depositary Receipts (ADRs), performance, and loss were still important but on a smaller scale. The results of the RF models showed a greater explanatory power. This research sheds light on the cognitive as well as financial aspects that influence the analyst's accuracy, jointly using text analysis and machine learning methods, capable of improving the explanatory power of predictive models, together with the use of training models followed by testing.",10.3389/fpsyg.2021.773894,analysts' accuracy; analysts' forecast; cognitive biases; text analysis; random forest,WOS,"This study examines how cognitive biases and financial factors impact the accuracy of financial analysts' profit forecasts, utilizing machine learning and text analysis to identify key determinants and enhance predictive models.",✔️,Profit forecasts,✔️,?
WOS:000254056900005,The Markov-switching multifractal model of asset returns: GMM estimation and linear forecasting of volatility,"Multifractal processes have recently been proposed as a new formalism for modeling the time series of returns in finance. The major attraction of these processes is their ability to generate various degrees of long memory in different powers of returns-a feature that has been found in virtually all financial data. Initial difficulties stemming from nonstationarity and the combinatorial nature of the original model have been overcome by the introduction of an iterative Markov-switching multifractal model which allows for estimation of its parameters via maximum likelihood (ML) and Bayesian forecasting of volatility. However, applicability of MLE is restricted to cases with a discrete distribution of volatility components. From a practical point of view, ML also becomes computationally unfeasible for large numbers of components even if they are drawn from a discrete distribution. Here we propose an alternative generalized method of moments (GMM) estimator together with linear forecasts which in principle is applicable for any continuous distribution with any number of volatility components. Monte Carlo studies show that GMM performs reasonably well for the popular binomial and lognormal models and that the loss incurred with linear compared to optimal forecasts is small. Extending the number of volatility components beyond what is feasible with MLE leads to gains in forecasting accuracy for some time series.",10.1198/073500107000000403,generalized method of moments; Levinson-Durbin algorithm; long memory; multiplicative; volatility model,WOS,"The article introduces a generalized method of moments (GMM) estimator for Markov-switching multifractal models of asset returns, facilitating linear volatility forecasting and demonstrating improved forecasting accuracy through extensive Monte Carlo simulations.",✔️,Asset returns volatility,❌,✔️
WOS:000188597300010,The adaptive selection of financial and economic variables for use with artificial neural networks,"It has been widely accepted that predicting stock returns is not a simple task since many market factors are involved and their structural relationships are not perfectly linear. Recently, a promising data mining technique in machine learning has been proposed to uncover the predictive relationships of numerous financial and economic variables. Inspired by the fact that the determinant between these variables and their interrelationships over stock returns changes over time, we explore this issue further by using data mining to uncover the recent relevant variables with the greatest predictive ability. The objective is to examine whether using the recent relevant variables leads to additional improvements in stock return forecasting. Given evidence of non-linearity in the financial market, the resulting variables are then provided to neural networks, including probabilistic and feed-forward neural networks, for predicting the directions of future excess stock return. The results show that redeveloped neural network models that use the recent relevant variables generate higher profits with lower risks than the buy-and-hold strategy, conventional linear regression, and the random walk model, as well as the neural network models that use constant relevant variables. (C) 2003 Elsevier B.V. All rights reserved.",10.1016/j.neucom.2003.05.001,neural networks; variable relevance analysis; financial and economic variables; stock market prediction,WOS,"Uses machine learning and neural networks with adaptive selection of recent relevant variables to predict stock returns, showing improved profits and lower risks compared to traditional methods.",✔️,Stocks,✔️,❌
10.1504/IJGUC.2019.098213,The big data mining forecasting model based on combination of improved manifold learning and deep learning,"In this paper, we use the combination of Local Linear Embedding (LLE) with Continuous Deep Belief Networks (CDBN) as the input of RBF, and construct a mixed-feature RBF model. However, LLE depends too much on the local domain which is not easy to be determined, so we propose a new method, Kernel Entropy Linear Embedding (KELE) which uses Kernel Entropy Component Analysis (KECA) to transfer the non-linear problem into linear problem. CDBN has the difficulty in confirming network structure and lacks supervision, so we improve the situations by using the kernel entropy information obtained from KECA, which is called KECDBN. In the empirical part, we use the foreign exchange rate time series to examine the effects of the improved methods, and results show that both the KELE and the KECDBN show better effects in reducing dimensionality and extracting features, respectively, an also improve the prediction accuracy of the mixed-feature RBF. Copyright © 2019 Inderscience Enterprises Ltd.",10.1504/ijguc.2019.098213,CDBN; Continuous deep belief network; KECA; KECDBN; KELE; Kernel entropy component analysis; Kernel entropy continuous deep belief network; Kernel entropy linear embedding; LLE; Local linear embedding,SCOPUS,"The study develops a big data forecasting model combining improved manifold learning and deep learning techniques, enhancing prediction accuracy in foreign exchange rate time series.",✔️,Foreign exchange rates,✔️,❌
WOS:000620273200025,The impact of the global stock and energy market on EU ETS: A structural equation modelling approach,"The industrial revolution has brought about great development in the economy, but it has also increased the dependence on fossil energy. The emissions of CO2 and other greenhouse gases have contradicted economic development and the ecological environment. The establishment of the EU Emission Trading System (EU ETS) has improved the global carbon emission price mechanism, but as a new commodity, its price trend will affect buyers' risk evaluation. Therefore, it is influential to master the driving factors behind carbon emission prices and make effective predictions. First, the paper points out that the driving factors are divided into macroeconomic risk factors and energy factors. Second, the Bayesian Network is used to select variables and make prediction of carbon prices. The results show that its accuracy exceeds other machine learning algorithms. Third, a structural equation model is used to study the impact of the selected markets on the carbon market. Finally, from the perspective of global carbon emission reduction, the relationship between driving factors and the carbon futures market is explained. The empirical results show that Cotation Assistee en Continu 40, natural gas and Brent crude oil will directly affect the yield of European Union Allowances and Certified Emission Reduction futures, and the Standard Poor 500 and Global Clean Energy Index will indirectly affect the yield of European Union Allowances and Certified Emission Reduction futures. The energy market will affect the carbon market through the intermediary effect of the stock market, in which the clean energy index is the most relevant factor. From the perspective of how to improve the carbon trading system, this paper proposes suggestions for the sustainable development of the world to promote the virtuous cycle of the global carbon emission market and the high-quality development of the global economy. (C) 2020 Elsevier Ltd. All rights reserved.",10.1016/j.jclepro.2020.125140,EU ETS; Carbon price; Structural equation model; Bayesian network,WOS,"Analyzes the impact of global stock and energy markets on EU Emission Trading System (EU ETS) prices using Bayesian Networks and structural equation models, showing direct and indirect effects via stock markets.",✔️,"EU Allowances, Certified Emission Reduction futures",✔️,✔️
WOS:001066578500051,The roles of liquidity and delay in financial markets based on an optimal forecasting model,"We investigate the roles of liquidity and delay in financial markets through our proposed optimal forecasting model. The efficiency and liquidity of the financial market are examined using stochastic models that incorporate information delay. Based on machine learning, we estimate the in-sample and out-of-sample forecasting price performances of the six proposed methods using the likelihood function and Bayesian methods, and the out-of-sample prediction performance is compared with the benchmark model ARIMA-GARCH. We discover that the forecasting price performance of the proposed simplified delay stochastic model is superior to that of the benchmark methods by the test methods of a variety of loss function, superior predictive ability test (SPA), Akaike information criterion (AIC), and Bayesian information criterion (BIC). Using data from the Chinese stock market, the best forecasting model assesses the efficiency and liquidity of the financial market while accounting for information delay and trade probability. The rise in trade probability and delay time affects the stability of the return distribution and raises the risk, according to stochastic simulation. The empirical findings show that empirical and best forecasting approaches are compatible, that company size and liquidity (delay time) have an inverse relationship, and that delay time and liquidity have a nonlinear relationship. The most efficient have optimal liquidity.",10.1371/journal.pone.0290869,,WOS,"Investigates the impact of liquidity and information delay on financial market forecasting using machine learning models, demonstrating that optimized models outperform benchmarks in predicting market efficiency and liquidity-related risks.",✔️,Financial Markets,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869829,Time Series Impact Through Topic Modeling,"A time-series of numerical data and a sequence of time-ordered documents are often correlated. This paper aims at modeling the impact that the underlying themes discussed in the text data have on the time series. To do so, we introduce an original topic model, Time Series Impact Through Topic Modeling (TSITM), that includes contextual data by coupling Latent Dirichlet Allocation (LDA) with linear regression, using an elastic net prior to set to zero the impact of uncorrelated topics. The resulting topics act as explanatory variables for the regression of the numerical time series, which allows us to understand the time series movements based on the events described on the text data. We have tested our model on two datasets: first, we used political news to explain the US president’s disapproval ratings; then, we considered a corpus of economic news to explain the financial returns of 4 different multinational corporations. Our experiments show that an appropriate selection of hyperparameters (via repeated random subsampling validation and Bayesian optimization) leads to significant correlations: both an intrinsic baseline and state of the art methods were significantly outperformed by TSITM in MSE, MAE and out-of-sample  $R^{2}$ , according to our hypothesis tests. We believe that this framework can be useful in the context of reputational risk management.",10.1109/access.2022.3202960,Time series analysis;Numerical models;Correlation;Data models;Predictive models;Social networking (online);Vocabulary;Natural language processing;Text analysis;Expectation-maximization algorithms;natural language processing;regression analysis;text mining;text analysis;time series analysis,IEEE,"Introduces TSITM, combining topic modeling with regression to explain financial returns of corporations based on economic news, outperforming baseline methods.",✔️,Financial Returns (Stocks),✔️,❌
10.5829/ije.2020.33.07a.16,Time series forecasting of bitcoin price based on autoregressive integrated moving average and machine learning approaches,"Bitcoin as the current leader in cryptocurrencies is a new asset class receiving significant attention in the financial and investment community and presents an interesting time series prediction problem. In this paper, some forecasting models based on classical like ARIMA and machine learning approaches including Kriging, Artificial Neural Network (ANN), Bayesian method, Support Vector Machine (SVM) and Random Forest (RF) are proposed and analyzed for modelling and forecasting the Bitcoin price. While some of the proposed models are univariate, the other models are multivariate and as a result, the maximum, minimum and the opening daily price of Bitcoin are also used in these models. The proposed models are applied on the Bitcoin price from December 18, 2019 to March 1, 2020 and their performances are compared in terms of the performance measures of RMSE and MAPE by Diebold- Mariano statistical test. Based on RMSE and MAPE measures, the results show that SVM provides the best performance among all the models. In addition, ARIMA and Bayesian approaches outperform other univariate models where they provide smaller values for RMSE and MAPE. © 2020 Materials and Energy Research Center. All rights reserved.",10.5829/ije.2020.33.07a.16,Bitcoin; Machine learning; Multivariate models; Time series forecasting,SCOPUS,"Presents nonlinear manifold learning techniques for high-dimensional time series forecasting, applied to foreign exchange rates.",✔️,Foreign Exchange Rates,✔️,❌
WOS:000592318300001,"Time series modelling, NARX neural network and hybrid KPCA-SVR approach to forecast the foreign exchange market in Mauritius","Purpose This study constructs time series model, artificial neural networks (ANNs) and statistical topologies to examine the volatility and forecast foreign exchange rates. The Mauritian forex market has been utilized as a case study, and daily data for nominal spot rate (during a time period of five years spanning from 2014 to 2018) for EUR/MUR, GBP/MUR, CAD/MUR and AUD/MUR have been applied for the predictions. Design/methodology/approach Autoregressive integrated moving average (ARIMA) and generalized autoregressive conditional heteroskedasticity (GARCH) models are used as a basis for time series modelling for the analysis, along with the non-linear autoregressive network with exogenous inputs (NARX) neural network backpropagation algorithm utilizing different training functions, namely, Levenberg-Marquardt (LM), Bayesian regularization and scaled conjugate gradient (SCG) algorithms. The study also features a hybrid kernel principal component analysis (KPCA) using the support vector regression (SVR) algorithm as an additional statistical tool to conduct financial market forecasting modelling. Mean squared error (MSE) and root mean square error (RMSE) are employed as indicators for the performance of the models. Findings The results demonstrated that the GARCH model performed better in terms of volatility clustering and prediction compared to the ARIMA model. On the other hand, the NARX model indicated that LM and Bayesian regularization training algorithms are the most appropriate method of forecasting the different currency exchange rates as the MSE and RMSE seemed to be the lowest error compared to the other training functions. Meanwhile, the results reported that NARX and KPCA-SVR topologies outperformed the linear time series models due to the theory based on the structural risk minimization principle. Finally, the comparison between the NARX model and KPCA-SVR illustrated that the NARX model outperformed the statistical prediction model. Overall, the study deduced that the NARX topology achieves better prediction performance results compared to time series and statistical parameters. Research limitations/implications The foreign exchange market is considered to be instable owing to uncertainties in the economic environment of any country and thus, accurate forecasting of foreign exchange rates is crucial for any foreign exchange activity. The study has an important economic implication as it will help researchers, investors, traders, speculators and financial analysts, users of financial news in banking and financial institutions, money changers, non-banking financial companies and stock exchange institutions in Mauritius to take investment decisions in terms of international portfolios. Moreover, currency rates instability might raise transaction costs and diminish the returns in terms of international trade. Exchange rate volatility raises the need to implement a highly organized risk management measures so as to disclose future trend and movement of the foreign currencies which could act as an essential guidance for foreign exchange participants. By this way, they will be more alert before conducting any forex transactions including hedging, asset pricing or any speculation activity, take corrective actions, thus preventing them from making any potential losses in the future and gain more profit. Originality/value This is one of the first studies applying artificial intelligence (AI) while making use of time series modelling, the NARX neural network backpropagation algorithm and hybrid KPCA-SVR to predict forex using multiple currencies in the foreign exchange market in Mauritius.",10.1108/ajems-04-2019-0161,Forex market; Time series model; Artificial intelligence; ARIMA; GARCH; ANN; NARX; KPCA-SVR,WOS,"Applies time series models, NARX neural networks, and KPCA-SVR hybrid models to forecast forex rates in Mauritius, finding NARX outperforms others.",✔️,"Forex (EUR/MUR, GBP/MUR, etc.)",✔️,❌
WOS:000863319300002,"Time-series forecasting using manifold learning, radial basis function interpolation, and geometric harmonics","We address a three-tier numerical framework based on nonlinear manifold learning for the forecasting of high-dimensional time series, relaxing the ""curse of dimensionality "" related to the training phase of surrogate/machine learning models. At the first step, we embed the high-dimensional time series into a reduced low-dimensional space using nonlinear manifold learning (local linear embedding and parsimonious diffusion maps). Then, we construct reduced-order surrogate models on the manifold (here, for our illustrations, we used multivariate autoregressive and Gaussian process regression models) to forecast the embedded dynamics. Finally, we solve the pre-image problem, thus lifting the embedded time series back to the original high-dimensional space using radial basis function interpolation and geometric harmonics. The proposed numerical data-driven scheme can also be applied as a reduced-order model procedure for the numerical solution/propagation of the (transient) dynamics of partial differential equations (PDEs). We assess the performance of the proposed scheme via three different families of problems: (a) the forecasting of synthetic time series generated by three simplistic linear and weakly nonlinear stochastic models resembling electroencephalography signals, (b) the prediction/propagation of the solution profiles of a linear parabolic PDE and the Brusselator model (a set of two nonlinear parabolic PDEs), and (c) the forecasting of a real-world data set containing daily time series of ten key foreign exchange rates spanning the time period 3 September 2001-29 October 2020. Published under an exclusive license by AIP Publishing.",10.1063/5.0094887,,WOS,"Develops a manifold learning-based framework for forecasting high-dimensional time series, demonstrated on synthetic data and foreign exchange rates.",✔️,Foreign Exchange Rates,✔️,✔️
WOS:001023114600001,Treatment Effect Risk: Bounds and Inference,"Because the average treatment effect (ATE) measures the change in social welfare, even if positive, there is a risk of negative effect on, say, some 10% of the population. Assessing such risk is difficult, however, because any one individual treatment effect (ITE) is never observed, so the 10% worst-affected cannot be identified, whereas distributional treatment effects only compare the first deciles within each treatment group, which does not correspond to any 10% subpopulation. In this paper, we consider how to nonetheless assess this important risk measure, formalized as the conditional value at risk (CVaR) of the ITE distribution. We leverage the availability of pretreatment covariates and characterize the tightest possible upper and lower bounds on ITE-CVaR given by the covariate-conditional average treatment effect (CATE) function. We then proceed to study how to estimate these bounds efficiently from data and construct confidence intervals. This is challenging even in randomized experiments as it requires understanding the distribution of the unknown CATE function, which can be very complex if we use rich covariates to best control for heterogeneity. We develop a debiasing method that overcomes this and prove it enjoys favorable statistical properties even when CATE and other nuisances are estimated by black box machine learning or even inconsistently. Studying a hypothetical change to French job search counseling services, our bounds and inference demonstrate a small social benefit entails a negative impact on a substantial subpopulation.",10.1287/mnsc.2023.4819,individual treatment effect; conditional average treatment effect; conditional value at risk; partial identification; debiased machine learning,WOS,"Discusses bounds on conditional value at risk of treatment effects in causal inference using Bayesian methods, allowing for uncertainty in estimates.",❌,?,✔️,✔️
WOS:000294432100009,Trend forecasting of financial time series using PIPs detection and continuous HMM,"Many machine learning methods in Artificial intelligence literature, such as Neural Networks, Genetic Algorithms, SVM, and Case-Based Reasoning, have been applied to forecast the financial market with high irregularity and uncertatinty. Among them, SVM is the most representative method that models and forecasts financial time series. However, SVM cannot reflect on the dynamic characteristic of financial time series effectively due to its superior generalization performance. And we cannot guarantee that the parameters of SVM have the optimum values, since they are locally searched owing to the limited time bound. These vulnerabilities are the main factors that degenerates the forecasting performance of SVM. On the other hand, continuous HMM can effectively capture the irregular and dynamic movement of financial time series with a non-stationary property, since it models a financial time series stochastically, rather than deterministically. Therefore, this paper suggests a new method that constructs the trend forecasting model of financial time series. It firstly detects PIPs indicating the significant turnabout of trend in each financial time series. And then the detected PIPs are used to construtct its trend forecasting model based on continuous HMM. In the experiment with various financial time series datasets we demonstrate its superiority.",10.3233/ida-2011-0495,Trend forecasting; financial time series; PIPs detection; Continuous Hidden Markov Model,WOS,"A trend forecasting model for financial time series is developed using PIPs detection and continuous Hidden Markov Models, demonstrating superiority over existing methods.",✔️,Financial Time Series,✔️,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10122777,"Uncertainties in Onboard Algorithms for Autonomous Vehicles: Challenges, Mitigation, and Perspectives","Autonomous driving is considered one of the revolutionary technologies shaping humanity’s future mobility and quality of life. However, safety remains a critical hurdle in the way of commercialization and widespread deployment of autonomous vehicles on public roads. Safety concerns require the autonomous driving system to handle uncertainties from multiple sources that are either preexisting, e.g., the stochastic behavior of traffic participants or scenario occlusion, or introduced as a result of processing, e.g., the application of neural networks. Thus, it is crucial to analyze the sources of uncertainties and quantify the risks associated with them, including the propagated risks that accumulate in the decision-making system. In this context, this paper provides an overview of uncertainty challenges and state-of-the-art techniques for mitigating these challenges. We argue that the uncertainties mainly originate from two aspects: 1) the external traffic environment, and 2) the internal autonomous driving system. Specifically, this paper first analyzes the safety challenges caused by the uncertainties and summarizes their sources. In addition, the corresponding techniques that mitigate and quantify the risk of uncertainties are presented. Finally, research perspectives are highlighted to facilitate future studies for guaranteeing the safety of autonomous vehicles.",10.1109/tits.2023.3270887,Uncertainty;Safety;Autonomous vehicles;Task analysis;Decision making;Roads;Pipelines;Autonomous driving;uncertainty challenges;mitigation techniques;future perspectives,IEEE,"Investigates the impact of market sentiment, liquidity, persistence, and leverage on implied volatility during earnings announcements using Bayesian methods, enhancing option trading strategies and risk management.",✔️,Options (Implied Volatility during earnings),✔️,✔️
WOS:000902290300014,Uncertainty Quantification and Optimal Robust Design for Machining Operations,"In this study, we carry out robust optimal design for the machining operations, one key process in wafer polishing in chip manufacturing, aiming to avoid the peculiar regenerative chatter and maximize the material removal rate (MRR) considering the inherent material and process uncertainty. More specifically, we characterize the cutting tool dynamics using a delay differential equation (DDE) and enlist the temporal finite element method (TFEM) to derive its approximate solution and stability index given process settings or design variables. To further quantify the inherent uncertainty, replications of TFEM under different realizations of random uncontrollable variables are performed, which however incurs extra computational burden. To eschew the deployment of such a crude Monte Carlo (MC) approach at each design setting, we integrate the stochastic TFEM with a stochastic surrogate model, stochastic kriging, in an active learning framework to sequentially approximate the stability boundary. The numerical result suggests that the nominal stability boundary attained from this method is on par with that from the crude MC, but only demands a fraction of the computational overhead. To further ensure the robustness of process stability, we adopt another surrogate, the Gaussian process, to predict the variance of the stability index at unexplored design points and identify the robust stability boundary per the conditional value at risk (CVaR) criterion. Therefrom, an optimal design in the robust stable region that maximizes the MRR can be identified.",10.1115/1.4055039,uncertainty quantification; robust optimal design; stochastic kriging; Gaussian process; conditional value-at-risk; computational foundations for engineering optimization; data-driven engineering; machine learning,WOS,(Not financial instrument-related),❌,?,❌,?
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10155311,Uncertainty-Aware Decision-Making for Autonomous Driving at Uncontrolled Intersections,"Reinforcement learning (RL) has been widely used in the decision-making of autonomous vehicles (AVs) in recent studies. However, existing RL methods generally find the optimal policy by maximizing the expectation of future returns, which lacks distributional treatments of risky situations. Additionally, various uncertainties arising from the environment could also cause unreliable decisions, particularly in some complex urban environments. In this paper, the fully parameterized quantile network (FPQN) is utilized to estimate the full return distribution. Then, the conditional value-at-risk (CVaR) is utilized with the return distribution information to generate uncertainty-aware driving behavior. Additionally, an uncontrolled four-way intersection is developed by the Simulation of Urban Mobility (SUMO) simulation platform, which considers both the surrounding vehicles (SVs) and pedestrians. More specifically, to simulate the real-world traffic environment, the uncertainty arising from the occlusion, and the behavior uncertainty of surrounding traffic participants are also considered. The experiment results suggest that the proposed method outperforms the baseline methods in terms of safety. Furthermore, the results also indicate that the proposed method can make reasonable decisions in some challenging driving cases in the presence of uncertainty.",10.1109/tits.2023.3283019,Uncertainty;Decision making;Behavioral sciences;Autonomous vehicles;Safety;Mathematical models;Urban areas;Autonomous driving;distributional reinforcement learning;decision-making;uncertainty;uncontrolled intersection,IEEE,"Combines distributional reinforcement learning with ensemble methods to provide uncertainty-aware predictions in autonomous driving, enhancing safety and decision-making.",❌,Autonomous Vehicles,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779871,Uncertainty-Aware Portfolio Management With Risk-Sensitive Multiagent Network,"As deep neural networks (DNNs) have gained considerable attention in recent years, there have been several cases applying DNNs to portfolio management (PM). Although some researchers have experimentally demonstrated its ability to make a profit, it is still insufficient to use in real situations because existing studies have failed to answer how risky investment decisions are. Furthermore, even though the objective of PM is to maximize returns within a risk tolerance, they overlook the predictive uncertainty of DNNs in the process of risk management. To overcome these limitations, we propose a novel framework called risk-sensitive multiagent network (RSMAN), which includes risk-sensitive agents (RSAs) and a risk adaptive portfolio generator (RAPG). Standard DNNs do not understand the risks of their decision, whereas RSA can take risk-sensitive decisions by estimating market uncertainty and parameter uncertainty. Acting as a trader, this agent is trained via reinforcement learning from dynamic trading simulations to estimate the distribution of reward and via unsupervised learning to assess parameter uncertainty without labeled data. We also present an RAPG that can generate a portfolio fitting the user’s risk appetite without retraining by exploiting the estimated information from the RSAs. We tested our framework on the U.S. and Korean real financial markets to demonstrate the practicality of the RSMAN.",10.1109/tnnls.2022.3174642,Uncertainty;Portfolios;Investment;Uncertain systems;Task analysis;Training;Q-learning;Deep learning;financial trading;portfolio management (PM);reinforcement learning (RL);uncertainty quantification,IEEE,"Proposes the RSMAN framework using AI models to manage portfolios by estimating and incorporating uncertainty, demonstrating practicality in US and Korean financial markets.",✔️,Portfolio,✔️,✔️
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401536,Unified Low-Rank Matrix Estimate via Penalized Matrix Least Squares Approximation,"Low-rank matrix estimation arises in a number of statistical and machine learning tasks. In particular, the coefficient matrix is considered to have a low-rank structure in multivariate linear regression and multivariate quantile regression. In this paper, we propose a method called penalized matrix least squares approximation (PMLSA) toward a unified yet simple low-rank matrix estimate. Specifically, PMLSA can transform many different types of low-rank matrix estimation problems into their asymptotically equivalent least-squares forms, which can be efficiently solved by a popular matrix fast iterative shrinkage-thresholding algorithm. Furthermore, we derive analytic degrees of freedom for PMLSA, with which a Bayesian information criterion (BIC)-type criterion is developed to select the tuning parameters. The estimated rank based on the BIC-type criterion is verified to be asymptotically consistent with the true rank under mild conditions. Extensive experimental studies are performed to confirm our assertion.",10.1109/tnnls.2018.2844242,Tuning;Learning systems;Estimation;Computational modeling;Task analysis;Robustness;Least squares approximation;Degrees of freedom;low-rank matrix estimate;multivariate linear regression;multivariate quantile regression (QR),IEEE,"Proposes PMLSA method for low-rank matrix estimation in statistical and machine learning tasks, providing a unified and efficient approach.",❌,?,✔️,❌
10.1109/ACCESS.2019.2918292,Unsupervised Detection of Apnea Using Commodity RFID Tags with a Recurrent Variational Autoencoder,"With the rapid development of intelligent health sensing in the Internet of Things (IoT), vital sign monitoring (e.g., respiration) and abnormal respiration detection have attracted increasing attention. Considering the challenging and the cost of collecting labeled training data from patients with breathing related diseases, we develop the AutoTag system, an unsupervised recurrent variational autoencoder-based method for respiration rate estimation and abnormal breathing detection with off-the-shelf RFID tags. Moreover, for real-time breath monitoring, a novel method is proposed to cancel the distortion on measured phase values caused by channel hopping for FCC-complaint RFID systems. The efficacy of the proposed system is demonstrated by the extensive experiments conducted in two indoor environments, while the impact of various design and environmental factors is also evaluated. © 2013 IEEE.",10.1109/access.2019.2918292,Apnea; deep learning; radio-frequency identification (RFID); recurrent variational autoencoder; respiration monitoring,SCOPUS,The AutoTag system employs an unsupervised recurrent variational autoencoder for respiration rate estimation and abnormal breathing detection using RFID tags.,❌,?,✔️,❌
WOS:000650445800001,Using Fuzzy Inference Systems for the Creation of Forex Market Predictive Models,"This paper presents a method for creating Forex market predictive models using multi-agent and fuzzy systems, which have the objective of simulating the interactions that provoke changes in the price. Agents in the system represent traders performing buy and sell orders in a market, and fuzzy systems are used to model the rules followed by traders performing trades in a live market and intuitionistic fuzzy logic to model their decisions' indeterminacy. We use functions to restrict the agents' decisions, which make the agents become specialized at particular market conditions. These ""specialization"" functions use the grades of membership obtained from an agent's fuzzy system and thresholds obtained from training data sets, to determine if that agent is specialized enough to handle a market's current conditions. We have performed experiments and compared against the state of the art. Results demonstrate that our method obtains predictive errors (using mean absolute error) that are in the same order of magnitude than those errors obtained by models generated using deep learning and models generated by random forest, AdaBoost, XGBoost, and support-vector machines. Furthermore, we performed experiments that show that identifying specialized agents yields better results.",10.1109/access.2021.3077910,Fuzzy sets; Fuzzy logic; Predictive models; Fuzzy systems; Hidden Markov models; Biological system modeling; Shape; Economic forecasting; fuzzy systems; multi-agent system; forex market,WOS,"A method utilizing fuzzy inference systems and multi-agent systems is presented for creating Forex market predictive models, achieving predictive errors comparable to deep learning and ensemble models.",✔️,Forex,✔️,❌
10.3390/su16051789,Using Probabilistic Machine Learning Methods to Improve Beef Cattle Price Modeling and Promote Beef Production Efficiency and Sustainability in Canada,"Accurate agricultural commodity price models enable efficient allocation of limited natural resources, leading to improved sustainability in agriculture. Because of climate change, price volatility and uncertainty in the sector are expected to increase in the future, increasing the need for improved price modeling. With the emergence of machine learning (ML) algorithms, novel tools are now available to enhance the modeling of agricultural commodity prices. This research explores both univariate and multivariate ML techniques to perform probabilistic price prediction modeling for the Canadian beef industry, taking into account beef production, commodity markets, and international trade features to enhance accuracy. We model Alberta fed steer prices using three multivariate ML algorithms (support vector regression (SVR), random forest (RF), and Adaboost (AB)) and three univariate ML algorithms (autoregressive integrated moving average (ARIMA), seasonal ARIMA (SARIMA), and the seasonal autoregressive integrated moving average with exogenous factors (SARIMAX)). We apply these models to monthly fed steer price data between January 2005 and September 2023 and compare predicted prices with observed prices using several validation metrics. The outcomes indicate that both random forest (RF) and Adaboost (AB) show superior overall performance in accurately predicting Alberta fed steer prices in comparison to other algorithms. To better account for the variance of the best model performance, we subsequently adopted a probabilistic approach by considering uncertainty in our best-selected ML model. The beef industry can use these improved price models to minimize resource waste and inefficiency in the sector and improve the long-term sustainability prospects for beef producers in Canada. © 2024.",10.3390/su16051789,Adaboost; ARIMA; Canadian Cattle Price Modeling; machine learning; multivariate and univariate modeling; probabilistic modeling; random forest; SARIMA; SARIMAX; support vector regression,SCOPUS,"Implements machine learning models with Bayesian optimization and Gaussian process regression to forecast flat steel product price indices in China, achieving high forecasting accuracy.",✔️,Flat steel price index,✔️,✔️
10.18178/ijmlc.2017.7.2.614,Using machine learning classifiers to predict stock exchange index,"Predicting stock exchange index is an attractive research topic in the field of machine learning. Numerous studies have been conducted using various techniques to predict stock market volume. This paper presents first detailed study on data of Karachi Stock Exchange (KSE) and Saudi Stock Exchange (SSE) to predict the stock market volume of ten different companies. In this study, we have applied and compared salient machine learning algorithms to predict stock exchange volume. The performance of these algorithms have been compared using accuracy metrics on the dataset, collected over the period of six months, by crawling the KSE and SSE website.",10.18178/ijmlc.2017.7.2.614,Ada-boost; Bayesian network; Machine learning; Neural networks; Stock exchange prediction; SVM,SCOPUS,Applies and compares various machine learning classifiers to predict stock exchange volumes for ten companies on the Karachi and Saudi Stock Exchanges using six months of data.,✔️,Stock Exchange Indices,✔️,❌
978-1-109-52503-8,Variance-based clustering methods and higher order data transformations and their applications,"Two approaches have been proposed in statistical and machine learning communities in order to address the problem of uncovering clusters with complex structure. One approach relies on the development of clustering criteria that are able to accommodate increasingly complex characteristics of the data. The other approach is based on simplification of structure of data by mapping it to a different feature space via a non-linear function and then clustering in the new space. This dissertation covers three related studies: development of a novel multi-dimensional clustering method, development of non-linear mapping functions that leverage higher-order co-occurrences between features in boolean data, and applications of these mapping functions for improving the performance of clustering methods. In particular, we treat clustering as a combinatorial optimization problem of finding a partition of the data so as to minimize a certain criterion. We develop a novel multi-dimensional clustering method based on a statistically-motivated criterion proposed by J. Neyman for stratified sampling from one-dimensional data. We show that this criterion is more reflective of the underlying data structure than the seemingly similar K-means criterion when second order variability is not homogeneous between constituent subgroups. Furthermore, experimental results demonstrate that generalization of the Neyman's criterion to multi-dimensional spaces and development of the associated clustering algorithm allow for statistically efficient estimation of the grand mean vector of a population. In the framework of the mapping-based approach to discovering complex cluster structures, we introduced a novel adaptive non-linear data transformation termed Unsupervised Second Order Transformation (USOT). The novelties behind USOT are (a) that it leverages in a unsupervised manner, higher-order co-occurrences between features in boolean data, and (b) that it considers each feature in the context of probabilistic relationships with other features. In addition, USOT has two desirable properties. USOT adaptively selects features that would influence the mapping of a given feature, and preserves the interpretability of dimensions of the transformed space. Experimental results on text corpora and financial time series demonstrate that by leveraging higher-order co-occurrences between features, clustering methods achieved statistically significant improvements in USOT space over the original boolean space.",,,Proquest,"The dissertation develops novel variance-based clustering methods and higher-order data transformations, applying them to financial time series data to uncover complex cluster structures and improve data analysis in finance.",❌,?,✔️,❌
WOS:000972006100092,Visual recognition and prediction analysis of China's real estate index and stock trend based on CNN-LSTM algorithm optimized by neural networks,"Today, with the rapid growth of Internet technology, the changing trend of real estate finance has brought great an impact on the progress of the social economy. In order to explore the visual identification (VI) effect of Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) algorithm based on neural network optimization on China's real estate index and stock trend, in this study, artificial neural network (ANN) algorithm is introduced to predict its trend. Firstly, LSTM algorithm can effectively solve the problem of vanishing gradient, which is suitable for dealing with the problems related to time series. Secondly, CNN, with its unique fine-grained convolution operation, has significant advantages in classification problems. Finally, combining the LSTM algorithm with the CNN algorithm, and using the Bayesian Network (BN) layer as the transition layer for further optimization, the CNN-LSTM algorithm based on neural network optimization has been constructed for the VI and prediction model of real estate index and stock trend. Through the performance verification of the model, the results reveal that the CNN-LSTM optimization algorithm has a more accurate prediction effect, the prediction accuracy is 90.55%, and the prediction time is only 52.05s. At the same time, the significance advantage of CNN-LSTM algorithm is verified by statistical method, which can provide experimental reference for intelligent VI and prediction of trend of China real estate index and property company stocks.",10.1371/journal.pone.0282159,,WOS,The study explores the use of an optimized CNN-LSTM neural network to visually identify and predict trends in China's real estate index and stock market.,✔️,"Stock, Real Estate Index",✔️,❌
WOS:000891788100011,Volatility index prediction based on a hybrid deep learning system with multi-objective optimization and mode decomposition,"Advances in volatility index prediction based on computational intelligence have brought wide-ranging benefits to financial risk management. However, current studies in the field remain limited and need further improve-ment due to these research gaps: (1) ignoring the important role of probabilistic prediction in characterizing uncertainty risks; (2) relying on single-objective optimization algorithm to optimize prediction model, thereby ignoring the advantages of multi-objective optimization; (3) emphasizing nonlinear modeling, not considering both nonlinear and linear modeling simultaneously. Aiming to address these gaps, a novel multi-objective hybrid deep learning system, composed of a modified multi-objective optimizer, a clockwork recurrent neural network, and an improved mode decomposition method, is newly proposed to perform deterministic and probabilistic volatility index prediction. Concretely, the volatility index is decomposed into some modes using an advanced data decomposition method; further, the clockwork recurrent neural network is considered a prediction engine to model these modes, which has an excellent ability to model the long-term dependency for linear and nonlinear time series depending on its mechanism of temporal granularity, as compared to traditional recurrent neural networks; finally, the prediction results can be obtained by integrating the predictions from these modes, using the mode weights calculated by an improved multi-objective optimizer with the objectives of prediction accuracy and stability. To validate the performance of the proposed hybrid deep learning system, case studies and cor-responding sensitivity and convergence analyses are carried out. From the perspective of the indicator mean absolute percentage error, the maximum improvements of our proposed system reach 67.50%, 75.82%, and 75.42% in Case I, Case II, and Case III, respectively, thus indicating its superiority and practical feasibility.",10.1016/j.eswa.2022.119184,Volatility index; Mode decomposition; Deep learning; Multi-objective optimization; Prediction,WOS,"This paper develops a hybrid deep learning system integrating multi-objective optimization and mode decomposition to perform both deterministic and probabilistic predictions of volatility indices, achieving significant improvements in forecasting accuracy and stability.",✔️,Volatility indices,✔️,✔️
10.1109/LRA.2021.3070308,Volumetric occupancy mapping with probabilistic depth completion for robotic navigation,"In robotic applications, a key requirement for safe and efficient motion planning is the ability to map obstacle-free space in unknown, cluttered 3D environments. However, commodity-grade RGB-D cameras commonly used for sensing fail to register valid depth values on shiny, glossy, bright, or distant surfaces, leading to missing data in the map. To address this issue, we propose a framework leveraging probabilistic depth completion as an additional input for spatial mapping. We introduce a deep learning architecture providing uncertainty estimates for the depth completion of RGB-D images. Our pipeline exploits the inferred missing depth values and depth uncertainty to complement raw depth images and improve the speed and quality of free space mapping. Evaluations on synthetic data show that our approach maps significantly more correct free space with relatively low error when compared against using raw data alone in different indoor environments; thereby producing more complete maps that can be directly used for robotic navigation tasks. The performance of our framework is validated using real-world data. © 2016 IEEE.",10.1109/lra.2021.3070308,Computer vision; Machine learning; Mobile robots; Simultaneous localisation and mapping,SCOPUS,"Develops a probabilistic depth completion framework using deep learning for volumetric occupancy mapping, enhancing robotic navigation in cluttered environments.",❌,?,✔️,✔️
https://doi.org/10.3390/signals1010001,"Welcome to SIGNALS: A New Open-Access Scientific Journal on Signal Analysis, Retrieval and Processing","The sheer exposure to vast amounts of signals created in our modern society and an ever increasing need to make sense of such data calls for continuing advances in signal processing as an enabling technology for a huge number of applications, ranging from wireless communication and medicine, through to bioengineering, the economy and entertainment.Activity recognition, event detection, anomaly detection Adaptive filtering and signal processing Applications of signal processing (Biomedical, Bioinformatics, Genomic, Seismic, Radar, Sonar, Remote Sensing, Positioning, Embedded Systems, etc.) Array signal processing Audio/speech processing and coding Biometrics and authentification Biomedical Signal Processing and biomedical data analysis (EEG/MEG, fMRI, PET etc.) Biological network and data analysis/modelling Biosignal processing and understanding Blind and semi-blind signal separation (e.g., single- and multi-channel recordings, audio source separation, bio-signal separation, independent component analysis (ICA), nonnegative matrix/tensor factorization (NMF/NTF) Brain Computer Interface (BCI) Communication signal processing Compressive Sensing (CS) and sparse information retrieval Computer Vision (CV) and Virtual Reality (VR) Computational Neuroscience and brain data analysis/modelling Cryptography and network security Emerging technologies Image processing and understanding Image/Video Processing and Coding Inference and prediction of hidden patterns in signals/images Multimedia signal processing Natural Language Processing (NLP) Neuroimaging and signal processing Signal processing for human-computer interaction (HCI) and Brain Computer Interface (BCI).Image and multidimensional signal processing using tensor representation Scalable and distributed algorithms for tensor processing Methods for robust tensor processing with noisy, incomplete and/or missing signals/data Tensor methods in neural networks and deep learning Tensor-based time series and image processing Tensor processing and analysis in social networks and economics Applications of tensor processing in wireless communications and sensor networks Tensor developments in computer vision Tensor methods in neuroscience and medicine and Stochastic modelling of biological processes, systems biology, Information theory articles with a signal processing perspective Deep learning probabilistic neural networks with signals/data processing perspective Financial time series analysis Bioinformatics and neuroinfomatics Biochemical interaction in biological and biologically-inspired systems Signal processing for performance arts using audio, and video Signal processing for renewable energy Game theory and group theory for signal processing Environmental signal processing Signal processing with intelligent user interfaces Quantum signal processing.",10.3390/signals1010001,,Proquest,"Introduction to the open-access journal SIGNALS, which focuses on signal analysis, retrieval, and processing across various applications.",❌,,❌,❌
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386066,When CVaR Meets With Bluetooth PAN: A Physical Distancing System for COVID-19 Proactive Safety,"In this work, we propose a risk-aware physical distancing system to assure a private safety distance from others for reducing the chance of being affected by the COVID-19 or such kind of pandemic. In particular, we have formulated a physical distancing problem by capturing Conditional Value-at-Risk (CVaR) of a Bluetooth-enabled personal area network (PAN). To solve the formulated risk-aware physical distancing problem, we propose two stages solution approach by imposing control flow, linear model, and curve-fitting schemes. Notably, in the first stage, we determine a PAN creator’s safe movement distance by proposing a probabilistic linear model. This scheme can effectively cope with a tail-risk from the probability distribution by satisfying the CVaR constraint for estimating safe movement distance. In the second stage, we design a Levenberg-Marquardt (LM)-based curve fitting algorithm upon the recommended safety distance and current distances between the PAN creator and others to find an optimal high-risk trajectory plan for the PAN creator. Finally, we have performed an extensive performance analysis using state-of-the-art Bluetooth data to establish the proposed risk-aware physical distancing system’s effectiveness. Our experimental results show that the proposed solution approach can effectively reduce the risk of recommending safety distance towards ensuring private safety. In particular, for a 95% CVaR confidence, we can successfully deal with 45.11% of the risk for measuring the PAN creator’s safe movement distance.",10.1109/jsen.2021.3068782,COVID-19;Safety;Bluetooth;Sensors;Trajectory;Particle measurements;Atmospheric measurements;Physical distancing;conditional value-at-risk (CVaR);personal area network (PAN);Bluetooth;COVID-19,IEEE,A risk-aware physical distancing system using Conditional Value-at-Risk (CVaR) is developed to ensure safety distance during pandemics through Bluetooth-enabled networks.,❌,?,✔️,✔️
10.3389/fpls.2023.1160645,“How sweet are your strawberries?”: Predicting sugariness using non-destructive and affordable hardware,"Global soft fruit supply chains rely on trustworthy descriptions of product quality. However, crucial criteria such as sweetness and firmness cannot be accurately established without destroying the fruit. Since traditional alternatives are subjective assessments by human experts, it is desirable to obtain quality estimations in a consistent and non-destructive manner. The majority of research on fruit quality measurements analyzed fruits in the lab with uniform data collection. However, it is laborious and expensive to scale up to the level of the whole yield. The “harvest-first, analysis-second” method also comes too late to decide to adjust harvesting schedules. In this research, we validated our hypothesis of using in-field data acquirable via commodity hardware to obtain acceptable accuracies. The primary instance that the research concerns is the sugariness of strawberries, described by the juice’s total soluble solid (TSS) content (unit: °Brix or Brix). We benchmarked the accuracy of strawberry Brix prediction using convolutional neural networks (CNN), variational autoencoders (VAE), principal component analysis (PCA), kernelized ridge regression (KRR), support vector regression (SVR), and multilayer perceptron (MLP), based on fusions of image data, environmental records, and plant load information, etc. Our results suggest that: (i) models trained by environment and plant load data can perform reliable prediction of aggregated Brix values, with the lowest RMSE at 0.59; (ii) using image data can further supplement the Brix predictions of individual fruits from (i), from 1.27 to as low up to 1.10, but they by themselves are not sufficiently reliable. Copyright © 2023 Wen, Abeel and de Weerdt.",10.3389/fpls.2023.1160645,computer vision; crop management; data fusion; feature selection; in-field test; machine learning; non-destructive analysis; total soluble solid,SCOPUS,"This research validates the use of commodity hardware and machine learning models, including CNNs and VAEs, to non-destructively predict the sugariness of strawberries, achieving reliable Brix value predictions.",❌,,✔️,❌
