"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Abstract","Author Keywords","Index Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"Caprioli S.; Cagliero E.; Crupi R.","Caprioli, Sergio (58632917500); Cagliero, Emanuele (58631756500); Crupi, Riccardo (57222250441)","58632917500; 58631756500; 57222250441","Quantifying credit portfolio sensitivity to asset correlations with interpretable generative neural networks","2024","Journal of Risk Model Validation","18","1","","1","17","16","1","10.21314/JRMV.2024.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194178240&doi=10.21314%2fJRMV.2024.002&partnerID=40&md5=dd27c0e6ebdb7dbe41621323fb78bb3f","We propose a novel approach for quantifying the sensitivity of credit portfolio value-at-risk to asset correlations with the use of synthetic financial correlation matrixes generated with deep learning models. In previous work, generative adversarial networks (GANs) were employed to demonstrate the generation of plausible correlation matrixes that capture the essential characteristics observed in empirical correlation matrixes estimated on asset returns. Instead of GANs, we employ variational autoencoders (VAEs) to achieve a more interpretable latent space representation and to obtain a generator of plausible correlation matrixes by sampling the VAE’s latent space. Through our analysis, we reveal that the VAE’s latent space can be a useful tool to capture the crucial factors impacting portfolio diversification, particularly in relation to the sensitivity of credit portfolios to changes in asset correlations. A VAE trained on the historical time series of correlation matrixes is used to generate synthetic correlation matrixes that satisfy a set of expected financial properties. Our analysis provides clear indications that the capacity for realistic data augmentation provided by VAEs, combined with the ability to obtain model interpretability, can prove useful for risk management, enhancing the resilience and accuracy of models when backtesting, as past data may exhibit biases and might not contain the essential high-stress events required for evaluating diverse risk scenarios. © 2024 Infopro Digital Risk (IP) Limited","concentration risk; credit portfolio model; explainable artificial intelligence (XAI); generative neural network; interpretable generative neural networks; variational autoencoder (VAE)","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85194178240"
"Clintworth M.; Lyridis D.; Boulougouris E.","Clintworth, Mark (57194013072); Lyridis, Dimitrios (6506983549); Boulougouris, Evangelos (7801393511)","57194013072; 6506983549; 7801393511","Financial risk assessment in shipping: a holistic machine learning based methodology","2023","Maritime Economics and Logistics","25","1","","90","121","31","7","10.1057/s41278-020-00183-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098792497&doi=10.1057%2fs41278-020-00183-2&partnerID=40&md5=5bcec820bb4f99bb3c5ab420236183a7","Corporate financial distress (FD) prediction models are of great importance to all stakeholders, including regulators and banks, who rely on acceptable estimates of default risk, for both individual borrowers and bank loan portfolios. Whilst this subject has been covered extensively in finance research, its application to international shipping companies has been limited while the focus has mainly been on the application of traditional linear modelling, using sparse, cross-sectional financial statement data. Insufficient attention has been paid to the noisy and incomplete nature of shipping company financial statement information. This study contributes to the literature through the design, development and testing of a novel holistic machine learning methodology which integrates predictor evaluation and missing data analysis into the distress prediction process. The model was validated using a longitudinal dataset of over 5000 company year-end financial statements combined with macroeconomic and market predictors. We applied this methodology first for individual company level distress prediction before testing the models’ ability to provide accurate confidence intervals by backtesting conditional value-at-risk estimations of the distress rates for bank portfolios. We conclude that, by adopting a holistic approach, our methodology can enhance financial monitoring of company loans and bank loan portfolios thereby providing a practical “early warning system” for financial distress. © 2021, The Author(s), under exclusive licence to Springer Nature Limited part of Springer Nature.","Conditional value-at-risk; Extreme gradient boosting; Financial distress; Generalised additive modelling; Machine learning; Multivariate imputation; Random forest","","Article","Final","","Scopus","2-s2.0-85098792497"
"Kim J.-M.; Han H.H.; Kim S.","Kim, Jong-Min (55720212100); Han, Hope H. (57216825024); Kim, Sangjin (57190955712)","55720212100; 57216825024; 57190955712","Forecasting Crude Oil Prices with Major S&P 500 Stock Prices: Deep Learning, Gaussian Process, and Vine Copula","2022","Axioms","11","8","375","","","","5","10.3390/axioms11080375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137349001&doi=10.3390%2faxioms11080375&partnerID=40&md5=4d7986ea8eeeda89646d2f25cc7c3383","This paper introduces methodologies in forecasting oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. We also apply Bayesian variable selection and nonlinear principal component analysis (NLPCA) for data dimension reduction. With a reduced number of important covariates, we also forecast oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. To apply real data to the proposed methods, we select monthly log returns of 2 oil prices and 74 large-cap, major S&P 500 stock prices across the period of February 2001–October 2019. We conclude that vine copula regression with NLPCA is superior overall to other proposed methods in terms of the measures of prediction errors. © 2022 by the authors.","Bayesian variable selection; functional principal component analysis; Gaussian process model; multivariate time series; nonlinear principal component analysis; oil prices; S&P 500; vine copula","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137349001"
"Jin B.; Xu X.","Jin, Bingzi (58914834300); Xu, Xiaojie (57192066072)","58914834300; 57192066072","Forecasting wholesale prices of yellow corn through the Gaussian process regression","2024","Neural Computing and Applications","36","15","","8693","8710","17","32","10.1007/s00521-024-09531-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186458437&doi=10.1007%2fs00521-024-09531-2&partnerID=40&md5=0fe2e3c0698e99f38493a7e632e5f849","For market players and policy officials, commodity price forecasts are crucial problems that are challenging to address due to the complexity of price time series. Given its strategic importance, corn crops are hardly an exception. The current paper evaluates the forecasting issue for China’s weekly wholesale price index for yellow corn from January 1, 2010 to January 10, 2020. We develop a Gaussian process regression model using cross validation and Bayesian optimizations over various kernels and basis functions that could effectively handle this sophisticated commodity price forecast problem. The model provides precise out-of-sample forecasts from January 4, 2019 to January 10, 2020, with a relative root mean square error, root mean square error, and mean absolute error of 1.245%, 1.605, and 0.936, respectively. The models developed here might be used by market players for market evaluations and decision-making as well as by policymakers for policy creation and execution. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Commodity price; Corn; Forecasting; Gaussian process regression; Machine learning","Commerce; Decision making; Errors; Gaussian distribution; Gaussian noise (electronic); Machine learning; Mean square error; Regression analysis; Commodity prices; Corn; Gaussian process regression; Machine-learning; Market players; Price forecasts; Root mean square errors; Times series; Whole sale prices; Yellow corn; Forecasting","Article","Final","","Scopus","2-s2.0-85186458437"
"Li Z.; Li C.; Min L.; Lin D.","Li, Zhen (58514566900); Li, Changfei (58558014600); Min, Liangyu (57220547786); Lin, Dijia (58724491900)","58514566900; 58558014600; 57220547786; 58724491900","Black-Litterman Portfolio Optimization Using Gaussian Process Regression","2023","IAENG International Journal of Applied Mathematics","53","4","IJAM_53_4_34","","","","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177977642&partnerID=40&md5=fbf575a15307ad11af0b36c81aedb536","The Black-Litterman portfolios based on the predictions provided by Gaussian Process are constructed in this study. Besides the expert views generated by the Gaussian Process, an customized algorithm quantifying the confidence level of the given investor opinions is also designed, which can be inputted into the Black-Litterman framework to revise the posterior parameters estimations. Low-risk anomaly is observed from the numerical experiments through the grouping method base on stock β, demonstrating the potential irrationality for even giant companies and brands on the advanced market. Empirical analysis shows that Gaussian Process is able to model the low β stock effectively, while not feasible for stocks with high volatility. Thus, the proposed BLGPlo portfolio outperform the benchmarks in terms of cumulative excess return and Sharpe ratio. Moreover, the BLGPlo performance can be further improved by allocating higher confidence level for the Gaussian Process-derived investor opinions. © (2023), (International Association of Engineers). All Rights Reserved.","Black-Litterman; Gaussian Process; Machine learning; Portfolio selection","Financial data processing; Financial markets; Gaussian distribution; Gaussian noise (electronic); Numerical methods; Black-litterman; Confidence levels; Gaussian process regression; Gaussian Processes; Machine-learning; Method base; Numerical experiments; Parameters estimation; Portfolio optimization; Portfolio selection; Machine learning","Article","Final","","Scopus","2-s2.0-85177977642"
"Bucci A.; He L.; Liu Z.","Bucci, Andrea (57195419707); He, Lidan (57216738390); Liu, Zhi (16245021700)","57195419707; 57216738390; 16245021700","Combining dimensionality reduction methods with neural networks for realized volatility forecasting","2023","Annals of Operations Research","","","","","","","7","10.1007/s10479-023-05544-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168905569&doi=10.1007%2fs10479-023-05544-7&partnerID=40&md5=97bcb89dab73c355644864e60b86164f","The application of artificial neural networks to finance has recently received a great deal of attention from both investors and researchers, particularly as a forecasting tool. However, when dealing with a large number of predictors, these methods may overfit the data and provide poor out-of-sample forecasts. Our paper addresses this issue by employing two different approaches to predict realized volatility. On the one hand, we use a two-step procedure where several dimensionality reduction methods, such as Bayesian Model Averaging (BMA), Principal Component Analysis (PCA), and Least Absolute Shrinkage and Selection Operator (Lasso), are employed in the initial step to reduce dimensionality. The reduced samples are then combined with artificial neutral networks. On the other hand, we implement two single-step regularized neural networks that can shrink the input weights to zero and effectively handle high-dimensional data. Our findings on the volatility of different stock asset prices indicate that the reduced models outperform the compared models without regularization in terms of predictive accuracy. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial neural network; Bayesian model averaging; Machine-learning; PCA Method; Realized volatility","","Article","Article in press","","Scopus","2-s2.0-85168905569"
"Abaker A.O.I.; Mahmoud A.S.; Mohammed B.O.; Alzahrani A.R.R.; Mohamed A.O.Y.; Elhag A.A.","Abaker, Abdelgalal O.I. (58817476400); Mahmoud, Abdalla S. (58817586500); Mohammed, Badawi O. (58817476500); Alzahrani, Ali R.R. (57215434238); Mohamed, Adil O.Y. (58148958300); Elhag, Azhari A. (57217536854)","58817476400; 58817586500; 58817476500; 57215434238; 58148958300; 57217536854","A Study of The Saudi Stock Market Using Some Statistical Models","2023","Journal of Statistics Applications and Probability","12","","","1591","1596","5","0","10.18576/jsap/12S115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182584884&doi=10.18576%2fjsap%2f12S115&partnerID=40&md5=7e015e695ca1d8e1807506960ce77c07","The objective of this paper is to estimate the diversification effects/benefits of an investment in a portfolio consisting of the South African Industrial (J520) and the Financial (J580) Indices using the Generalised Pareto Distributions (GPDs) with an extreme value Gumbel copula. The GPD is used as the marginal distribution to both assets to better characterize the extreme risk of returns in both Indices tails. The extreme value Gumbel copula captures the dependence structure (co-movement) of the financial assets in the portfolio. The Akaike information criterion (AIC) and Bayesian information criterion (BIC) goodness of fit tests and the scatterplots indicate that the upper tail of the gains (the larger gains) risk and the losses tail (the larger losses) are best captured using the extreme value Gumbel copula. Monte Carlo simulation of an equally weighted portfolio of the two Indices is used to estimate the portfolio risk. The univariate marginal risks and the portfolio risks are used to calculate the diversification effects/benefits. The results show that there are benefits in diversification since the riskiness of the portfolio is less than the sum of the risk of the two financial assets. This implies that VaR, although not additive theoretically, is sub-additive in this practical situation. This property of sub-additivity represents the benefits of diversification for a portfolio. The implication is that investors investing in individual risky assets can benefit from constructing such a portfolio to reduce extreme risk. Due to high dependence and contagion between developed markets/Global markets, this is useful information for local and international investors seeking a portfolio which includes developing countries' market Indices, such as South African assets, which are less correlated with other Global markets, thereby reducing the risk of contagion. © 2023 NSP Natural Sciences Publishing Cor.","ARIMA models; GARCH models; Leverage effect; Machine Learning; Statistical Model; Stock market; Volatility clustering","","Article","Final","","Scopus","2-s2.0-85182584884"
"Jin B.; Xu X.","Jin, Bingzi (58914834300); Xu, Xiaojie (57192066072)","58914834300; 57192066072","Predictions of steel price indices through machine learning for the regional northeast Chinese market","2024","Neural Computing and Applications","36","33","","20863","20882","19","3","10.1007/s00521-024-10270-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199406308&doi=10.1007%2fs00521-024-10270-7&partnerID=40&md5=b2c530af714ae07e5c9015a0b46f31d0","Projections of commodity prices have long been a significant source of dependence for investors and the government. This study investigates the challenging topic of forecasting the daily regional steel price index in the northeast Chinese market from January 1, 2010, to April 15, 2021. The projection of this significant commodity price indication has not received enough attention in the literature. The forecasting model that is used is Gaussian process regressions, which are trained using a mix of cross-validation and Bayesian optimizations. The models that were built precisely predicted the price indices between January 8, 2019, and April 15, 2021, with an out-of-sample relative root mean square error of 0.5432%. Investors and government officials can use the established models to study pricing and make judgments. Forecasting results can help create comparable commodity price indices when reference data on the price trends suggested by these models are used. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Bayesian optimization; Cross-validation; Gaussian process regression; Regional steel price index; Time series forecast","Commerce; Costs; Gaussian distribution; Investments; Prediction models; Bayesian optimization; Chinese markets; Commodity prices; Cross validation; Gaussian process regression; Machine-learning; Price index; Regional steel price index; Steel price; Time series forecasts; Mean square error","Article","Final","","Scopus","2-s2.0-85199406308"
"Zaffar A.; Hussain S.M.A.","Zaffar, Asma (55853877100); Hussain, S. M. Aalim (51663532800)","55853877100; 51663532800","Modeling and prediction of KSE – 100 index closing based on news sentiments: an applications of machine learning model and ARMA (p, q) model","2022","Multimedia Tools and Applications","81","23","","33311","33333","22","7","10.1007/s11042-022-13052-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128331249&doi=10.1007%2fs11042-022-13052-2&partnerID=40&md5=29109fe07a2008cbc256042d7ee0dbcb","The main financial markets of every country are stock exchange and consider as an imperative cause for the corporations to increase capital. The novelty of this study to explore machine learning techniques when applied to financial stock market data, and to understand how machine learning algorithms can be applied and compare the result with time series analysis to real lifetime series data and helpful for any investor. Investors are constantly reviewing past pricing history and using it to influence their future investment decisions. The another novelty of this study, using news sentiments, the values will be processed into lists displaying and representing the stock and predicting the future rates to describe the market, and to compare investments, which will help to avoid uncertainty amongst the investors regarding the stock index. Using artificial neural network technique for prediction for KSE 100 index data on closing day. In this regard, six months’ data cycle trained the data and apply the statistical interference using a ARMA (p, q) model to calculate numerical result. The novelty of this study to find the relation between them either they are strongly correlated or not, using machine learning techniques and ARMA (p, q) process to forecast the behavior KSE 100 index cycles. The adequacy of model describes via least values Akaike information criterion (AIC), Bayesian Schwarz information criterion (SIC) and Hannan Quinn information criterion (HIC). Durbin- Watson (DW) test is also applied. DW values (< 2) shows that all cycles are strongly correlated. Most of the KSE-100 index cycles expresses that the appropriate model is ARMA (2,1). Cycle’s 2nd,3rd,4th and 5th shows that ARMA (3,1) is best fitted. Cycle 8th is shows ARMA (1,1) best fit and cycle 12th shows that the most appropriate model is ARMA (4,1). Diagnostic checking tests like Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Theil’s U-Statistics are used to predict KSE-100 index cycles. Theil’s U-Statistics demonstrate that each cycle is strongly correlated to previous one. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","ARMA (p; KSE-100 index; MAE; Q); RMSE; Theil’s U-statistics","Commerce; Electronic trading; Errors; Financial markets; Forecasting; Investments; Machine learning; Mean square error; Neural networks; Statistical tests; Time series analysis; Appropriate models; ARMA (p; Information criterion; KSE-100 index; Machine learning techniques; Mean absolute error; Q); Root mean squared errors; Theil’s U-statistic; U-statistics; Learning algorithms","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85128331249"
"Fabiani G.; Evangelou N.; Cui T.; Bello-Rivas J.M.; Martin-Linares C.P.; Siettos C.; Kevrekidis I.G.","Fabiani, Gianluca (57221812867); Evangelou, Nikolaos (58707788300); Cui, Tianqi (57223960659); Bello-Rivas, Juan M. (56536961700); Martin-Linares, Cristina P. (58632749700); Siettos, Constantinos (6603568664); Kevrekidis, Ioannis G. (35479930600)","57221812867; 58707788300; 57223960659; 56536961700; 58632749700; 6603568664; 35479930600","Task-oriented machine learning surrogates for tipping points of agent-based models","2024","Nature Communications","15","1","4117","","","","3","10.1038/s41467-024-48024-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193318428&doi=10.1038%2fs41467-024-48024-7&partnerID=40&md5=c612f29b8137df31a84d2f712127bd65","We present a machine learning framework bridging manifold learning, neural networks, Gaussian processes, and Equation-Free multiscale approach, for the construction of different types of effective reduced order models from detailed agent-based simulators and the systematic multiscale numerical analysis of their emergent dynamics. The specific tasks of interest here include the detection of tipping points, and the uncertainty quantification of rare events near them. Our illustrative examples are an event-driven, stochastic financial market model describing the mimetic behavior of traders, and a compartmental stochastic epidemic model on an Erdös-Rényi network. We contrast the pros and cons of the different types of surrogate models and the effort involved in learning them. Importantly, the proposed framework reveals that, around the tipping points, the emergent dynamics of both benchmark examples can be effectively described by a one-dimensional stochastic differential equation, thus revealing the intrinsic dimensionality of the normal form of the specific type of the tipping point. This allows a significant reduction in the computational cost of the tasks of interest. © The Author(s) 2024.","","benchmarking; cost analysis; financial market; machine learning; numerical model; simulator; agent based model; Article; digital twin; epidemiological model; feed forward neural network; financial market; imitation; information; machine learning; manifold learning; mean squared error; positive feedback; prediction; probability; simulation; social connectedness; social network; steady state; stochastic model; stock market; article; benchmarking; controlled study; epidemiological model; financial market; human; learning; manifold learning; nerve cell network; simulator","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85193318428"
"Makarov I.S.; Bagantsova E.R.; Iashin P.A.; Kovaleva M.D.; Gorbachev R.A.","Makarov, Ivan S. (57224484501); Bagantsova, Ekaterina R. (58176334500); Iashin, Prokhor A. (58176618700); Kovaleva, Maria D. (57476974100); Gorbachev, Roman A. (56769537700)","57224484501; 58176334500; 58176618700; 57476974100; 56769537700","Development of and research on machine learning algorithms for solving the classification problem in Twitter publications; [Разработка и исследование алгоритмов машинного обучения для решения задачи классификации в публикациях Twitter]","2023","Computer Research and Modeling","15","1","","185","195","10","0","10.20537/2076-7633-2023-15-1-185-195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152111479&doi=10.20537%2f2076-7633-2023-15-1-185-195&partnerID=40&md5=e0d6dbc9bcc5e9f49995db9d8fc8091d","Posts on social networks can both predict the movement of the financial market, and in some cases even determine its direction. The analysis of posts on Twitter contributes to the prediction of cryptocurrency prices. The specificity of the community is represented in a special vocabulary. Thus, slang expressions and abbreviations are used in posts, the presence of which makes it difficult to vectorize text data, as a result of which preprocessing methods such as Stanza lemmatization and the use of regular expressions are considered. This paper describes created simplest machine learning models, which may work despite such problems as lack of data and short prediction timeframe. A word is considered as an element of a binary vector of a data unit in the course of the problem of binary classification solving. Basic words are determined according to the frequency analysis of mentions of a word. The markup is based on Binance candlesticks with variable parameters for a more accurate description of the trend of price changes. The paper introduces metrics that reflect the distribution of words depending on their belonging to a positive or negative classes. To solve the classification problem, we used a dense model with parameters selected by Keras Tuner, logistic regression, a random forest classifier, a naive Bayesian classifier capable of working with a small sample, which is very important for our task, and the k-nearest neighbors method. The constructed models were compared based on the accuracy metric of the predicted labels. During the investigation we recognized that the best approach is to use models which predict price movements of a single coin. Our model deals with posts that mention LUNA project, which no longer exist. This approach to solving binary classification of text data is widely used to predict the price of an asset, the trend of its movement, which is often used in automated trading. © 2023 Ivan S. Makarov, Ekaterina R. Bagantsova, Prokhor A. Iashin, Maria D. Kovaleva, Roman A. Gorbachev.","dense model; KNN; logistic regression; machine learning; naive Bayes classifier; natural language processing; random fores classifier; Twitter; vectorization; сryptocurrency","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85152111479"
"Kim J.; Lee M.","Kim, Jiwook (58066416000); Lee, Minhyeok (57194701375)","58066416000; 57194701375","Portfolio optimization using predictive auxiliary classifier generative adversarial networks","2023","Engineering Applications of Artificial Intelligence","125","","106739","","","","4","10.1016/j.engappai.2023.106739","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166234204&doi=10.1016%2fj.engappai.2023.106739&partnerID=40&md5=12ca89565577dd0a9899b5f5a9cd8746","In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. Despite numerous studies on shallow learning models, they have shown limited success in analyzing the complex nature of massive stock data, a task where recent deep learning models excel. However, the deterministic nature of conventional deep learning models impedes their consideration of portfolio risk due to an inherent lack of uncertainty quantification in their predictions. This paper proposes a novel portfolio weighting strategy, incorporating both risk and return considerations within a deep learning framework. We propose the Predictive Auxiliary Classifier Generative Adversarial Networks (PredACGAN), a probabilistic deep learning model, to measure prediction uncertainty. The PredACGAN generator leverages latent vectors and historical stock prices to predict future returns. The model synthesizes predictive distributions from various latent vectors and past prices. The associated risk is produced via the entropy of these distributions, facilitating portfolio optimization through both return and risk considerations. The proposed algorithm removes high-risk assets from the investment universe at rebalancing moments, enabling PredACGAN to optimize portfolios considering both return and risk. We evaluated PredACGAN and the accompanying algorithm with S&P 500 stocks from 1990 to 2020, with portfolios rebalanced monthly based on PredACGAN predictions and risk measures. The PredACGAN portfolios yielded 9.123% annual returns and a 1.054 Sharpe ratio, outperforming a risk-agnostic portfolio yielding 1.024% annual returns and a 0.236 Sharpe ratio. The PredACGAN portfolio also exhibited lower maximum drawdowns, highlighting its effectiveness. © 2023 Elsevier Ltd","Deep learning; Generative adversarial network; Portfolio optimization; Risk estimation; Uncertainty","Costs; Deep learning; Financial markets; Forecasting; Generative adversarial networks; Investments; Learning systems; Risk perception; Annual returns; Assets distributions; Deep learning; Financial engineering; Latent vectors; Learning models; Portfolio optimization; Risk estimation; Sharpe ratios; Uncertainty; Risk assessment","Article","Final","","Scopus","2-s2.0-85166234204"
"Salama R.","Salama, Reda (56511506800)","56511506800","Integrating spotted hyena optimization technique with generative artificial intelligence for time series forecasting","2024","Expert Systems","","","","","","","0","10.1111/exsy.13681","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200054642&doi=10.1111%2fexsy.13681&partnerID=40&md5=1d86d2c56b51ded1412294691ea58eff","Generative artificial intelligence (AI) has developed as an effective tool for time series predicting, revolutionizing the typical methods of prediction. Different classical approaches that depend on existing approaches and assumptions, generative AI controls advanced deep learning (DL) approaches like generative adversarial networks (GANs) and recurrent neural networks (RNNs), to identify designs and connections in time series data. DL has accomplished major success in optimizing performances connected with AI. In the financial area, it can be extremely utilized for the stock market predictive, trade implementation approaches, and set of optimizers. Stock market predictive is the most important use case in this field. GANs with advanced AI approaches have become more significant in recent times. However, it can be utilized in image-image-translation and other computer vision (CV) conditions. GANs could not utilized greatly for stock market prediction because of their effort to establish the proper set of hyperparameters. This study develops an integrated spotted hyena optimization algorithm with generative artificial intelligence for time series forecasting (SHOAGAI-TSF) technique. The purpose of the SHOAGAI-TSF technique is to accomplish a forecasting process for the utilization of stock price prediction. The SHOAGAI-TSF technique uses probabilistic forecasting with a conditional GAN (CGAN) approach for the prediction of stock prices. The CGAN model learns the data generation distribution and determines the probabilistic prediction from it. To boost the prediction results of the CGAN approach, the hyperparameter tuning can be performed by the use of the SHOA. The simulation result analysis of the SHOAGAI-TSF technique takes place on the stock market dataset. The experimental outcomes determine the significant solution of the SHOAGAI-TSF algorithm with other compared methods in terms of distinct metrics. © 2024 John Wiley & Sons Ltd.","artificial intelligence; generative adversarial network; spotted hyena optimization; stock market prediction; time series forecasting","Commerce; Electronic trading; Financial markets; Forecasting; Probability distributions; Recurrent neural networks; Time series; Effective tool; Forecasting techniques; Hyper-parameter; Optimisations; Optimization algorithms; Optimization techniques; Spotted hyena optimization; Stock market prediction; Time series forecasting; Times series; Generative adversarial networks","Article","Article in press","","Scopus","2-s2.0-85200054642"
"Basak G.K.; Das P.K.; Marjit S.; Mukherjee D.; Yang L.","Basak, Gopal K. (6603742670); Das, Pranab Kumar (55451768400); Marjit, Sugata (7004076035); Mukherjee, Debashis (57226879305); Yang, Lei (55732949900)","6603742670; 55451768400; 7004076035; 57226879305; 55732949900","The British Stock Market, currencies, brexit, and media sentiments: A big data analysis","2023","North American Journal of Economics and Finance","64","","101861","","","","5","10.1016/j.najef.2022.101861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146032549&doi=10.1016%2fj.najef.2022.101861&partnerID=40&md5=292b38bef6b3c372ab76e26ced47cc5b","In this study, we use a machine learning framework and draw on an extensive body of media articles on Brexit to provide evidence of cointegration and causality between the sentiments of the media and the movement of British currency. Our contribution to the literature is novel. In addition to applying lexicons commonly used in sentiment analysis, we devise a method using Bayesian learning to create a more context-aware and informative lexicon for Brexit. By leveraging and extending this method, we reveal the relationship between original media sentiment and related economic and financial variables. Our method is a distinct improvement over existing methods and can better predict out-of-sample outcomes than conventional ones. © 2022 Elsevier Inc.","Brexit; British currency; British Stock Market; Machine learning; Media sentiment","","Article","Final","","Scopus","2-s2.0-85146032549"
"Tian C.; Niu T.; Wei W.","Tian, Chaonan (57793330400); Niu, Tong (57193523842); Wei, Wei (57198567282)","57793330400; 57193523842; 57198567282","Volatility index prediction based on a hybrid deep learning system with multi-objective optimization and mode decomposition","2023","Expert Systems with Applications","213","","119184","","","","3","10.1016/j.eswa.2022.119184","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141920364&doi=10.1016%2fj.eswa.2022.119184&partnerID=40&md5=9dba682912fc24beb531dcb4c769f87e","Advances in volatility index prediction based on computational intelligence have brought wide-ranging benefits to financial risk management. However, current studies in the field remain limited and need further improvement due to these research gaps: (1) ignoring the important role of probabilistic prediction in characterizing uncertainty risks; (2) relying on single-objective optimization algorithm to optimize prediction model, thereby ignoring the advantages of multi-objective optimization; (3) emphasizing nonlinear modeling, not considering both nonlinear and linear modeling simultaneously. Aiming to address these gaps, a novel multi-objective hybrid deep learning system, composed of a modified multi-objective optimizer, a clockwork recurrent neural network, and an improved mode decomposition method, is newly proposed to perform deterministic and probabilistic volatility index prediction. Concretely, the volatility index is decomposed into some modes using an advanced data decomposition method; further, the clockwork recurrent neural network is considered a prediction engine to model these modes, which has an excellent ability to model the long-term dependency for linear and nonlinear time series depending on its mechanism of temporal granularity, as compared to traditional recurrent neural networks; finally, the prediction results can be obtained by integrating the predictions from these modes, using the mode weights calculated by an improved multi-objective optimizer with the objectives of prediction accuracy and stability. To validate the performance of the proposed hybrid deep learning system, case studies and corresponding sensitivity and convergence analyses are carried out. From the perspective of the indicator mean absolute percentage error, the maximum improvements of our proposed system reach 67.50%, 75.82%, and 75.42% in Case I, Case II, and Case III, respectively, thus indicating its superiority and practical feasibility. © 2022 Elsevier Ltd","Deep learning; Mode decomposition; Multi-objective optimization; Prediction; Volatility index","Forecasting; Learning systems; Multiobjective optimization; Recurrent neural networks; Risk management; Uncertainty analysis; Deep learning; Financial risk management; Index predictions; Mode decomposition; Multi objective; Multi-objectives optimization; Non-linear modelling; Optimizers; Prediction-based; Volatility index; Mode decomposition","Article","Final","","Scopus","2-s2.0-85141920364"
"Sağlam C.; Çetin N.","Sağlam, Cevdet (57521630800); Çetin, Necati (57204595476)","57521630800; 57204595476","Machine learning algorithms to estimate drying characteristics of apples slices dried with different methods","2022","Journal of Food Processing and Preservation","46","10","e16496","","","","17","10.1111/jfpp.16496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132264562&doi=10.1111%2fjfpp.16496&partnerID=40&md5=90ac145f30155e89d45a8edd6aebdcf3","In this study, three different apple cultivars were dried using five different drying methods and moisture ratio (MR), moisture content (MC) and drying rate values were determined. Then, different machine learning algorithms (artificial neural network, k-nearest neighbors, random forest, gaussian processes, and support vector regression) were used to estimate MR, MC and drying rate. For MR estimation of Golden Delicious, Oregon Spur and Granny Smith cultivars, Random Forest was most successful algorithm with correlation coefficients (R) of 0.9800, 0.9873, and 0.9841, respectively. This was followed by SVR with R: 0.9323 for Golden Delicious, ANN with R: 0.9766 for Oregon Spur and 5-NN with R: 0.9827 for Granny Smith. MC and drying rate estimation results showed that RF, SVR, and k-NN achieved higher R for all cultivars. It was concluded that machine learning algorithms are an effective approach for the accurate estimation of the drying characteristics of apple slices. Practical applications: Machine learning-like precise modeling techniques are used to estimate the drying characteristics of agricultural commodities. Models should be assessed and compared for optimization of drying conditions and operational costs. Machine learning models predictions agreed well with testing data sets and they could be useful for understanding and controlling the factors affecting drying behaviors. © 2022 Wiley Periodicals LLC.","","Decision trees; Drying; Fruits; Machine learning; Nearest neighbor search; Random forests; Well testing; Apple cultivars; Apple slices; Drying characteristics; Drying methods; Drying rates; Gaussian Processes; Machine learning algorithms; Moisture ratios; Random forests; Support vector regressions; Moisture","Article","Final","","Scopus","2-s2.0-85132264562"
"Jin B.; Xu X.","Jin, Bingzi (58914834300); Xu, Xiaojie (57192066072)","58914834300; 57192066072","Regional steel price index predictions for North China through machine learning","2024","International Journal of Mining and Mineral Engineering","15","3","","314","350","36","3","10.1504/IJMME.2024.140697","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203154181&doi=10.1504%2fIJMME.2024.140697&partnerID=40&md5=3caf4038041d08127adb604c870b25e8","Projections of commodity prices have long been heavily relied upon by investors and the government. This study examines the challenging task of estimating the daily regional steel price index in the north Chinese market for the period of 1 January 2010 to 15 April 2021. The projection of this significant commodity price indication has not received enough attention in the literature. After training our models with cross-validation and Bayesian optimisations, we apply Gaussian process regressions to verify our findings. The models that were built properly predicted the price indices between 8 January 2019 and 15 April 2021, with an out-of-sample relative root mean square error of 0.5871%. Investors and government officials can utilise the generated models for price analysis and decision-making. Forecasting results can help create comparable commodity price indices when reference data on the price trends suggested by these models are used. © 2024 Inderscience Enterprises Ltd.","Bayesian optimisation; China; cross validation; Gaussian process regression; GPR; regional steel price index; time-series forecast","Bayesian optimization; China; Commodity prices; Cross validation; Gaussian process regression; Index predictions; Price index; Regional steel price index; Steel price; Time series forecasts; Prediction models","Article","Final","","Scopus","2-s2.0-85203154181"
"Patrick Vincent A.M.; Salleh H.","Patrick Vincent, Assunta Malar (59317783400); Salleh, Hassilah (55650877400)","59317783400; 55650877400","Improving Stock Price Forecasting Accuracy with Stochastic Multilayer Perceptron","2024","Malaysian Journal of Fundamental and Applied Sciences","20","4","","914","922","8","0","10.11113/mjfas.v20n4.3497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203346360&doi=10.11113%2fmjfas.v20n4.3497&partnerID=40&md5=3930e75f05b40c5c3a8f22381ca8eb93","The stock market operates in a stochastic environment, making accurate price forecasting challenging. To address this issue, a stochastic multilayer perceptron (S-MLP) model has been developed to simulate the stock market's stochastic nature. By incorporating a Gaussian process into the sigmoid activation function, this model incorporates stochasticity into the traditional multilayer perceptron (MLP). As the perturbation factor, a stochastic sigmoid activation function (SAF) with a volatility estimator is used. Although S-MLP has demonstrated superiority over MLP, there is still room for improvement in terms of forecasting precision. In this study, we propose S-MLP with a trainable perturbation factor (S-MLPT), an improved variant of S-MLP. SAF employs the Yang-Zhang volatility estimator as the perturbation factor. The proposed model first employed MLP, and all the parameters were trained. After freezing the parameters, S-MLP is used to train the perturbation factor in the SAF. To evaluate the predictive performance of the models, MLP, S-MLP, and S-MLPT are used to predict the one day ahead highest stock price of four counters listed in Bursa Malaysia. As an evaluation metric, the coefficient of determination is utilised, and the relative percentage improvement of the models is calculated to determine their superiority. The results demonstrated that S-MLP outperforms MLP by effectively minimizing the loss function and converging towards a better local or global minimum during training. In conclusion, S-MLPT exhibits even better performance than S-MLP, with relative percentage improvements of 0.14%, 15.45%, and 0.48% for counters 0166.KL, 2445.KL, and 4707.KL, respectively. ©Copyright Patrick Vincent.","deep learning; Forecasting stock price; multilayer perceptron; stochastic multilayer perceptron","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85203346360"
"Dezhkam A.; Manzuri M.T.; Aghapour A.; Karimi A.; Rabiee A.; Shalmani S.M.","Dezhkam, Arsalan (54897977700); Manzuri, Mohammad Taghi (6506067964); Aghapour, Ahmad (57912775400); Karimi, Afshin (57208365344); Rabiee, Ali (55860096200); Shalmani, Shervin Manzuri (57219757992)","54897977700; 6506067964; 57912775400; 57208365344; 55860096200; 57219757992","A Bayesian-based classification framework for financial time series trend prediction","2023","Journal of Supercomputing","79","4","","4622","4659","37","8","10.1007/s11227-022-04834-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139094561&doi=10.1007%2fs11227-022-04834-4&partnerID=40&md5=101b6c44cd2be5d215a38bde1112e77f","Financial time series have been extensively studied within the past decades; however, the advent of machine learning and deep neural networks opened new horizons to apply supercomputing techniques to extract more insights from the underlying patterns of price data. This paper presents a tri-state labeling approach to classify the underlying patterns in price data into up, down and no-action classes. The introduction of a no-action state in our novel approach alleviates the burden of denoising the dataset as a preprocessing task. The performance of our labeling algorithm is experimented with using machine learning and deep learning models. The framework is augmented by applying the Bayesian optimization technique for the selection of the best tuning values of the hyperparameters. The price trend prediction module generates the required trading signals. The results show that the average annualized Sharpe ratio as the trading performance metric is about 2.823, indicating the framework produces excellent cumulative returns. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Classification; Deep learning; Feature engineering; Financial time series; Machine learning; Trend prediction","Classification (of information); Commerce; Finance; Financial data processing; Forecasting; Learning systems; Time series; Bayesian; Classification framework; De-noising; Deep learning; Feature engineerings; Financial time series; Labelings; Machine-learning; Performance; Trend prediction; Deep neural networks","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85139094561"
"Chan B.K.; Johnson O.V.; Chew X.; Khaw K.W.; Lee M.H.; Alnoor A.","Chan, Bey Kun (59125722900); Johnson, Olanrewaju Victor (57216844696); Chew, XinYing (57209359890); Khaw, Khai Wah (57193604178); Lee, Ming Ha (36348639300); Alnoor, Alhamzah (57204894353)","59125722900; 57216844696; 57209359890; 57193604178; 36348639300; 57204894353","PROPOSED BAYESIAN OPTIMIZATION BASED LSTM-CNN MODEL FOR STOCK TREND PREDICTION","2024","Computing and Informatics","43","1","","38","63","25","0","10.31577/cai_2024_1_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192980131&doi=10.31577%2fcai_2024_1_38&partnerID=40&md5=09bd96080f63cc0bd6b58857203004e4","Stock prediction is prominent in the field of Artificial Intelligence. Stock prediction problems are handled either as a regression or classification task. Studies in the literature have also shown success for hybrid learning to stock prediction. But little attention is paid to finding out the effect of spatial feature extraction/ distortion over the temporal effect of the deep neural network and vice versa for the problem under study. The paper, therefore, proposes a hybrid long shortterm memory (LSTM) network over a convolutional neural network (CNN) called LSTM-CNN as against the popular CNN-LSTM model. The daily price movement of the S&P 500 index data is utilized. A sliding window technique is considered to obtain a balanced data of 20-days window data from the S&P 500. The proposed stock prediction model is investigated further for an optimal set of hyperparameters using the Bayesian optimization (Bo) technique. In addition, the proposed model is compared with optimized CNN, LSTM, and CNN-LTSM models. The optimized LSTM-CNN model is found to outperform the other models with accuracy, precision, and recall values of 0.9741, 0.9684, and 0.9800, respectively. The proposed model is established to provide a better stock trend prediction. © 2024 Slovak Academy of Sciences. All rights reserved.","deep learning; hybrid learning; optimization; prediction; Stock management","Convolutional neural networks; Deep neural networks; Long short-term memory; Neural network models; Bayesian optimization; Convolutional neural network; Deep learning; Hybrid learning; Neural network model; Optimisations; Short term memory; Stock management; Stock predictions; Stock trend prediction; Forecasting","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85192980131"
"Wan J.; Che Y.; Wang Z.; Cheng C.","Wan, Jinming (57933353100); Che, Yiming (57203971902); Wang, Zimo (56133566300); Cheng, Changqing (36909872200)","57933353100; 57203971902; 56133566300; 36909872200","Uncertainty Quantification and Optimal Robust Design for Machining Operations","2023","Journal of Computing and Information Science in Engineering","23","1","011005","","","","3","10.1115/1.4055039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144112631&doi=10.1115%2f1.4055039&partnerID=40&md5=63640f89e63eccb50644b5314f551874","In this study, we carry out robust optimal design for the machining operations, one key process in wafer polishing in chip manufacturing, aiming to avoid the peculiar regenerative chatter and maximize the material removal rate (MRR) considering the inherent material and process uncertainty. More specifically, we characterize the cutting tool dynamics using a delay differential equation (DDE) and enlist the temporal finite element method (TFEM) to derive its approximate solution and stability index given process settings or design variables. To further quantify the inherent uncertainty, replications of TFEM under different realizations of random uncontrollable variables are performed, which however incurs extra computational burden. To eschew the deployment of such a crude Monte Carlo (MC) approach at each design setting, we integrate the stochastic TFEM with a stochastic surrogate model, stochastic kriging, in an active learning framework to sequentially approximate the stability boundary. The numerical result suggests that the nominal stability boundary attained from this method is on par with that from the crude MC, but only demands a fraction of the computational overhead. To further ensure the robustness of process stability, we adopt another surrogate, the Gaussian process, to predict the variance of the stability index at unexplored design points and identify the robust stability boundary per the conditional value at risk (CVaR) criterion. Therefrom, an optimal design in the robust stable region that maximizes the MRR can be identified.  Copyright © 2022 by ASME.","computational foundations for engineering optimization; conditional value-at-risk; data-driven engineering; Gaussian process; machine learning; robust optimal design; stochastic kriging; uncertainty quantification","Cutting tools; Differential equations; Gaussian distribution; Gaussian noise (electronic); Machine learning; Machining centers; Metal cutting; Milling (machining); Numerical methods; Optimal systems; Optimization; Product design; Stability; Stochastic models; Stochastic systems; Surface roughness; Uncertainty analysis; Value engineering; Computational foundation for engineering optimization; Conditional Value-at-Risk; Data driven; Data-driven engineering; Engineering optimization; Gaussian Processes; Kriging; Machine-learning; Robust Optimal Design; Stochastic kriging; Stochastics; Uncertainty quantifications; Kriging","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85144112631"
"Kallus N.","Kallus, Nathan (56305894700)","56305894700","Treatment Effect Risk: Bounds and Inference","2023","Management Science","69","8","","4579","4590","11","5","10.1287/mnsc.2023.4819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168991648&doi=10.1287%2fmnsc.2023.4819&partnerID=40&md5=200755c962f61559c0b809de8925efa7","Because the average treatment effect (ATE) measures the change in social welfare, even if positive, there is a risk of negative effect on, say, some 10% of the population. Assessing such risk is difficult, however, because any one individual treatment effect (ITE) is never observed, so the 10% worst-affected cannot be identified, whereas distributional treatment effects only compare the first deciles within each treatment group, which does not correspond to any 10% subpopulation. In this paper, we consider how to nonetheless assess this important risk measure, formalized as the conditional value at risk (CVaR) of the ITE distribution. We leverage the availability of pretreatment covariates and characterize the tightest possible upper and lower bounds on ITE-CVaR given by the covariate-conditional average treatment effect (CATE) function. We then proceed to study how to estimate these bounds efficiently from data and construct confidence intervals. This is challenging even in randomized experiments as it requires understanding the distribution of the unknown CATE function, which can be very complex if we use rich covariates to best control for heterogeneity. We develop a debiasing method that overcomes this and prove it enjoys favorable statistical properties even when CATE and other nuisances are estimated by black box machine learning or even inconsistently. Studying a hypothetical change to French job search counseling services, our bounds and inference demonstrate a small social benefit entails a negative impact on a substantial subpopulation. © 2023 INFORMS.","conditional average treatment effect; conditional value at risk; debiased machine learning; individual treatment effect; partial identification","Risk assessment; Value engineering; Average treatment effects; Conditional average; Conditional average treatment effect; Conditional Value-at-Risk; Covariates; Debiased machine learning; Individual treatment effect; Machine-learning; Partial identification; Treatment effects; Machine learning","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85168991648"
"Magris M.; Shabani M.; Iosifidis A.","Magris, Martin (57201775466); Shabani, Mostafa (57196058647); Iosifidis, Alexandros (36720841400)","57201775466; 57196058647; 36720841400","Bayesian bilinear neural network for predicting the mid-price dynamics in limit-order book markets","2023","Journal of Forecasting","42","6","","1407","1428","21","2","10.1002/for.2955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148585144&doi=10.1002%2ffor.2955&partnerID=40&md5=268cfe2f2052aa0281083f0d4d6b2bab","The prediction of financial markets is a challenging yet important task. In modern electronically driven markets, traditional time-series econometric methods often appear incapable of capturing the true complexity of the multilevel interactions driving the price dynamics. While recent research has established the effectiveness of traditional machine learning (ML) models in financial applications, their intrinsic inability to deal with uncertainties, which is a great concern in econometrics research and real business applications, constitutes a major drawback. Bayesian methods naturally appear as a suitable remedy conveying the predictive ability of ML methods with the probabilistically oriented practice of econometric research. By adopting a state-of-the-art second-order optimization algorithm, we train a Bayesian bilinear neural network with temporal attention, suitable for the challenging time-series task of predicting mid-price movements in ultra-high-frequency limit-order book markets. We thoroughly compare our Bayesian model with traditional ML alternatives by addressing the use of predictive distributions to analyze errors and uncertainties associated with the estimated parameters and model forecasts. Our results underline the feasibility of the Bayesian deep-learning approach and its predictive and decisional advantages in complex econometric tasks, prompting future research in this direction. © 2023 The Authors. Journal of Forecasting published by John Wiley & Sons Ltd.","Bayesian neural networks; bilinear neural network; financial time-series classification; limit-order book","Bayesian networks; Commerce; Complex networks; Conveying; Deep learning; Electronic trading; Financial markets; Forecasting; Learning systems; Neural networks; Uncertainty analysis; Bayesian; Bayesian neural networks; Bilinear neural network; Financial time series; Financial time-series classification; Limit order book; Neural-networks; Price dynamics; Time series classifications; Times series; Time series","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85148585144"
"Shah Y.; Liu Y.; Shah F.; Shah F.; Satti M.I.; Asenso E.; Shabaz M.; Irshad A.","Shah, Yasir (57197873733); Liu, Yumin (36519039800); Shah, Faiza (57197866365); Shah, Fadia (57197866361); Satti, Muhammad Islam (57965733300); Asenso, Evans (57204683478); Shabaz, Mohammad (57202955007); Irshad, Azeem (58109783500)","57197873733; 36519039800; 57197866365; 57197866361; 57965733300; 57204683478; 57202955007; 58109783500","COVID-19 and commodity effects monitoring using financial & machine learning models","2023","Scientific African","21","","e01856","","","","2","10.1016/j.sciaf.2023.e01856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167826227&doi=10.1016%2fj.sciaf.2023.e01856&partnerID=40&md5=b29b79a8ea661f1e27ce67569b2e05c7","This article focuses on examining the effects of the COVID-19 pandemic and gold prices on the stock market. It primarily analyzes the relationship between COVID-19 cases and stock market prices, along with the impact on various commodity elements such as gold, oil, Chinese RMB, and US Dollar prices. These commodity elements are considered essential indicators of a country's financial health, and the study investigates how the increase in COVID-19 cases affects these financial elements. The research incorporates financial models, machine learning algorithms, and a financial Gaussian mixture model for data analysis and comparison. The findings shed light on the correlation between the virus, trading outcomes, and the importance of Karachi Stock Exchange-100 index data in preventing market crashes. The study also explores the implications of emergencies on the finance sector and provides insights for future financial predictions and the impact of social disasters on the economy. © 2023","Commodity effect; COVID-19; Global financial analysis; Machine learning; VAR model","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85167826227"
"Ghosh I.; Jana R.K.","Ghosh, Indranil (57215412709); Jana, Rabin K. (9639932600)","57215412709; 9639932600","A granular machine learning framework for forecasting high-frequency financial market variables during the recent black swan event","2023","Technological Forecasting and Social Change","194","","122719","","","","5","10.1016/j.techfore.2023.122719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162834191&doi=10.1016%2fj.techfore.2023.122719&partnerID=40&md5=2d3591193b288b7224e3f90f433d8b95","This paper analyses highly voluminous 1-minute intraday movements of the closing prices of Bitcoin, crude oil, the Dow Jones Industrial Average (DJIA) and the euro–U.S. dollar exchange rate in various non-overlapping regimes spanning across the COVID-19 pandemic, a recent black swan event. The empirical characteristics of the intraday dynamics of chosen assets are gauged using nonlinear modelling tools and tests. The proposed methodological framework utilises maximal overlap discrete wavelet transformation, Bayesian structural time series forecasting and random walk with drift to evaluate the quantum of predictability of select variables in different phases across the pandemic horizon. The framework survives a series of performance and statistical checks to justify the efficacy of drawing highly accurate predictions from big data setups. The findings suggest that, despite chaotic traces, all variables can be precisely forecast across different sub-regimes, eliminating the adverse effects of the first and second waves of the COVID-19 pandemic. High-frequency movements of Bitcoin and Euro–U.S. dollar exchange rates are relatively better predictable, signifying resilience during the pandemic. Finally, the outcome of this research will help mitigate financial risk during volatile periods. © 2023 Elsevier Inc.","Bayesian structural time series; Big data analytics; High-frequency financial market forecasting; Maximal overlap discrete wavelet transformation; Nonlinear dynamics","Big data; Bitcoin; Discrete wavelet transforms; Financial markets; Forecasting; Machine learning; Signal reconstruction; Time series; Bayesian; Bayesian structural time series; Big data analytic; Data analytics; Discrete wavelets transformations; High frequency HF; High-frequency financial market forecasting; Market forecasting; Maximal overlap discrete wavelet transformation; Times series; Bayesian analysis; financial crisis; financial market; forecasting method; frequency analysis; granular medium; machine learning; nonlinearity; price dynamics; Data Analytics","Article","Final","","Scopus","2-s2.0-85162834191"
"Teste F.; Gangloff H.; Chen M.; Ciais P.; Makowski D.","Teste, Florian (57703067100); Gangloff, Hugo (57200037792); Chen, Mathilde (57208792030); Ciais, Philippe (55399842300); Makowski, David (6603950439)","57703067100; 57200037792; 57208792030; 55399842300; 6603950439","Leveraging satellite data with machine and deep learning techniques for corn yield and price forecasting","2024","IEEE Transactions on Geoscience and Remote Sensing","","","","1","1","0","0","10.1109/TGRS.2024.3448205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201787675&doi=10.1109%2fTGRS.2024.3448205&partnerID=40&md5=e4f79f000274188e349ef5462411f991","This research introduces a new method for predicting changes in corn yield and price, critical for food security. Instead of relying on difficult-to-access pre-harvest production data, our approach uses satellite-derived Gross Primary Production (GPP) data and dimension-reduction techniques to forecast national corn yield and price changes. We conducted case studies in the US, Malawi, and South Africa to validate this approach, analyzing predictors from annual GPP variations during peak growing seasons. We applied dimension reduction strategies, such as spatial averaging and Empirical Orthogonal Functions (EOFs). Additionally, we used deep learning techniques like Autoencoders (AEs) and Variational Autoencoders (VAEs) to extract meaningful features from the high-dimensional GPP datasets. These features were then used as predictors in yield and price classification models based on Generalized Linear Models and ElasticNet. We also considered a neural network model trained to predict yield and price variations from GPP input data directly. We evaluated the model performances using metrics such as Area Under Curve, Brier Skill Score, and Matthew&#x2019;s Correlation Coefficient. Our results indicate that dimension-reduction techniques based on AEs and VAEs provided better predictive capabilities across all three countries compared to EOF, particularly in Malawi, where the Brier Skill Score increased from 0.26 with EOF to 0.81 with AE for yield and from -0.004 with EOF to 0.77 with VAE for price. This study demonstrates that integrating open-access satellite data with dimension-reduction techniques can significantly improve crop forecast accuracy, providing an accessible tool to enhance agricultural management and food security. IEEE","Autoencoder; Biological system modeling; Classification; Commodity price; Crop yield; Crop yield; Dimension reduction; Forecasting; Land surface; Neural network; Predictive models; Production; Remote sensing; Remote sensing","Costs; Information management; Auto encoders; Biological system modeling; Commodity prices; Crop yield; Dimension reduction; Land surface; Neural-networks; Predictive models; Remote-sensing; Orthogonal functions","Article","Article in press","","Scopus","2-s2.0-85201787675"
"Kalaycı B.; Purutçuoğlu V.; Weber G.W.","Kalaycı, Betül (57218511405); Purutçuoğlu, Vilda (16023097100); Weber, Gerhard Wilhelm (55634220900)","57218511405; 16023097100; 55634220900","Optimal model description of finance and human factor indices","2024","Central European Journal of Operations Research","","","","","","","4","10.1007/s10100-023-00897-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181652228&doi=10.1007%2fs10100-023-00897-7&partnerID=40&md5=bc7d1248e4433d29236aa0b11c6c28b6","Economists have conducted research on several empirical phenomena regarding the behavior of individual investors, such as how their emotions and opinions influence their decisions. All those emotions and opinions are described by the word Sentiment. In finance, stochastic changes might occur according to investors sentiment levels. In this study, our main goal is to apply several operational research techniques and analyze these techniques’ accurance. Firstly, we represent the mutual effects between some financial process and investors sentiment with multivariate adaptive regression splines (MARS) model. Furthermore, we consider to extend this model by using distinct data mining techniques and compare the gain in accuracy and computational time with its strong alternatives applied in the analyses of the financial data. Hence, the goal of this study is to compare the forecasting performance of sentiment index by using two-stage MARS-NN (neural network), MARS-RF (random forest), RF-MARS, RF-NN, NN-MARS, and NN-RF hybrid models. Furthermore, we aim to classify the peoples’ feelings about economy according to their confidence levels. Moreover, to forecast the underlying state change of the consumer confidence index (CCI) and to observe the relationship with some macroeconomic data (CPI, GDP and currency rate) at a monthly interval, we apply hidden Markov model (HMM). The aim is to detect the switch between these states and to define a path of these states. We also aim to use volatility models for mainly sentiment index, consumer confidence index, and other indices so that we can get better forecasting results from those datasets. © 2024, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Consumer confidence index; HMM; Investor sentiment; Machine learning; Operational research; Sentiment index; Volatility model","Data mining; Economics; Forecasting; Investments; Machine learning; Stochastic systems; Confidence indices; Consumer confidence index; Hidden-Markov models; Investor's sentiments; Machine-learning; Multivariate adaptive regression splines; Operational research; Optimal model; Sentiment index; Volatility modeling; Hidden Markov models","Article","Article in press","","Scopus","2-s2.0-85181652228"
"dos Santos Gularte A.P.; Filho D.G.G.; de Oliveira Torres G.; da Silva T.C.N.; Curtis V.V.","dos Santos Gularte, Ana Paula (58341163800); Filho, Danusio Gadelha Guimarães (58773175200); de Oliveira Torres, Gabriel (57844721000); da Silva, Thiago Carvalho Nunes (58772595200); Curtis, Vitor Venceslau (56800330100)","58341163800; 58773175200; 57844721000; 58772595200; 56800330100","Machine Learning-Based Time Series Prediction at Brazilian Stocks Exchange","2023","Computational Economics","","","","","","","1","10.1007/s10614-023-10529-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180190379&doi=10.1007%2fs10614-023-10529-6&partnerID=40&md5=377b830da8daae1c873cd415fed53eba","This study proposes a novel method for forecasting the returns of assets comprising the Ibovespa from January 1, 2016, to December 30, 2020, by integrating machine learning algorithms-Gradient Boosting Machine, k-Nearest Neighbor, and Bayesian Regularized Neural Networks. Employing an ensemble strategy with diverse data modeling approaches, the method includes a pre-processing stage for variable selection, ranking their importance using statistical techniques such as OneR, Information Gain, and Chi-Square. This approach aims to overcome common challenges such as overfitting, high dimensionality, and computational efficiency, thus enhancing the robustness of the machine learning model and reducing susceptibility to biases and fluctuations. Empirical results demonstrate that, compared to the ARIMA model, the machine learning algorithm shows superior performance in forecast error and forecast hit rate and precision (R2, Willmott, and Kurtosis). Furthermore, the results suggest that the proposed algorithm can significantly improve predictive precision when applied to the ARIMA model and generalized to various datasets that include various markets and assets. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Ensemble; Financial time series; Hybrid intelligent algorithm; Machine learning; Prediction","","Article","Article in press","","Scopus","2-s2.0-85180190379"
"Wu Z.; Wang M.; Lan T.; Zhang A.","Wu, Zhenfeng (57290944400); Wang, Mengmeng (57218401807); Lan, Tian (57345422000); Zhang, Anyuan (58479145700)","57290944400; 57218401807; 57345422000; 58479145700","GHM-FKNN: A generalized Heronian mean based fuzzy k-nearest neighbor classifier for the stock trend prediction","2023","High Technology Letters","29","2","","122","129","7","0","10.3772/j.issn.1006-6748.2023.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164298849&doi=10.3772%2fj.issn.1006-6748.2023.02.002&partnerID=40&md5=2b8c04bf07399bdabccb8e35b3a24aed","Stock trend prediction is a challenging problem because it involves many variables. Aiming at the problem that some existing machine learning techniques, such as random forest (RF), probabilistic random forest (PRF), k-nearest neighbor (KNN), and fuzzy KNN (FKNN), have difficulty in accurately predicting the stock trend (uptrend or downtrend) for a given date, a generalized Heronian mean (GHM) based FKNN predictor named GHM-FKNN was proposed. GHM-FKNN combines GHM aggregation function with the ideas of the classical FKNN approach. After evaluation, the comparison results elucidated that GHM-FKNN outperformed the other best existing methods RF, PRF, KNN and FKNN on independent test datasets corresponding to three stocks, namely AAPL, AMZN and NFLX. Compared with RF, PRF, KNN and FKNN, GHM-FKNN achieved the best performance with accuracy of 62. 37% for AAPL, 58. 25% for AMZN, and 64. 10% for NFLX. © 2023 Inst. of Scientific and Technical Information of China. All rights reserved.","fuzzy k-nearest neighbor (FKNN); Heronian mean; stock trend prediction","Forecasting; Learning systems; Motion compensation; Aggregation functions; Comparison result; Fuzzy k-near neighbor; Fuzzy K-nearest neighbor classifier; Heronian means; Machine learning techniques; Nearest-neighbor approaches; Probabilistics; Random forests; Stock trend prediction; Nearest neighbor search","Article","Final","","Scopus","2-s2.0-85164298849"
"Friday I.K.; Pati S.P.; Mishra D.; Mallick P.K.; Kumar S.","Friday, Ibanga Kpereobong (57730957300); Pati, Sarada Prasanna (55626430300); Mishra, Debahuti (35070028500); Mallick, Pradeep Kumar (56441104200); Kumar, Sachin (57199513131)","57730957300; 55626430300; 35070028500; 56441104200; 57199513131","CAGTRADE: Predicting Stock Market Price Movement with a CNN-Attention-GRU Model","2024","Asia-Pacific Financial Markets","","","","","","","0","10.1007/s10690-024-09463-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196002596&doi=10.1007%2fs10690-024-09463-w&partnerID=40&md5=1cada1950685961a8dc03e846231a075","Accurately predicting market direction is crucial for informed trading decisions to buy or sell stocks. This study proposes a deep learning based hybrid approach combining convolutional neural network (CNN), attention mechanism (AM), and gated recurrent unit (GRU) to predict short-term market trends (1 day, 3 days, 7 days, 10 days) across different stock indices (BSE, HSI, IXIC, NIFTY, N225, SSE). The architecture dynamically weights the input sequence with the AM model, captures local patterns through CNN and effectively models long-term dependencies with GRU thus aiming to accurately classify either ""buy"" or ""sell"" positions of stocks. The model is assessed using classification and financial evaluation metrics involving accuracy, precision, recall, f1-score, annualized returns, maximum drawdown, and return on investment. It outperforms benchmark models, and different technical indicators including average directional index, rate of change, moving average convergence divergence, and the buy-and-hold strategy, demonstrating its effectiveness in various market conditions. The proposed model achieves an average accuracy of 98% in predicting the 1 day-ahead direction, and an average accuracy of 88.53% across all prediction intervals. The model was also validated using the wilcoxon signed rank test that further supported its significance over the benchmark models. The CAG model presents a comprehensive and intuitive approach to stock market trend prediction, with potential applications in real-world asset decision-making. © The Author(s), under exclusive licence to Springer Japan KK, part of Springer Nature 2024.","Attention mechanism (AM); Convolutional neural network (CNN); Deep learning (DL); Gated recurrent unit (GRU); Imbalanced dataset; Stock market trend prediction","","Article","Article in press","","Scopus","2-s2.0-85196002596"
"Horenko I.; Vecchi E.; Kardoš J.; Wächter A.; Schenk O.; O'Kane T.; Gagliardini P.; Gerber S.","Horenko, Illia (6506963918); Vecchi, Edoardo (57269717000); Kardoš, Juraj (57218249033); Wächter, Andreas (7004014085); Schenk, Olaf (6701544373); O'Kane, Terence (6602611209); Gagliardini, Patrick (57203702320); Gerber, Susanne (24176550700)","6506963918; 57269717000; 57218249033; 7004014085; 6701544373; 6602611209; 57203702320; 24176550700","On cheap entropy-sparsified regression learning","2023","Proceedings of the National Academy of Sciences of the United States of America","120","1","e2214972120","","","","6","10.1073/pnas.2214972120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145132109&doi=10.1073%2fpnas.2214972120&partnerID=40&md5=96488961e2490acc8f9484c416922be9","Regression learning is one of the long-standing problems in statistics, machine learning, and deep learning (DL). We show that writing this problem as a probabilistic expectation over (unknown) feature probabilities, increasing the number of unknown parameters and seemingly making the problem more complex-actually leads to a simplification, allowing to incorporate the physical principle of entropy maximization. It helps decompose a very general setting of this learning problem (including discretization, feature selection, and learning multiple piece-wise linear regressions) into an iterative sequence of simple substeps, which are either analytically solvable or cheaply computable through an efficient second-order numerical solver with a sublinear cost scaling. This leads to the computationally cheap and robust non- DL second-order Sparse Probabilistic Approximation for Regression Task Analysis (SPARTAn) algorithm, that can be efficiently applied to problems with millions of feature dimensions on a commodity laptop, when the state-of-the-art learning tools would require supercomputers. SPARTAn is compared to a range of commonly used regression learning tools on synthetic problems and on the prediction of the El Niño Southern Oscillation, the dominant interannual mode of tropical climate variability. The obtained SPARTAn learners provide more predictive, sparse, and physically explainable data descriptions, clearly discerning the important role of ocean temperature variability at the thermocline in the equatorial Pacific. SPARTAn provides an easily interpretable description of the timescales by which these thermocline temperature features evolve and eventually express at the surface, thereby enabling enhanced predictability of the key drivers of the interannual climate.  © 2022 the Author(s).","climate prediction; entropy; numerics; supervised learning","Algorithms; El Nino-Southern Oscillation; Entropy; Temperature; Tropical Climate; Article; climate change; deep learning; El Nino; entropy; learning algorithm; mathematical computing; prediction; regression learning; sea; Sparse Probabilistic Approximation for Regression Task Analysis; statistical analysis; temperature measurement; thermocline; tropic climate; algorithm; El Nino; entropy; temperature; tropic climate","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85145132109"
"Zhu W.; Dai W.; Tang C.; Zhou G.; Liu Z.; Zhao Y.","Zhu, Wenke (59280468900); Dai, Weisi (58951343500); Tang, Chunling (58899762300); Zhou, Guoxiong (7403685922); Liu, Zewei (58951343400); Zhao, Yunjing (59254307800)","59280468900; 58951343500; 58899762300; 7403685922; 58951343400; 59254307800","PMANet: a time series forecasting model for Chinese stock price prediction","2024","Scientific Reports","14","1","18351","","","","0","10.1038/s41598-024-69303-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200910296&doi=10.1038%2fs41598-024-69303-9&partnerID=40&md5=29a88e19d761afbe98116bfb3dd004c3","Forecasting stock movements is a crucial research endeavor in finance, aiding traders in making informed decisions for enhanced profitability. Utilizing actual stock prices and correlating factors from the Wind platform presents a potent yet intricate forecasting approach. While previous methodologies have explored this avenue, they encounter challenges including limited comprehension of interrelations among stock data elements, diminished accuracy in extensive series, and struggles with anomaly points. This paper introduces an advanced hybrid model for stock price prediction, termed PMANet. PMANet is founded on Multi-scale Timing Feature Attention, amalgamating Multi-scale Timing Feature Convolution and Ant Particle Swarm Optimization. The model elevates the understanding of dependencies and interrelations within stock data sequences through Probabilistic Positional Attention. Furthermore, the Encoder incorporates Multi-scale Timing Feature Convolution, augmenting the model's capacity to discern multi-scale and significant features while adeptly managing lengthy input sequences. Additionally, the model's proficiency in addressing anomaly points in stock sequences is enhanced by substituting the optimizer with Ant Particle Swarm Optimization. To ascertain the model’s efficacy and applicability, we conducted an empirical study using stocks from four pivotal industries in China. The experimental outcomes demonstrate that PMANet is both feasible and versatile in its predictive capability, yielding forecasts closely aligned with actual values, thereby fulfilling application requirements more effectively. © The Author(s) 2024.","Deep learning; Informer; Stock price prediction; Time series forecasting model","article; Chinese; controlled study; deep learning; empiricism; forecasting; human; particle swarm optimization; prediction; predictive model; price; time series analysis; wind","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85200910296"
"Li J.; Chen W.; Zhou Z.; Yang J.; Zeng D.","Li, Jiacheng (58951472300); Chen, Wei (58459454800); Zhou, Zhiheng (24924109600); Yang, Junmei (16302434000); Zeng, Delu (15057229900)","58951472300; 58459454800; 24924109600; 16302434000; 15057229900","DeepAR-Attention probabilistic prediction for stock price series","2024","Neural Computing and Applications","36","25","","15389","15406","17","0","10.1007/s00521-024-09916-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192886886&doi=10.1007%2fs00521-024-09916-3&partnerID=40&md5=ea34f6e7f10b1c9d0023950a55769fea","Stock price prediction is a significant research domain, intersecting statistics, finance, and economics. Accurately forecasting stock price trends has always been a focal point for many researchers. However, traditional statistical methods for time series prediction still lack accuracy. The existing deep learning-based methods for stock price prediction have significantly enhanced the accuracy of predicting individual stock prices. However, they are not effective in forecasting the probability range of future stock price trends. In this paper, to address these limitations, we propose a novel DeepAR model based on the attention mechanism (DeepARA) for both single-point and probabilistic predictions of stock prices. This enhances the accuracy and flexibility of stock price forecasting. Although the attention mechanism was initially developed for natural language processing, it has now found applications in time series forecasting, including the dynamics of the stock market. Attention allocates different weights to time points of varying importance, thereby enhancing the model’s ability to capture fundamental market dynamics. We conducted multiple experiments in the Chinese stock market, involving 30 stocks across the top six sectors. Compared with baseline models, the DeepARA model demonstrates superior predictive capabilities. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Attention mechanism; Deep learning; DeepAR; Recurrent neural networks; Stock prediction","Commerce; Costs; Financial markets; Forecasting; Learning systems; Natural language processing systems; Time series; Attention mechanisms; Deep learning; Deepar; Forecasting stock prices; Price trends; Probabilistic prediction; Research domains; Stock predictions; Stock price; Stock price prediction; Recurrent neural networks","Article","Final","","Scopus","2-s2.0-85192886886"
"Wang Y.; Lin T.","Wang, Yan (58855581200); Lin, Tong (58554350900)","58855581200; 58554350900","A Novel Deterministic Probabilistic Forecasting Framework for Gold Price with a New Pandemic Index Based on Quantile Regression Deep Learning and Multi-Objective Optimization","2024","Mathematics","12","1","29","","","","0","10.3390/math12010029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182197492&doi=10.3390%2fmath12010029&partnerID=40&md5=b1d44232310d252c8ac6752f017da4e4","The significance of precise gold price forecasting is accentuated by its financial attributes, mirroring global economic conditions, market uncertainties, and investor risk aversion. However, predicting the gold price is challenging due to its inherent volatility, influenced by multiple factors, such as COVID-19, financial crises, geopolitical issues, and fluctuations in other metals and energy prices. These complexities often lead to non-stationary time series, rendering traditional time series modeling methods inadequate. Our paper presents a multi-objective optimization algorithm that refines the interval prediction framework with quantile regression deep learning in response to this issue. This framework comprehensively responds to gold’s financial market dynamics and uncertainties with a screening process of various factors, including pandemic-related indices, geopolitical indices, the US dollar index, and prices of various commodities. The quantile regression deep-learning models optimized by multi-objective optimization algorithms deliver robust, interpretable, and highly accurate predictions for handling non-linear relationships and complex data structures and enhance the overall predictive performance. The results demonstrate that the QRBiLSTM model, optimized using the MOALO algorithm, delivers excellent forecasting performance. The composite indicator AIS reaches −15.6240 and −11.5581 at 90% and 95% confidence levels, respectively. This underscores the model’s high forecasting accuracy and its potential to provide valuable insights for assessing future trends in gold prices. The deterministic and probabilistic forecasting framework for gold prices captures the market dynamics with the new pandemic index and comprehensively sets a new benchmark for predictive modeling in volatile market commodities like gold. © 2023 by the authors.","feature screening; gold price forecasting; multi-objective optimization algorithms; probabilistic prediction models; quantile regression","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85182197492"
"Çetin N.","Çetin, Necati (57204595476)","57204595476","Prediction of moisture ratio and drying rate of orange slices using machine learning approaches","2022","Journal of Food Processing and Preservation","46","11","e17011","","","","13","10.1111/jfpp.17011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136473757&doi=10.1111%2fjfpp.17011&partnerID=40&md5=d667afd18f39631e2dcb7e0045253acc","In order to improve the drying characteristics and to optimization of drying conditions, machine learning (ML) and response surface methodology (RSM) were applied in air-convective drying of orange slices (Washington Navel and Valencia cultivars). Interactions of temperature (T, 50–60°C), sample thickness (ST, 5–9 mm), and drying time (DT, 8–10 h) like independent variables with specific moisture extraction rate, effective moisture diffusivity, energy efficiency, and energy consumption like dependent variables were determined. In addition, five machine learning algorithms (random forest-RF; artificial neural network-ANN; gaussian processes-GP support vector regression-SVR, and k-nearest neighbors-kNN) were used to predict moisture ratio and drying rate. In Washington Navel and Valencia cultivars, the greatest correlation coefficients (R) for prediction of moisture ratio were obtained k-NN algorithm with values of 0.9944 and 0.9898, respectively. Also, drying rate prediction results showed that k-NN achieved higher R with values of 1.0000 and 0.9954, respectively. Experimental findings were adapted by a second-degree polynomial model through variance analysis to identify model fitness and optimal drying conditions. Combined desirability value was calculated as 0.8812 for Valencia and 0.8564 for Washington. Increasing energy consumption was encountered with increasing drying time and sample thickness. Besides, energy consumption had a decreasing trend at higher temperatures. Practical applications: Machine learning models are novelty and rapid methods that have been successfully utilized to solve such challenges agricultural commodities. Drying is common process to preserve the food quality. This study provides optimum conditions for drying orange slices in single unit air-convective dryer and improves the effect of drying system on some drying characteristics energy aspects. In addition, this study can be able to present a technical knowledge for orange slice drying and related equipment design. © 2022 Wiley Periodicals LLC.","","Citrus fruits; Decision trees; Drying; Energy efficiency; Forecasting; Learning algorithms; Machine learning; Moisture; Nearest neighbor search; Neural networks; Plants (botany); Drying characteristics; Drying condition; Drying rates; Drying time; Energy-consumption; Machine learning approaches; Moisture ratios; Sample thickness; Valencia; Washington; Energy utilization","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85136473757"
"Höcht S.; Schoutens W.; Verschueren E.","Höcht, Stephan (24821855800); Schoutens, Wim (6603008020); Verschueren, Eva (57338013100)","24821855800; 6603008020; 57338013100","On the pricing of capped volatility swaps using machine learning techniques","2024","Quantitative Finance","","","","","","","0","10.1080/14697688.2024.2305643","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184441353&doi=10.1080%2f14697688.2024.2305643&partnerID=40&md5=e165aa1a69cb78aa16322000b1aa46fe","A capped volatility swap is a forward contract on an asset's capped, annualized, realized volatility, over a predetermined period of time. This paper presents data-driven machine learning techniques for pricing such capped volatility swaps, using unique data sets comprising both the strike price of contracts at initiation and the daily observed prices of running contracts. Additionally, the developed model can serve as a validation tool for external volatility swap prices, flagging prices that deviate significantly from the estimated value. In order to predict the capped, future, realized volatility, we explore distributional information on the underlying asset, specifically by extracting information from the implied volatilities and market-implied moments of the asset. The pricing performance of tree-based machine learning techniques and a Gaussian process regression model is evaluated in a validation setting tailored to the use of financial data. © 2024 Informa UK Limited, trading as Taylor & Francis Group.","Capped volatility swaps; Gaussian process regression; Implied volatility; Market-implied moments; Pricing; Tree-based machine learning","","Article","Article in press","","Scopus","2-s2.0-85184441353"
"Parum F.; Dharmasena S.","Parum, Faith (57224367689); Dharmasena, Senarath (37107378800)","57224367689; 37107378800","Food Price Inflation in the United States as a Complex Dynamic Economic System","2024","Journal of Agricultural and Food Industrial Organization","","","","","","","0","10.1515/jafio-2023-0043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193907057&doi=10.1515%2fjafio-2023-0043&partnerID=40&md5=2e7467cc96fd41c4ba8e70707126c0ce","The issue of volatile food prices is a consistent problem for American consumers, as rising prices make it challenging to afford nutritious food that meets dietary standards. Various complex factors influence this price volatility, including economic conditions, weather patterns, global trade, energy prices, and more. Notably, the impact of food price increases is not equal for everyone. Low-income individuals and those in rural areas are disproportionately affected. A comprehensive understanding of the driving factors is essential to tackle this issue effectively. We employ advanced time-series techniques such as Vector Error Correction Models (VECM) and modern causal inference methods such as probabilistic graphical models implemented via machine learning and artificial intelligence approaches on monthly data from 2000 to 2021 to investigate the U.S. food price inflation issue. These methods help unravel the intricate dynamics among key variables driving food price inflation. The study aims to achieve several objectives. It intends to (1) clarify how factors influencing food price inflation in the U.S. change over time using VECM models, (2) establish causal relationships among interconnected variables to develop probabilistic graphical models using innovative search algorithms, and (3) create and validate forecasts related to U.S. food price inflation. The end goal is to provide actionable insights for policy design. Results show that food price inflation is heavily tied to commodity pricing and pricing for medical services. Additionally, historical decompositions for COVID-19 show ties between food price inflation and energy inflation. © 2024 Walter de Gruyter GmbH, Berlin/Boston 2024.","directed acyclic graphs; food price inflation; innovation accounting; time-series analysis; vector error correction model","","Article","Article in press","","Scopus","2-s2.0-85193907057"
"Khattak B.H.A.; Shafi I.; Khan A.S.; Flores E.S.; Lara R.G.; Samad M.A.; Ashraf I.","Khattak, Bilal Hassan Ahmed (58699546400); Shafi, Imran (23393559800); Khan, Abdul Saboor (58699546500); Flores, Emmanuel Soriano (57743061600); Lara, Roberto Garcia (58700175700); Samad, Md. Abdus (57220375948); Ashraf, Imran (57195478761)","58699546400; 23393559800; 58699546500; 57743061600; 58700175700; 57220375948; 57195478761","A Systematic Survey of AI Models in Financial Market Forecasting for Profitability Analysis","2023","IEEE Access","11","","","125359","125380","21","4","10.1109/ACCESS.2023.3330156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177053812&doi=10.1109%2fACCESS.2023.3330156&partnerID=40&md5=5ee91d92c74f586543015092c0000768","Artificial intelligence (AI)-based models have emerged as powerful tools in financial markets, capable of reducing investment risks and aiding in selecting highly profitable stocks by achieving precise predictions. This holds immense value for investors, as it empowers them to make data-driven decisions. Identifying current and future trends in multi-class forecasting techniques employed within financial markets, particularly profitability analysis as an evaluation metric is important. The review focuses on examining stud-ies conducted between 2018 and 2023, sourced from three prominent academic databases. A meticulous three-stage approach was employed, encompassing the systematic planning, conduct, and analysis of the se-lected studies. Specifically, the analysis emphasizes technical assessment, profitability analysis, hybrid mod-eling, and the type of results generated by models. Articles were shortlisted based on inclusion and exclusion criteria, while a rigorous quality assessment through ten quality criteria questions, utilizing a Likert-type scale was employed to ensure methodological robustness. We observed that ensemble and hybrid models with long short-term memory (LSTM) and support vector machines (SVM) are being more adopted for financial trends and price prediction. Moreover, hybrid models employing AI algorithms for feature engineering have great potential at par with ensemble techniques. Most studies only employ performance metrics and lack utilization of profitability metrics or investment or trading strategy (simulated or real-time). Similarly, research on multi-class or output is severely lacking in financial forecasting and can be a good avenue for future research.  © 2013 IEEE.","Artificial intelligence; convolution neural network; cryptocurrency; deep learning; financial forecasting; stock market analysis","Convolution; Electronic trading; Financial markets; Forecasting; Hidden Markov models; Long short-term memory; Profitability; Risk assessment; Support vector machines; Convolution neural network; Convolutional neural network; Deep learning; Financial forecasting; Financial managements; Hidden-Markov models; Predictive models; Profitability analysis; Stock market analysis; Investments","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85177053812"
"Paes L.M.; Suresh A.T.; Beutel A.; Calmon F.P.; Beirami A.","Paes, Lucas Monteiro (58367454900); Suresh, Ananda Theertha (59128494700); Beutel, Alex (36701124200); Calmon, Flavio P. (56102780400); Beirami, Ahmad (37012997600)","58367454900; 59128494700; 36701124200; 56102780400; 37012997600","Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing","2024","IEEE Journal on Selected Areas in Information Theory","","","","1","1","0","0","10.1109/JSAIT.2024.3397741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192685762&doi=10.1109%2fJSAIT.2024.3397741&partnerID=40&md5=386296b8b1ced69a62291b27ec0f1366","Machine learning (ML) models used in prediction and classification tasks may display performance disparities across population groups determined by sensitive attributes (e.g., race, sex, age). We consider the problem of evaluating the performance of a fixed ML model across population groups defined by multiple sensitive attributes (e.g., race and sex and age). Here, the sample complexity for estimating the worst-case performance gap across groups (e.g., the largest difference in error rates) increases exponentially with the number of group-denoting sensitive attributes. To address this issue, we propose an approach to test for performance disparities based on Conditional Value-at-Risk (CVaR). By allowing a small probabilistic slack on the groups over which a model has approximately equal performance, we show that the sample complexity required for discovering performance violations is reduced exponentially to be at most upper bounded by the square root of the number of groups. As a byproduct of our analysis, when the groups are weighted by a specific prior distribution, we show that R&#x00E9;nyi entropy of order 2/3 of the prior distribution captures the sample complexity of the proposed CVaR test algorithm. Finally, we also show that there exists a non-i.i.d. data collection strategy that results in a sample complexity independent of the number of groups. IEEE","Complexity theory; Entropy; hypothesis testing; Information theory; intersectional fairness; intersectionality; Measurement; multi-group fairness; Sociology; Statistics; Testing","Information theory; Population statistics; Statistical tests; Value engineering; Complexity theory; Conditional Value-at-Risk; Hypothesis testing; Intersectional fairness; Intersectionality; Machine learning models; Multi-group; Multi-group fairness; Performance; Sample complexity; Entropy","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85192685762"
"Guo H.; Wang J.; Li Z.; Lu H.; Zhang L.","Guo, Honggang (57223978577); Wang, Jianzhou (56380147600); Li, Zhiwu (55588010000); Lu, Haiyan (57189905647); Zhang, Linyue (57224531039)","57223978577; 56380147600; 55588010000; 57189905647; 57224531039","A non-ferrous metal price ensemble prediction system based on innovative combined kernel extreme learning machine and chaos theory","2022","Resources Policy","79","","102975","","","","8","10.1016/j.resourpol.2022.102975","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138454856&doi=10.1016%2fj.resourpol.2022.102975&partnerID=40&md5=9eda8d06da968918188dca9fa1ded097","Non-ferrous metal futures, as a significant component of the financial market, are complementary and coordinated with other financial elements, which has been a key area of research in recent years. However, given the apparent volatility and chaotic nature of the non-ferrous metal price sequence, forecasting it remains a difficult challenge. While prior research employed a variety of methodologies to forecast metal prices, they overlooked the critical role of chaos feature analysis and the necessity of error analysis, severely limiting prediction accuracy. This paper designs a novel non-ferrous metal price ensemble prediction system that incorporates data decomposition, phase space reconstruction, multi-objective optimization, point prediction, and interval prediction. A combined kernel extreme learning machine based on the improved multi-objective lion swarm optimization algorithm is developed and theoretically explained to improve prediction accuracy and reliability. Additionally, the appropriate creation of the prediction interval based on the best-fit distribution of the point prediction error enabled the examination of various levels of uncertainty. In an empirical experiment using copper and aluminum prices from the London Metal Exchange, the proposed system demonstrated benefits in point and interval prediction, providing decision makers with useful prediction references. © 2022 Elsevier Ltd","Combined kernel extreme learning machine; Machine learning; Multi-objective optimization algorithm; Non-ferrous metal price prediction; Phase space reconstruction","Chaos theory; Costs; Decision making; Knowledge acquisition; Learning algorithms; Machine learning; Metals; Multiobjective optimization; Phase space methods; Combined kernel extreme learning machine; Combined kernels; Learning machines; Machine-learning; Multi-objective optimization algorithm; Multi-objectives optimization; Non-ferrous metal price prediction; Non-ferrous metals prices; Optimization algorithms; Phase space reconstruction; Phase spaces; Price prediction; Space reconstruction; algorithm; chaos theory; ensemble forecasting; innovation; machine learning; metals industry; price determination; Forecasting","Article","Final","","Scopus","2-s2.0-85138454856"
"Viet N.T.; Kravets A.","Viet, Nguyen Thanh (57219697357); Kravets, Alla (57200583694)","57219697357; 57200583694","A Novel Method for Predicting Technology Trends Based on Processing Multiple Data Sources","2023","Advances in Systems Science and Applications","23","1","","69","90","21","1","10.25728/assa.2023.23.01.1251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158848764&doi=10.25728%2fassa.2023.23.01.1251&partnerID=40&md5=4b815ffdf12a946f4c4c2f022eccf632","In order to gain competing capability in conditions of quickly scientific changes, it is crucial to track the evolution of existing technologies and to explore promising and emerging technologies. Moreover, numerous previous studies showed that sudden changes in R&D and patents are actually correlated with great variations in the market profit of firms. For this reason, if stock prices of an enterprise keep uptrend, then the technologies developed by considered one will be likely to become promising innovations in future. In this paper, we proposed a method to predict technology trends based on processing multiple data sources by mining Web news, forecasting stock price trends of high-tech companies, and patent clustering analysis. Different from other studies, our proposed method promotes an idea of predicting technology trends by forecasting stock price trend using univariate and multivariate data preparation approaches, with the utilization of Bayesian optimization for exploring best hyperparameters of machine/deep learning models, also a new method for patent analysis. Besides, a program system was created for analyzing word burst detection, predicting trend of stock prices, and analyzing patent applications. After collecting patents of Samsung Electronics Co Ltd, as a case study, clustering analysis is implemented on extracted noun phrases to explore technology trends developed by the company. These technology trends have recently been confirmed by domain experts in their corresponding published articles. The obtained forecast precision is about 93.8%, which proves that the proposed method gains positive reliability. © 2023 ASSA.","Bayesian optimization; clustering analysis; deep learning; extraction; machine learning; patent analysis; Samsung; stock price; technology forecast; Web news","","Article","Final","","Scopus","2-s2.0-85158848764"
"Rahmani E.; Khatami M.; Stephens E.","Rahmani, Elham (56638193700); Khatami, Mohammad (57023519900); Stephens, Emma (36835728800)","56638193700; 57023519900; 36835728800","Using Probabilistic Machine Learning Methods to Improve Beef Cattle Price Modeling and Promote Beef Production Efficiency and Sustainability in Canada","2024","Sustainability (Switzerland) ","16","5","1789","","","","2","10.3390/su16051789","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187880680&doi=10.3390%2fsu16051789&partnerID=40&md5=90451b9bb3e7c8c4f7d7d5f4e9172ada","Accurate agricultural commodity price models enable efficient allocation of limited natural resources, leading to improved sustainability in agriculture. Because of climate change, price volatility and uncertainty in the sector are expected to increase in the future, increasing the need for improved price modeling. With the emergence of machine learning (ML) algorithms, novel tools are now available to enhance the modeling of agricultural commodity prices. This research explores both univariate and multivariate ML techniques to perform probabilistic price prediction modeling for the Canadian beef industry, taking into account beef production, commodity markets, and international trade features to enhance accuracy. We model Alberta fed steer prices using three multivariate ML algorithms (support vector regression (SVR), random forest (RF), and Adaboost (AB)) and three univariate ML algorithms (autoregressive integrated moving average (ARIMA), seasonal ARIMA (SARIMA), and the seasonal autoregressive integrated moving average with exogenous factors (SARIMAX)). We apply these models to monthly fed steer price data between January 2005 and September 2023 and compare predicted prices with observed prices using several validation metrics. The outcomes indicate that both random forest (RF) and Adaboost (AB) show superior overall performance in accurately predicting Alberta fed steer prices in comparison to other algorithms. To better account for the variance of the best model performance, we subsequently adopted a probabilistic approach by considering uncertainty in our best-selected ML model. The beef industry can use these improved price models to minimize resource waste and inefficiency in the sector and improve the long-term sustainability prospects for beef producers in Canada. © 2024.","Adaboost; ARIMA; Canadian Cattle Price Modeling; machine learning; multivariate and univariate modeling; probabilistic modeling; random forest; SARIMA; SARIMAX; support vector regression","Alberta; Canada; cattle; commodity price; international trade; machine learning; multivariate analysis; prediction; price dynamics; probability; regression analysis; support vector machine; sustainability","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85187880680"
"Mussoi Almeida L.; Müller F.M.; Perlin M.S.","Mussoi Almeida, Lucas (58964981200); Müller, Fernanda Maria (57218322292); Perlin, Marcelo Scherer (31767585500)","58964981200; 57218322292; 31767585500","Risk Forecasting Comparisons in Decentralized Finance: An Approach in Constant Product Market Makers","2024","Computational Economics","","","","","","","0","10.1007/s10614-024-10585-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189147277&doi=10.1007%2fs10614-024-10585-6&partnerID=40&md5=56bbd12a323ce58ba563afc99221070c","This study leverages decentralized liquidity pool data sourced from UNISWAP-V2 to forecast Value-at-Risk (VaR) and Expected Shortfall (ES) employing the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model with varied error distributions and the deep learning probabilistic forecasting algorithm known as DeepAR. Performance evaluations of these distinct forecasting methodologies are conducted using an appropriate loss function. Results indicate that the GARCH model with a normal distribution consistently outperforms other models, particularly when forecasting VaR. Conversely, the DeepAR model exhibits limited effectiveness in VaR forecasting across all scenarios, except for liquidity pools involving at least one stablecoin. However, it demonstrates greater reliability in predicting most ES risk measures and associated data. Our findings underscore that in a subset of the data, providing liquidity to pairs involving at least one stablecoin entails statistically significant lower risk compared to holding an equivalent amount of crypto assets. Furthermore, this research contributes to the advancement of novel risk management tools and strategies tailored for liquidity providers. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Cryptocurrency; DeFi; Liquidity pool; Risk forecasting","","Article","Article in press","","Scopus","2-s2.0-85189147277"
"Shi S.; Yu J.; Zhang C.","Shi, Shuping (54909151400); Yu, Jun (7405530121); Zhang, Chen (58870463700)","54909151400; 7405530121; 58870463700","Fractional gaussian noise: Spectral density and estimation methods","2024","Journal of Time Series Analysis","","","","","","","0","10.1111/jtsa.12750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193700844&doi=10.1111%2fjtsa.12750&partnerID=40&md5=9b3019983e0a04fef2d5be8693350e2c","The fractional Brownian motion (fBm) process, governed by a fractional parameter (Formula presented.), is a continuous-time Gaussian process with its increment being the fractional Gaussian noise (fGn). This article first provides a computationally feasible expression for the spectral density of fGn. This expression enables us to assess the accuracy of a range of approximation methods, including the truncation method, Paxson's approximation, and the Taylor series expansion at the near-zero frequency. Next, we conduct an extensive Monte Carlo study comparing the finite sample performance and computational cost of alternative estimation methods for (Formula presented.) under the fGn specification. These methods include two semi-parametric methods (based on the Taylor series expansion), two versions of the Whittle method (utilising either the computationally feasible expression or Paxson's approximation of the spectral density), a time-domain maximum likelihood (ML) method (employing a recursive approach for its likelihood calculation), and a change-of-frequency method. Special attention is paid to highly anti-persistent processes with (Formula presented.) close to zero, which are of empirical relevance to financial volatility modelling. Considering the trade-off between statistical and computational efficiency, we recommend using either the Whittle ML method based on Paxson's approximation or the time-domain ML method. We model the log realized volatility dynamics of 40 financial assets in the US market from 2012 to 2019 with fBm. Although all estimation methods suggest rough volatility, the implied degree of roughness varies substantially with the estimation methods, highlighting the importance of understanding the finite sample performance of various estimation methods. © 2024 The Authors. Journal of Time Series Analysis published by John Wiley & Sons Ltd.","change-of-frequency; Fractional Brownian motion; fractional Gaussian noise; maximum likelihood; realised volatility; semi-parametric method; Whittle likelihood","","Article","Article in press","","Scopus","2-s2.0-85193700844"
"Li Y.; Chen L.; Sun C.; Liu G.; Chen C.; Zhang Y.","Li, Yi (58447921000); Chen, Lei (58973619800); Sun, Cuiping (57808388600); Liu, Guoxu (57208738932); Chen, Chunlei (55203918700); Zhang, Yonghui (57193323816)","58447921000; 58973619800; 57808388600; 57208738932; 55203918700; 57193323816","Accurate Stock Price Forecasting Based on Deep Learning and Hierarchical Frequency Decomposition","2024","IEEE Access","12","","","49878","49894","16","1","10.1109/ACCESS.2024.3384430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189618755&doi=10.1109%2fACCESS.2024.3384430&partnerID=40&md5=6cdb3660f9272bd59e7d0fb4e03d5896","The stock market is playing an increasingly important role in the global economy. Accurate stock price forecasting not only aids the government in predicting economic trends but also helps investors anticipate higher expected returns. Nevertheless, hurdles such as nonlinearity, complexity and high volatility make it a daunting task to predict stock prices. To address this issue, this study proposes a new hybrid model, termed Hierarchical Decomposition-based Forecasting Model (HDFM), to decompose and forecast stock prices in a hierarchical fashion. The model utilizes complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) for the initial decomposition of stock price time series. To enhance the predictive efficiency, sub-series with similar sample entropy from the decomposition were combined using the K-means clustering method. Through a thorough analysis, it was found that the first combined sub-series contained more high-frequency signals. Therefore, the first combined sub-series is subjected to a second decomposition with variational mode decomposition (VMD). Subsequently, the gated recurrent unit (GRU) model was used to individually predict each sub-series. The final results were obtained by merging the prediction outcomes. The proposed model was evaluated on three different stock markets. The experimental results show that the proposed model outperforms other forecasting methods across all stock indices. Moreover, ablation studies demonstrated the effectiveness of each component within the proposed model.  © 2013 IEEE.","clustering; deep learning; hierarchical decomposition; Stock price prediction","Cluster analysis; Clustering algorithms; Commerce; Costs; Deep learning; Electronic trading; Financial markets; Forecasting; Hidden Markov models; Investments; Time series analysis; Adaptation models; Auto regressive process; Clusterings; Deep learning; Hidden-Markov models; Hierarchical decompositions; Predictive models; Stock price prediction; Time-series analysis; Empirical mode decomposition","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189618755"
"Lahmiri S.","Lahmiri, Salim (39061577500)","39061577500","Fossil energy market price prediction by using machine learning with optimal hyper-parameters: A comparative study","2024","Resources Policy","92","","105008","","","","1","10.1016/j.resourpol.2024.105008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190730143&doi=10.1016%2fj.resourpol.2024.105008&partnerID=40&md5=d697ff29aef2801c3fd89506a2c5b584","Fossil energy markets are important commodities, and their price fluctuations impact worldwide economy and financial markets. Hence, it is essential to forecast the prices of fossil energy commodities. In this study, various machine learning systems are optimized by using Bayesian optimization method and implemented to forecast prices in 12 different fossil energy markets including crude oil, natural gas, propane, kerosene, gasoline, heating oil, and coal based on price information from all fossil energy markets. The optimized machine learning systems considered in modeling and simulations are Gaussian regression process, support vector regression, regression trees, k-nearest neighbor algorithm, and deep feedforward neural networks. The simulation results show that Gaussian regression process is the best system to forecast fossil energy markets. In addition, the deep learning feedforward neural networks system yields to stable forecasts. Furthermore, the prediction of the prices in natural gas, coal, and propane markets is a difficult task compared to the prediction of the prices in crude oil markets. The understanding of the effectiveness of machine learning systems in pricing different fossil energy markets can help international economic agents establish appropriate investment strategies. © 2024 Elsevier Ltd","Bayesian optimization; Deep feedforward neural networks; Fossil energy market price; Gaussian regression process; K-nearest neighbors; Machine learning; Regression trees; Support vector regression","Bayesian networks; Costs; Feedforward neural networks; Financial markets; Forecasting; Gaussian distribution; Investments; Learning algorithms; Learning systems; Long short-term memory; Natural gas; Regression analysis; Trees (mathematics); Bayesian optimization; Deep feedforward neural network; Energy markets; Fossil energy; Fossil energy market price; Gaussian regression; Gaussian regression process; K-near neighbor; Machine-learning; Market price; Nearest-neighbour; Regression trees; Support vector regressions; Bayesian analysis; comparative study; energy market; fossil fuel; Gaussian method; machine learning; numerical model; parameter estimation; price determination; price dynamics; Nearest neighbor search","Article","Final","","Scopus","2-s2.0-85190730143"
"Grudniewicz J.; Ślepaczuk R.","Grudniewicz, Jan (58528791700); Ślepaczuk, Robert (57188547619)","58528791700; 57188547619","Application of machine learning in algorithmic investment strategies on global stock markets","2023","Research in International Business and Finance","66","","102052","","","","4","10.1016/j.ribaf.2023.102052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167407541&doi=10.1016%2fj.ribaf.2023.102052&partnerID=40&md5=8d5dfdd070331bdc2bb2e8782aae75b0","The research undertakes the subject of machine learning based algorithmic investment strategies. Several technical analysis indicators were employed as inputs to machine learning models such as Neural Networks, K Nearest Neighbor, Regression Trees, Random Forests, Naïve Bayes classifiers, Bayesian Generalized Linear Models, and Support Vector Machines. Models were used to generate trading signals on WIG20, DAX, S&P500, and selected CEE indices in the period between 2002-01–01 and 2023–03–31. Strategies were compared with each other and with the benchmark buy-and-hold strategy in terms of achieved levels of risk and return. Sensitivity analysis was used to assess the quality of the estimation on independent subsets. The findings of the study showed that algorithmic strategies outperformed passive strategies in terms of risk-adjusted returns and that for the analyzed indices, Linear Support Vector Machine and Bayesian Generalized Linear Model were the best-performing models. The Linear Support Vector Machine was chosen as the model that, on average, produced the best results using a more thorough rank approach based on the outcomes for all examined models and indices. © 2023","Algorithmic investment strategies; Developed and emerging markets; Equity stock indices; Information ratio; Machine learning; Neural networks; Random forests; Regression trees; Support vector machine; Technical analysis","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85167407541"
"Sher T.; Rehman A.; Kim D.; Ihsan I.","Sher, Tahir (57926504600); Rehman, Abdul (57200894071); Kim, Dongsun (55742964600); Ihsan, Imran (58648779800)","57926504600; 57200894071; 55742964600; 58648779800","Exploiting Data Science for Measuring the Performance of Technology Stocks","2023","Computers, Materials and Continua","76","3","","2979","2995","16","0","10.32604/cmc.2023.036553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174419934&doi=10.32604%2fcmc.2023.036553&partnerID=40&md5=faa701f6c815fdda4ffdc6f2fb393601","The rise or fall of the stock markets directly affects investors’ interest and loyalty. Therefore, it is necessary to measure the performance of stocks in the market in advance to prevent our assets from suffering significant losses. In our proposed study, six supervised machine learning (ML) strategies and deep learning (DL) models with long short-term memory (LSTM) of data science was deployed for thorough analysis and measurement of the performance of the technology stocks. Under discussion are Apple Inc. (AAPL), Microsoft Corporation (MSFT), Broadcom Inc., Taiwan Semiconductor Manufacturing Company Limited (TSM), NVIDIA Corporation (NVDA), and Avigilon Corporation (AVGO). The datasets were taken from the Yahoo Finance API from 06-05-2005 to 06-05-2022 (seventeen years) with 4280 samples. As already noted, multiple studies have been performed to resolve this problem using linear regression, support vector machines, deep long short-term memory (LSTM), and many other models. In this research, the Hidden Markov Model (HMM) outperformed other employed machine learning ensembles, tree-based models, the ARIMA (Auto Regressive Integrated Moving Average) model, and long short-term memory with a robust mean accuracy score of 99.98. Other statistical analyses and measurements for machine learning ensemble algorithms, the Long Short-Term Model, and ARIMA were also carried out for further investigation of the performance of advanced models for forecasting time series data. Thus, the proposed research found the best model to be HMM, and LSTM was the second-best model that performed well in all aspects. A developed model will be highly recommended and helpful for early measurement of technology stock performance for investment or withdrawal based on the future stock rise or fall for creating smart environments. © 2023 Tech Science Press. All rights reserved.","data science; deep learning; Machine learning; smart environments; stock marketing; stocks movement","Brain; Commerce; Financial markets; Hidden Markov models; Investments; Learning systems; Semiconductor device manufacture; Support vector machines; Time series analysis; Best model; Deep learning; Hidden-Markov models; Machine-learning; Measurements of; Performance; Smart environment; Stock marketing; Stock movement; Supervised machine learning; Long short-term memory","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85174419934"
"Vuletić M.; Prenzel F.; Cucuringu M.","Vuletić, Milena (57473083100); Prenzel, Felix (57980467000); Cucuringu, Mihai (16644545900)","57473083100; 57980467000; 16644545900","Fin-GAN: forecasting and classifying financial time series via generative adversarial networks","2024","Quantitative Finance","24","2","","175","199","24","4","10.1080/14697688.2023.2299466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184220335&doi=10.1080%2f14697688.2023.2299466&partnerID=40&md5=92ce2360c48ef639eba15e342305951e","We investigate the use of Generative Adversarial Networks (GANs) for probabilistic forecasting of financial time series. To this end, we introduce a novel economics-driven loss function for the generator. This newly designed loss function renders GANs more suitable for a classification task, and places them into a supervised learning setting, whilst producing full conditional probability distributions of price returns given previous historical values. Our approach moves beyond the point estimates traditionally employed in the forecasting literature, and allows for uncertainty estimates. Numerical experiments on equity data showcase the effectiveness of our proposed methodology, which achieves higher Sharpe Ratios compared to classical supervised learning models, such as LSTMs and ARIMA. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Classification; Financial returns; GANs; Time series forecasting","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85184220335"
"Ting L.; Abd El-Raouf M.M.; Bakr M.E.; Alsahangiti A.M.","Ting, Lai (58569948100); Abd El-Raouf, M.M. (57211605899); Bakr, M.E. (57206727602); Alsahangiti, Arwa M. (58132196800)","58569948100; 57211605899; 57206727602; 58132196800","Analysis of bitcoin prices using a heavy-tailed version of Dagum distribution and machine learning methods","2023","Alexandria Engineering Journal","80","","","572","583","11","2","10.1016/j.aej.2023.08.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170421403&doi=10.1016%2fj.aej.2023.08.025&partnerID=40&md5=b2c70b742a372f1005e118c45035f647","Statistical modeling and forecasting are very important for decision-making in any field of life. This paper has two major objectives, namely, statistical modeling and forecasting of real phenomena. For covering the first aim (i.e., statistical modeling), we introduce a new probabilistic model. The new model is introduced by mixing the Dagum distribution with the weighted TX family approach. The proposed model is called the weighted TX Dagum distribution and possesses heavy-tailed characteristics. The new model is illustrated by analyzing real-life data related to Bitcoin prices. To cover the second aim (i.e., forecasting), we take into account six macroeconomic and financial indicators to investigate their impact on Bitcoin prices such as the Adaptive least absolute shrinkage and selection operator (Alasso), elastic net, and minimax concave penalty. After analyzing the data, it is found that Alasso and MCP have retained all the included predictors, except import, while Enet holds all the predictors. The root means square error and mean absolute error associated with MCP are lower than Alasso and Enet, which reveals that MCP fits the data very well as compared to rival methods. © 2023 The Author(s)","Bitcoin prices; Dagum distribution; Heavy-tailed characteristics; Machine learning and robust regression methods; Macroeconomic variables","Bitcoin; Costs; Decision making; Forecasting; Regression analysis; Bitcoin price; Dagum distribution; Heavy-tailed characteristics; Least absolute shrinkage and selection operators; Machine learning and robust regression method; Machine-learning; Macroeconomic variables; Regression method; Robust regressions; Statistic modeling; Machine learning","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85170421403"
"Akram T.; Ramakrishnan S.A.I.; Naveed M.","Akram, Tooba (57217619731); Ramakrishnan, Suresh A/I (56566080100); Naveed, Muhammad (55567966400)","57217619731; 56566080100; 55567966400","Prevalence of money laundering and terrorism financing through stock market: a comprehensive conceptual review paper","2023","Journal of Money Laundering Control","26","5","","1027","1044","17","3","10.1108/JMLC-06-2022-0094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138205931&doi=10.1108%2fJMLC-06-2022-0094&partnerID=40&md5=91e903100c903d166b34690da6b9f8c2","Purpose: This paper aims to provide a comprehensive conceptual framework and strong arguments with an intent to examine the stock market variables (predictors) indicating the money laundering (ML) and terrorism financing (FT) proceeds. Design/methodology/approach: This paper provides a comprehensive review of ML/FT through the stock market across developed, developing and emerging jurisdictions, sheds light on the existing literature and critically evaluates the gap in the relevant studies. Moving forward, this paper develops the conceptual framework and formulates hypotheses to explore the empirical relationship. Findings: This paper advocates and finds a basis to carry out much-needed empirical research between the ML/FT and stock market keeping in view the growing criminal cases in the developing countries. This paper suggests mining proxies from the publically available stock market data and the results of existing seminal research as variables of the study. These data and results carry information about the ML determinants. After developing hypothetical research providing concepts, this paper also finds that using a suitable methodology, preferable Bayesian logistic and linear regression models, it is possible to find the typologies and factors that can indicate and endorse the use of the stock market for ML/FT. Broadly, it is found that the significance of this study will be two-pronged: empirical development and policy implications. Research limitations/implications: This paper mainly focuses on the developing region, a newly emerging market and, peculiarly, a grey-listed region by the Financial Action Task Force (FATF). Practical implications: In light of the existing literature and to the best of the researchers’ knowledge, this study will bring into focus the new age of the action research on the ML regime in the securities markets of the developing countries, hence, the emerging markets. Moreover, this research shall have a sheer significance for the policy measures on FATF recommendations on ML and FT, especially for the countries listed as “grey”. Social implications: The research based on comprehensive review will help in controlling the social behaviours aiding the proceeds of ML. Originality/value: This research is extremely novel to the best of the researcher's knowledge. © 2022, Emerald Publishing Limited.","Due diligence; FATF; Insider trading; Money laundering; Stock market; Terrorism financing","","Article","Final","","Scopus","2-s2.0-85138205931"
"Fereydooni A.; Mahootchi M.","Fereydooni, Ali (58107239800); Mahootchi, Masoud (21743241800)","58107239800; 21743241800","An algorithmic trading system based on a stacked generalization model and hidden Markov model in the foreign exchange market","2023","Global Finance Journal","56","","100825","","","","5","10.1016/j.gfj.2023.100825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151690140&doi=10.1016%2fj.gfj.2023.100825&partnerID=40&md5=a26893f86a8040fa89357b24daf14e2f","The Forex market has been one of the most attractive markets to researchers, funds, and traders. Literature shows that a single model algorithm usually cannot perform satisfactorily on the foreign exchange (Forex) time series because of the market's complexity. This study develops an algorithm based on two stacked generalization models consisting of four machine-learning models. First, the optimal lags of features are found using the Fisher discriminant ratio and partial autocorrelation function. Second, one stacked model fits the bullish trends, and the other holds the bearish trends resulting from a hidden Markov model. We reinforce the predictive signals of these models by extracting relationships between currency pairs with correlation and mutual information. Lastly, the proposed algorithm constructs a portfolio based on the strength of signals dependent on correlation and mutual information. As a result, this paper compares the performance of the proposed approach with different states of the model and several established benchmarks regarding return and risk metrics. The outcomes show that the proposed model's added features—such as time series clustering, considering a range of inputs, and internal relationships among different assets—can increase its performance in the Forex market. © 2023 Elsevier Inc.","Foreign exchange market; Hidden Markov model; Stacked generalization model; Time series clustering; Time series forecasting","","Article","Final","","Scopus","2-s2.0-85151690140"
"Tian R.; Lu M.; Wang H.; Wang B.; Tang Q.","Tian, Ran (56119550700); Lu, Meng (58774819500); Wang, Haopeng (58295231900); Wang, Bo (58994708800); Tang, Qingxia (58774819600)","56119550700; 58774819500; 58295231900; 58994708800; 58774819600","IACPPO: A deep reinforcement learning-based model for warehouse inventory replenishment","2024","Computers and Industrial Engineering","187","","109829","","","","3","10.1016/j.cie.2023.109829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180364902&doi=10.1016%2fj.cie.2023.109829&partnerID=40&md5=7514bc06e89ffb3d8e9bcdebd8586438","Inventory cost is a significant factor in Supply Chain Management (SCM), and an effective replenishment strategy can reduce warehouse operation costs. However, traditional replenishment strategies often struggle to meet the complex and ever-changing demands of real-world warehouse scenarios. Moreover, the spatiotemporal heterogeneity of commodity demand and inventory cost poses significant challenges to time series prediction models, as individual training strategies for different commodities significantly increase modeling and time costs. To address these issues, we propose a replenishment model called IACPPO, which incorporates the Advantage Actor-Critic (A2C) algorithm with the Proximal Policy Optimization (PPO) algorithm. Firstly, we introduce gated recurrent unit (GRU) and Attention Mechanisms into the Actor-Critic network to analyze data state spaces for probabilistic modeling and extracting valid information from environmental state sequences by memory reasoning and focusing on critical state sequences; additionally, we fuse the A2C algorithm with the PPO algorithm to train the whole network simultaneously to obtain the replenishment strategy. Finally, experimental results on two different real-world inventory datasets show that using the IACPPO model has achieved the best cost control strategies in most experimental validations of replenishment strategies. © 2023 Elsevier Ltd","Inventory cost management; Markov decision process; Replenishment strategy; Supply chain","Costs; Critical current density (superconductivity); Deep learning; Inventory control; Markov processes; Reinforcement learning; Supply chain management; Actor critic; Cost management; Inventory cost management; Inventory costs; Markov Decision Processes; Optimization algorithms; Policy optimization; Real-world; Replenishment strategies; State sequences; Warehouses","Article","Final","","Scopus","2-s2.0-85180364902"
"Jin B.; Xu X.","Jin, Bingzi (58914834300); Xu, Xiaojie (57192066072)","58914834300; 57192066072","Machine learning price index forecasts of flat steel products","2024","Mineral Economics","","","","","","","2","10.1007/s13563-024-00457-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199381469&doi=10.1007%2fs13563-024-00457-8&partnerID=40&md5=76bb9b2fc00fbc470cbb0875ec6f8936","Investors and authorities have always placed a high emphasis on commodity price forecasting. In this study, the issue of daily price index forecasting for flat steel products on the Chinese market between June 15, 2011, and April 15, 2021 is examined. There hasn’t been enough focus in the literature on anticipating this important commodity price indicator. Cross-validation and Bayesian optimizations are used to train our models, and Gaussian process regressions are used to support our conclusions. With an out-of-sample relative root mean square error of 0.1293%, the created models correctly forecasted the price indices between April 26, 2019, and April 15, 2021. The developed models may be used for policy research and decision-making by investors and policymakers. When creating similar commodity price indices with reference data on the price trends predicted by the models, the forecasting findings may prove helpful. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.","Bayesian optimization; Cross validation; Flat steel product; Gaussian process regression; Price prediction","","Article","Article in press","","Scopus","2-s2.0-85199381469"
"Yang G.-H.; Ma S.-Q.; Bian X.-D.; Li J.-C.","Yang, Guo-Hui (57194237912); Ma, Si-Qi (58559476300); Bian, Xiao-Dong (58559514400); Li, Jiang-Cheng (25921575100)","57194237912; 58559476300; 58559514400; 25921575100","The roles of liquidity and delay in financial markets based on an optimal forecasting model","2023","PLoS ONE","18","9 September","e0290869","","","","0","10.1371/journal.pone.0290869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169527039&doi=10.1371%2fjournal.pone.0290869&partnerID=40&md5=f7c69fed32fc2a29e7b5302f630c1fa2","We investigate the roles of liquidity and delay in financial markets through our proposed optimal forecasting model. The efficiency and liquidity of the financial market are examined using stochastic models that incorporate information delay. Based on machine learning, we estimate the in-sample and out-of-sample forecasting price performances of the six proposed methods using the likelihood function and Bayesian methods, and the out-of-sample prediction performance is compared with the benchmark model ARIMA-GARCH. We discover that the forecasting price performance of the proposed simplified delay stochastic model is superior to that of the benchmark methods by the test methods of a variety of loss function, superior predictive ability test (SPA), Akaike information criterion (AIC), and Bayesian information criterion (BIC). Using data from the Chinese stock market, the best forecasting model assesses the efficiency and liquidity of the financial market while accounting for information delay and trade probability. The rise in trade probability and delay time affects the stability of the return distribution and raises the risk, according to stochastic simulation. The empirical findings show that empirical and best forecasting approaches are compatible, that company size and liquidity (delay time) have an inverse relationship, and that delay time and liquidity have a nonlinear relationship. The most efficient have optimal liquidity. Copyright: © 2023 Yang et al.","","Aptitude Tests; Asian People; Bayes Theorem; Benchmarking; Humans; Likelihood Functions; Article; bootstrapping; data base; finance; forecasting; human; liquidity; mathematical parameters; prediction; predictive model; price; probability; simulation; stochastic model; stock market; trade (economics); aptitude test; Asian; Bayes theorem; benchmarking; statistical model","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85169527039"
"Leng J.; Liu W.; Guo Q.","Leng, Jielin (57983268100); Liu, Wei (58360609100); Guo, Qiang (56435022400)","57983268100; 58360609100; 56435022400","Stock movement prediction model based on gated orthogonal recurrent units","2022","Intelligent Systems with Applications","16","","200156","","","","4","10.1016/j.iswa.2022.200156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142670868&doi=10.1016%2fj.iswa.2022.200156&partnerID=40&md5=0f9d8b24c04ec239d9a34f2fbdac3594","Stock movement prediction has received growing interest in the deep learning community. However, the generalization ability of some existing prediction models is weak due to the highly stochastic property of stock market, and some models suffer from the problem of gradient explosion or gradient vanishing in the training process. To solve the above issues, in this paper, we propose a novel stock movement prediction model based on gated orthogonal recurrent units (GORU) and variational auto-encoder (VAE). Specifically, GORU encodes the text information, and then VAE infers and decodes the market information formed by concatenating encoded text information with normalized historical price information. Meanwhile, orthogonality introduced by GORU can alleviate the problem of gradient explosion or gradient vanishing and enhance the generalization ability of the model. We evaluate the relative contributions of text information and historical prices with respect to prediction accuracy by the results of an ablation study. The experimental results on publicly available datasets show that the proposed model is better than several state-of-the-art models, which indicates that the GORU and VAE can effectively improve the model's generalization ability and accuracy for predicting stock trends. © 2022 The Author(s)","Deep neural network; Gated orthogonal recurrent unit; Stock movement prediction; Text information encoding; Variational inference","Commerce; Encoding (symbols); Forecasting; Motion estimation; Network coding; Recurrent neural networks; Stochastic models; Stochastic systems; Gated orthogonal recurrent unit; Generalization ability; Information encoding; Movement prediction; Prediction modelling; Stock movement; Stock movement prediction; Text information; Text information encoding; Variational inference; Deep neural networks","Article","Final","","Scopus","2-s2.0-85142670868"
"Vincent A.M.P.; Salleh H.","Vincent, Assunta Malar Patrick (58657252300); Salleh, Hassilah (55650877400)","58657252300; 55650877400","Adaptation of stochasticity into activation function of deep learning for stock price forecasting","2023","Bulletin of Electrical Engineering and Informatics","12","6","","3780","3789","9","1","10.11591/eei.v12i6.4987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174604229&doi=10.11591%2feei.v12i6.4987&partnerID=40&md5=30b1e6952b6e8fa58960c9f8c24e86ce","Stock market is an example of a stochastic environment in the real world. multilayer perceptron (MLP) is often applied to forecast stock price. However, it is widely used to approximate the input-output mapping deterministically. Hence, this study aims to adapt stochasticity into MLP by introducing the Gaussian process into the sigmoid activation function. In addition, the adapted activation function incorporates Roger-Satchell and Yang-Zhang volatity estimators. Besides, the stochastic activation function was considered as a hyperparameter by applying it either only in training time or in both testing and training time. The stochastic multilayer perceptron (S-MLP) is then applied to forecast one day's highest stock price of eight constituents in FTSE Bursa Malaysia KLCI (FBMKLCI). The result shows that the proposed network is inferior in comparison to MLP except for several constituents. In addition, S-MLP with stochastic activation function during both the training and testing time performs better compared to the presence of stochastic activation function in S-MLP during training time only. © 2023, Institute of Advanced Engineering and Science. All rights reserved.","Forecasting stock price; Gaussian process; Multilayer perceptron; Stochastic neural network","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85174604229"
"Rawlins C.; Sarangapani J.","Rawlins, Charles (57226380307); Sarangapani, Jagannathan (22951746400)","57226380307; 22951746400","Predicting IoT Distributed Ledger Fraud Transactions With a Lightweight GAN Network","2024","IEEE Transactions on Mobile Computing","23","7","","7818","7829","11","0","10.1109/TMC.2023.3339384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179783274&doi=10.1109%2fTMC.2023.3339384&partnerID=40&md5=a75ee4ee4167246e14f1bf8656fe0577","Decision-making and consensus in traditional blockchain protocols is formulated as a repeated Bernoulli trial that solves a computationally-intense lottery puzzle, called Proof-of-Work (PoW) in Bitcoin. This approach has shown robustness through practice, but does not scale with increasing network size and generation of new transactions. Resource constrained Internet of Things (IoT) networks are incompatible with full computation of schemes like Bitcoin's PoW. Our effort proposes a first step towards an alternative consensus using machine learning-based decision-making with prediction of fraud transactions to alleviate need for intense computation. To improve base approval probabilities for fraud detection in an ideal security setting, Vector GAN (VecGAN) is proposed to augment blockchain data in classifier training, which combines error-driven learning with Bayesian estimation to alleviate calculations. This two-step approach with augmentation and classification on new transactions is proposed as a novel approach to blockchain decision-making. Experimental prediction accuracy using VecGAN improved up to 3% on simplistic classifiers compared to other state-of-the-art augmentation techniques. Resource consumption in a realistic blockchain setting was reduced while improving block throughput by 50% compared to PoW. Future work will explore Sybil-spam defensive measures for realistic protocol implementation with this approach.  © 2002-2012 IEEE.","Blockchain; data augmentation; generative adversarial network; Internet of Things (IoT)","Bayesian networks; Classification (of information); Decision making; Forecasting; Generative adversarial networks; Internet of things; Internet protocols; Network security; Bernoulli trials; Block-chain; Data augmentation; Decision consensus; Decisions makings; Fraud; Network size; Proof of work; Security; Blockchain","Article","Final","","Scopus","2-s2.0-85179783274"
"Nayyer N.; Javaid N.; Akbar M.; Aldegheishem A.; Alrajeh N.; Jamil M.","Nayyer, Noor (58547922500); Javaid, Nadeem (26428797500); Akbar, Mariam (15764791400); Aldegheishem, Abdulaziz (55850984600); Alrajeh, Nabil (36338477200); Jamil, Mohsin (57616931600)","58547922500; 26428797500; 15764791400; 55850984600; 36338477200; 57616931600","A New Framework for Fraud Detection in Bitcoin Transactions Through Ensemble Stacking Model in Smart Cities","2023","IEEE Access","11","","","90916","90938","22","9","10.1109/ACCESS.2023.3308298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168677690&doi=10.1109%2fACCESS.2023.3308298&partnerID=40&md5=5b1ccd15cbfda2ccc38737881ecff2ee","Bitcoin has a reputation of being used for unlawful activities, such as money laundering, dark web transactions, and payments for ransomware in the context of smart cities. Blockchain technology prevents illegal transactions, but cannot detect these transactions. Anomaly detection is a fundamental technique for recognizing potential fraud. The heuristic and signature-based approaches were the foundation of earlier detection techniques, but tragically, these methods were insufficient to explore the entire complexity of anomaly detection. Machine Learning (ML) is a promising approach to anomaly detection, as it can be trained on large datasets of known malware samples to identify patterns and features of the transactions. Researchers are focusing on determining an efficient fraud and security threat detection model that overcomes the drawbacks of the existing methods. Therefore, ensemble learning can be applied to anomaly detection in Bitcoin by combining multiple ML classifiers. In the proposed model, the ADASYN-TL (Adaptive Synthetic + Tomek Link) balancing technique is used for data balancing. Random search, grid search and Bayesian optimization are used for hyperparameter tuning. The hyperparameters have a great impact on the performance of the model. For classification, we used the stacking model by combining Decision Tree, Naive Bayes, K-Nearest Neighbors, and Random Forest. We used SHapley Additive exPlanation (SHAP) to interpret the predictions of the stacking model. The model also explores the performance of different classifiers using accuracy, F1-score, Area Under Curve-Receiver Operating Characteristic (AUC-ROC), precision, recall, False Positive Rate (FPR) and execution time, and ultimately selects the ideal model. The proposed model contributes to the development of effective fraud detection models that address the limitations of the existing algorithms. Our stacking model, which combines the prediction of multiple classifiers, achieved the highest F1-score of 97%, precision of 96%, recall of 98%, accuracy of 97%, AUC-ROC of 99% and FPR of 3%.  © 2013 IEEE.","Bitcoin transaction; hyperparameter tuning; machine learning; ransomware attack; smart cities; stacking model","Bitcoin; Blockchain; Crime; Decision trees; Learning systems; Malware; Nearest neighbor search; Smart city; Anomaly detection; Bitcoin transaction; Block-chain; Features extraction; Fraud; Hyper-parameter; Hyperparameter tuning; Machine-learning; Parameters estimation; Ransomware attack; Stacking models; Stackings; Feature extraction","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85168677690"
"Yu X.; Li Y.; Zhao Q.","Yu, Xing (55434083800); Li, Yanyan (57289858800); Zhao, Qian (59226229700)","55434083800; 57289858800; 59226229700","Research on optimization strategy of futures hedging dependent on market state","2024","Applied Energy","373","","123885","","","","0","10.1016/j.apenergy.2024.123885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199038813&doi=10.1016%2fj.apenergy.2024.123885&partnerID=40&md5=e791a09121bb078427e47aa64af170a5","Considering the dynamic nature of market conditions, this paper introduces a state-dependent futures hedging optimization model and methodology. This approach dynamically adjusts the traditional model-driven hedging strategy, effectively balancing the pursuit of returns with the imperative of risk mitigation. Empirical evidence shows that integrating Hidden Markov Model (HMM) with machine learning techniques, as demonstrated in this study, improves the accuracy of market state forecasts. Compared to the traditional model-driven hedging strategy, the innovative state-dependent hedging strategy introduced here significantly enhances the return-to-risk ratio, and revenue, without increasing hedging risks. Moreover, the hedging portfolio developed under this strategy achieves an average hedging efficiency of 0.76, highlighting the effectiveness of the proposed methodology. Additional robustness tests indicate that this market state-dependent hedging optimization strategy is promising under various conditions, including different position adjustment ratios, volatility benchmarks, evaluation periods, types of crude oil, and transaction costs. The research conducted in this paper not only contributes to and expands traditional hedging theories but also provides a practical risk management solution for market participants. © 2024 Elsevier Ltd","Futures hedging; HMM; Machine learning; Model-driven; State dependence","Balancing; Commerce; Electronic trading; Financial markets; Hidden Markov models; Investments; Risk management; Dynamic nature; Future hedging; Hedging strategies; Hidden-Markov models; Machine-learning; Model-driven; Optimization strategy; State dependence; State-dependent; Traditional models; crude oil; local participation; machine learning; market conditions; market system; Markov chain; optimization; risk factor; Machine learning","Article","Final","","Scopus","2-s2.0-85199038813"
"Song X.","Song, Xinyuan (58718634000)","58718634000","Predicting stock price of construction companies using weighted ensemble learning","2024","Heliyon","10","11","e31604","","","","0","10.1016/j.heliyon.2024.e31604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194584098&doi=10.1016%2fj.heliyon.2024.e31604&partnerID=40&md5=61d5754d64d1bd0cf7f8b35fe47a8182","Modeling the behavior of stock price data has always been one of the challenging applications of Artificial Intelligence (AI) and Machine Learning (ML) due to its high complexity and dependence on various conditions. Recent studies show that this will be difficult to do with just one learning model. The problem can be more complex for companies in the construction sector, due to the dependency of their behavior on more conditions. This study aims to provide a hybrid model for improving the accuracy of prediction for the stock price index of companies in the construction section. The contribution of this paper can be considered as follows: First, a combination of several prediction models is used to predict stock prices so that learning models can cover each other's errors. In this research, an ensemble model based on Artificial Neural Network (ANN), Gaussian Process Regression (GPR), and Classification and Regression Tree (CART) is presented for predicting the stock price index. Second, the optimization technique is used to determine the effect of each learning model on the prediction result. For this purpose, first, all three mentioned algorithms process the data simultaneously and perform the prediction operation. Then, using the Cuckoo Search (CS) algorithm, the output weight of each algorithm is determined as a coefficient. Finally, using the ensemble technique, these results are combined and the final output is generated through weighted averaging on optimal coefficients. The proposed system was implemented, and its efficiency was evaluated by real stock data of construction companies. The results showed that using CS optimization in the proposed ensemble system is highly effective in reducing prediction error. According to the results, the proposed system can predict the price index with an average accuracy of 96.6 %, which shows a reduction of at least 2.4 % in prediction error compared to the previous methods. Comparing the evaluation results of the proposed system with similar algorithms indicates that our model is more accurate and can be useful for predicting the stock price index in real-world scenarios. © 2024 The Author","Artificial Intelligence; Ensemble learning; Forecasting stock price of construction companies; Machine Learning","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85194584098"
"Bai J.; Guo J.; Sun B.; Guo Y.; Chen Y.; Xiao X.","Bai, Juncheng (57210154125); Guo, Jianfeng (57191228104); Sun, Bingzhen (7401984470); Guo, Yuqi (57895850000); Chen, Youwei (57191227425); Xiao, Xia (57192156850)","57210154125; 57191228104; 7401984470; 57895850000; 57191227425; 57192156850","Probability rough set and portfolio optimization integrated three-way predication decisions approach to stock price","2023","Applied Intelligence","53","24","","29918","29942","24","0","10.1007/s10489-023-05085-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175815469&doi=10.1007%2fs10489-023-05085-3&partnerID=40&md5=a90f823a51548b1bae19c81a65f8d119","In the stock market, accurate trend judgment and reasonable asset distribution are effective ways to obtain ideal return. However, the real stock market is affected by the objective economic environment, investors’ expected return and other potential factors, which makes the classical portfolio strategy face more challenges and pressures. How to build a reliable portfolio strategy in an uncertain environment will be a scientific problem worthy of in-depth discussion. To address this issue, this paper combines machine learning with rough set to establish a new rough set theory prediction model, quantitatively dividing the stock data into three categories and targetedly predicting the future trend according to the complexity. Based on the proposed prediction model, a new portfolio strategy is proposed by integrating the mean-variance model. Firstly, for reducing the volatility and noise of the original data of stock price, outlier processing (OP) and wavelet denoising (WD) are utilized. Secondly, for the sake of pertinently forecasting the future trend of different characteristic stock price, a three-way prediction (TWP) decisions approach is constructed based on multiscale permutation entropy (MPE), probabilistic rough set (PRS), variational modal decomposition (VMD) and deep learning. Finally, 20 stocks of Shanghai and Shenzhen stock exchanges are taken as research samples to verify the scientificity and rationality of the portfolio strategy. The results show that the proposed approach not only provides scientific support and reference for investors’ investment decisions, but also provides a new investment strategy theory and method for the investment decisions of the stock market. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Bidirectional gated recurrent unit; Mean-variance model; Probability rough set; Stock price forecasting","Commerce; Deep learning; Electronic trading; Forecasting; Investments; Rough set theory; Bidirectional gated recurrent unit; Future trends; Investment decisions; Mean variance model; Portfolio strategies; Prediction modelling; Probability rough set; Set optimizations; Stock price; Stock price forecasting; Financial markets","Article","Final","","Scopus","2-s2.0-85175815469"
"Abunasser B.S.; Daud S.M.; Abu-Naser S.S.","Abunasser, Basem S. (57841947400); Daud, Salwani Mohd (57194563213); Abu-Naser, Samy S. (26533902900)","57841947400; 57194563213; 26533902900","Predicting Stock Prices using Artificial Intelligence: A Comparative Study of Machine Learning Algorithms","2023","International Journal of Advances in Soft Computing and its Applications","15","3","","41","53","12","2","10.15849/IJASCA.231130.03","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178276616&doi=10.15849%2fIJASCA.231130.03&partnerID=40&md5=c605e51899eb266f82bd8a93fa535be0","The prediction of stock prices poses an intricate and demanding challenge within the realm of finance. The emergence of artificial intelligence (AI) and machine learning (ML) methodologies has escalated the significance of stock price prediction for investors, traders, and financial experts. This study unveils a comparative examination of diverse ML algorithms intended for stock price prediction through AI mechanisms. We assess the efficacy of multiple algorithms, encompassing Linear Regression, Ridge Regression, Lasso Regression, Random Forest Regression, and Gradient Boosting Regression, employing a dataset of historical stock prices sourced from Yahoo Finance. Our findings demonstrate that the Gaussian Process Regressor surpasses other algorithms, boasting an impeccable R-squared value of 1.00. Moreover, we delve into the pivotal role played by feature engineering and preprocessing techniques in augmenting the precision of prediction models. This investigation furnishes valuable insights into the integration of AI in the financial domain, with the potential to enlighten investment and trading strategies. © Al-Zaytoonah University of Jordan (ZUJ).","Artificial Intelligence; Machine Learning; prediction; Stock Prices","","Article","Final","","Scopus","2-s2.0-85178276616"
"Gunawan A.E.K.; Wibowo A.","Gunawan, Albertus Emilio Kurniajaya (58804487300); Wibowo, Antoni (57190940136)","58804487300; 57190940136","Stock Price Movement Classification Using Ensembled Model of Long Short-Term Memory (LSTM) and Random Forest (RF)","2023","International Journal on Informatics Visualization","7","4","","2255","2262","7","2","10.30630/joiv.7.4.1640","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181970512&doi=10.30630%2fjoiv.7.4.1640&partnerID=40&md5=c4734020e8e74046818ddddba668dea2","Stock investing is known worldwide as a passive income available for everyone. To increase the profit possibly gained, many researchers and investors brainstorm to gain a strategy with the most profit. Machine learning and deep learning are two of these approaches to predicting the stock's movement and deciding the strategy to gain as much as possible. To reach this goal, the researcher experiments with Random Forest (RF) and Long Short-Term Memory (LSTM) by trying them individually and merging them into an ensembled model. The researcher used RF to classify the results from LSTM models obtained throughout the Hyperparameter Optimization (HPO) process. This idea is implemented to lessen the time needed to train and optimize each LSTM model inside the ensembled model. Another anticipation done in this research to overcome the time needed to train the model is classifying the return for longer periods. The dataset used in this model is 45 stocks listed in LQ45 as of August 2021 This research results in showing that LSTM gives better results than RF model especially when using Bayesian Optimization as the HPO method, and that the ensembled model can return better precision in predicting stocks in comparison to the LSTM model itself. Future improvement can focus on the model structure, additional model types as the ensemble model estimator, improvement on the model efficiency, and datasets research to be used in predicting the stock movement prediction. © 2023, Politeknik Negeri Padang. All rights reserved.","bayesian optimization; classification; deep learning; ensembled model; long short-term memory; Machine learning; random forest; random search; stock investing","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85181970512"
"Kovantsev A.N.","Kovantsev, Anton N. (57222088145)","57222088145","Probabilistic criteria for time-series predictability estimation","2023","Scientific and Technical Journal of Information Technologies, Mechanics and Optics","23","1","","105","111","6","1","10.17586/2226-1494-2023-23-1-105-111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148531526&doi=10.17586%2f2226-1494-2023-23-1-105-111&partnerID=40&md5=8c8bdf82d979804b25414170974a80d0","Assessing the time series predictability is necessary for forecasting models validating, for classifying series to optimize the choice of the model and its parameters, and for analyzing the results. The difficulties in assessing predictability occur due to large heteroscedasticity of errors obtained when predicting several series of different nature and characteristics. In this work, the internal predictability of predictive modeling objects is investigated. Using the example of time series forecasting, we explore the possibility of quantifying internal predictability in terms of the probability (frequency) of obtaining a forecast with an error greater than some certain level. We also try to determine the relationship of such a measure with the characteristics of the time series themselves. The idea of the proposed method is to estimate the internal predictability by the probability of an error exceeding a predetermined threshold value. The studies were carried out on data from open sources containing more than seven thousand time series of stock market prices. We compare the probability of errors which exceed the allowable value (miss probabilities) for the same series on different forecasting models. We show that these probabilities differ insignificantly for different forecasting models with the same series, and hence, the probability can be a measure of predictability. We also show the relationship of the miss probability values with entropy, the Hurst exponent, and other characteristics of the series according to which the predictability can be estimated. It has been established that the resulting measure makes it possible to compare the predictability of time series with pronounced heteroscedasticity of forecast errors and when using different models. The measure is related to the characteristics of the time series and is interpretable. The results can be generalized to any objects of predictive modeling and forecasting quality scores. It can be useful to developers of predictive modeling algorithms, machine learning specialists in solving practical problems of forecasting. © 2023, ITMO University. All rights reserved.","forecasting error; intrinsic predictability; misprediction","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85148531526"
"Emick E.; Babcock C.; White G.W.; Hudak A.T.; Domke G.M.; Finley A.O.","Emick, Ethan (58367479300); Babcock, Chad (55450836100); White, Grayson W. (57390990200); Hudak, Andrew T. (36520959600); Domke, Grant M. (15764524400); Finley, Andrew O. (7003297143)","58367479300; 55450836100; 57390990200; 36520959600; 15764524400; 7003297143","An approach to estimating forest biomass while quantifying estimate uncertainty and correcting bias in machine learning maps","2023","Remote Sensing of Environment","295","","113678","","","","3","10.1016/j.rse.2023.113678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163160646&doi=10.1016%2fj.rse.2023.113678&partnerID=40&md5=066b31bcb921dd9f92078c62b2e4b219","Providing forest biomass estimates with desired accuracy and precision for small areas is a key challenge to incorporating forest carbon offsets into commodity trading programs. Enrolled forest carbon projects and verification entities typically rely on probabilistically sampled field data and design-based (DB) estimators to estimate carbon storage and characterize uncertainty. However, this methodology requires a large amount of field data to achieve sufficient precision and collection of these data can be prohibitively expensive. This has spurred interest in developing regional-scale maps of forest biomass that incorporate remote sensing data as an alternative to collecting expensive plot data. These maps are often generated using machine learning (ML) algorithms that combine remote sensing products and field measurements. While these maps can produce estimates across large geographic regions at fine spatial resolutions, the estimates are prone to bias and do not have associated uncertainty estimates. Here, we assess one such map developed by the National Aeronautics and Space Administration's Carbon Monitoring System. We consider model-assisted (MA) and geostatistical model-based (GMB) estimators to address map bias and uncertainty quantification. The MA and GMB estimators use a sample of field observations as the response, and the ML-produced map as an auxiliary variable to achieve statistically defensible predictions. We compare MA and GMB estimator performance to DB and direct (DR) estimators. This assessment considers both counties and a small areal extent experimental forest, all within Oregon USA. Results suggest the MA and GMB estimators perform similar to the DB estimator at the state level and in counties containing many field plots. But in counties with moderate to small field sample sizes, the GMB and MA estimators are more precise than the DB estimator. As within-county sample sizes get smaller, the GMB estimator tends to outperform MA. Results also show the DR estimator's state-level estimates are substantially larger than the DB, MA and GMB estimates, indicating that that the DR estimator may be biased. When assessing the GMB estimator for the experimental forest, we find the GMB estimator has sufficient precision for stand-level carbon accounting even when no field observations are available within the stand. Plot-level GMB uncertainty interval coverage probabilities were estimated and showed adequate coverage. This suggests that the GMB estimator is producing statistically rigorous uncertainty estimates. © 2023 Elsevier Inc.","Bayesian hierarchical spatial modeling; Bias correction; Carbon monitoring; Design-based inference; Forest inventory; Machine learning; Model-based inference; Random forest; Remote sensing; Small area estimation","Oregon; United States; Biomass; Data acquisition; Digital storage; Forestry; Machine learning; NASA; Uncertainty analysis; Bayesian; Bayesian hierarchical spatial modeling; Bias correction; Carbon monitoring; Design-based inference; Forest inventory; Machine-learning; Model-based inference; Model-based OPC; Random forests; Remote-sensing; Small area estimation; Spatial modelling; algorithm; biomass; carbon storage; ecological modeling; forest inventory; machine learning; map; remote sensing; uncertainty analysis; Remote sensing","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85163160646"
"Matvienko I.; Gasanov M.; Petrovskaia A.; Kuznetsov M.; Jana R.; Pukalchik M.; Oseledets I.","Matvienko, Ivan (57206483843); Gasanov, Mikhail (57217481511); Petrovskaia, Anna (57217480473); Kuznetsov, Maxim (57203840792); Jana, Raghavendra (23035006300); Pukalchik, Maria (56368460100); Oseledets, Ivan (8529104000)","57206483843; 57217481511; 57217480473; 57203840792; 23035006300; 56368460100; 8529104000","Bayesian Aggregation Improves Traditional Single-Image Crop Classification Approaches","2022","Sensors","22","22","8600","","","","2","10.3390/s22228600","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142675122&doi=10.3390%2fs22228600&partnerID=40&md5=940d6d4ef79cb8d86cdc1aa6d412b4f3","Accurate information about growing crops allows for regulating the internal stocks of agricultural products and drawing strategies for negotiating agricultural commodities on financial markets. Machine learning methods are widely implemented for crop type recognition and classification based on satellite images. However, field classification is complicated by class imbalance and aggregation of pixel-wise into field-wise forecasting. We propose here a Bayesian methodology for the aggregation of classification results. We report the comparison of class balancing techniques. We also report the comparison of classical machine learning methods and the U-Net convolutional neural network for classifying crops using a single satellite image. The best result for single-satellite-image crop classification was achieved with an overall accuracy of 77.4% and a Macro F1-score of 0.66. Bayesian aggregation for field-wise classification improved the result obtained using majority voting aggregation by 1.5%. We demonstrate here that the Bayesian aggregation approach outperforms the majority voting and averaging strategy in overall accuracy for the single-image crop classification task. © 2022 by the authors.","crop classification; pixel-wise aggregation; unbalanced classes problem","Agriculture; Bayes Theorem; Crops, Agricultural; Machine Learning; Neural Networks, Computer; Agricultural products; Balancing; Convolutional neural networks; Crops; Image classification; Image enhancement; Machine learning; Satellites; Bayesian; Classification approach; Crop classification; Machine learning methods; Overall accuracies; Pixel-wise aggregation; Product strategy; Satellite images; Single images; Unbalanced class problem; agriculture; Bayes theorem; crop; machine learning; Pixels","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85142675122"
"Golnari A.; Komeili M.H.; Azizi Z.","Golnari, Amin (57217684618); Komeili, Mohammad Hossein (59177655200); Azizi, Zahra (59177352300)","57217684618; 59177655200; 59177352300","Probabilistic deep learning and transfer learning for robust cryptocurrency price prediction","2024","Expert Systems with Applications","255","","124404","","","","0","10.1016/j.eswa.2024.124404","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196264046&doi=10.1016%2fj.eswa.2024.124404&partnerID=40&md5=479f270cc428dd384a81775aded2dfaa","Forecasting the price of Bitcoin (BTC) with precision is a complex endeavor, given the market's inherent uncertainty and volatility, influenced by a diverse range of parameters. This research is driven by the central goal of introducing a specialized deep learning model tailored to predict digital currency prices, with a specific emphasis on BTC. To address this challenge, a pioneering strategy has been established, leveraging probabilistic gated recurrent units (P-GRU). This approach integrates probabilistic attributes into the model, facilitating the generation of probability distributions for projected values. The effectiveness of this method is assessed using one year of BTC price history, sampled at a five-minute interval. In parallel, a comparative analysis is conducted against alternative models, including GRU, long short-term memory (LSTM), and variants thereof (time-distributed, bidirectional, and simple models). In pursuit of optimizing model efficacy, a bespoke callback mechanism is deployed. This callback, driven by R2-score tracking, captures optimal model weights based on validation data. Moreover, a transfer learning paradigm is adopted to broaden the study's horizons. A pre-trained model on BTC data is harnessed to predict prices for six other prominent cryptocurrencies: Ethereum, Litecoin, Tron, Polkadot, Cardano, and Stellar. Consequently, a distinct model is tailored for each cryptocurrency. The outcomes of this investigation conclusively underscore the superior performance of the proposed methodology. In the midst of a volatile and uncertain market landscape, the proposed approach outshines its counterparts, showcasing an enhanced ability for cryptocurrency price forecasting. © 2024 Elsevier Ltd","Bayesian neural networks (BNNs); BTC price prediction; Cryptocurrency prediction; Probabilistic gated recurrent units (P-GRU); Transfer learning","Bayesian networks; Bitcoin; Costs; Learning systems; Long short-term memory; Probability distributions; Bayesian neural network; Bayesian neural networks; Bitcoin price prediction; Cryptocurrency prediction; Diverse range; Price prediction; Probabilistic gated recurrent unit; Probabilistics; Transfer learning; Uncertainty; Forecasting","Article","Final","","Scopus","2-s2.0-85196264046"
"Dorn J.; Guo K.; Kallus N.","Dorn, Jacob (57222186558); Guo, Kevin (57222184194); Kallus, Nathan (56305894700)","57222186558; 57222184194; 56305894700","Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with Unmeasured Confounding","2024","Journal of the American Statistical Association","","","","","","","0","10.1080/01621459.2024.2335588","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191348994&doi=10.1080%2f01621459.2024.2335588&partnerID=40&md5=2396def4af0b51277418016fce750414","We consider the problem of constructing bounds on the average treatment effect (ATE) when unmeasured confounders exist but have bounded influence. Specifically, we assume that omitted confounders could not change the odds of treatment for any unit by more than a fixed factor. We derive the sharp partial identification bounds implied by this assumption by leveraging distributionally robust optimization, and we propose estimators of these bounds with several novel robustness properties. The first is double sharpness: our estimators consistently estimate the sharp ATE bounds when one of two nuisance parameters is misspecified and achieve semiparametric efficiency when all nuisance parameters are suitably consistent. The second and more novel property is double validity: even when most nuisance parameters are misspecified, our estimators still provide valid but possibly conservative bounds for the ATE and our Wald confidence intervals remain valid even when our estimators are not asymptotically normal. As a result, our estimators provide a highly credible method for sensitivity analysis of causal inferences. Supplementary materials for this article are available online including a standardized description of the materials available for reproducing the work. © 2024 American Statistical Association.","Conditional value at risk; Debiased machine learning; Double robustness; Marginal sensitivity model; Partial identification; Semiparametric efficiency","","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85191348994"
"Li K.; Zhou Y.","Li, Kangyi (58967425100); Zhou, Yang (59154033200)","58967425100; 59154033200","Improved Financial Predicting Method Based on Time Series Long Short-Term Memory Algorithm","2024","Mathematics","12","7","1074","","","","0","10.3390/math12071074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190087917&doi=10.3390%2fmath12071074&partnerID=40&md5=bbe54c0c06b30e70a14e1c1e47c51836","With developments in global economic integration and the increase in future economic uncertainty, it is imperative to have the ability to predict future capital in relation to financial capital inflow and outflow predictions to ensure capital optimization is within a controllable range within the current macroeconomic environment and situation. This paper proposes an automated capital prediction strategy for the capital supply chain using time series analysis artificial intelligence methods. Firstly, to analyze the fluctuation and tail risk of the financial characteristics, the paper explores the financial characteristics for measuring the dynamic VaR from the perspectives of volatility, tail, and peak with the Bayesian peaks over threshold (POT) model. Following this, in order to make the modeling more refined, the forecast targets are split before modeling with seasonal Autoregressive Integrated Moving Average (ARIMA) models and Prophet models. Finally, the time series modeling of the wavelet Long Short-Term Memory (LSTM) model is carried out using a two-part analysis method to determine the linear separated wavelet and non-linear embedded wavelet parts to predict strong volatility in financial capital. Taking the user capital flow of the Yu’e Bao platform, the results prove the feasibility and prediction accuracy of the innovative model proposed. © 2024 by the authors.","artificial intelligence; Bayesian POT; financial capital; time series","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190087917"
"Wand T.; Heßler M.; Kamps O.","Wand, Tobias (57658375000); Heßler, Martin (57227737700); Kamps, Oliver (23667209500)","57658375000; 57227737700; 23667209500","Identifying dominant industrial sectors in market states of the S&P 500 financial data","2023","Journal of Statistical Mechanics: Theory and Experiment","2023","4","043402","","","","2","10.1088/1742-5468/accce0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159220629&doi=10.1088%2f1742-5468%2faccce0&partnerID=40&md5=ed8c3090ad56bd7e1093ee00611ee82e","Understanding and forecasting changing market conditions in complex economic systems like the financial market is of great importance to various stakeholders such as financial institutions and regulatory agencies. Based on the finding that the dynamics of sector correlation matrices of the S&P 500 stock market can be described by a sequence of distinct states via a clustering algorithm, we try to identify the industrial sectors dominating the correlation structure of each state. For this purpose, we use a method from explainable artificial intelligence (XAI) on daily S&P 500 stock market data from 1992 to 2012 to assign relevance scores to every feature of each data point. To compare the significance of the features for the entire data set we develop an aggregation procedure and apply a Bayesian change point analysis to identify the most significant sector correlations. We show that the correlation matrix of each state is dominated only by a few sector correlations. Especially the energy and IT sector are identified as key factors in determining the state of the economy. Additionally we show that a reduced surrogate model, using only the eight sector correlations with the highest XAI-relevance, can replicate 90% of the cluster assignments. In general our findings imply an additional dimension reduction of the dynamics of the financial market.  © 2023 The Author(s). Published on behalf of SISSA Medialab srl by IOP Publishing Ltd.","clustering; econophysics; explainable AI; finance; market states","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85159220629"
"Papaioannou P.G.; Talmon R.; Kevrekidis I.G.; Siettos C.","Papaioannou, Panagiotis G. (56893584400); Talmon, Ronen (26421445400); Kevrekidis, Ioannis G. (35479930600); Siettos, Constantinos (6603568664)","56893584400; 26421445400; 35479930600; 6603568664","Time-series forecasting using manifold learning, radial basis function interpolation, and geometric harmonics","2022","Chaos","32","8","083113","","","","11","10.1063/5.0094887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135131456&doi=10.1063%2f5.0094887&partnerID=40&md5=63b8a81d3137b8a950f9bc5b3333bde2","We address a three-tier numerical framework based on nonlinear manifold learning for the forecasting of high-dimensional time series, relaxing the ""curse of dimensionality""related to the training phase of surrogate/machine learning models. At the first step, we embed the high-dimensional time series into a reduced low-dimensional space using nonlinear manifold learning (local linear embedding and parsimonious diffusion maps). Then, we construct reduced-order surrogate models on the manifold (here, for our illustrations, we used multivariate autoregressive and Gaussian process regression models) to forecast the embedded dynamics. Finally, we solve the pre-image problem, thus lifting the embedded time series back to the original high-dimensional space using radial basis function interpolation and geometric harmonics. The proposed numerical data-driven scheme can also be applied as a reduced-order model procedure for the numerical solution/propagation of the (transient) dynamics of partial differential equations (PDEs). We assess the performance of the proposed scheme via three different families of problems: (a) the forecasting of synthetic time series generated by three simplistic linear and weakly nonlinear stochastic models resembling electroencephalography signals, (b) the prediction/propagation of the solution profiles of a linear parabolic PDE and the Brusselator model (a set of two nonlinear parabolic PDEs), and (c) the forecasting of a real-world data set containing daily time series of ten key foreign exchange rates spanning the time period 3 September 2001-29 October 2020. © 2022 Author(s).","","article; electroencephalography; forecasting; machine learning; manifold learning; prediction; radial basis function; regression model; stochastic model; time series analysis","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85135131456"
"Jayanth T.; Manimaran A.","Jayanth, Talabathula (59243299800); Manimaran, A. (57211311577)","59243299800; 57211311577","Developing a Novel Hybrid Model Double Exponential Smoothing and Dual Attention Encoder-Decoder Based Bi-Directional Gated Recurrent Unit Enhanced with Bayesian Optimization to Forecast Stock Price","2024","IEEE Access","12","","","114760","114785","25","0","10.1109/ACCESS.2024.3435683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200254465&doi=10.1109%2fACCESS.2024.3435683&partnerID=40&md5=43bf42f9a6484d193456080c55c1993d","Financial market prediction has shown considerable potential in the past few years from the combination of contemporary Deep Learning (DL) techniques and traditional time series forecasting methodologies. To predict the stock prices of three distinct companies General Electric (GE), Microsoft (MSFT), and Amazon (AMZN) datasets. This study presents a novel hybrid model that combines the Double Exponential Smoothing (DES) method with a Deep Learning (DL) model Dual Attention Encoder-Decoder based Bi-directional GRU, optimized using Bayesian Optimization (DES-DA-ED-Bi-GRU-BO). By combining the best features of contemporary and old methods, the hybrid model seeks to efficiently identify patterns and trends in stock data. When handling time series data, the DES method offers a reliable and flexible mechanism that considers trends and seasonality in the data. The DA-ED-Bi-GRU added to the deep learning model further improves its comprehension of intricate patterns found in the stock data. The parameters are adjusted using Bayesian optimization (BO) to maximize the model's performance. Several performance indicators, such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-Square (R2), and Theil's U-Statistics (TUS), are used to assess the effectiveness of the model. These measures offer thorough insights into the precision, dependability, and accuracy of the model's predictions. The experimental findings show that the proposed hybrid model has the ability to predict GE, MSFT, and AMZN stock values with reasonable accuracy. Along with the optimization framework, DL and conventional smoothing approaches combine to provide a potent forecasting tool that may help traders and investors make wise judgments.  © 2013 IEEE.","Bayesian optimization (BO); bi-directional GRU (Bi-GRU); Double exponential smoothing (DES); dual attention mechanism (DA); encoder-decoder (ED); stock price prediction","Commerce; Costs; Data handling; Decoding; Deep learning; Electronic trading; Errors; Financial markets; Investments; Mean square error; Signal encoding; Time series analysis; Accuracy; Attention mechanisms; Bayesian optimization; Bi-directional; Bi-directional GRU; Double exponential; Double exponential smoothing; Dual attention mechanism; Encoder; Encoder-decoder; Exponential smoothing; Predictive models; Smoothing methods; Stock price prediction; Time-series analysis; Forecasting","Article","Final","","Scopus","2-s2.0-85200254465"
"Thumu S.R.; Nellore G.","Thumu, Subba Reddy (58993381500); Nellore, Geethanjali (58993219600)","58993381500; 58993219600","Optimized Ensemble Support Vector Regression Models for Predicting Stock Prices with Multiple Kernels","2024","Acta Informatica Pragensia","13","1","","24","37","13","2","10.18267/j.aip.226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190787573&doi=10.18267%2fj.aip.226&partnerID=40&md5=e66ea92d8bd58eadc5b7ef5329745a35","Stock forecasting is a complicated and daily challenge for investors because of the non-linearity of the market and the high volatility of financial assets such as stocks, bonds and other commodities. There is a need for a powerful and adaptive stock prediction model that handles complexities and provides accurate predictions. The support vector regression (SVR) model is one of the most prominent machine learning models for forecasting time series data. An ensemble hyperbolic tangent kernel SVR (HTK-SVR-BO) is proposed in this paper, combining Tanh and inverse Tanh kernels with Bayesian optimization. Combining the strengths of multiple kernels using the ensemble technique and then using optimization to identify the optimal values for each SVR model to enhance the ensemble model performance is possible. Our proposed model is compared with an ensemble SVR model (LPR-SVR-BO), which uses well-known SVR kernel types, including linear, polynomial and radial basis function (RBF). We apply the proposed models to Microsoft Corporation (MSFT) stock prices. The mean absolute error (MAE), mean squared error (MSE), root mean squared error (RMSE), R2 score (model accuracy) and mean absolute percentage error (MAPE) are the regression metrics used to compare the effectiveness of each ensemble model. In our comparison, HTK-SVR-BO performs better in terms of regression metrics compared to LPR-SVR-BO and achieves results of 0.27424, 0.13392, 0.36595, 0.99997 and 5.2331 respectively. According to the analysis, the proposed model is more predictive and may generalize to previously unknown data more effectively, so it can be accurate when forecasting future stock prices. © 2024 by the author(s).","Bayesian optimization (BO); Ensemble model; Hyperbolic tangent kernels (HTK); Linear polynomial RBF kernels (LPR); Microsoft corporation (MSFT); Regression metrics; Stock forecast; SVR","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190787573"
"Avinash G.; Ramasubramanian V.; Ray M.; Paul R.K.; Godara S.; Nayak G.H.H.; Kumar R.R.; Manjunatha B.; Dahiya S.; Iquebal M.A.","Avinash, G. (58643847000); Ramasubramanian, V. (57343489500); Ray, Mrinmoy (57201758982); Paul, Ranjit Kumar (57190431258); Godara, Samarth (57555090100); Nayak, G.H. Harish (58871200600); Kumar, Rajeev Ranjan (57425715300); Manjunatha, B. (58707981100); Dahiya, Shashi (55994213400); Iquebal, Mir Asif (32667601200)","58643847000; 57343489500; 57201758982; 57190431258; 57555090100; 58871200600; 57425715300; 58707981100; 55994213400; 32667601200","Hidden Markov guided Deep Learning models for forecasting highly volatile agricultural commodity prices","2024","Applied Soft Computing","158","","111557","","","","4","10.1016/j.asoc.2024.111557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189757855&doi=10.1016%2fj.asoc.2024.111557&partnerID=40&md5=9d1d25100db2300c3cecdb2b99850602","Predicting agricultural commodity prices accurately is of utmost importance due to various factors such as perishability, seasonality, production uncertainty etc. Moreover, the substantial volatility that may be exhibited in time series further adds to the complexity and constitutes a significant challenge. In this paper, a Hidden Markov (HM) guided Deep Learning (DL) models has been developed on nonlinear and nonstationary price data of agricultural commodities for forecasting by considering technical indicators viz., Moving Average (MA), Bollinger Bands (BB), Moving Average Convergence Divergence (MACD), Exponential MA (EMA) and Fast Fourier Transformation (FFT). HM Models (HMMs) can effectively handle the sequential dependencies and hidden states, while DL approach can learn complex patterns and relationships within the price series and thus the drawback of lack of generalization capability in the DL model has been overcome by HMM. In this study, the Potato price data of the Champadanga district of West Bengal, India has been utilized to assess the performance of the proposed technique. HMM has been combined with six baseline DL models viz., Recurrent Neural Networks (RNN), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), Bidirectional LSTM (BiLSTM) and Bidirectional GRU (BiGRU) for forecast modeling. Performance evaluation metrics viz., Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE) and the insightful Diebold–Mariano (DM) test revealed that Hidden Markov hybridized with DL models surpassed baseline DL models in forecasting accuracy for 1-week, 4-week, 8-week and 12-week ahead DL predictions. The proposed approach holds significant promise for enhancing the precision of agricultural commodity price forecasting with far-reaching implications for various stakeholders such as farmers and planners. © 2024 Elsevier B.V.","Bollinger Bands; Fourier transform; Gated Recurrent Unit (GRU)/ Bidirectional GRU (BiGRU); Long Short-Term Memory (LSTM)/ Bidirectional LSTM (BiLSTM); Recurrent Neural Network (RNN)/ Convolutional Neural Networks (CNN)","Agriculture; Brain; Complex networks; Convolutional neural networks; Costs; Errors; Forecasting; Hidden Markov models; Learning systems; Mean square error; Agricultural commodities; Bollinge band; Commodity prices; Convolutional neural network; Gated recurrent unit / bidirectional gated recurrent unit; Hidden markov; Learning models; Long short-term memory / bidirectional long short-term memory; Moving averages; Recurrent neural network / convolutional neural network; Long short-term memory","Article","Final","","Scopus","2-s2.0-85189757855"
"Ferenczi A.; Bădică C.","Ferenczi, Andras (57807490700); Bădică, Costin (8900004600)","57807490700; 8900004600","Prediction of Ethereum gas prices using DeepAR and probabilistic forecasting","2024","Journal of Information and Telecommunication","8","1","","18","32","14","0","10.1080/24751839.2023.2250113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169797877&doi=10.1080%2f24751839.2023.2250113&partnerID=40&md5=d72b23a54b6b7f6985b46f55d6a58329","Ethereum is a major public blockchain. Besides being the second-largest digital currency by market capitalization for its cryptocurrency, the Ether (Ξ), it is also the foundation of Web3 and decentralized applications, or DApps, that are fuelled by Smart Contracts. At the time of this writing, Ethereum still uses Proof of Work (PoW) consensus algorithm to ensure the integrity of the blockchain and to prevent double spend. PoW requires the participation of miners, who are incentivized to assemble blocks of transactions by being rewarded with cryptocurrency paid by transaction originators and by the blockchain network itself via newly minted Ξ. Network fees for transaction submissions are called gas, by analogy to the fuel used by cars, and are negotiable. They are also highly volatile and hence it is critical to predict the direction they are heading into, so that one can time transaction submissions, when feasible. There have been several efforts to predict gas prices, including usage of large Mempools, analysis of committed blocks, and more recent ones using Facebook's Prophet model [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2]. In this study, we introduce an innovative approach that employs the DeepAR [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001] model, known for its superior forecasting accuracy over conventional methods by virtue of its ability to learn from multiple related time series. This methodology not only offers immediate advantages but also holds promise for ongoing enhancements. We substantiate our claims through empirical testing, utilizing data extracts from the Ethereum blockchain and cryptocurrency price feeds. This document is an extended version of our ICCS 2022 paper on the same topic. In this paper, we dive deeper into the internals of DeepAR forecasting algorithm [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001], analyse the correlation between the on-chain/off-chain sample data, and describe additional experiments that empirically prove our findings and, finally, perform a comparison of our outputs with those from the Prophet [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2] model. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","blockchain; DeepAR; Ethereum; gas price; machine learning; prediction; probabilistic forecasting; proof of work","Bitcoin; Costs; Ethereum; Forecasting; Gases; HTTP; Recurrent neural networks; Auto-regressive; Block-chain; Deepar; Gas price; International journals; Machine-learning; Probabilistic forecasting; Proof of work; Recurrent networks; Transaction submission; Blockchain","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85169797877"
"Hassan M.","Hassan, Masoud Muhammed (57205433406)","57205433406","Bitcoin Price Prediction Using Deep Bayesian LSTM With Uncertainty Quantification: A Monte Carlo Dropout–Based Approach","2024","Stat","13","3","e70001","","","","0","10.1002/sta4.70001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203187450&doi=10.1002%2fsta4.70001&partnerID=40&md5=8b18e473c19d36f30123d4aa693b309a","Bitcoin, being one of the most triumphant cryptocurrencies, is gaining increasing popularity online and is being used in a variety of transactions. Recently, research on Bitcoin price predictions is receiving more attention, and researchers have investigated the various state-of-the-art machine learning (ML) and deep learning (DL) models to predict Bitcoin price. However, despite these models providing promising predictions, they consistently exhibit uncertainty, which cannot be adequately quantified by classical ML models alone. Motivated by the enormous success of applying Bayesian approaches in several disciplines of ML and DL, this study aims to use Bayesian methods alongside Long Short-Term Memory (LSTM) to predict the closing Bitcoin price and consequently measure the uncertainty of the prediction model. Specifically, we adopted the Monte Carlo dropout (MC-Dropout) method with the Bayesian LSTM model to quantify the epistemic uncertainty of the model's predictions and provided confidence intervals for the predicted outputs. Experimental results showed that the proposed model is efficient and outperforms other state-of-the-art models in terms of root mean square error (RMSE), mean absolute error (MAE) and R2. Thus, we believe that these models may assist the investors and traders in making critical decisions based on short-term predictions of Bitcoin price. This study illustrates the potential benefits of utilizing Bayesian DL approaches in time series analysis to improve data prediction accuracy and reliability. © 2024 John Wiley & Sons Ltd.","Bayesian inference; Bitcoin; deep learning; LSTM; MC-Dropout","","Article","Final","","Scopus","2-s2.0-85203187450"
"Ávila Calderón M.A.; Aragón H.G.; Caballero V.M.S.; Osuna M.A.; Rego E.C.P.D.; Garrido B.C.; Smarçaro da Cunha V.; Bebić J.; Banjanac K.; Claramunt A.V.; Avendaño Rivera P.; Barrios J.; Gonzalez I.; Wollinger W.; Carvalho L.J.; Monteiro T.M.; Castañeda T.; Etcheverry J.; Varas M.S.; Almirón F.; Silva A.; Shearman K.; Chaiphet T.; Marajh D.; Makgatho P.; Visser R.; Fernandes-Whaley M.","Ávila Calderón, Marco Antonio (57191375344); Aragón, Hugo Gasca (55247146400); Caballero, Víctor Manuel Serrano (58847827900); Osuna, Mariana Arce (57217025027); Rego, Eliane Cristina Pires do (55150535300); Garrido, Bruno Carius (37037417100); Smarçaro da Cunha, Valnei (57218396407); Bebić, Jelena (57193441051); Banjanac, Katarina (56035527700); Claramunt, Adrian Vicent (57202643482); Avendaño Rivera, Paola (58847753900); Barrios, Juliana (58847530700); Gonzalez, Ivonne (57470285200); Wollinger, Wagner (23096770500); Carvalho, Lucas J (57212871835); Monteiro, Tânia M (57205983494); Castañeda, Tomas (58847681500); Etcheverry, Jimena (57191817663); Varas, Marcelo Soto (58847530900); Almirón, Florencia (57827802200); Silva, Ana (58273832700); Shearman, Kittiya (56681171300); Chaiphet, Thitiphan (56136462600); Marajh, Dominique (57217024927); Makgatho, Phaswe (57936096500); Visser, Ria (57193672478); Fernandes-Whaley, Maria (40861123100)","57191375344; 55247146400; 58847827900; 57217025027; 55150535300; 37037417100; 57218396407; 57193441051; 56035527700; 57202643482; 58847753900; 58847530700; 57470285200; 23096770500; 57212871835; 57205983494; 58847681500; 57191817663; 58847530900; 57827802200; 58273832700; 56681171300; 56136462600; 57217024927; 57936096500; 57193672478; 40861123100","SIM.QM-S17 Ethanol in Aqueous Matrix: Supplement Key Comparison, Model 1","2023","Metrologia","60","1 A","08020","","","","0","10.1088/0026-1394/60/1A/08020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183318241&doi=10.1088%2f0026-1394%2f60%2f1A%2f08020&partnerID=40&md5=0e60ed43d23cf7bd0512b1acfcdab82c","Main text To establish international measurement capabilities for the determination of ethanol in aqueous matrices, the CCQM Organic Analysis Working Group (OAWG) has performed three ethanol Key comparisons (2002: CCQM-K27a for forensic aqueous ethanol and CCQM-K27b for ethanol in wine as a commodity; 2005: CCQM-K27 subsequent studies - four levels of ethanol in water; 2007: CCQM-K27.2 Subsequent 2 for forensic levels). To provide an opportunity for the NMIs and DIs within the RMOs, three Key comparisons has been conducted within SIM (SIM.QM-K1, SIM.QM-K27) and AFRIMETS (AFRIMETS.QM-K27). In addition, for the NMIs to support their ethanol in aqueous matrices measurements capabilities, a Track A Model 2 (formerly known as Track B) Key comparison CCQM-K79 (2010) has been completed to compare aqueous ethanol certified reference material (CRM) solutions certified by the participant NMIs and DIs. The current comparison is important to NMIs and DIs to maintain their ethanol in water measurement capabilities, to claim it as a new one as well as to complement their existing measurement capabilities, mainly within the range where the alcohol meter (breathalyzer) needs to be calibrated and verified. In 2017, several NMIs and DIs in SIM expressed their interest in a complementary SIM.QM-K27 comparison, therefore CENAM and INMETRO agreed to collaborate for the realization of a SIM supplement comparison, which was identified as SIM.QM-K27.2019 by the OAWG, and the final assigned name by SIM was SIM.QM-S17. The main purpose of this comparison was to offer to SIM countries and other regions an additional opportunity for the NMI and DIs to evaluate their measurements capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. Fourteen laboratories were registered to take part in this comparison, and thirteen sent their results. This report presents the results of the SIM Key comparison SIM.QM-S17. The measurements capabilities demonstrated by the participants in SIM.QM-S17, underpin their ability to assign reference values of ethanol content in aqueous samples for both forensic and commodities applications. Successful participation in SIM.QM-S17 demonstrates the laboratories measurement capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. The study material was two batches of solutions of ethanol in water prepared gravimetrically at concentrations between 0.1 mg/g - 5 mg/g by CENAM, dispensed in glass bottles of 50 mL sealed with tear off aluminum crimp seals, with rubber stoppers. In previous SIM.QM.K27 comparison, the purity-corrected gravimetric value of the aqueous ethanol solutions assigned by the coordinating NMI was used to link SIM.QM-K27 to the CCQM-K27 Key comparison reference value (KCRV), where 1 % uncertainty was assigned to the KCRV to have the same uncertainty from the CCQM-K27.2. For this comparison, SIM.QM-S17 two levels aqueous ethanol solutions, the purity assigned by CENAM was not used for KCRV as was informed initially in the protocol, instead in 5-June-2020 at the OAWG, CENAM gravimetric values were presented, as well as the participants results evaluated by four different statistical approaches to assess the candidate KCRV. For both levels of ethanol in aqueous matrix solutions, the DerSimonian-Laird Weighted mean and the Hierarchical Bayes mean methods seem to give a better estimation of the KCRV ± KCRU95 candidate and was agreed by OAWG to use the Hierarchical Bayesian mean, from where the KCRV for SIM.QM-S17 Level 1 (Low-level) and Level 2 (high-level) were (240.92 ± 1.28) mg/kg (k =2) and (389.87 ± 1.52) mg/kg (k =2), respectively. All the thirteen participants in the SIM.QM-S17, including both coordinators, demonstrated their capability to measure ethanol in aqueous matrix in the mass fraction range of 0.1 mg/g to 5 mg/g. To reach the main text of this paper, click on Final Report. Note that this text is that which appears in Appendix B of the BIPM key comparison database https://www.bipm.org/kcdb/. The final report has been peer-reviewed and approved for publication by the CCQM, according to the provisions of the CIPM Mutual Recognition Arrangement (CIPM MRA). © 2023 BIPM & IOP Publishing Ltd.","","Forensic science; Wine; Aqueous ethanol; Aqueous ethanol solutions; Aqueous matrix; Key comparison; Key Comparison Reference Value; Main texts; Mass-fraction; Organics; Uncertainty; Working groups; Ethanol","Review","Final","","Scopus","2-s2.0-85183318241"
"Hang L.; Liu D.; Xie F.","Hang, Lei (57196461072); Liu, Dandan (58484917300); Xie, Fusheng (57884136900)","57196461072; 58484917300; 57884136900","A Hybrid Model Using PCA and BP Neural Network for Time Series Prediction in Chinese Stock Market with TOPSIS Analysis","2023","Scientific Programming","2023","","9963940","","","","3","10.1155/2023/9963940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164587237&doi=10.1155%2f2023%2f9963940&partnerID=40&md5=3271d8f894e568c661e465674abc4c8f","The stock price changes rapidly and is highly nonlinear in the financial market. One of the common concerns of many scholars and investors is how to accurately predict the stock price and the trend of rising and falling in a short time. Machine learning and deep learning techniques have found their place in financial institutions thanks to the ability of time series data prediction with high precision. However, the prediction accuracy of these models is still far from satisfactory. Most existing studies use original, single prediction algorithms that cannot overcome inherent limitations. This study proposes a hybrid model using principal component analysis (PCA) and backpropagation (BP) neural networks. The historical records of China Merchants Bank are used for data collection from 2015 to 2021. PCA preprocesses the original data to reduce the dimensionality and is then adopted by the BP neural network to predict the stock closing price of China Merchants Bank. We compare and analyze the PCA-BP model with three training algorithms, and the results indicate that the Bayesian regularization algorithm performs best. Besides, we perform the stock prediction using a traditional exponential smoothing approach. The experiment results show that the predicted stock closing price is close to the actual value, and the mean absolute percentage error can reach 0.0130, which is more significant than the traditional approach. Furthermore, A TOPSIS approach is utilized to evaluate the robustness of the proposed model. Finally, we demonstrate the usability of the designed hybrid model by predicting the stock price of another selected stock.  © 2023 Lei Hang et al.","","Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Investments; Learning systems; Neural networks; Time series; Time series analysis; Back-propagation neural networks; Chinese stock market; Financial institution; Hybrid model; Learning techniques; Machine-learning; Price changes; Principal-component analysis; Stock price; Time series prediction; Principal component analysis","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85164587237"
"Khandelwal S.; Gupta P.; Jain A.; Nehra A.; Yadav G.S.; Kushwaha R.; Ramani S.","Khandelwal, Shubham (58130736100); Gupta, Piyush (58378846400); Jain, Aman (58130560800); Nehra, Ajay (55233877100); Yadav, Gyan Singh (55378054300); Kushwaha, Riti (57194211332); Ramani, Selvanambi (57868011400)","58130736100; 58378846400; 58130560800; 55233877100; 55378054300; 57194211332; 57868011400","Machine learning-based probabilistic profitable model in algorithmic trading","2023","Journal of Electronic Imaging","32","1","013039","","","","1","10.1117/1.JEI.32.1.013039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149434593&doi=10.1117%2f1.JEI.32.1.013039&partnerID=40&md5=14c6b07bbeb614fe2e1dd5d7f4262d5e","Machine learning models are nowadays becoming ubiquitous in algorithmic trading and investment management. These models are mostly used in the pre-trade analysis phase to determine the buy or sell decisions using various machine learning techniques. We aim to implement a machine learning-driven approach using various technical indicators to predict stock market prices and then accordingly make a decision about buying or selling. First, an effective trading strategy is discussed that selects the potentially profitable stocks, and then the technical indicators such as simple moving average (SMA), exponential moving average (EMA), relative strength index (RSI), and moving average convergence divergence (MACD) are calculated for those potentially profitable stocks. Then supervised machine learning algorithms such as multiple linear regression, support vector machine regression, and decision tree regression are applied, where the close price of the stock is predicted using technical indicators for the next day, and based on that buy or sell signals are generated. The model is then tested on 12 different SNP500 stocks, one for every month in 2018, with the mean squared error (MSE) varying between 30.33 and 48.16 and the root MSE varying between 5.51 and 6.93, where the error is calculated on the difference in the number of days when the stock price actually increases and the predicted number of days for various models.  © 2023 SPIE and IS&T.","algorithmic trading; machine learning; technical analysis; trading strategy","Decision trees; Financial markets; Investments; Learning algorithms; Learning systems; Mean square error; Multiple linear regression; Profitability; Sales; Support vector machines; Algorithmic trading; Investment management; Machine learning models; Machine learning techniques; Machine-learning; Moving averages; Probabilistics; Technical analysis; Technical indicator; Trading strategies; Commerce","Article","Final","","Scopus","2-s2.0-85149434593"
"Bui Q.-T.; Pham Q.-T.; Pham V.-M.; Tran V.-T.; Nguyen D.-H.; Nguyen Q.-H.; Nguyen H.-D.; Do N.T.; Vu V.-M.","Bui, Quang-Thanh (57189899688); Pham, Quang-Tuan (57219407896); Pham, Van-Manh (57216088558); Tran, Van-Thuy (57219404886); Nguyen, Dinh-Hung (58767401800); Nguyen, Quoc-Huy (49461676000); Nguyen, Huu-Duy (57208347181); Do, Nhung Thi (58767998100); Vu, Van-Manh (37862120600)","57189899688; 57219407896; 57216088558; 57219404886; 58767401800; 49461676000; 57208347181; 58767998100; 37862120600","Hybrid machine learning models for aboveground biomass estimations","2024","Ecological Informatics","79","","102421","","","","6","10.1016/j.ecoinf.2023.102421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179971097&doi=10.1016%2fj.ecoinf.2023.102421&partnerID=40&md5=d9e1e55ffd050df2c0f83886f03e7397","Forest biomass provides a quantitative assessment for carbon stock marketing on a national or regional scale. Some countries have committed to net zero carbon emissions, so proper biomass estimations are essential. This study investigates the uses of machine learning (LightGBM, XGBoost), in which hyperparameters were tuned by Bayesian-based Optimisers and a novel Tasmanian Devil Optimisation algorithm for estimates of aboveground biomass (AGB) using Sentinel 1A, Landsat images, and ground survey data. A province in the northern part of Vietnam was selected as a case study since the change in land cover has been considered crucial. The models were optimized/trained and validated using statistical indicators, namely, root mean square error (RMSE), coefficient of determination (R2), and mean absolute error (MAE). The trained models were further explained using SHAP values to understand better how they perform and the contribution of each feature to the overall estimates. The results showed that the three indicators of the proposed model were statistically better than those of the reference methods. Specifically, the hybrid model ended up at RMSE ∼13.87, MAE ∼ 10.62, and R2 ∼ 0.79 for the estimation of AGB. Based on the experience, such hybrid integration can be recommended as an alternative solution for biomass estimation. In a broader context, the fast growth of machine learning and optimization algorithms has created new scientifically sound solutions for a better analysis of forest cover. © 2023 Elsevier B.V.","Aboveground biomass; Bayesian optimisations; Gradient boosting; Meta-heuristic optimisation","Viet Nam; aboveground biomass; algorithm; Bayesian analysis; land cover; Landsat; machine learning; satellite imagery; Sentinel","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85179971097"
"Tang Z.; Huang J.; Rinprasertmeechai D.","Tang, Zhenyang (59254561400); Huang, Jinshui (59147255800); Rinprasertmeechai, Denisa (57224776187)","59254561400; 59147255800; 57224776187","Period-aggregated transformer for learning latent seasonalities in long-horizon financial time series","2024","PLoS ONE","19","8","e0308488","","","","0","10.1371/journal.pone.0308488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200925905&doi=10.1371%2fjournal.pone.0308488&partnerID=40&md5=f024f1045a6d2f9a84e3a8d2f1acfa64","Fluctuations in the financial market are influenced by various driving forces and numerous factors. Traditional financial research aims to identify the factors influencing stock prices, and existing works construct a common neural network learning framework that learns temporal dependency using a fixed time window of historical information, such as RNN and LSTM models. However, these models only consider the short-term and point-to-point relationships within stock series. The financial market is a complex and dynamic system with many unobservable temporal patterns. Therefore, we propose an adaptive period-aggregation model called the Latent Period-Aggregated Stock Transformer (LPAST). The model integrates a variational autoencoder (VAE) with a period-to-period attention mechanism for multistep prediction in the financial time series. Additionally, we introduce a self-correlation learning method and routing mechanism to handle complex multi-period aggregations and information distribution. Main contributions include proposing a novel period-aggregation representation scheme, introducing a new attention mechanism, and validating the model’s superiority in long-horizon prediction tasks. The LPAST model demonstrates its potential and effectiveness in financial market prediction, highlighting its relevance in financial research and predictive analytics. © 2024 Tang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Algorithms; Financial Management; Humans; Investments; Models, Economic; Neural Networks, Computer; Seasons; Time Factors; analysis; Article; autoregressive conditional heteroscedasticity; deep learning; financial time; generalized autoregressive conditional heteroscedasticit; information processing; learning; network analysis; nonhuman; principal component analysis; seasonal affective disorder; time; algorithm; artificial neural network; economic model; economics; financial management; human; investment; season; time factor","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85200925905"
"Latif S.; Javaid N.; Aslam F.; Aldegheishem A.; Alrajeh N.; Bouk S.H.","Latif, Saima (57218263133); Javaid, Nadeem (26428797500); Aslam, Faheem (55841775200); Aldegheishem, Abdulaziz (55850984600); Alrajeh, Nabil (36338477200); Bouk, Safdar Hussain (24780719300)","57218263133; 26428797500; 55841775200; 55850984600; 36338477200; 24780719300","Enhanced prediction of stock markets using a novel deep learning model PLSTM-TAL in urbanized smart cities","2024","Heliyon","10","6","e27747","","","","0","10.1016/j.heliyon.2024.e27747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188785510&doi=10.1016%2fj.heliyon.2024.e27747&partnerID=40&md5=4b829f7c38a54d90714046e989105481","Accurate predictions of stock markets are important for investors and other stakeholders of the equity markets to formulate profitable investment strategies. The improved accuracy of a prediction model even with a slight margin can translate into considerable monetary returns. However, the stock markets' prediction is regarded as an intricate research problem for the noise, complexity and volatility of the stocks' data. In recent years, the deep learning models have been successful in providing robust forecasts for sequential data. We propose a novel deep learning-based hybrid classification model by combining peephole LSTM with temporal attention layer (TAL) to accurately predict the direction of stock markets. The daily data of four world indices including those of U.S., U.K., China and India, from 2005 to 2022, are examined. We present a comprehensive evaluation with preliminary data analysis, feature extraction and hyperparameters' optimization for the problem of stock market prediction. TAL is introduced post peephole LSTM to select the relevant information with respect to time and enhance the performance of the proposed model. The prediction performance of the proposed model is compared with that of the benchmark models CNN, LSTM, SVM and RF using evaluation metrics of accuracy, precision, recall, F1-score, AUC-ROC, PR-AUC and MCC. The experimental results show the superior performance of our proposed model achieving better scores than the benchmark models for most evaluation metrics and for all datasets. The accuracy of the proposed model is 96% and 88% for U.K. and Chinese stock markets respectively and it is 85% for both U.S. and Indian markets. Hence, the stock markets of U.K. and China are found to be more predictable than those of U.S. and India. Significant findings of our work include that the attention layer enables peephole LSTM to better identify the long-term dependencies and temporal patterns in the stock markets' data. Profitable and timely trading strategies can be formulated based on our proposed prediction model. © 2024 The Author(s)","Bayesian optimization; Contractive autoencoder; Ensemble empirical mode decomposition; Peephole LSTM; Stock market prediction; Temporal attention layer; Time series; Urban planing","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85188785510"
"Liu W.; Suzuki Y.; Du S.","Liu, Wei (57985001700); Suzuki, Yoshihisa (57214489961); Du, Shuyi (57211125533)","57985001700; 57214489961; 57211125533","Forecasting the Stock Price of Listed Innovative SMEs Using Machine Learning Methods Based on Bayesian optimization: Evidence from China","2024","Computational Economics","63","5","","2035","2068","33","1","10.1007/s10614-023-10393-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153784040&doi=10.1007%2fs10614-023-10393-4&partnerID=40&md5=d42fb4e2397c4cf05d7231595ddb1963","Innovative SMEs have had an important impact on the economies of emerging countries in recent years. In particular, the volatility of their share prices is closely related to economic development and investor behaviors. Therefore, this study takes the Chinese market as an example, after constructing 34 determinants that affect the stock price, the RF, DNN, GBDT, and Adaboost models under Bayesian optimization are employed to forecast the next day's closing price of listed innovative SMEs. The number of samples is 78,708 from 337 SMEs listed on the Chinese SSE STAR market, from July 22, 2019, to September 10, 2021 period. The experimental results show the RF and DNN models perform at a better prediction level than the GBDT and Adaboost models, in terms of the evaluation indicators of R2, RMSE, MAPE, and DA. Then K-fold method and t-tests as robustness checks ensure our experimental results are more reliable and robust. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2023.","Bayesian optimization; Innovative SMEs; K-fold method; Machine learning; Stock price","","Article","Final","","Scopus","2-s2.0-85153784040"
"Roy P.K.; Kumar A.; Singh A.; Sangaiah A.K.","Roy, Pradeep Kumar (56900440500); Kumar, Abhinav (57198891988); Singh, Ashish (57211751093); Sangaiah, Arun Kumar (55616335800)","56900440500; 57198891988; 57211751093; 55616335800","Forecasting Bitcoin Prices Using Deep Learning for Consumer-Centric Industrial Applications","2024","IEEE Transactions on Consumer Electronics","70","1","","1351","1358","7","0","10.1109/TCE.2023.3321653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174817664&doi=10.1109%2fTCE.2023.3321653&partnerID=40&md5=a9c9a9c64f1801a299b4e7bb4c042740","As cryptocurrencies become more popular as investment vehicles, bitcoin draws interest from businesses, consumers, and computer scientists all across the world. Bitcoin is a computer file stored in digital wallet applications where each transaction is secured using strong cryptographic algorithms. It was challenging to forecast the future price of bitcoin due to its nonlinearity and extreme volatility. Several recent classic parametric models have been found with limited accuracy. To address the limitations and fill the existing research gaps, there is a need for a good prediction model which will provide the desired accuracy in the case of uncertainty and dynamism. This research suggested a deep learning-based framework for predicting and forecasting Bitcoin price. The research will be helpful for worldwide consumers and industries to take their decision on whether to invest or not. The research utilizes Yahoo! finance dataset for the period of 01-03-2016 to 26-02-2021 having 1828 samples. The experimental outcomes of the proposed Long Short-Term Memory (LSTM) model outperformed similar deep learning models by securing minimum loss and confirming that it can be used for future price prediction of the cryptocurrencies, which is helpful for the buyer to take their decision. © 1975-2011 IEEE.","bitcoin; cryptocurrency; Deep learning; GRU; LSTM; machine learning","Bitcoin; Costs; Forecasting; Long short-term memory; Computer files; Computer scientists; Consumer-centric; Deep learning; Digital wallets; GRU; Hidden-Markov models; Machine-learning; Predictive models; Hidden Markov models","Article","Final","","Scopus","2-s2.0-85174817664"
"Unjhawala H.; Hansen T.; Zhang H.; Caldraru S.; Chatterjee S.; Bakke L.; Wu J.; Serban R.; Negrut D.","Unjhawala, Huzaifa (58313836300); Hansen, Thomas (57984458400); Zhang, Harry (57984991800); Caldraru, Stefan (58908388500); Chatterjee, Shouvik (58251053100); Bakke, Luning (58629766900); Wu, Jinlong (56093780500); Serban, Radu (6701801877); Negrut, Dan (57207560202)","58313836300; 57984458400; 57984991800; 58908388500; 58251053100; 58629766900; 56093780500; 6701801877; 57207560202","An Expeditious and Expressive Vehicle Dynamics Model for Applications in Controls and Reinforcement Learning","2024","IEEE Access","12","","","33000","33015","15","0","10.1109/ACCESS.2024.3368874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186073636&doi=10.1109%2fACCESS.2024.3368874&partnerID=40&md5=17769c641c71260768f02c76045044ba","We present a Vehicle Model (VM) that has 17 degrees of freedom and includes nonlinear tire and powertrain subsystems. Implemented as a relatively small piece of C++ code, the model runs vehicle dynamics 2000 times faster than real time at a simulation time step of 1 × 10^-3, s on a single core of a commodity CPU. When executed on the GPU, one can perform 300000 vehicle simulations in real-time. These properties make the model a good candidate for reinforcement learning, model predictive control, model predictive path integral control, path planning, state estimation, and traffic simulation tasks. The model is expressive in that it can capture the dynamics of vastly different vehicles. This is demonstrated by first calibrating the model to mimic the dynamics of a 1/6^th scale vehicle called the Autonomy Research Testbed (ART) vehicle, which has a mass of approximately 5.8 kg. Subsequently, the model is calibrated to mimic the dynamics of a heavy-duty High Mobility Multipurpose Wheeled Vehicle (HMMWV), which has a mass of 2097 kg. The Bayesian calibration process discussed can (i) handle real-life measurement noise, and (ii) provide model parameter probability distributions. The vehicle model, which is open source and freely available in a public repository, can also be imported into Python owing to SWIG wrapping.  © 2013 IEEE.","Bayesian inference; calibration; control; machine learning; state estimation; traffic simulation; Vehicle models","Bayesian networks; C++ (programming language); Calibration; Dynamics; Hidden Markov models; Inference engines; Model predictive control; Motion planning; Probability distributions; Reinforcement learning; State estimation; Bayes method; Bayesian inference; Hidden-Markov models; In-control; Machine-learning; Real- time; Traffic simulations; Vehicle dynamics models; Vehicle modelling; Vehicle's dynamics; Degrees of freedom (mechanics)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85186073636"
"Barlybayev A.; Zhetkenbay L.; Karimov D.; Yergesh B.","Barlybayev, Alibek (55866529900); Zhetkenbay, Lena (57191377709); Karimov, Didar (58577325400); Yergesh, Banu (55701931400)","55866529900; 57191377709; 58577325400; 55701931400","DEVELOPMENT NEURO-FUZZY MODEL TO PREDICT THE STOCKS OF COMPANIES IN THE ELECTRIC VEHICLE INDUSTRY","2023","Eastern-European Journal of Enterprise Technologies","4","4(124)","","72","87","15","20","10.15587/1729-4061.2023.281138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171284742&doi=10.15587%2f1729-4061.2023.281138&partnerID=40&md5=4e8183b7c7f7252bc6afee163a3f0d2a","Adaptive neuro-fuzzy inference system (ANFIS) it is a type of neural network that combines the strengths of both fuzzy logic and artificial neural networks. ANFIS is particularly useful in stock trading because it can handle uncertainty and imprecision in the data, which is common in stock market data. In stock trading, ANFIS can be used for a variety of purposes, such as predicting stock prices, identifying profitable trades, and detecting stock market trends. One of the key advantages of using ANFIS for stock trading is that it can handle both linear and non-linear relationships in the data. This is particularly useful in the stock market, where the relationships between different variables are often complex and non-linear. ANFIS can also be updated and retrained as new data becomes available, which allows it to adapt to changing market conditions. Therefore, the main hypothesis of this work is to understand whether it is possible to predict the dynamics of prices for stocks of companies in the electric vehicle (EV) sector using technical analysis indicators. The purpose of this work is to create a model for predicting the prices of companies in the EV sector. The technical analysis indicators were processed by several machine learning models. Linear models generally perform worse than more advanced techniques. Decision trees, whether fine or coarse, tend to yield poorer performance results in terms of RMSE, MSE and MAE. After conducting a data analysis, the ANFIS and Bayesian regularization back propagation Neural Network (BR-BPNN) models were seen to be the most effective. The ANFIS was trained for 2000 epochs which yielded a minimum RMSE of 5.90926 © 2023, Authors. This is an open access article under the Creative Commons CC BY license","adaptive neuro-fuzzy inference system; correlation of technical indicators; electric vehicle sector; neural network; stock price forecasting","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85171284742"
"Gunnarsson E.S.; Isern H.R.; Kaloudis A.; Risstad M.; Vigdel B.; Westgaard S.","Gunnarsson, Elias Søvik (58953749500); Isern, Håkon Ramon (58634665600); Kaloudis, Aristidis (59264093300); Risstad, Morten (57669968000); Vigdel, Benjamin (58953266500); Westgaard, Sjur (24402167300)","58953749500; 58634665600; 59264093300; 57669968000; 58953266500; 24402167300","Prediction of realized volatility and implied volatility indices using AI and machine learning: A review","2024","International Review of Financial Analysis","93","","103221","","","","1","10.1016/j.irfa.2024.103221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188534223&doi=10.1016%2fj.irfa.2024.103221&partnerID=40&md5=16d2fcd43e4fc77dbbf5863b4502e2f2","In this systematic literature review, we examine the existing studies predicting realized volatility and implied volatility indices using artificial intelligence and machine learning. We survey the literature in order to discover whether the proposed methods provide superior forecasts compared to traditional econometric models, how widespread the application of explainable AI is, and to outline potential areas for further research. Generally, we find the efficacy of AI and ML methods for volatility prediction to be highly promising, often providing comparative or better results than their econometric counterparts. Neural networks employing memory, such as Long–Short Term Memory and Gated Recurrent Units, consistently rank among the top performing models. However, traditional econometric models are still highly relevant, commonly yielding similar results as more advanced ML and AI models. In light of the success with ensemble methods, a promising area of research is the use of hybrid models, combining machine learning and econometric models. In spite of the common critique of many machine learning models being of a black-box nature, we find that very few papers apply XAI to analyze and support their empirical results. Thus, we recommend that researchers strive harder to employ XAI in future work. Similarly, we see potential for applications of probabilistic machine learning, effectively quantifying uncertainty in volatility forecasts from machine learning models. © 2024 The Author(s)","Explainable artificial intelligence; Machine learning; Volatility forecasting","","Review","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85188534223"
"Mari C.; Baldassari C.","Mari, Carlo (57201181498); Baldassari, Cristiano (57223865553)","57201181498; 57223865553","Optimization of mixture models on time series networks encoded by visibility graphs: an analysis of the US electricity market","2023","Computational Management Science","20","1","28","","","","1","10.1007/s10287-023-00460-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160746977&doi=10.1007%2fs10287-023-00460-4&partnerID=40&md5=586a722c0394c127d6679380f3598eab","We propose a fully unsupervised network-based methodology for estimating Gaussian Mixture Models on financial time series by maximum likelihood using the Expectation-Maximization algorithm. Visibility graph-structured information of observed data is used to initialize the algorithm. The proposed methodology is applied to the US wholesale electricity market. We will demonstrate that encoding time series through Visibility Graphs allows us to capture the behavior of the time series and the nonlinear interactions between observations well. The results reveal that the proposed methodology outperforms more established approaches. © 2023, The Author(s).","Graph embedding; Graph machine learning; Markov transition field; Topological data analysis; Visibility graph","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85160746977"
"Alarab I.; Prakoonwit S.","Alarab, Ismail (57218836277); Prakoonwit, Simant (7801639285)","57218836277; 7801639285","Graph-Based LSTM for Anti-money Laundering: Experimenting Temporal Graph Convolutional Network with Bitcoin Data","2023","Neural Processing Letters","55","1","","689","707","18","19","10.1007/s11063-022-10904-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132175777&doi=10.1007%2fs11063-022-10904-8&partnerID=40&md5=c95faedc73e9d22659c2a879a648d248","Elliptic data—one of the largest Bitcoin transaction graphs—has admitted promising results in many studies using classical supervised learning and graph convolutional network models for anti-money laundering. Despite the promising results provided by these studies, only few have considered the temporal information of this dataset, wherein the results were not very satisfactory. Moreover, there is very sparse existing literature that applies active learning to this type of blockchain dataset. In this paper, we develop a classification model that combines long-short-term memory with GCN—referred to as temporal-GCN—that classifies the illicit transactions of Elliptic data using its transaction’s features only. Subsequently, we present an active learning framework applied to the large-scale Bitcoin transaction graph dataset, unlike previous studies on this dataset. Uncertainties for active learning are obtained using Monte-Carlo dropout (MC-dropout) and Monte-Carlo based adversarial attack (MC-AA) which are Bayesian approximations. Active learning frameworks with these methods are compared using various acquisition functions that appeared in the literature. To the best of our knowledge, MC-AA method is the first time to be examined in the context of active learning. Our main finding is that temporal-GCN model has attained significant success in comparison to the previous studies with the same experimental settings on the same dataset. Moreover, we evaluate the performance of the provided acquisition functions using MC-AA and MC-dropout and compare the result against the baseline random sampling model. © 2022, The Author(s).","Active learning; Anti-money laundering; Bitcoin data; Temporal GCN; Uncertainty estimation","Bitcoin; Convolution; Graphic methods; Large dataset; Laundering; Learning systems; Long short-term memory; Active Learning; Anti-money laundering; Bitcoin data; Convolutional networks; Graph-based; Learning frameworks; Network models; Temporal GCN; Temporal graphs; Uncertainty estimation; Monte Carlo methods","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85132175777"
"Zhang W.; Li L.; Zhang G.","Zhang, Wenyong (57225064612); Li, Lingfei (55962544900); Zhang, Gongqiu (56849577000)","57225064612; 55962544900; 56849577000","A two-step framework for arbitrage-free prediction of the implied volatility surface","2023","Quantitative Finance","23","1","","21","34","13","3","10.1080/14697688.2022.2135454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141355133&doi=10.1080%2f14697688.2022.2135454&partnerID=40&md5=3e9920c87e2c10f0528319cc71ab837b","In this study, we propose a two-step framework to predict the implied volatility surface (IVS) in a manner that excludes static arbitrage. First, we select features to represent the surface and predict them. Second, we use the predicted features to construct the IVS using a deep neural network (DNN) model by incorporating constraints that can prevent static arbitrage. We consider three methods to extract features from the implied volatility data: principal component analysis, variational autoencoder, and sampling the surface. We predict these features using the long short-term memory model. Additionally, we use a long time series of implied volatility data for S&P500 index options to train our models. We find that two feature construction methods (i.e. sampling the surface and variational autoencoders combined with DNN for surface construction) are the best performers in the out-of-sample prediction. Furthermore, both of them substantially outperform a popular regression model. We also find that the DNN model for surface construction not only removes static arbitrage but also significantly reduces the prediction error compared with a standard interpolation method. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Deep learning; Implied volatility surface; Prediction; Static arbitrage; Variational autoencoder","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85141355133"
"Tripathi B.; Sharma R.K.","Tripathi, Bhaskar (57946067300); Sharma, Rakesh Kumar (57214842940)","57946067300; 57214842940","Modeling Bitcoin Prices using Signal Processing Methods, Bayesian Optimization, and Deep Neural Networks","2023","Computational Economics","62","4","","1919","1945","26","15","10.1007/s10614-022-10325-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140845132&doi=10.1007%2fs10614-022-10325-8&partnerID=40&md5=8c9af76c14c96625ccbd234826b06903","Bitcoin is a volatile financial asset that runs on a decentralized peer-to-peer Blockchain network. Investors need accurate price forecasts to minimize losses and maximize profits. Extreme volatility, speculative nature, and dependence on intrinsic and external factors make Bitcoin price forecast challenging. This research proposes a reliable forecasting framework by reducing the inherent noise in Bitcoin time series and by examining the predictive power of three distinct types of predictors, namely fundamental indicators, technical indicators, and univariate lagged prices. We begin with a three-step hybrid feature selection procedure to identify the variables with the highest predictive ability, then use Hampel and Savitzky–Golay filters to impute outliers and remove signal noise from the Bitcoin time series. Next, we use several deep neural networks tuned by Bayesian Optimization to forecast short-term prices for the next day, three days, five days, and seven days ahead intervals. We found that the Deep Artificial Neural Network model created using technical indicators as input data outperformed other benchmark models like Long Short Term Memory, Bi-directional LSTM (BiLSTM), and Convolutional Neural Network (CNN)-BiLSTM. The presented results record a high accuracy and outperform all existing models available in the past literature with an absolute percentage error as low as 0.28% for the next day forecast and 2.25% for the seventh day for the latest out of sample period ranging from Jan 1, 2021, to Nov 1, 2021. With contributions in feature selection, data-preprocessing, and hybridizing deep learning models, this work contributes to researchers and traders in fundamental and technical domains. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Bayesian optimization; Deep learning; Outlier detection; Savitzky–Golay Filter; Time series forecasting","","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85140845132"
"Sen A.; Dutta Choudhury K.","Sen, Abhibasu (57219586238); Dutta Choudhury, Karabi (56550043000)","57219586238; 56550043000","A case study of Gulf Securities Market in the last 20 years: A Long Short-Term Memory approach","2024","Statistica Neerlandica","78","1","","136","166","30","1","10.1111/stan.12309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162068221&doi=10.1111%2fstan.12309&partnerID=40&md5=7af8104eb573da2f6708f51b32e3fcf8","Various researches have been conducted on forecasting stock prices. Several tools ranging from statistical techniques to quantitative methods have been used by researchers to forecast the market. But so far, very little research has been done on forecasting the stock markets of the Gulf countries such as Saudi Arabia, United Arab Emirates, Oman, Kuwait, Bahrain, and Qatar. Our approach is to predict the market indices of the Gulf countries using Long Short-Term Memory (LSTM) techniques. Thereafter, we optimized the hyperparameters of the LSTM technique using various optimization methods such as Grid Search and Bayesian Optimization with Gaussian Process and found out the best-suited hyperparameter for the LSTM model. We tried the LSTM method for predicting the indices using data from the last twenty years. © 2023 Netherlands Society for Statistics and Operations Research.","deep learning; hyperparameter optimization; LSTM; Middle East markets; stock market prediction","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85162068221"
"Peng C.; Gui L.; Sheng B.; Guo Z.; Xiao F.","Peng, Cheng (58663881700); Gui, Linqing (36632142800); Sheng, Biyun (57217373007); Guo, Zhengxin (57195472491); Xiao, Fu (7201709602)","58663881700; 36632142800; 57217373007; 57195472491; 7201709602","RoSeFi: A Robust Sedentary Behavior Monitoring System With Commodity WiFi Devices","2024","IEEE Transactions on Mobile Computing","23","5","10269067","6470","6489","19","0","10.1109/TMC.2023.3321306","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174824103&doi=10.1109%2fTMC.2023.3321306&partnerID=40&md5=acf5820d8af8f824782399502ba7af40","Sedentary behaviors are shown to be hazardous to human health. Detecting sedentary behaviors in a ubiquitous way can be realized by the promising WiFi sensing technique. The accurate detection of sedentary behaviors is determined by the accurate recognition of sit-stand postural transition (SPT). However, according to our findings, SPT recognition errors are inevitable even with advanced machine-learning methods, because different SPTs may result in a similar change in WiFi channel state information (CSI). To effectively reduce SPT recognition errors, in this paper we propose RoSeFi, a robust sedentary behavior monitoring system. We first classify the errors in SPT recognition results into two categories: the errors violating SPT's consistency and the errors violating SPTs' symmetry. To correct the above errors, we reveal two inherent features in the CSI data of SPTs, i.e., contextual association and waveform mirror symmetry. Then a novel metric named WMSF is defined to quantify the degree of waveform mirror symmetry between two SPTs' CSI data. Integrating the above features, the problem of recognition error correction can be modeled as a constrained nonlinear optimization problem (CNOP). To solve the problem, we design a unified error detection/correction scheme, named UEDC, which converts the CNOP into a sequence decoding problem in Hidden Markov Model (HMM). A tailored Viterbi algorithm combined with WMSF is proposed to detect and correct the errors simultaneously. The experimental results show that RoseFi reduces 60-82% SPT recognition errors, gains 15-20% relative improvement in the accuracy of SPT recognition, and eventually reduces the sedentary time estimation errors by 10%-20%, compared with typical existing systems. In addition, our error correction method can be adapted to most existing machine learning based human action recognition methods, effectively improving their performance. © 2023 IEEE.","channel state information; recognition error correction; Sedentary behavior monitoring; sit-stand transition recognition; WiFi","Behavioral research; Constrained optimization; Error correction; Hidden Markov models; Learning algorithms; Machine learning; Mirrors; Nonlinear programming; Simulated annealing; Viterbi algorithm; Wi-Fi; Wireless local area networks (WLAN); Behavioral science; Behaviour monitoring; Channel-state information; Errors correction; Hidden-Markov models; Human activity recognition; Recognition error; Recognition error correction; Sedentary behavior monitoring; Sit-stand transition recognition; Wifi; Wireless fidelities; Channel state information","Article","Final","","Scopus","2-s2.0-85174824103"
"Polamuri S.R.; Srinivas D.K.; Krishna Mohan D.A.","Polamuri, Subba Rao (57211397513); Srinivas, Dr. Kudipudi (56708183800); Krishna Mohan, Dr. A. (57193388690)","57211397513; 56708183800; 57193388690","Multi-Model Generative Adversarial Network Hybrid Prediction Algorithm (MMGAN-HPA) for stock market prices prediction","2022","Journal of King Saud University - Computer and Information Sciences","34","9","","7433","7444","11","35","10.1016/j.jksuci.2021.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110410701&doi=10.1016%2fj.jksuci.2021.07.001&partnerID=40&md5=294dd33605070bf6e9100c700e284179","Deep learning has achieved greater success in optimizing solutions associated with Artificial Intelligence (AI). In the financial domain, it is widely used for stock market prediction, trade execution strategies and portfolio optimization. Stock market prediction is a very significant use case in this domain. Generative Adversarial Networks (GANs) with advanced AI models have gained significance of late. However, it is used in image-image-translation and other computer vision scenarios. GANs are not used much for stock market prediction due to its difficulty in setting the right set of hyperparameters. In this paper, overcome this problem with reinforcement learning and Bayesian optimization. A deep learning framework based on GAN, named Stock-GAN, is implemented with generator and discriminator. The former is realized with LSTM, a variant of Recurrent Neural Network (RNN), while the latter uses Convolutional Neural Network. An algorithm named Generative Adversarial Network based Hybrid Prediction Algorithm (GAN-HPA) is proposed. An empirical study revealed that Stock-GAN achieves promising performance in stock price prediction when compared with the state of the art model known as Multi-Model based Hybrid Prediction Algorithm (MM-HPA). Afterwards, MM-HPA and GAN-HPA combined to form yet another hybrid model known as MMGAN-HPA for improved performance over MM-HPA and GAN-HPA. © 2021 The Authors","Convolutional Neural Network (CNN); Deep learning; Generative Adversarial Network (GAN); Recurrent Neural Network (RNN); Stock market analysis","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85110410701"
"Renkema Y.; Brinkel N.; Alskaif T.","Renkema, Yvet (58988735800); Brinkel, Nico (57212489442); Alskaif, Tarek (56652204500)","58988735800; 57212489442; 56652204500","Conformal prediction for stochastic decision-making of PV power in electricity markets","2024","Electric Power Systems Research","234","","110750","","","","0","10.1016/j.epsr.2024.110750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196662535&doi=10.1016%2fj.epsr.2024.110750&partnerID=40&md5=fead7b5d7e0ecc5119a19220aabbf07f","This paper studies the use of conformal prediction (CP), an emerging probabilistic forecasting method, for day-ahead photovoltaic power predictions to enhance participation in electricity markets. First, machine learning models are used to construct point predictions. Thereafter, several variants of CP are implemented to quantify the uncertainty of those predictions by creating CP intervals and cumulative distribution functions. Optimal quantity bids for the electricity market are estimated using several bidding strategies under uncertainty, namely: trust-the-forecast, worst-case, Newsvendor and expected utility maximization (EUM). Results show that CP in combination with k-nearest neighbors and/or Mondrian binning outperforms its corresponding linear quantile regressors. Using CP in combination with certain bidding strategies can yield high profit with minimal energy imbalance. In concrete, using conformal predictive systems with k-nearest neighbors and Mondrian binning after random forest regression yields the best profit and imbalance regardless of the decision-making strategy. Combining this uncertainty quantification method with the EUM strategy with conditional value at risk (CVaR) can yield up to 93% of the potential profit with minimal energy imbalance. © 2024 The Author(s)","Conformal prediction; Electricity markets; Machine learning; Photovoltaic power; Stochastic optimization","Decision making; Distribution functions; Forecasting; Motion compensation; Nearest neighbor search; Power markets; Profitability; Uncertainty analysis; Value engineering; Bidding strategy; Conformal predictions; Expected utility; Machine-learning; Minimal energy; Mondrian; Photovoltaic power; Stochastic optimizations; Uncertainty; Utility maximizations; Machine learning","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85196662535"
"Xin J.; Frangopol D.M.; Akiyama M.; Han X.","Xin, Jiyu (57209108527); Frangopol, Dan M. (7103084807); Akiyama, Mitsuyoshi (35784056100); Han, Xu (57209237266)","57209108527; 7103084807; 35784056100; 57209237266","Probabilistic Life-Cycle Connectivity Assessment of Transportation Networks Using Deep Learning","2023","Journal of Bridge Engineering","28","9","04023066","","","","4","10.1061/JBENF2.BEENG-6149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165509056&doi=10.1061%2fJBENF2.BEENG-6149&partnerID=40&md5=74b1b659cab37557e3f47f5d1c58e9f3","Bridges and pavements are two major infrastructure components of a transportation network providing mobility of freight and commodities for economic vitality and access to a range of users as social benefits. However, the lack of a comprehensive infrastructure management system incorporating bridges and pavements inhibits accurate performance prediction, optimal maintenance actions, and the associated use of shrinking budgets. This paper presents an integrated probabilistic life-cycle connectivity framework for the performance analysis of transportation networks containing bridges and asphalt pavements by considering flexural and shear failure modes for prestressed concrete and steel bridges and four failure modes, including international roughness index, rut depth, alligator cracking, and transverse cracking, for asphalt pavements. In this framework, neural network-based deep learning models are used to assess the probabilistic performance of transportation networks and to provide guidance for the associated maintenance strategies. An existing transportation network consisting of bridges and asphalt pavement segments is selected to investigate its life-cycle connectivity reliability and component importance using the matrix-based system reliability method. Results show that the consideration of asphalt pavement failure probability has a significant effect on the probability of transportation network connectivity. © 2023 American Society of Civil Engineers.","Asphalt pavement; Bridge; Connectivity; Deep learning; Neural networks; System reliability; Transportation network","Asphalt; Asphalt pavements; Budget control; Deep neural networks; Learning systems; Prestressed concrete; Accurate performance; Connectivity; Deep learning; Economic vitality; Infrastructure management system; Neural-networks; Probabilistics; Social benefits; System reliability; Transportation network; Life cycle","Article","Final","","Scopus","2-s2.0-85165509056"
"Wen J.; Abeel T.; de Weerdt M.","Wen, Junhan (58184605400); Abeel, Thomas (18533730700); de Weerdt, Mathijs (6508150096)","58184605400; 18533730700; 6508150096","“How sweet are your strawberries?”: Predicting sugariness using non-destructive and affordable hardware","2023","Frontiers in Plant Science","14","","1160645","","","","2","10.3389/fpls.2023.1160645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152522706&doi=10.3389%2ffpls.2023.1160645&partnerID=40&md5=7a60b397c85a66b902ef7175aa0f6f79","Global soft fruit supply chains rely on trustworthy descriptions of product quality. However, crucial criteria such as sweetness and firmness cannot be accurately established without destroying the fruit. Since traditional alternatives are subjective assessments by human experts, it is desirable to obtain quality estimations in a consistent and non-destructive manner. The majority of research on fruit quality measurements analyzed fruits in the lab with uniform data collection. However, it is laborious and expensive to scale up to the level of the whole yield. The “harvest-first, analysis-second” method also comes too late to decide to adjust harvesting schedules. In this research, we validated our hypothesis of using in-field data acquirable via commodity hardware to obtain acceptable accuracies. The primary instance that the research concerns is the sugariness of strawberries, described by the juice’s total soluble solid (TSS) content (unit: °Brix or Brix). We benchmarked the accuracy of strawberry Brix prediction using convolutional neural networks (CNN), variational autoencoders (VAE), principal component analysis (PCA), kernelized ridge regression (KRR), support vector regression (SVR), and multilayer perceptron (MLP), based on fusions of image data, environmental records, and plant load information, etc. Our results suggest that: (i) models trained by environment and plant load data can perform reliable prediction of aggregated Brix values, with the lowest RMSE at 0.59; (ii) using image data can further supplement the Brix predictions of individual fruits from (i), from 1.27 to as low up to 1.10, but they by themselves are not sufficiently reliable. Copyright © 2023 Wen, Abeel and de Weerdt.","computer vision; crop management; data fusion; feature selection; in-field test; machine learning; non-destructive analysis; total soluble solid","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85152522706"
"Faridi S.; Madanchi Zaj M.; Daneshvar A.; Shahverdiani S.; Rahnamay Roodposhti F.","Faridi, Sanaz (57962347500); Madanchi Zaj, Mahdi (57226769296); Daneshvar, Amir (57226774952); Shahverdiani, Shadi (57224769682); Rahnamay Roodposhti, Fereydoon (36873169700)","57962347500; 57226769296; 57226774952; 57224769682; 36873169700","Portfolio rebalancing based on a combined method of ensemble machine learning and genetic algorithm","2023","Journal of Financial Reporting and Accounting","21","1","","105","125","20","10","10.1108/JFRA-11-2021-0413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141756313&doi=10.1108%2fJFRA-11-2021-0413&partnerID=40&md5=d84a8b245a85d3e1b7b3177a297bf56c","Purpose: This paper presents a combined method of ensemble learning and genetics to rebalance the corporate portfolio. The primary purpose of this paper is to determine the amount of investment in each of the shares of the listed company and the time of purchase, holding or sale of shares to maximize total return and reduce investment risk. Design/methodology/approach: To achieve the goals of the problem, a two-level combined intelligent method, such as a support vector machine, decision tree, network Bayesian, k-nearest neighbors and multilayer perceptron neural network as heterogeneous basic models of ensemble learning in the first level, was applied. Then, the majority vote method (weighted average) in the second stage as the final model of learning was collectively used. Therefore, the data collected from 208 listed companies active in the Tehran stock exchange (http://tsetmc.com) from 2011 to 2015 have been used to teach the data. For testing and analysis, the data of the same companies between 2016 and 2020 have been used. Findings: The results showed that the method of combined ensemble learning and genetics has the highest total stock portfolio yield of 114.12%, with a risk of 0.905%. Also, by examining the rate of return on capital, it was observed that the proposed method has the highest average rate of return on investment of 110.64%. As a result, the proposed method leads to higher returns with lower risk than the purchase and maintenance method for fund managers and companies and predicts market trends. Research limitations/implications: In the forthcoming research, there were no limitations to obtain research data were easily extracted from the site of Tehran Stock Exchange Technology Management Company and Rahvard Novin software, and simulation was performed in MATLAB software. Practical implications: In this paper, using combined machine learning methods, companies’ stock prices are predicted and stock portfolio optimization is optimized. As companies and private organizations are trying to increase their rate of return, so they need a way to predict stock prices based on specific indicators. It turned out that this algorithm has the highest stock portfolio return with reasonable investment risk, and therefore, investors, portfolio managers and market timers can be used this method to optimize the stock portfolio. Social implications: The homogeneous and heterogeneous two-level hybrid model presented in the research can be used to predict market trends by market timers and fund managers. Also, adjusting the portfolio with this method has a much higher return than the return on buying and holding, and with controlled risk, it increases the security of investors’ capital, and investors invest their capital in the funds more safely. And will achieve their expected returns. As a result, the psychological security gained from using this method for portfolio arrangement will eventually lead to the growth of the capital market. Originality/value: This paper tries to present the best combination of stock portfolios of active companies of the Tehran Stock Exchange by using the two-level combined intelligent method and genetic algorithm. © 2022, Emerald Publishing Limited.","Combined learning methods; Ensemble learning; Market timing; Portfolio balancing","","Article","Final","","Scopus","2-s2.0-85141756313"
"Gadi M.F.A.; Sicilia M.A.","Gadi, Manoel Fernando Alonso (58029780100); Sicilia, Miguel Angel (8266687800)","58029780100; 8266687800","Annotators' Selection Impact on the Creation of a Sentiment Corpus for the Cryptocurrency Financial Domain","2023","IEEE Access","11","","","131081","131088","7","1","10.1109/ACCESS.2023.3334260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178064848&doi=10.1109%2fACCESS.2023.3334260&partnerID=40&md5=35ea96dada8d325d4caa6176c8890097","Well labeled natural language corpus data is essential for most natural language processing techniques, especially in specialized fields. However, cohort biases remain a significant challenge in machine learning. The narrow origin of data sampling or human annotators in cohorts is a prevalent issue for machine learning researchers due to its potential to induce bias in the final product. During the development of the CryptoLin corpus for another research project, the authors became concerned about the potential influence of cohort bias on the selection of annotators. Therefore, this paper addresses the question of whether cohort diversity improves the labeling result through the implementation of a repeated annotator process, involving two annotator cohorts and a statistically robust comparison methodology. The utilization of statistical tests, such as the Chi-Square Independence test for absolute frequency tables, and the construction of confidence intervals for Kappa point estimates, facilitates a rigorous analysis of the differences between Kappa estimates. Furthermore, the application of a two-proportion z-test to compare the accuracy scores of UTAD and IE annotators for various pre-trained models, including Vader Sentiment Analysis, TextBlob Sentiment Analysis, Flair NLP library, and FinBERT Financial Sentiment Analysis with BERT, contributes to the advancement of knowledge in this field. The paper utilizes Cryptocurrency Linguo (CryptoLin), a corpus containing 2683 cryptocurrency-related news articles spanning more than three years, and compares two different selection criteria for the annotators. CryptoLin was annotated twice with discrete values representing negative, neutral, and positive news respectively. The first annotation was done by twenty-seven annotators from the same cohort. Each news title was randomly assigned and blindly annotated by three human annotators. The second annotation was carried out by eighty-three annotators from three cohorts. Each news title was randomly assigned and blindly annotated by three human annotators, one in each different cohort. In both annotations, a consensus mechanism using simple voting was applied. The first annotation used the same cohort with students from the same nationality and background. The second used three cohorts with students from a very diverse set of nationalities and educational backgrounds. The results demonstrate that manual labeling done by both groups was acceptable according to inter-rater reliability coefficients Fleiss's Kappa, Krippendorff's Alpha, and Gwet's AC1. Preliminary analysis utilizing Vader, Textblob, Flair, and FinBERT confirmed the utility of the data set labeling for further refinement of sentiment analysis algorithms. Our results also highlight that the more diverse annotator pool performed better in all measured aspects. © 2013 IEEE.","Annotation; annotator selection criteria; cryptocurrency; labeled data set; news event; news sentiment corpus; NLP","Data mining; Learning systems; Linguistics; Machine learning; Students; Annotation; Annotator selection criteria; Data set; Labeled data; Labeled data set; Natural languages; News event; News sentiment corpus; Selection criteria; Sentiment analysis; Sentiment analysis","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85178064848"
"Preethi G.; Santhi B.","Preethi, G. (57310220800); Santhi, B. (53664579800)","57310220800; 53664579800","Stock market forecasting techniques: A survey","2012","Journal of Theoretical and Applied Information Technology","46","1","","24","30","6","37","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874513449&partnerID=40&md5=a2c53b02d78af944d4f3b2042853fd70","This paper surveys recent literature in the area of Neural Network, Data Mining, Hidden Markov Model and Neuro-Fuzzy system used to predict the stock market fluctuation. Neural Networks and Neuro-Fuzzy systems are identified to be the leading machine learning techniques in stock market index prediction area. The Traditional techniques are not cover all the possible relation of the stock price fluctuations. There are new approaches to known in-depth of an analysis of stock price variations. NN and Markov Model can be used exclusively in the finance markets and forecasting of stock price. In this paper, we propose a forecasting method to provide better an accuracy rather traditional method. © 2005 - 2012 JATIT & LLS. All rights reserved.","And time series analysis; Data mining; Forecasting techniques; Markov model; Neuro-fuzzy systems; Stock market prediction","Data mining; Finance; Forecasting; Fuzzy systems; Hidden Markov models; Learning systems; Neural networks; Surveys; Time series analysis; Forecasting methods; Forecasting techniques; Machine learning techniques; Markov model; Neurofuzzy system; New approaches; Paper surveys; Stock market; Stock market forecasting; Stock market index; Stock market prediction; Stock price; Stock price fluctuation; Traditional techniques; Commerce","Article","Final","","Scopus","2-s2.0-84874513449"
"Suphawan K.; Kardkasem R.; Chaisee K.","Suphawan, Kamonrat (57226275669); Kardkasem, Ruethaichanok (57490530500); Chaisee, Kuntalee (57201469777)","57226275669; 57490530500; 57201469777","A Gaussian Process Regression Model for Forecasting Stock Exchange of Thailand","2022","Trends in Sciences","19","6","3045","","","","2","10.48048/tis.2022.3045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126455682&doi=10.48048%2ftis.2022.3045&partnerID=40&md5=fa0ca5464a82f0a5822d56f4220d2696","A stock price index measures the change in several share prices, which can describe the market and assist investors in deciding on a specific investment. Thus, foreseeing the stock price index benefits investors in creating a better investment strategy. However, forecasting the stock price index can be challenging due to its non-linearity, non-stationary and high uncertainty. Gaussian process regression (GPR) is an attractive and powerful approach for prediction, especially when the data fluctuates over time with fewer restrictions. Besides, the GPR gains advantages over other forecasting techniques as it can offer predictions with uncertainty to provide margin errors. In this study, we evaluate the use of GPR to predict the stock price of Thailand (SET). The SET data are divided into 2 datasets; the data in the year 2015-2020 and the data in the year 2020 due to the massive change during the COVID-19 pandemic. The prediction results from the GPR are then compared to the machine learning approaches, artificial neural network (ANN) and recurrent neural network (RNN) using evaluation scores; the root mean square error (RMSE), the mean absolute error (MAE), the mean absolute percentage error (MAPE) and the Nash-Sutcliffe efficiency (NSE). The results indicate that the GPR is superior to the ANN and RNN for both datasets as it provides a high prediction accuracy. Moreover, the results suggest that the GPR is less sensitive to the number of input lags in the model. Therefore, the GPR is more favorable for the prediction of SET than the ANN and RNN. © 2022, Walailak University. All rights reserved.","Artificial neural network; Gaussian process regression; Recurrent neural network; Stock price index","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85126455682"
"Li L.; Muwafak B.M.","Li, Liangxiong (57477933900); Muwafak, Bishr Muhamed (57856511300)","57477933900; 57856511300","Adoption of deep learning Markov model combined with copula function in portfolio risk measurement","2021","Applied Mathematics and Nonlinear Sciences","","","","","","","1","10.2478/amns.2021.1.00085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125786433&doi=10.2478%2famns.2021.1.00085&partnerID=40&md5=4e4c06e19e683fbc8cf1785b5c5b34f7","In order to accurately describe the risk dependence structure and correlation between financial variables, a scientific financial risk assessment was carried out, and the basis for accurate financial decision-making was provided; the basic theory of copula function is established first, and the mixed copula model is constructed; then, the hybrid copula model is nested in a hidden Markov model (HMM); the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio; finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed copula model based on the HMM is more effective than the single copula model and the mixed copula model. The empirical structure shows that among the four major financial industries in China, banking and insurance industries have strong interdependence and a high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by the Copula-Garch model is 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of the deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56%, respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion so that the macro or systemic risks may arise, and the deep learning Markov model can be adopted to predict the stock prices.  © 2021 Liangxiong Li et al., published by Sciendo 2021.","financial index; HMM; investment failure rate; mixed copula model; risk contagion","Costs; Decision making; Decision theory; Deep learning; Failure analysis; Financial markets; Forecasting; Hidden Markov models; Risk assessment; Roller bearings; Copula functions; Copula models; Failure rate; Financial index; Hidden-Markov models; Investment failure rate; Markov modeling; Mixed copula model; Mixed copulas; Risk contagion; Investments","Article","Article in press","","Scopus","2-s2.0-85125786433"
"Jang H.; Lee J.","Jang, Huisu (57196702616); Lee, Jaewook (8852130600)","57196702616; 8852130600","Generative Bayesian neural network model for risk-neutral pricing of American index options","2019","Quantitative Finance","19","4","","587","603","16","25","10.1080/14697688.2018.1490807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057339267&doi=10.1080%2f14697688.2018.1490807&partnerID=40&md5=5995c1c1382d9d62fadafc45a9d14934","Financial models with stochastic volatility or jumps play a critical role as alternative option pricing models for the classical Black–Scholes model, which have the ability to fit different market volatility structures. Recently, machine learning models have elicited considerable attention from researchers because of their improved prediction accuracy in pricing financial derivatives. We propose a generative Bayesian learning model that incorporates a prior reflecting a risk-neutral pricing structure to provide fair prices for the deep ITM and the deep OTM options that are rarely traded. We conduct a comprehensive empirical study to compare classical financial option models with machine learning models in terms of model estimation and prediction using S&P 100 American put options from 2003 to 2012. Results indicate that machine learning models demonstrate better prediction performance than the classical financial option models. Especially, we observe that the generative Bayesian neural network model demonstrates the best overall prediction performance. © 2018, © 2018 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","American index option market; Financial option models; Generative Bayesian learning; Machine Learning; Option pricing","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85057339267"
"Daniali S.M.; Barykin S.E.; Kapustina I.V.; Khortabi F.M.; Sergeev S.M.; Kalinina O.V.; Mikhaylov A.; Veynberg R.; Zasova L.; Senjyu T.","Daniali, Sara Mehrab (57207846277); Barykin, Sergey Evgenievich (57202814691); Kapustina, Irina Vasilievna (57194710660); Khortabi, Farzin Mohammadbeigi (57207846263); Sergeev, Sergey Mikhailovich (57200788956); Kalinina, Olga Vladimirovna (57190621094); Mikhaylov, Alexey (57214766800); Veynberg, Roman (55151132000); Zasova, Liubov (57219782668); Senjyu, Tomonobu (7004938207)","57207846277; 57202814691; 57194710660; 57207846263; 57200788956; 57190621094; 57214766800; 55151132000; 57219782668; 7004938207","Predicting volatility index according to technical index and economic indicators on the basis of deep learning algorithm","2021","Sustainability (Switzerland)","13","24","14011","","","","42","10.3390/su132414011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121520323&doi=10.3390%2fsu132414011&partnerID=40&md5=196a62bb4de4019279466b468732d66c","The Volatility Index (VIX) is a real-time index that has been used as the first measure to quantify market expectations for volatility, which affects the financial market as a main actor of the overall economy that is sensitive to the environmental and social aspects of investors and companies. The VIX is calculated using option prices for the S&P 500 Index (SPX) and is expressed as a percentage. Taking into account that VIX only shows the implicit volatility of the S&P 500 for the next 30 days, the authors develop a model for a near-optimal state trying to avoid uncertainty and insufficient accuracy. The researchers are trying to make a contribution to the theory of socially responsible portfolio management. The developed approach allows potential investments to make decisions regarding such important topics as ethical investing, performance analysis, as well as sustainable investment strategies. The approach of this research allows to use deep probabilistic convolutional neural networks based on conditional variance as a linear function of errors with the aim of estimating and predicting the VIX. For this purpose, the use of technical indicators and economic indexes such as Chicago Board Options Exchange (CBOE) VIX and S&P 500 is considered. The results of estimating and predicting the VIX with the proposed method indicate high precision and create a certainty in modeling to achieve the goals. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolution of probability; Deep neural network; Sustainable financial markets; Volatility index","Chicago; Illinois; United States; artificial nest; artificial neural network; economic conditions; financial market; index method; market conditions; spatiotemporal analysis; strategic approach; sustainability","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121520323"
"Reddi S.K.; Babu C.R.","Reddi, Sowmya Kethi (58203679300); Babu, Ch Ramesh (58204010000)","58203679300; 58204010000","Meta-Heuristic-Based Hybrid Resnet with Recurrent Neural Network for enhanced Stock Market Prediction","2022","International Journal of Distributed Systems and Technologies","13","1","","","","","0","10.4018/IJDST.307152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153950231&doi=10.4018%2fIJDST.307152&partnerID=40&md5=05ab86b0abc6d2ee1e742ec761c6d1b6","This paper is to design a new hybrid deep learning model for stock market prediction. Initially, the collected stock market data from the benchmark sources are pre-processed using empirical wavelet transform (EWT). This pre-processed data is subjected to the prediction model based on hybrid deep learning approach by adopting Resnet and recurrent neural network (RNN). Here, the fully connected layer of Resnet is replaced with the RNN. In both the Resnet and RNN structures, the parameter is optimized using the probabilistic spider monkey optimization (P-SMO) for attaining accurate prediction. When analyzing the proposed P-SMO-ResRNN, it secures 6.27%, 12.26%, 15.13%, 13.61%, and 14.10% more than RNN, DNN, NN, KNN, and SVM, respectively, regarding the MASE analysis. Hence, the proposed model shows enhanced performance. With the elaborated model and estimation of prediction term based on several analyses, this work supports the stock analysis research community. Copyright © 2022, IGI Global.","Hybrid Deep Learning; Probabilistic Spider Monkey Optimization; Recurrent Neural Network; Resnet","Commerce; Financial markets; Forecasting; Optimization; Support vector machines; Wavelet transforms; Hybrid deep learning; Learning models; Market data; Metaheuristic; Optimisations; Probabilistic spider monkey optimization; Probabilistics; Resnet; Stock market prediction; Wavelets transform; Recurrent neural networks","Article","Final","","Scopus","2-s2.0-85153950231"
"Gunduz H.","Gunduz, Hakan (56247222800)","56247222800","An efficient stock market prediction model using hybrid feature reduction method based on variational autoencoders and recursive feature elimination","2021","Financial Innovation","7","1","28","","","","40","10.1186/s40854-021-00243-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104605211&doi=10.1186%2fs40854-021-00243-3&partnerID=40&md5=0d9332a799bf1a24f74722734ffef844","In this study, the hourly directions of eight banking stocks in Borsa Istanbul were predicted using linear-based, deep-learning (LSTM) and ensemble learning (LightGBM) models. These models were trained with four different feature sets and their performances were evaluated in terms of accuracy and F-measure metrics. While the first experiments directly used the own stock features as the model inputs, the second experiments utilized reduced stock features through Variational AutoEncoders (VAE). In the last experiments, in order to grasp the effects of the other banking stocks on individual stock performance, the features belonging to other stocks were also given as inputs to our models. While combining other stock features was done for both own (named as allstock_own) and VAE-reduced (named as allstock_VAE) stock features, the expanded dimensions of the feature sets were reduced by Recursive Feature Elimination. As the highest success rate increased up to 0.685 with allstock_own and LSTM with attention model, the combination of allstock_VAE and LSTM with the attention model obtained an accuracy rate of 0.675. Although the classification results achieved with both feature types was close, allstock_VAE achieved these results using nearly 16.67% less features compared to allstock_own. When all experimental results were examined, it was found out that the models trained with allstock_own and allstock_VAE achieved higher accuracy rates than those using individual stock features. It was also concluded that the results obtained with the VAE-reduced stock features were similar to those obtained by own stock features. © 2021, The Author(s).","Borsa Istanbul; LightGBM; Long-short term memory; Recursive feature elimination; Stock market prediction; Variational autoencoder","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104605211"
"Wang D.; Wang P.; Yuan Y.; Wang P.; Shi J.","Wang, Di (57205570363); Wang, Ping (57202998642); Yuan, Yue (56587171400); Wang, Pingping (57211551891); Shi, Junzhi (56366316300)","57205570363; 57202998642; 56587171400; 57211551891; 56366316300","A fast conformal predictive system with regularized extreme learning machine","2020","Neural Networks","126","","","347","361","14","14","10.1016/j.neunet.2020.03.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083000530&doi=10.1016%2fj.neunet.2020.03.022&partnerID=40&md5=0f57c6619ee7aa3a3e2f4ad1ff29a8b7","A conformal predictive system(CPS) is based on the learning framework of conformal prediction, which outputs cumulative distribution functions(CDFs) for labels in regression problems. The CDFs output by a CPS provide useful information for users, as they not only provide probability for the events related to the test labels, but also can be transformed to prediction intervals with the corresponding quantiles. Moreover, CPSs have the property of validity since the distributions and intervals they output have statistical compatibility with the realizations. This property is very useful for many risk-sensitive applications such as financial time series forecast and weather forecast. However, as based on conformal predictors, CPSs inherit the computational issue. To build a fast CPS, in this paper, we propose a CPS with regularized extreme learning machine as the underlying algorithm. To be specific, we combine the leave-one-out cross-conformal predictive system(Leave-One-Out CCPS), a variant of the original CPS, with regularized extreme learning machine(RELM), which is named as LOO-CCPS-RELM. We analyse the computational complexity of it and prove its asymptotic validity based on some regularity assumptions. We also prove that the error rate of the prediction interval output by LOO-CCPS-RELM is under control in the asymptotic setting. Experiments with 20 public data sets were conducted to test LOO-CCPS-RELM and the results showed that LOO-CCPS-RELM is empirically valid and compared favourably with the other CPSs. © 2020 Elsevier Ltd","Asymptotic validity; Conformal predictive system; Cross-conformal predictive system; Cumulative distribution function; Regularized extreme learning machine","Algorithms; Forecasting; Humans; Machine Learning; Time Factors; Distribution functions; Financial data processing; Knowledge acquisition; Weather forecasting; Asymptotic validity; Conformal predictions; Cumulative distribution function; Extreme learning machine; Financial time series; Predictive systems; Regularity assumption; Sensitive application; algorithm; article; machine learning; prediction; time series analysis; validity; weather; forecasting; human; machine learning; time factor; Machine learning","Article","Final","","Scopus","2-s2.0-85083000530"
"Gupta R.; Marfatia H.A.; Pierdzioch C.; Salisu A.A.","Gupta, Rangan (18037301200); Marfatia, Hardik A. (55554060500); Pierdzioch, Christian (55891223700); Salisu, Afees A. (55392158900)","18037301200; 55554060500; 55891223700; 55392158900","Machine Learning Predictions of Housing Market Synchronization across US States: The Role of Uncertainty","2022","Journal of Real Estate Finance and Economics","64","4","","523","545","22","19","10.1007/s11146-020-09813-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099368452&doi=10.1007%2fs11146-020-09813-1&partnerID=40&md5=184f97beb28e818734b54519be4ee0fc","We analyze the role of macroeconomic uncertainty in predicting synchronization in housing price movements across all the United States (US) states plus District of Columbia (DC). We first use a Bayesian dynamic factor model to decompose the house price movements into a national, four regional (Northeast, South, Midwest, and West), and state-specific factors. We then study the ability of macroeconomic uncertainty in forecasting the comovements in housing prices, by controlling for a wide-array of predictors, such as factors derived from a large macroeconomic dataset, oil shocks, and financial market-related uncertainties. To accommodate for multiple predictors and nonlinearities, we take a machine learning approach of random forests. Our results provide strong evidence of forecastability of the national house price factor based on the information content of macroeconomic uncertainties over and above the other predictors. This result also carries over, albeit by a varying degree, to the factors associated with the four census regions, and the overall house price growth of the US economy. Moreover, macroeconomic uncertainty is found to have predictive content for (stochastic) volatility of the national factor and aggregate US house price. Our results have important implications for policymakers and investors. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","Bayesian dynamic factor model; Forecasting; Housing markets synchronization; Machine learning; Random forests; United States","","Article","Final","","Scopus","2-s2.0-85099368452"
"Taguchi R.; Watanabe H.; Sakaji H.; Izumi K.; Hiramatsu K.","Taguchi, Rei (57468684200); Watanabe, Hikaru (57468838000); Sakaji, Hiroki (24339329000); Izumi, Kiyoshi (7203048296); Hiramatsu, Kenji (57468069400)","57468684200; 57468838000; 24339329000; 7203048296; 57468069400","Constructing Equity Investment Strategies Using Analyst Reports and Regime Switching Models","2022","Frontiers in Artificial Intelligence","5","","865950","","","","2","10.3389/frai.2022.865950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131542359&doi=10.3389%2ffrai.2022.865950&partnerID=40&md5=44ed71dc4a507d89163ea8964ad0fbbd","This study demonstrates whether analysts' sentiments toward individual stocks are useful for stock investment strategies. This is achieved by using natural language processing to create a polarity index from textual information in analyst reports. In this study, we performed time series forecasting for the created polarity index using deep learning, and clustered the forecasted values by volatility using a regime switching model. In addition, we constructed a portfolio from stock data and rebalanced it at each change point of the regime. Consequently, the investment strategy proposed in this study outperforms the benchmark portfolio in terms of returns. This suggests that the polarity index is useful for constructing stock investment strategies. Copyright © 2022 Taguchi, Watanabe, Sakaji, Izumi and Hiramatsu.","BERT; financial market; Hidden Markov Model; regime switching model; trading strategy","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85131542359"
"Çetin N.; Sağlam C.","Çetin, Necati (57204595476); Sağlam, Cevdet (57521630800)","57204595476; 57521630800","Rapid detection of total phenolics, antioxidant activity and ascorbic acid of dried apples by chemometric algorithms","2022","Food Bioscience","47","","101670","","","","29","10.1016/j.fbio.2022.101670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126532448&doi=10.1016%2fj.fbio.2022.101670&partnerID=40&md5=33cafc4a788280009fec6ad6cf937408","Multivariate approaches like machine learning are commonly used in estimation of biochemical traits from spectral and color characteristics of foodstuffs and agricultural commodities. In present study, windfall apples of Golden Delicious, Oregon Spur and Granny Smith cultivars were dried in open-sun, controlled greenhouse, microwave oven (200W), hybrid system (100W + 60°C), convective dryer (70°C) and freeze-dryer (−55°C). Spectral, chromatic and biochemical characteristics of dried apples were determined and assessed through machine learning algorithms. Total phenolic matter, DPPH (2,2-Diphenyl-1-picrylhydrazyl), FRAP (Ferric Reducing Antioxidant Power) and ascorbic acid content were estimated with the use of five different machine learning algorithms (artificial neural networks, k-nearest neighbor, random forest, gaussian processes and support vector regression). The most successful results were achieved in estimation of total phenolic content (R ≥ 0.85). Additionally, Multilayer Perceptron, Support Vector Regression and Gaussian Processes were identified as the best machine learning algorithms in estimation of biochemical compositions of dried apples. © 2022 Elsevier Ltd","Apple; Biochemical composition; Drying; Machine learning; VIS/NIR spectra","","Article","Final","","Scopus","2-s2.0-85126532448"
"Lahmiri S.; Bekiros S.","Lahmiri, Salim (39061577500); Bekiros, Stelios (8560165000)","39061577500; 8560165000","Intelligent forecasting with machine learning trading systems in chaotic intraday Bitcoin market","2020","Chaos, Solitons and Fractals","133","","109641","","","","55","10.1016/j.chaos.2020.109641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078443617&doi=10.1016%2fj.chaos.2020.109641&partnerID=40&md5=3c286e24cada794e18c95438d787e5da","Due to the remarkable boost in cryptocurrency trading on digital blockchain platforms, the utilization of advanced machine learning systems for robust prediction of highly nonlinear and noisy data, gains further popularity by individual and institutional market agents. The purpose of our study is to comparatively evaluate a plethora of Artificial Intelligence systems in forecasting high frequency Bitcoin price series. We employ three different sets of models, i.e., statistical machine learning approaches including support vector regressions (SVR) and Gaussian Poisson regressions (GRP), algorithmic models such as regression trees (RT) and the k-nearest neighbours (kNN) and finally artificial neural network topologies such as feedforward (FFNN), Bayesian regularization (BRNN) and radial basis function networks (RBFNN). To the best of our knowledge, this is the first time an extensive empirical investigation of the comparative predictability of various machine learning models is implemented in high-frequency trading of Bitcoin. The entropy analysis of training and testing samples reveals long memory traits, high levels of stochasticity, and topological complexity. The presence of inherent nonlinear dynamics of Bitcoin time series fully rationalizes the use of advanced machines learning techniques. The optimal parameter values for SVR, GRP and kNN are found via Bayesian optimization. Based on diverse performance metrics, our results show that the BRNN renders an outstanding accuracy in forecasting, while its convergence is unhindered and remarkably fast. The overall superiority of artificial neural networks is due to parallel processing features that efficiently emulate human decision-making in the presence of underlying nonlinear input-output relationships in noisy signal environments. © 2020","90.01 Social Phenomena; Bitcoin; Forecasting; Intraday trading; Machine learning","Bayesian networks; Bitcoin; Decision making; Electronic trading; Forecasting; Learning algorithms; Learning systems; Nearest neighbor search; Radial basis function networks; Regression analysis; Topology; 90.01 Social Phenomena; Artificial intelligence systems; Artificial neural network topology; Empirical investigation; Intraday trading; K nearest neighbours (k-NN); Statistical machine learning; Support vector regression (SVR); Machine learning","Article","Final","","Scopus","2-s2.0-85078443617"
"Ghazanfar M.A.; Alahmari S.A.; Aldhafiri Y.F.; Mustaqeem A.; Maqsood M.; Azam M.A.","Ghazanfar, Mustansar Ali (36023331300); Alahmari, Saad Ali (36552096700); Aldhafiri, Yasmeen Fahad (57197823211); Mustaqeem, Anam (57196078797); Maqsood, Muazzam (57197810097); Azam, Muhammad Awais (57190946338)","36023331300; 36552096700; 57197823211; 57196078797; 57197810097; 57190946338","Using machine learning classifiers to predict stock exchange index","2017","International Journal of Machine Learning and Computing","7","2","","24","29","5","23","10.18178/ijmlc.2017.7.2.614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034989454&doi=10.18178%2fijmlc.2017.7.2.614&partnerID=40&md5=5ac81a29f65d4ec969631ca3103fe110","Predicting stock exchange index is an attractive research topic in the field of machine learning. Numerous studies have been conducted using various techniques to predict stock market volume. This paper presents first detailed study on data of Karachi Stock Exchange (KSE) and Saudi Stock Exchange (SSE) to predict the stock market volume of ten different companies. In this study, we have applied and compared salient machine learning algorithms to predict stock exchange volume. The performance of these algorithms have been compared using accuracy metrics on the dataset, collected over the period of six months, by crawling the KSE and SSE website.","Ada-boost; Bayesian network; Machine learning; Neural networks; Stock exchange prediction; SVM","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85034989454"
"Jiao Y.; Wang P.; Feng S.; Niyato D.","Jiao, Yutao (57194324215); Wang, Ping (59000770400); Feng, Shaohan (57194330579); Niyato, Dusit (8919714700)","57194324215; 59000770400; 57194330579; 8919714700","Profit Maximization Mechanism and Data Management for Data Analytics Services","2018","IEEE Internet of Things Journal","5","3","8326475","2001","2014","13","56","10.1109/JIOT.2018.2819706","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044869164&doi=10.1109%2fJIOT.2018.2819706&partnerID=40&md5=f62bb6103f25e0a5dcc2c79372d76a06","With the advancement and emergence of new network services, such as social network, Internet of Things, and crowdsensing, large volume of diverse data is collected, shared, and leveraged to develop analytics services. The data analytics service has become a key commodity that can be traded among various economic entities. In this paper, we address the optimal pricing mechanisms and data management for data analytics services and further discuss the perishable services in the time varying environment. We first propose a data market model and define the data utility based on the impact of data size on the performance of data analytics, e.g., prediction and verification accuracy. For perishable services, we study the perishability of data that affects the service quality and provide a quality decay function. The data analytics services are considered as digital goods and uniquely characterized by 'unlimited supply' compared to conventional goods. Therefore, we apply the Bayesian profit maximization mechanism in selling data analytics services, which is truthful, rational, and computationally efficient. The optimal service price, data amount, and service update interval are obtained to maximize the profit under different customer's valuation distributions. Finally, experimental results on real-world datasets show that our data market model and pricing mechanism effectively solve the profit maximization problem and provide useful strategies for the data analytics service provider. © 2014 IEEE.","Data analytics; deep learning; digital goods auction; Internet of Things (IoT); optimal pricing; perishable service","Analytical models; Cloud computing; Commerce; Costs; Data reduction; Data structures; Deep learning; Information management; Internet of things; Profitability; Computationally efficient; Data analytics; Digital goods; Optimal pricing; perishable service; Profit maximization; Real-world datasets; Time-varying environments; Big data","Article","Final","","Scopus","2-s2.0-85044869164"
"Gankhuu B.; Kleinow J.; Lkhamsuren A.; Horsch A.","Gankhuu, Battulga (57271142300); Kleinow, Jacob (56262121600); Lkhamsuren, Altangerel (57742414700); Horsch, Andreas (56261829600)","57271142300; 56262121600; 57742414700; 56261829600","DIVIDENDS AND COMPOUND POISSON PROCESSES: A NEW STOCHASTIC STOCK PRICE MODEL","2022","International Journal of Theoretical and Applied Finance","25","3","2250014","","","","4","10.1142/S0219024922500145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132008571&doi=10.1142%2fS0219024922500145&partnerID=40&md5=48fafbdf7c1234584fb2c6d308649e5f","This study introduces a stochastic multi-period dividend discount model (DDM) that includes (i) a compound nonhomogenous Poisson process for dividend growth and (ii) the probability of firm default. We obtain maximum likelihood (ML) estimators and confidence interval formulas of our model parameters. We apply the model to a set of firms from the S&P 500 index using historical dividend and price data over a 42-year period. Interestingly, stock price estimations calculated with the model are close to the observable prices. Overall, we prove that the model can be a useful tool for stock pricing.  © 2022 World Scientific Publishing Company.","compound nonhomogeneous poisson process; ML estimators; random time of firm default; Stochastic dividend discount model","","Article","Final","","Scopus","2-s2.0-85132008571"
"Piendl R.; Matteis T.; Liedtke G.","Piendl, Raphael (57191978011); Matteis, Tilman (57190489006); Liedtke, Gernot (26635383800)","57191978011; 57190489006; 26635383800","A machine learning approach for the operationalization of latent classes in a discrete shipment size choice model","2019","Transportation Research Part E: Logistics and Transportation Review","121","","","149","161","12","12","10.1016/j.tre.2018.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045073886&doi=10.1016%2fj.tre.2018.03.005&partnerID=40&md5=dcdc489589575b1f4a753e60cab7c0af","This paper elaborates a novel approach for implementation of latent segments concerning behaviorally sensitive shipment size choice in strategic interregional freight transport models. Discrete shipment size choice models are estimated for different homogenous segments formed by latent class analysis. A machine learning technique called Bayesian classifier is applied to link segments obtained from a sample to data of commodity flows being available on a national level. Finally, in an exemplary scenario, the impact of information and communication technologies on shipment size distributions is calculated, revealing moderate elasticities and a predominant substitution of less than truck loads by full truck loads. © 2018 Elsevier Ltd","Bayesian classification; Freight transport; Latent class analysis; Machine learning; Shipment size","Freight transportation; Ships; Trucks; Bayesian classification; Choice model; Freight transport; Latent class; Latent class analysis; Machine learning approaches; Machine learning techniques; Machine-learning; Shipment size; Transport modelling; Bayesian analysis; freight transport; machine learning; modeling; trucking; Machine learning","Article","Final","","Scopus","2-s2.0-85045073886"
"HORENKO I.; MARCHENKO G.; GAGLIARDINI P.","HORENKO, ILLIA (6506963918); MARCHENKO, GANNA (57205462170); GAGLIARDINI, PATRICK (57203702320)","6506963918; 57205462170; 57203702320","ON A COMPUTATIONALLY SCALABLE SPARSE FORMULATION OF THE MULTIDIMENSIONAL AND NONSTATIONARY MAXIMUM ENTROPY PRINCIPLE","2020","Communications in Applied Mathematics and Computational Science","15","2","","129","146","17","1","10.2140/CAMCOS.2020.15.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097561377&doi=10.2140%2fCAMCOS.2020.15.15&partnerID=40&md5=f2a1fb5660c3c5b1b5dea5dbbe731bd3","Data-driven modeling and computational predictions based on the maximum entropy principle (MaxEnt principle) aim to find as simple as possible—but not simpler than necessary—models that allow one to avoid the data-overfitting problem. We derive a multivariate nonparametric and nonstationary formulation of the MaxEnt principle and show that its solution can be approximated through a numerical maximization of the sparse constrained optimization problem with regularization. Application of the resulting algorithm to popular financial benchmarks reveals memoryless models allowing for simple and qualitative descriptions of data of the major stock market indices. We compare the obtained MaxEnt models to the heteroscedastic models from computational econometrics (GARCH, GARCH-GJR, MS-GARCH, and GARCH-PML4) in terms of the model fit, complexity, and prediction quality. We compare the resulting model log-likelihoods, the values of the Bayesian information criterion, posterior model probabilities, the quality of the data autocorrelation function fits, as well as the value-at-risk prediction quality. We show that all of the seven considered major financial benchmark time series (DJI, SPX, FTSE, STOXX, SMI, HSI, and N225) are better described by conditionally memoryless MaxEnt models with nonstationary regime-switching than by the common econometric models with finite memory. This analysis also reveals a sparse network of statistically significant temporal relations for the positive and negative latent variance changes among different markets. The code is provided for open access. © 2020. All Rights Reserved.","financial time series; heteroscedasticity; machine learning; maximum entropy; sparsity","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85097561377"
"Kordabad A.B.; Wisniewski R.; Gros S.","Kordabad, Arash Bahari (57215419563); Wisniewski, Rafael (23394098500); Gros, Sebastien (55694310100)","57215419563; 23394098500; 55694310100","Safe Reinforcement Learning Using Wasserstein Distributionally Robust MPC and Chance Constraint","2022","IEEE Access","10","","","130058","130067","9","7","10.1109/ACCESS.2022.3228922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144775674&doi=10.1109%2fACCESS.2022.3228922&partnerID=40&md5=44c8d98aa3cb1a32ac8ebf0fef2c80bf","In this paper, we address the chance-constrained safe Reinforcement Learning (RL) problem using the function approximators based on Stochastic Model Predictive Control (SMPC) and Distributionally Robust Model Predictive Control (DRMPC). We use Conditional Value at Risk (CVaR) to measure the probability of constraint violation and safety. In order to provide a safe policy by construction, we first propose using parameterized nonlinear DRMPC at each time step. DRMPC optimizes a finite-horizon cost function subject to the worst-case constraint violation in an ambiguity set. We use a statistical ball around the empirical distribution with a radius measured by the Wasserstein metric as the ambiguity set. Unlike the sample average approximation SMPC, DRMPC provides a probabilistic guarantee of the out-of-sample risk and requires lower samples from the disturbance. Then the Q-learning method is used to optimize the parameters in the DRMPC to achieve the best closed-loop performance. Wheeled Mobile Robot (WMR) path planning with obstacle avoidance will be considered to illustrate the efficiency of the proposed method. © 2013 IEEE.","chance constraint; conditional value at risk; distributionally robust optimization; model predictive control; Q-learning; Safe reinforcement learning","Constrained optimization; Cost functions; Mobile robots; Motion estimation; Motion planning; Predictive control systems; Random processes; Reinforcement learning; Risk assessment; Risk management; Robot programming; Robust control; Safety engineering; Stochastic control systems; Stochastic models; Stochastic systems; Chance constraint; Conditional Value-at-Risk; Distributionally robust optimization; Model-predictive control; Predictive control; Q-learning; Reinforcement learnings; Risks management; Robust optimization; Safe reinforcement learning; Model predictive control","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144775674"
"Gandhmal D.P.; Kumar K.","Gandhmal, Dattatray P. (57205063745); Kumar, K. (7402676231)","57205063745; 7402676231","Systematic analysis and review of stock market prediction techniques","2019","Computer Science Review","34","","100190","","","","156","10.1016/j.cosrev.2019.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074265936&doi=10.1016%2fj.cosrev.2019.08.001&partnerID=40&md5=b185a99a4aec49defbdc48c1c9711189","Prediction of stock market trends is considered as an important task and is of great attention as predicting stock prices successfully may lead to attractive profits by making proper decisions. Stock market prediction is a major challenge owing to non-stationary, blaring, and chaotic data, and thus, the prediction becomes challenging among the investors to invest the money for making profits. Several techniques are devised in the existing techniques to predict the stock market trends. This work presents the detailed review of 50 research papers suggesting the methodologies, like Bayesian model, Fuzzy classifier, Artificial Neural Networks (ANN), Support Vector Machine (SVM) classifier, Neural Network (NN), Machine Learning Methods and so on, based on stock market prediction. The obtained papers are classified based on different prediction and clustering techniques. The research gaps and the challenges faced by the existing techniques are listed and elaborated, which help the researchers to upgrade the future works. The works are analyzed using certain datasets, software tools, performance evaluation measures, prediction techniques utilized, and performance attained by different techniques. The commonly used technique for attaining effective stock market prediction is ANN and the fuzzy-based technique. Even though a lot of research efforts, the current stock market prediction technique still have many limits. From this survey, it can be concluded that the stock market prediction is a very complex task, and different factors should be considered for predicting the future of the market more accurately and efficiently. © 2019 Elsevier Ltd. All rights reserved.","ANN; Bayesian model; Classification; Clustering; Fuzzy classifier; Stock market prediction","Bayesian networks; Classification (of information); Commerce; Electronic trading; Financial markets; Forecasting; Fuzzy neural networks; Fuzzy sets; Profitability; Support vector machines; Bayesian model; Clustering; Clustering techniques; Fuzzy classifiers; Machine learning methods; Prediction techniques; Stock market prediction; Systematic analysis; Investments","Review","Final","","Scopus","2-s2.0-85074265936"
"Nguyen N.; Nguyen D.","Nguyen, Nguyet (56496160300); Nguyen, Dung (57224876421)","56496160300; 57224876421","Global stock selection with hidden markov model","2021","Risks","9","1","9","1","18","17","6","10.3390/risks9010009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098854168&doi=10.3390%2frisks9010009&partnerID=40&md5=c145785345826581f875e8ae5d01572e","Hidden Markov model (HMM) is a powerful machine-learning method for data regime detection, especially time series data. In this paper, we establish a multi-step procedure for using HMM to select stocks from the global stock market. First, the five important factors of a stock are identified and scored based on its historical performances. Second, HMM is used to predict the regimes of six global economic indicators and find the time periods in the past during which these indicators have a combination of regimes that is similar to those predicted. Then, we analyze the five stock factors of the All country world index (ACWI) in the identified time periods to assign a weighted score for each stock factor and to calculate the composite score of the five factors. Finally, we make a monthly selection of 10% of the global stocks that have the highest composite scores. This strategy is shown to outperform those relying on either ACWI, any single stock factor, or the simple average of the five stock factors. © 2020 by the authors. Li-censee MDPI, Basel, Switzerland.","Economics; Economics indicators; Global stocks; Hidden Markov model; Machine learning; Regimes; Stock ranking; Stocks’ factors; Trading","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85098854168"
"Calvo-Pardo H.F.; Mancini T.; Olmo J.","Calvo-Pardo, Hector F. (23097158900); Mancini, Tullio (57219938511); Olmo, Jose (23994295000)","23097158900; 57219938511; 23994295000","Machine Learning the Carbon Footprint of Bitcoin Mining","2022","Journal of Risk and Financial Management","15","2","71","","","","7","10.3390/jrfm15020071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130457859&doi=10.3390%2fjrfm15020071&partnerID=40&md5=4d485b7b45d4a748e6037ff05f98b4bb","Building on an economic model of rational Bitcoin mining, we measured the carbon footprint of Bitcoin mining power consumption using feed-forward neural networks. We found associated carbon footprints of 2.77, 16.08 and 14.99 MtCO2 e for 2017, 2018 and 2019 based on a novel bottom-up approach, which (i) conform with recent estimates, (ii) lie within the economic model bounds while (iii) delivering much narrower prediction intervals and yet (iv) raise alarming concerns, given recent evidence (e.g., from climate–weather integrated models). We demonstrate how machine learning methods can contribute to not-for-profit pressing societal issues, such as global warming, where data complexity and availability can be overcome. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Bitcoin mining; CO<sub>2</sub>; dropout methods; machine learning; neural networks","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130457859"
"Heiberger R.H.","Heiberger, Raphael H. (55600330900)","55600330900","Predicting economic growth with stock networks","2018","Physica A: Statistical Mechanics and its Applications","489","","","102","111","9","25","10.1016/j.physa.2017.07.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028070940&doi=10.1016%2fj.physa.2017.07.022&partnerID=40&md5=11abd5ce70dc8f126d2f3f078d0320ee","Networks derived from stock prices are often used to model developments on financial markets and are tightly intertwined with crises. Yet, the influence of changing market topologies on the broader economy (i.e. GDP) is unclear. In this paper, we propose a Bayesian approach that utilizes individual-level network measures of companies as lagged probabilistic features to predict national economic growth. We use a comprehensive data set consisting of Standard and Poor's 500 corporations from January 1988 until October 2016. The final model forecasts correctly all major recession and prosperity phases of the U.S. economy up to one year ahead. By employing different network measures on the level of corporations, we can also identify which companies’ stocks possess a key role in a changing economic environment and may be used as indication of critical (and prosperous) developments. More generally, the proposed approach allows to predict probabilities for different overall states of social entities by using local network positions and could be applied on various phenomena. © 2017 Elsevier B.V.","Economic growth; Econophysics; Machine learning; Naïve Bayes classifier; Stock networks","Bayesian networks; Commerce; Financial markets; Learning systems; Bayes Classifier; Bayesian approaches; Economic environment; Economic growths; Econophysicss; Individual levels; Model development; Network measures; Forecasting","Article","Final","","Scopus","2-s2.0-85028070940"
"Parker P.A.; Holan S.H.; Wills S.A.","Parker, Paul A. (57204705616); Holan, Scott H. (16238843200); Wills, Skye A. (16053979500)","57204705616; 16238843200; 16053979500","A general Bayesian model for heteroskedastic data with fully conjugate full-conditional distributions","2021","Journal of Statistical Computation and Simulation","91","15","","3207","3227","20","3","10.1080/00949655.2021.1925279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106234276&doi=10.1080%2f00949655.2021.1925279&partnerID=40&md5=08739df384d9e016665403691bb6dbfd","Models for heteroskedastic data are relevant in a variety of applications ranging from financial time series to environmental statistics. However, the topic of modelling the variance function conditionally has not seen as much attention as modelling the mean. Volatility models have been used in specific applications, but these models can be difficult to fit in a Bayesian setting due to posterior distributions that are challenging to sample efficiently. In this work, we introduce a general model for heteroskedastic data. This approach models the conditional variance as a function of any desired covariates or random effects. We rely on multivariate log-Gamma distribution theory to construct priors that yield fully conjugate full-conditional distributions for Gibbs sampling. Furthermore, we extend the model to a deep learning approach that can provide highly accurate estimates for time dependent data. We also provide an extension for heavy-tailed data. We illustrate our methodology via three applications. ©, This work was authored as part of the Contributor's official duties as an Employee of the United States Government and is therefore a work of the United States Government. In accordance with 17 USC. 105, no copyright protection is available for such works under US Law.","Deep learning; echo state network; Gibbs sampling; mixed models; multivariate log-Gamma; spatial; volatility","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85106234276"
"Li H.; Cui Y.; Wang S.; Liu J.; Qin J.; Yang Y.","Li, Hui (58742085300); Cui, Yunpeng (23970197600); Wang, Shuo (57192102600); Liu, Juan (57196291640); Qin, Jinyuan (57685540300); Yang, Yilin (57217524777)","58742085300; 23970197600; 57192102600; 57196291640; 57685540300; 57217524777","Multivariate Financial Time-Series Prediction with Certified Robustness","2020","IEEE Access","8","","9113475","109133","109143","10","14","10.1109/ACCESS.2020.3001287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087336295&doi=10.1109%2fACCESS.2020.3001287&partnerID=40&md5=6b5261e124330e481a6bcd9aa264c8eb","The futures market's forecasts are significant to investors and policymakers, where the application of deep learning approaches to finance has received a great deal of attention. In this study, we propose a multivariate financial time-series forecasting method. Our model addresses the long- and short-term features, multimodal and non-stationarity nature of multivariate time-series by incorporating the improved deep neural networks and certified noise injection. Specifically, multimodal variational autoencoder is used to extract deep high-level features of multivariate time-series, Long- and Short- Term recurrent neural network is applied for multivariate time-series forecasting, and certified noise injection mechanism, inspired by differential privacy, is proposed to improve the robustness and accuracy of prediction. Extensive empirical results on real-world agricultural commodity futures price time series and relevant external data demonstrate that our model achieves better performance over that of several state-of-the-art baseline methods.  © 2013 IEEE.","deep neural networks; Futures prices; Gaussian noise; multivariate; prediction","Agricultural robots; Agriculture; Deep neural networks; Electronic trading; Financial markets; Forecasting; Investments; Recurrent neural networks; Time series analysis; Agricultural commodity futures; Differential privacies; Financial time series forecasting; Financial time series predictions; High-level features; Learning approach; Multivariate time series; Non-stationarities; Time series","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85087336295"
"Amelot L.M.M.; Subadar Agathee U.; Sunecher Y.","Amelot, Lydie Myriam Marcelle (57219960690); Subadar Agathee, Ushad (55308239000); Sunecher, Yuvraj (57136783300)","57219960690; 55308239000; 57136783300","Time series modelling, NARX neural network and hybrid KPCA–SVR approach to forecast the foreign exchange market in Mauritius","2021","African Journal of Economic and Management Studies","12","1","","18","54","36","3","10.1108/AJEMS-04-2019-0161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096322236&doi=10.1108%2fAJEMS-04-2019-0161&partnerID=40&md5=e01c73d044e990ca001424f3aa3445fb","Purpose: This study constructs time series model, artificial neural networks (ANNs) and statistical topologies to examine the volatility and forecast foreign exchange rates. The Mauritian forex market has been utilized as a case study, and daily data for nominal spot rate (during a time period of five years spanning from 2014 to 2018) for EUR/MUR, GBP/MUR, CAD/MUR and AUD/MUR have been applied for the predictions. Design/methodology/approach: Autoregressive integrated moving average (ARIMA) and generalized autoregressive conditional heteroskedasticity (GARCH) models are used as a basis for time series modelling for the analysis, along with the non-linear autoregressive network with exogenous inputs (NARX) neural network backpropagation algorithm utilizing different training functions, namely, Levenberg–Marquardt (LM), Bayesian regularization and scaled conjugate gradient (SCG) algorithms. The study also features a hybrid kernel principal component analysis (KPCA) using the support vector regression (SVR) algorithm as an additional statistical tool to conduct financial market forecasting modelling. Mean squared error (MSE) and root mean square error (RMSE) are employed as indicators for the performance of the models. Findings: The results demonstrated that the GARCH model performed better in terms of volatility clustering and prediction compared to the ARIMA model. On the other hand, the NARX model indicated that LM and Bayesian regularization training algorithms are the most appropriate method of forecasting the different currency exchange rates as the MSE and RMSE seemed to be the lowest error compared to the other training functions. Meanwhile, the results reported that NARX and KPCA–SVR topologies outperformed the linear time series models due to the theory based on the structural risk minimization principle. Finally, the comparison between the NARX model and KPCA–SVR illustrated that the NARX model outperformed the statistical prediction model. Overall, the study deduced that the NARX topology achieves better prediction performance results compared to time series and statistical parameters. Research limitations/implications: The foreign exchange market is considered to be instable owing to uncertainties in the economic environment of any country and thus, accurate forecasting of foreign exchange rates is crucial for any foreign exchange activity. The study has an important economic implication as it will help researchers, investors, traders, speculators and financial analysts, users of financial news in banking and financial institutions, money changers, non-banking financial companies and stock exchange institutions in Mauritius to take investment decisions in terms of international portfolios. Moreover, currency rates instability might raise transaction costs and diminish the returns in terms of international trade. Exchange rate volatility raises the need to implement a highly organized risk management measures so as to disclose future trend and movement of the foreign currencies which could act as an essential guidance for foreign exchange participants. By this way, they will be more alert before conducting any forex transactions including hedging, asset pricing or any speculation activity, take corrective actions, thus preventing them from making any potential losses in the future and gain more profit. Originality/value: This is one of the first studies applying artificial intelligence (AI) while making use of time series modelling, the NARX neural network backpropagation algorithm and hybrid KPCA–SVR to predict forex using multiple currencies in the foreign exchange market in Mauritius. © 2020, Emerald Publishing Limited.","ANN; ARIMA; Artificial intelligence; Forex market; GARCH; KPCA–SVR; NARX; Time series model","","Article","Final","","Scopus","2-s2.0-85096322236"
"Cocco L.; Tonelli R.; Marchesi M.","Cocco, Luisanna (37861007600); Tonelli, Roberto (7004058057); Marchesi, Michele (7005947166)","37861007600; 7004058057; 7005947166","Predictions of bitcoin prices through machine learning based frameworks","2021","PeerJ Computer Science","7","","","1","23","22","25","10.7717/PEERJ-CS.413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104808916&doi=10.7717%2fPEERJ-CS.413&partnerID=40&md5=fc076124f35bbaf16f1d081373e5a8ff","The high volatility of an asset in financial markets is commonly seen as a negative factor. However short-term trades may entail high profits if traders open and close the correct positions. The high volatility of cryptocurrencies, and in particular of Bitcoin, is what made cryptocurrency trading so profitable in these last years. The main goal of this work is to compare several frameworks each other to predict the daily closing Bitcoin price, investigating those that provide the best performance, after a rigorous model selection by the so-called k-fold cross validation method. We evaluated the performance of one stage frameworks, based only on one machine learning technique, such as the Bayesian Neural Network, the Feed Forward and the Long Short Term Memory Neural Networks, and that of two stages frameworks formed by the neural networks just mentioned in cascade to Support Vector Regression. Results highlight higher performance of the two stages frameworks with respect to the correspondent one stage frameworks, but for the Bayesian Neural Network. The one stage framework based on Bayesian Neural Network has the highest performance and the order of magnitude of the mean absolute percentage error computed on the predicted price by this framework is in agreement with those reported in recent literature works. © 2021. Cocco et al.","Artificial Intelligence; Bayesian neural network; Cryptocurrencies; Data Mining and Machine Learning; Machine learning; Technical indicators","Bayesian networks; Bitcoin; Costs; Electronic trading; Machine learning; Predictive analytics; Profitability; Support vector regression; Bayesian neural networks; Feed forward; High volatility; K fold cross validations; Mean absolute percentage error; One-machine; Rigorous model; Short term; Feedforward neural networks","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85104808916"
"Petropoulos A.; Chatzis S.P.; Siakoulis V.; Vlachogiannakis N.","Petropoulos, Anastasios (57125824100); Chatzis, Sotirios P. (14919099600); Siakoulis, Vasilis (55897863800); Vlachogiannakis, Nikos (57192118273)","57125824100; 14919099600; 55897863800; 57192118273","A stacked generalization system for automated FOREX portfolio trading","2017","Expert Systems with Applications","90","","","290","302","12","34","10.1016/j.eswa.2017.08.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027974046&doi=10.1016%2fj.eswa.2017.08.011&partnerID=40&md5=f7ea56c9e0b2962bcc9a36b15225e28c","Multiple FOREX time series forecasting is a hot research topic in the literature of portfolio trading. To this end, a large variety of machine learning algorithms have been examined. However, it is now widely understood that, in real-world trading settings, no single machine learning model can consistently outperform the alternatives. In this work, we examine the efficacy and the feasibility of developing a stacked generalization system, intelligently combining the predictions of diverse machine learning models. Our approach establishes a novel inferential framework that comprises the following levels of data processing: (i) We model the dependence patterns between major currency pairs via a diverse set of commonly used machine learning algorithms, namely support vector machines (SVMs), random forests (RFs), Bayesian autoregressive trees (BART), dense-layer neural networks (NNs), and naïve Bayes (NB) classifiers. (ii) We generate implied signals of exchange rate fluctuation, based on the output of these models, as well as appropriate side information obtained by analyzing the correlations across currency pairs in our training datasets. (iii) We finally combine these implied signals into an aggregate predictive waveform, by leveraging majority voting, genetic algorithm optimization, and regression weighting techniques. We thoroughly test our framework in real-world trading scenarios; we show that our system leads to significantly better trading performance than the considered benchmarks. Thus, it represents an attractive solution for financial firms and corporations that perform foreign exchange portfolio management and daily trading. Our system can be used as an integrated part in international commercial trade activities or in a quantitative investing framework for algorithmic trading and carry-trade speculation. © 2017 Elsevier Ltd","Algorithmic trading; Forex forecasting; Machine learning; Portfolio management; Stacked generalization","","Article","Final","","Scopus","2-s2.0-85027974046"
"David M.; Ramahatana F.; Trombe P.J.; Lauret P.","David, M. (35486904800); Ramahatana, F. (57188806467); Trombe, P.J. (37115974000); Lauret, P. (7004327525)","35486904800; 57188806467; 37115974000; 7004327525","Probabilistic forecasting of the solar irradiance with recursive ARMA and GARCH models","2016","Solar Energy","133","","","55","72","17","170","10.1016/j.solener.2016.03.064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963628979&doi=10.1016%2fj.solener.2016.03.064&partnerID=40&md5=7e54ac783ac8b43bb3fb14de8e9c1903","Forecasting of the solar irradiance is a key feature in order to increase the penetration rate of solar energy into the energy grids. Indeed, the anticipation of the fluctuations of the solar renewables allows a better management of the production means of electricity and a better operation of the grid-connected storage systems. If numerous methods for forecasting the mean of the solar irradiance were recently developed, there are only few works dedicated to the evaluation of prediction intervals associated to these point forecasts. Time series of solar irradiance and more specifically of clear sky index show some similarities with that of financial time series. The aim of this paper is to assess the performances of a commonly used combination of two linear models (ARMA and GARCH) in econometrics in order to provide probabilistic forecasts of solar irradiance. In addition, a recursive estimation of the parameters of the models has been set up in order to provide a framework that can be applied easily in an operational context. A comprehensive testing procedure has been used to assess both point forecasts and probabilistic forecasts. Using only the past records of the solar irradiance, the proposed model is able to perform point forecasts as accurately as other methods based on machine learning techniques. Moreover, the recursive ARMA-GARCH model is easier to set-up and it gives additional information about the uncertainty of the forecasts. Even if some strong assumption has been made regarding the statistical distribution of the error, the reliability of the probabilistic forecasts stands in the same order of magnitude as other works done in the field of solar forecasting. © 2016 Elsevier Ltd.","ARMA; Clear sky index; GARCH; Operational framework; Probabilistic solar forecasts; Recursive least square","Arma; Artificial intelligence; Economics; Financial data processing; Learning systems; Probability distributions; Solar energy; Solar radiation; Statistics; Time series; ARMA; Clear sky; GARCH; Operational framework; Recursive least square (RLS); atmospheric modeling; clear sky; econometrics; energy planning; forecasting method; machine learning; numerical method; performance assessment; probability; solar radiation; time series analysis; Forecasting","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-84963628979"
"Andrée B.P.J.","Andrée, Bo Pieter Johannes (57191276860)","57191276860","Conducting Causal Analysis by Means of Approximating Probabilistic Truths","2022","Entropy","24","1","92","","","","2","10.3390/e24010092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122468495&doi=10.3390%2fe24010092&partnerID=40&md5=3e0b7480fcc7c32be293806d531f465f","The current paper develops a probabilistic theory of causation using measure-theoretical concepts and suggests practical routines for conducting causal inference. The theory is applicable to both linear and high-dimensional nonlinear models. An example is provided using random forest regressions and daily data on yield spreads. The application tests how uncertainty in short-and long-term inflation expectations interacts with spreads in the daily Bitcoin price. The results are contrasted with those obtained by standard linear Granger causality tests. It is shown that the suggested measure-theoretic approaches do not only lead to better predictive models, but also to more plausible parsimonious descriptions of possible causal flows. The paper concludes that researchers interested in causal analysis should be more aspirational in terms of developing predictive capabilities, even if the interest is in inference and not in prediction per se. The theory developed in the paper provides practitioners guidance for developing causal models using new machine learning methods that have, so far, remained relatively underutilized in this context. © 2022 by the author. Licensee MDPI, Basel, Switzerland.","Approximation theory; Bitcoin; Causality; Correct specification; Hellinger distance; Inflation; Kullback–Leibler divergence; Misspecified models; Yield spreads","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122468495"
"Zhang X.-D.; Li A.; Pan R.","Zhang, Xiao-dan (55715313800); Li, Ang (57199855236); Pan, Ran (57190965457)","55715313800; 57199855236; 57190965457","Stock trend prediction based on a new status box method and AdaBoost probabilistic support vector machine","2016","Applied Soft Computing Journal","49","","","385","398","13","84","10.1016/j.asoc.2016.08.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984830283&doi=10.1016%2fj.asoc.2016.08.026&partnerID=40&md5=c8f1ae1ed680bb851c523015ad9b17ae","Stock trend prediction is regarded as one of the most challenging tasks of financial time series prediction. Conventional statistical modeling techniques are not adequate for stock trend forecasting because of the non-stationarity and non-linearity of the stock market. With this regard, many machine learning approaches are used to improve the prediction results. These approaches mainly focus on two aspects: regression problem of the stock price and prediction problem of the turning points of stock price. In this paper, we concentrate on the evaluation of the current trend of stock price and the prediction of the change orientation of the stock price in future. Then, a new approach named status box method is proposed. Different from the prediction issue of the turning points, the status box method packages some stock points into three categories of boxes which indicate different stock status. And then, some machine learning techniques are used to classify these boxes so as to measure whether the states of each box coincides with the stock price trend and forecast the stock price trend based on the states of the box. These results would support us to make buying or selling strategies. Comparing with the turning points prediction that only considered the features of one day, each status box contains a certain amount of points which represent the stock price trend in a certain period of time. So, the status box reflects more information of stock market. To solve the classification problem of the status box, a special features construction approach is presented. Moreover, a new ensemble method integrated with the AdaBoost algorithm, probabilistic support vector machine (PSVM), and genetic algorithm (GA) is constructed to perform the status boxes classification. To verify the applicability and superiority of the proposed methods, 20 shares chosen from Shenzhen Stock Exchange (SZSE) and 16 shares from National Association of Securities Dealers Automated Quotations (NASDAQ) are applied to perform stock trend prediction. The results show that the status box method not only have the better classification accuracy but also effectively solve the unbalance problem of the stock turning points classification. In addition, the new ensemble classifier achieves preferable profitability in simulation of stock investment and remarkably improves the classification performance compared with the approach that only uses the PSVM or back-propagation artificial neural network (BPN). © 2016 Elsevier B.V.","AdaBoost; Piecewise linear representation; Probabilistic support vector machine; Status box method; Stock trend prediction","Adaptive boosting; Artificial intelligence; Backpropagation; Commerce; Costs; Finance; Financial data processing; Financial markets; Forecasting; Genetic algorithms; Investments; Learning systems; Neural networks; Piecewise linear techniques; Problem solving; Support vector machines; Time series analysis; Back propagation artificial neural network (BPANN); Classification performance; Financial time series predictions; Machine learning approaches; Machine learning techniques; Piecewise linear representation; Status box method; Stock trend prediction; Electronic trading","Article","Final","","Scopus","2-s2.0-84984830283"
"Chopra D.; Kaur A.","Chopra, Deepti (57196963238); Kaur, Arvinder (57548731500)","57196963238; 57548731500","IoT-based group size prediction and recommendation system using machine learning and deep learning techniques","2021","SN Applied Sciences","3","2","160","","","","1","10.1007/s42452-021-04162-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100738033&doi=10.1007%2fs42452-021-04162-x&partnerID=40&md5=1604b131d70d08ee60bead6731f9565f","In an open source software development environment, it is hard to decide the number of group members required for resolving software issues. Developers generally reply to issues based totally on their domain knowledge and interest, and there are no predetermined groups. The developers openly collaborate on resolving the issues based on many factors, such as their interest, domain expertise, and availability. This study compares eight different algorithms employing machine learning and deep learning, namely—Convolutional Neural Network, Multilayer Perceptron, Classification and Regression Trees, Generalized Linear Model, Bayesian Additive Regression Trees, Gaussian Process, Random Forest and Conditional Inference Tree for predicting group size in five open source software projects developed and managed using an open source development framework GitHub. The social information foraging model has also been extended to predict group size in software issues, and its results compared to those obtained using machine learning and deep learning algorithms. The prediction results suggest that deep learning and machine learning models predict better than the extended social information foraging model, while the best-ranked model is a deep multilayer perceptron((R.M.S.E. sequelize—1.21, opencv—1.17, bitcoin—1.05, aseprite—1.01, electron—1.16). Also it was observed that issue labels helped improve the prediction performance of the machine learning and deep learning models. The prediction results of these models have been used to build an Issue Group Recommendation System as an Internet of Things application that recommends and alerts additional developers to help resolve an open issue. © 2021, The Author(s).","Deep learning; Edge computing; Internet of things; Machine learning; Open source software development; Software repositories","Convolutional neural networks; Decision trees; Deep learning; Forecasting; Forestry; Inference engines; Information dissemination; Internet of things; Learning systems; Learning to rank; Multilayer neural networks; Multilayers; Open source software; Open systems; Predictive analytics; Recommender systems; Social aspects; Software design; Bayesian additive regression trees; Classification and regression tree; Generalized linear model; Group recommendation systems; Machine learning models; Open source development; Open source software projects; Prediction performance; Learning algorithms","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100738033"
"Park S.; Lee J.; Son Y.","Park, Saerom (57161194300); Lee, Jaewook (8852130600); Son, Youngdoo (56645738600)","57161194300; 8852130600; 56645738600","Predicting market impact costs using nonparametric machine learning models","2016","PLoS ONE","11","2","e0150243","","","","14","10.1371/journal.pone.0150243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960372443&doi=10.1371%2fjournal.pone.0150243&partnerID=40&md5=6f94b96757c474d2e6c5a4578218f875","Market impact cost is the most significant portion of implicit transaction costs that can reduce the overall transaction cost, although it cannot be measured directly. In this paper, we employed the state-of-the-art nonparametric machine learning models: neural networks, Bayesian neural network, Gaussian process, and support vector regression, to predict market impact cost accurately and to provide the predictive model that is versatile in the number of variables. We collected a large amount of real single transaction data of US stock market from Bloomberg Terminal and generated three independent input variables. As a result, most nonparametric machine learning models outperformed a-state-of-the-art benchmark parametric model such as I-star model in four error measures. Although these models encounter certain difficulties in separating the permanent and temporary cost directly, nonparametric machine learning models can be good alternatives in reducing transaction costs by considerably improving in prediction performance. © 2016 Park et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Costs and Cost Analysis; Investments; Machine Learning; Regression Analysis; Statistics, Nonparametric; machine learning; market; model; nervous system; prediction; statistical model; support vector machine; cost; economics; investment; nonparametric test; regression analysis; statistics and numerical data","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-84960372443"
"Nardi P.C.C.; Ribeiro E.M.S.; Bueno J.L.O.; Aggarwal I.","Nardi, Paula Carolina Ciampaglia (55877016600); Ribeiro, Evandro Marcos Saidel (55860800172); Bueno, José Lino Oliveira (35605510100); Aggarwal, Ishani (55764159600)","55877016600; 55860800172; 35605510100; 55764159600","The Influence of Cognitive Biases and Financial Factors on Forecast Accuracy of Analysts","2022","Frontiers in Psychology","12","","773894","","","","5","10.3389/fpsyg.2021.773894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123223736&doi=10.3389%2ffpsyg.2021.773894&partnerID=40&md5=d7ec6315a46894b8f07499ac9772a1af","The objective of this study was to jointly analyze the importance of cognitive and financial factors in the accuracy of profit forecasting by analysts. Data from publicly traded Brazilian companies in 2019 were obtained. We used text analysis to assess the cognitive biases from the qualitative reports of analysts. Further, we analyzed the data using statistical regression learning methods and statistical classification learning methods, such as Multiple Linear Regression (MRL), k-dependence Bayesian (k-DB), and Random Forest (RF). The Bayesian inference and classification methods allow an expansion of the research line, especially in the area of machine learning, which can benefit from the examples of factors addressed in this research. The results indicated that, among cognitive biases, optimism had a negative relationship with forecasting accuracy while anchoring bias had a positive relationship. Commonality, to a lesser extent, also had a positive relationship with the analyst’s accuracy. Among financial factors, the most important aspects in the accuracy of analysts were volatility, indebtedness, and profitability. Age of the company, fair value, American Depositary Receipts (ADRs), performance, and loss were still important but on a smaller scale. The results of the RF models showed a greater explanatory power. This research sheds light on the cognitive as well as financial aspects that influence the analyst’s accuracy, jointly using text analysis and machine learning methods, capable of improving the explanatory power of predictive models, together with the use of training models followed by testing. Copyright © 2022 Nardi, Ribeiro, Bueno and Aggarwal.","analysts’ accuracy; analysts’ forecast; cognitive biases; random forest; text analysis","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85123223736"
"Yang C.; Wang X.; Mao S.","Yang, Chao (57195334389); Wang, Xuyu (56344911700); Mao, Shiwen (57201755539)","57195334389; 56344911700; 57201755539","Unsupervised Detection of Apnea Using Commodity RFID Tags with a Recurrent Variational Autoencoder","2019","IEEE Access","7","","8720147","67526","67538","12","24","10.1109/ACCESS.2019.2918292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067169915&doi=10.1109%2fACCESS.2019.2918292&partnerID=40&md5=bc77268d0a5eb6eb608501026ce8eab7","With the rapid development of intelligent health sensing in the Internet of Things (IoT), vital sign monitoring (e.g., respiration) and abnormal respiration detection have attracted increasing attention. Considering the challenging and the cost of collecting labeled training data from patients with breathing related diseases, we develop the AutoTag system, an unsupervised recurrent variational autoencoder-based method for respiration rate estimation and abnormal breathing detection with off-the-shelf RFID tags. Moreover, for real-time breath monitoring, a novel method is proposed to cancel the distortion on measured phase values caused by channel hopping for FCC-complaint RFID systems. The efficacy of the proposed system is demonstrated by the extensive experiments conducted in two indoor environments, while the impact of various design and environmental factors is also evaluated. © 2013 IEEE.","Apnea; deep learning; radio-frequency identification (RFID); recurrent variational autoencoder; respiration monitoring","Deep learning; Internet of things; Patient monitoring; Real time systems; Apnea; Auto encoders; Environmental factors; Internet of thing (IOT); Respiration detections; Respiration monitoring; Unsupervised detection; Vital sign monitoring; Radio frequency identification (RFID)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85067169915"
"Yates E.J.; Yates L.C.; Harvey H.","Yates, E.J. (57202404170); Yates, L.C. (57202406360); Harvey, H. (57193520215)","57202404170; 57202406360; 57193520215","Machine learning “red dot”: open-source, cloud, deep convolutional neural networks in chest radiograph binary normality classification","2018","Clinical Radiology","73","9","","827","831","4","49","10.1016/j.crad.2018.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048220227&doi=10.1016%2fj.crad.2018.05.015&partnerID=40&md5=88fed5ef751ad1e1e8b36b136d7c1fb9","Aim: To develop a machine learning-based model for the binary classification of chest radiography abnormalities, to serve as a retrospective tool in guiding clinician reporting prioritisation. Materials and methods: The open-source machine learning library, Tensorflow, was used to retrain a final layer of the deep convolutional neural network, Inception, to perform binary normality classification on two, anonymised, public image datasets. Re-training was performed on 47,644 images using commodity hardware, with validation testing on 5,505 previously unseen radiographs. Confusion matrix analysis was performed to derive diagnostic utility metrics. Results: A final model accuracy of 94.6% (95% confidence interval [CI]: 94.3–94.7%) based on an unseen testing subset (n=5,505) was obtained, yielding a sensitivity of 94.6% (95% CI: 94.4–94.7%) and a specificity of 93.4% (95% CI: 87.2–96.9%) with a positive predictive value (PPV) of 99.8% (95% CI: 99.7–99.9%) and area under the curve (AUC) of 0.98 (95% CI: 0.97–0.99). Conclusion: This study demonstrates the application of a machine learning-based approach to classify chest radiographs as normal or abnormal. Its application to real-world datasets may be warranted in optimising clinician workload. © 2018 The Royal College of Radiologists","","Cloud Computing; Datasets as Topic; Diagnosis, Differential; Humans; Machine Learning; Neural Networks (Computer); Radiography, Thoracic; Sensitivity and Specificity; Article; binary normality classification; classification algorithm; cloud computing; deep convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; human; image analysis; image processing; machine learning; metadata; predictive value; priority journal; receiver operating characteristic; sensitivity and specificity; thorax radiography; transfer of learning; artificial neural network; classification; differential diagnosis; information processing; thorax radiography","Article","Final","","Scopus","2-s2.0-85048220227"
"Sanford A.; Moosa I.","Sanford, Andrew (8215422300); Moosa, Imad (7006511199)","8215422300; 7006511199","Operational risk modelling and organizational learning in structured finance operations: A Bayesian network approach","2015","Journal of the Operational Research Society","66","1","","86","115","29","23","10.1057/jors.2013.49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924368546&doi=10.1057%2fjors.2013.49&partnerID=40&md5=758e1df26065e81ffa99b929f7fdcd43","This paper describes the development of a tool, based on a Bayesian network model, that provides posteriori predictions of operational risk events, aggregate operational loss distributions, and Operational Value-at-Risk, for a structured finance operations unit located within one of Australia's major banks. The Bayesian network, based on a previously developed causal framework, has been designed to model the smaller and more frequent, attritional operational loss events. Given the limited availability of risk factor event information and operational loss data, we rely on the elicitation of subjective probabilities, sourced from domain experts. Parameter sensitivity analysis is performed to validate and check the model's robustness against the beliefs of risk management and operational staff. To ensure that the domain's evolving risk profile is captured through time, a formal approach to organizational learning is investigated that employs the automatic parameter adaption features of the Bayesian network model. A hypothetical case study is then described to demonstrate model adaption and the application of the tool to operational loss forecasting by a business unit risk manager. © 2015 Operational Research Society Ltd. All rights reserved.","Artificial intelligence; Banking; Bayesian networks; Finance; Operational risk; Probabilistic methods","Artificial intelligence; Finance; Human resource management; Knowledge management; Learning systems; Risk assessment; Risk management; Sensitivity analysis; Value engineering; Banking; Bayesian network models; Operational risks; Organizational learning; Parameter adaption; Parameter sensitivity analysis; Probabilistic methods; Subjective probability; Bayesian networks","Article","Final","","Scopus","2-s2.0-84924368546"
"Houssein E.H.; Dirar M.; Hussain K.; Mohamed W.M.","Houssein, Essam H. (43361385400); Dirar, Mahmoud (57219187365); Hussain, Kashif (57725431700); Mohamed, Waleed M. (57211990107)","43361385400; 57219187365; 57725431700; 57211990107","Assess deep learning models for Egyptian exchange prediction using nonlinear artificial neural networks","2021","Neural Computing and Applications","33","11","","5965","5987","22","26","10.1007/s00521-020-05374-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091604895&doi=10.1007%2fs00521-020-05374-9&partnerID=40&md5=2ebd34f199f700a67855ec0e07581c29","Financial analysis of the stock market using the historical data is the exigent demand in business and academia. This work explores the efficiency of three deep learning (Dl) techniques, namely Bayesian regularization (BE), Levenberg–Marquardt (lM), and scaled conjugate gradient (SCG), for training nonlinear autoregressive artificial neural networks (NARX) for predicting specifically the closing price of the Egyptian Stock Exchange indices (EGX-30, EGX-30-Capped, EGX-50-EWI, EGX-70, EGX-100, and NIlE). An empirical comparison is established among the experimented prediction models considering all techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. For performance evaluation, statistical measures such as mean squared error (MSE) and correlation R are used. From the simulation result, it can be clearly suggested that BR outperforms other models for short-term prediction especially for 3 days ahead. On the other hand, lM generates better prediction accuracy than BR- and SCG-based models for long-term prediction, especially for 7-day prediction. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Artificial neural networks; Autoregressive; Bayesian regularization; Deep learning; Egyptian stock market; Levenberg–Marquardt; Stock price prediction","Bayesian networks; Electronic trading; Financial markets; Forecasting; Mean square error; Neural networks; Predictive analytics; Bayesian regularization; Egyptian stock exchanges; Empirical - comparisons; Long-term prediction; Nonlinear artificial neural networks; Scaled conjugate gradients; Short term prediction; Statistical measures; Deep learning","Article","Final","","Scopus","2-s2.0-85091604895"
"Campino J.O.; Galizia F.; Serrano D.; Sperling F.","Campino, Jonas de Oliveira (42261384800); Galizia, Federico (57226368940); Serrano, Daniela (57226345816); Sperling, Frank (57226356435)","42261384800; 57226368940; 57226345816; 57226356435","Predicting sovereign credit ratings for portfolio stress testing","2021","Journal of Risk Management in Financial Institutions","14","3","","229","241","12","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111270345&partnerID=40&md5=b7e787cb45bc085b728c46e7dcb88f95","This paper analyses the relationship between macroeconomic and credit cycles. It is not a straightforward relationship, particularly in sovereign credit assessment. Modelling such a relationship requires blending scenario analysis and stress testing, together with dynamic modelling of macroeconomic and credit variables. The novelty of the presented approach is its ability to cross-pollinate machine learning and Monte Carlo (MC) simulation as part of a process that overcomes the challenges faced by risk managers. The result is a probabilistic forward-looking view of credit risk scenarios that can guide action. Sovereign credit ratings are expert opinions based on relevant macroeconomic, financial and policy information. We introduce a predictive machine learning model of sovereign credit ratings that lends itself naturally to MC simulations and stress testing. The Least Absolute Shrinkage and Selection Operator (LASSO) allows considering many variables simultaneously in a nonlinear fashion as candidates for predicting sovereign ratings. The portfolio stress testing capability comes in by augmenting the set of variables used in the MC simulations to include external shock variables common to the sovereigns in the portfolio, for example, relevant global commodity prices. The resulting rating distribution can be used to calculate different relevant risk metrics, including credit-sensitive measures of risk-weighted assets. © Henry Stewart Publications.","Capital adequacy; Credit rating; LASSO; Machine learning; Monte Carlo simulation; Sovereign risk; Stress testing","","Article","Final","","Scopus","2-s2.0-85111270345"
"Pröllochs N.; Feuerriegel S.; Neumann D.","Pröllochs, Nicolas (56902630900); Feuerriegel, Stefan (53881265200); Neumann, Dirk (7202067244)","56902630900; 53881265200; 7202067244","Negation scope detection in sentiment analysis: Decision support for news-driven trading","2016","Decision Support Systems","88","","","67","75","8","45","10.1016/j.dss.2016.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978808835&doi=10.1016%2fj.dss.2016.05.009&partnerID=40&md5=ee31c2cc1c8cee3ff33aa745c91d605f","Decision support for financial news using natural language processing requires robust methods that process all sentences correctly, including those that are negated. To predict the corresponding negation scope, related literature commonly utilizes rule-based algorithms and generative probabilistic models. In contrast, we propose the use of a tailored reinforcement learning method, since it can conquer learning task of arbitrary length. We then perform a thorough comparison with a two-pronged evaluation. First, we compare the predictive performance using a manually-labeled dataset. Here, reinforcement learning outperforms common approaches from the related literature, leading to a balanced classification accuracy of up to 70.17%. Second, we examine how detecting negation scopes can improve the accuracy of sentiment analysis for financial news, leading to an improvement of up to 10.63% in the correlation between news sentiment and stock market returns. This reveals negation scope detection as a crucial leverage in decision support from sentiment. © 2016 Elsevier B.V.","Decision support; Financial news; Machine learning; Negation scope detection; Sentiment analysis","Artificial intelligence; Commerce; Data mining; Finance; Learning algorithms; Learning systems; Natural language processing systems; Reinforcement learning; Classification accuracy; Decision supports; Financial news; NAtural language processing; Predictive performance; Reinforcement learning method; Rule based algorithms; Sentiment analysis; Decision support systems","Article","Final","","Scopus","2-s2.0-84978808835"
"Yan D.; Zhou Q.; Wang J.; Zhang N.","Yan, Dingqi (57191369819); Zhou, Qi (57191372419); Wang, Jianzhou (56380147600); Zhang, Na (57191371907)","57191369819; 57191372419; 56380147600; 57191371907","Bayesian regularisation neural network based on artificial intelligence optimisation","2017","International Journal of Production Research","55","8","","2266","2287","21","52","10.1080/00207543.2016.1237785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989252415&doi=10.1080%2f00207543.2016.1237785&partnerID=40&md5=817163b85669e08dd3d3a3ad2a688b4a","Stock prediction is generally considered to be challenging and known for its high noise and strong nonlinearities in financial time series analysis. However, current forecasting models ignore the importance of model parameter optimisation and the use of recent data. In this article, a novel forecasting approach with a Bayesian-regularised artificial neural networks (BR-ANN) was proposed. The weight of the proposed model (BR-ANN) is determined by the particle swarm optimisation (PSO) algorithm. Daily market prices and financial technical indicators are utilised as inputs to predict the one day future closing price of the Shanghai (in China) composite index. The Bayesian-regularised network uses a probabilistic nature for the network weights and can reduce the potential for over-fitting and over-training. Our empirical study and the results of our K-line theory analysis indicate that PSO is determined to be an effective algorithm to optimise the parameters of the Bayesian neural network compared with other well-known prediction algorithms. In particular, the PSO model is more reliable than the simple Bayesian regularisation neural network near the local maximum value. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","Bayesian methods; K-line; local weights; neural networks; over-fitting; PSO","Artificial intelligence; Bayesian networks; Financial data processing; Forecasting; Neural networks; Optimization; Time series analysis; Bayesian methods; Bayesian neural networks; Financial time series; K-lines; local weights; Overfitting; Particle swarm optimisation; Prediction algorithms; Particle swarm optimization (PSO)","Article","Final","","Scopus","2-s2.0-84989252415"
"Tan T.-K.; Lakehal-Ayat M.","Tan, Teik-Kheong (56767475700); Lakehal-Ayat, Merouane (57665864500)","56767475700; 57665864500","A big data Bayesian approach to earnings profitability in the S&P 500","2018","PSU Research Review","2","1","","35","58","23","1","10.1108/PRR-04-2017-0023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129419152&doi=10.1108%2fPRR-04-2017-0023&partnerID=40&md5=f1436cd320a393dc33cca661002b8225","Purpose: The impact of volatility crush can be devastating to an option buyer and results in a substantial capital loss, even with a directionally correct strategy. As a result, most volatility plays are for option sellers, but the profit they can achieve is limited and the sellers carry unlimited risk. This paper aims to demonstrate the dynamics of implied volatility (IV) as being influenced by effects of persistence, leverage, market sentiment and liquidity. From the exploratory factor analysis (EFA), they extract four constructs and the results from the confirmatory factor analysis (CFA) indicated a good model fit for the constructs. Design/methodology/approach: This section describes the methodology used for conducting the study. This includes the study area, study approach, sources of data, sampling technique and the method of data analysis. Findings: Although there is extensive literature on methods for estimating IV dynamics during earnings announcement, few researchers have looked at the impact of expected market maker move, IV differential and IV Rank on the IV path after the earnings announcement. One reason for this research gap is because of the recent introduction of weekly options for equities by the Chicago Board of Options Exchange (CBOE) back in late 2010. Even then, the CBOE only released weekly options four individual equities – Bank of America (BAC.N), Apple (AAPL.O), Citigroup (C.N) and US-listed shares of BP (BP.L) (BP.N). The introduction of weekly options provided more trading flexibility and precision timing from shorter durations. This automatically expanded expiration choices, which in turned offered greater access and flexibility from the perspective of trading volatility during earnings announcement. This study has demonstrated the impact of including market sentiment and liquidity into the forecasting model for IV during earnings. This understanding in turn helps traders to formulate strategies that can circumvent the undefined risk associated with trading options strategies such as writing strangles. Research limitations/implications: The first limitation of the study is that the firms included in the study are relatively large, and the results of the study can therefore not be generalized to medium sized and small firms. The second limitation lies in the current sample size, which in many cases was not enough to be able to draw reliable conclusions on. Scaling the sample size up is only a function of time and effort. This is easily overcome and should not be a limitation in the future. The third limitation concerns the measurement of the variables. Under the assumption of a normal distribution of returns (i.e. stock prices follow a random walk process), which means that the distribution of returns is symmetrical, one can estimate the probabilities of potential gains or losses associated with each amount. This means the standard deviation of securities returns, which is called historical volatility and is usually calculated as a moving average, can be used as a risk indicator. The prices used for the calculations are usually the closing prices, but Parkinson (1980) suggests that the day’s high and low prices would provide a better estimate of real volatility. One can also refine the analysis with high-frequency data. Such data enable the avoidance of the bias stemming from the use of closing (or opening) prices, but they have only been available for a relatively short time. The length of the observation period is another topic that is still under debate. There are no criteria that enable one to conclude that volatility calculated in relation to mean returns over 20 trading days (or one month) and then annualized is any more or less representative than volatility calculated over 130 trading days (or six months) and then annualized, or even than volatility measured directly over 260 trading days (one year). Nonetheless, the guidelines adopted in this study represent the best practices of researchers thus far. Practical implications: This study has indicated that an earnings announcement can provide a volatility mispricing opportunity to allow an investor to profit from a sudden, sharp drop in IV. More specifically, the methodology developed by Tan and Bing is now well supported both empirically and theoretically in terms of qualifying opportunities that can be profitable because of the volatility crush. Conventionally, the option strategy of shorting strangles carries unlimited theoretical risk; however, the methodology has demonstrated that this risk can be substantially reduced if followed judiciously. This profitable strategy relies on a set of qualifying parameters including liquidity, premium collection, volatility differential, expected market move and market sentiment. Building upon this framework, the understanding of the effects of persistence and leverage resulted in further reducing the risk associated with trading options during earnings announcements. As a guideline, the sentiment and liquidity variables help to qualify a trade and the effects of persistence and leverage help to close the qualified trade. Social implications: The authors find a positive association between the effects of market sentiment, liquidity, persistence and leverage in the dynamics of IV during earnings announcement. These findings substantiate further the four factors that influence IV dynamics during earnings announcement and conclude that just looking at persistence and leverage alone will not generate profitable trading opportunities. Originality/value: The impact of volatility crush can be devastating to the option buyer with substantial capital loss, even for a directionally correct strategy. As a result, most volatility plays are for option sellers; however, the profit is limited and the sellers carry unlimited risk. The authors demonstrate the dynamics of IV as being influenced by effects of persistence, leverage, market sentiment and liquidity. From the EFA, they extracted four constructs and the results from the CFA indicated a good model fit for the constructs. Using EFA, CFA and Bayesian analysis, how this model can help investors formulate the right strategy to achieve the best risk/reward mix is demonstrated. Using Bayesian estimation and IV differential to proxy for differences of opinion about term structures in option pricing, the authors find a positive association among the effects of market sentiment, liquidity, persistence and leverage in the dynamics of IV during earnings announcement. © 2018, Teik-Kheong Tan and Merouane Lakehal-Ayat.","Bayesian; Data analytics; Factor analysis; Implied volatility; Machine learning; Structured equation modeling","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85129419152"
"Wang J.; He J.; Feng C.; Feng L.; Li Y.","Wang, Jujie (36550718400); He, Junjie (57219018783); Feng, Chunchen (57219016914); Feng, Liu (57219011595); Li, Yang (57219007657)","36550718400; 57219018783; 57219016914; 57219011595; 57219007657","Stock index prediction and uncertainty analysis using multi-scale nonlinear ensemble paradigm of optimal feature extraction, two-stage deep learning and Gaussian process regression","2021","Applied Soft Computing","113","","107898","","","","14","10.1016/j.asoc.2021.107898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115806913&doi=10.1016%2fj.asoc.2021.107898&partnerID=40&md5=29fffcf7e4c9a70149c93e3910fb0459","Reliable prediction of stock indexes can be highly valuable for financial decision-making and risk management. The stock market is a highly complicated nonlinear system which makes it difficult to present accurate predictors. In this paper, an innovative multi-scale nonlinear ensemble paradigm is proposed for stock index prediction and uncertainty analysis, which consists of an optimal feature extraction including variational mode decomposition and auto-encoder, a two-stage deep learning based on recurrent neural network and long short-term memory, and Gaussian process regression. The optimal feature extraction is proposed to extract the optimal features of stock index fluctuations and eliminate the disturbance of illusive components. The two-stage deep learning is developed to conduct the prediction of each feature sub-signal and implement its nonlinear integration. The Gaussian process regression is utilized to construct the interval prediction of the original stock signal and analyze the uncertainties of stock market. The validity of the developed model is verified by the data from S&P 500, Dow Jones index and NASDAQ. After a series of comparisons, the mean absolute percentage errors of the proposed model in S&P 500, Dow Jones index and NASDAQ are 0.55%, 0.65% and 1.11%, respectively. These results fully verify the effectiveness of proposed model. © 2021 Elsevier B.V.","Gaussian process regression; Multi-scale nonlinear ensemble paradigm; Optimal feature extraction; Stock index prediction; Two-stage deep learning","Commerce; Decision making; Deep neural networks; Extraction; Financial markets; Forecasting; Gaussian distribution; Gaussian noise (electronic); Nonlinear analysis; Recurrent neural networks; Regression analysis; Risk management; Uncertainty analysis; Dow Jones; Features extraction; Gaussian process regression; Learning process; Multi-scale nonlinear ensemble paradigm; Multi-scales; Optimal feature extraction; Stock index predictions; Stock indices; Two-stage deep learning; Feature extraction","Article","Final","","Scopus","2-s2.0-85115806913"
"Ma Y.; Zhang Z.; Kang Y.; Özdoğan M.","Ma, Yuchi (57217279668); Zhang, Zhou (57001873100); Kang, Yanghui (57092900800); Özdoğan, Mutlu (7003494809)","57217279668; 57001873100; 57092900800; 7003494809","Corn yield prediction and uncertainty analysis based on remotely sensed variables using a Bayesian neural network approach","2021","Remote Sensing of Environment","259","","112408","","","","129","10.1016/j.rse.2021.112408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103401930&doi=10.1016%2fj.rse.2021.112408&partnerID=40&md5=6bdce738b246ec9626f1ae1737c11904","As the world's leading corn producer, the United States supplies more than 30% of the global corn production. Accurate and timely estimation of corn yield is therefore essential for commodity trading and global food security. Recently, several deep learning models have been explored for corn yield forecasting. Despite success, most existing models only provide yield estimations without quantifying the uncertainty associated with the predictions. Also, the traditional deep learning approaches typically require a large training set and are easily prone to overfitting when the number of samples in the training set is relatively small. To address these limitations, in this study, we developed a county-level corn yield prediction model based on Bayesian Neural Network (BNN) using multiple data sources that are publicly available, including time-series satellite products, sequential climate observations, soil property maps, and historical corn yield records. Using preceding years since 2001 for model training, the developed BNN model achieved an average coefficient of determination (R2) of 0.77 for late-season prediction across the U.S. Corn Belt in testing years 2010–2019, and outperformed five other state-of-the-art machine learning models. Detailed evaluation in three representative testing years demonstrated that the proposed BNN model could accurately estimate corn yield not only in normal years but also in abnormal years when extreme weather events happened. Moreover, the timeliness of the prediction was evaluated within the growing season with an R2~0.75 achieved by middle August, which is about 2 months before the harvest. We also assessed the predictive uncertainty, and more than 84% of the observed yield records were successfully enveloped in the 95% confidence interval of the predictive yield distribution. Our results also showed that the uncertainty level decreased steadily as time proceeded and stabilized around early August. Uncertainties in yield prediction were mainly induced by the observation noise and also related to the interannual and seasonal variabilities of environmental stress such as heat and water stress. This paper provides a robust framework for the within-season prediction of crop yield and highlights the need to obtain a deeper understanding of the effects of environmental stress on agricultural productivity and crop yield estimation. © 2021 Elsevier Inc.","Bayesian neural network; Corn yield prediction; Deep learning; Remote sensing; Uncertainty estimation","Bayesian networks; Climate models; Crops; Deep neural networks; Financial markets; Food supply; Forecasting; Productivity; Uncertainty analysis; Yield stress; Bayesian neural networks; Corn yield prediction; Corn yields; Deep learning; Remote-sensing; Training sets; Uncertainty; Uncertainty estimation; Yield estimation; Yield prediction; artificial neural network; Bayesian analysis; crop yield; estimation method; extreme event; food security; maize; numerical model; remote sensing; uncertainty analysis; Remote sensing","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85103401930"
"Hoque K.E.; Aljamaan H.","Hoque, Kazi Ekramul (57375570100); Aljamaan, Hamoud (57220207494)","57375570100; 57220207494","Impact of hyperparameter tuning on machine learning models in stock price forecasting","2021","IEEE Access","9","","","163815","163830","15","38","10.1109/ACCESS.2021.3134138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121360956&doi=10.1109%2fACCESS.2021.3134138&partnerID=40&md5=29cb767b8e4beb5dd1559cecda56cd58","Stock price forecasting has been reported as a challenging task in the scientific and financial communities due to stock prices’ nonlinear and dynamic nature. Machine learning models exhibit capabilities that allow them to handle nonlinear data and be candidate tools for stock price forecasting. In this study, an empirical evaluation of eight conventional machine learning models’ is conducted to forecast the stock price of eleven companies belonging to the Saudi Stock Exchange. Moreover, the optimal configuration of hyperparameters in each machine learning model is identified. Forecasting performance is evaluated by two well-known error metrics: Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). Wilcoxson effect size is utilized to determine the impact of hyperparameter tuning by comparing tuned and un-tuned machine learning models’ forecasting performance. Empirical results indicate there are varying impacts of hyperparameter tuning of machine learning models in forecasting stock price. After tuning the hyperparameters, Support Vector Regression outperforms other forecasting models with a significant statistical difference. In contrast, Kernel Ridge Regression shows noteworthy forecasting performance without hyperparameter tuning with respect to other un-tuned forecasting models. However, Decision Tree and K-Nearest Neighbour are the poor-performing models which demonstrate inadequate forecasting performance even after hyperparameter tuning. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Gaussian process regression; Hyperparameter tuning; Kernel ridge regression; LASSO; Machine learning; Stock price forecasting; Support vector regression; Time series analysis","Biological systems; Decision trees; Errors; Financial markets; Harmonic analysis; Machine learning; Mean square error; Nearest neighbor search; Regression analysis; Time series analysis; Biological system modeling; Gaussian process regression; Hyper-parameter; Hyperparameter tuning; Kernel ridge regressions; LASSO; Machine-learning; Predictive models; Stock price forecasting; Support vector regressions; Time-series analysis; Tuning; Forecasting","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121360956"
"Popovic M.; Thomas F.; Papatheodorou S.; Funk N.; Vidal-Calleja T.; Leutenegger S.","Popovic, Marija (57195415517); Thomas, Florian (57221702525); Papatheodorou, Sotiris (57191057984); Funk, Nils (57207943921); Vidal-Calleja, Teresa (6507021929); Leutenegger, Stefan (23009389600)","57195415517; 57221702525; 57191057984; 57207943921; 6507021929; 23009389600","Volumetric occupancy mapping with probabilistic depth completion for robotic navigation","2021","IEEE Robotics and Automation Letters","6","3","9392300","5072","5079","7","10","10.1109/LRA.2021.3070308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103784977&doi=10.1109%2fLRA.2021.3070308&partnerID=40&md5=04fd1d138df330392f89b2b30f71b21e","In robotic applications, a key requirement for safe and efficient motion planning is the ability to map obstacle-free space in unknown, cluttered 3D environments. However, commodity-grade RGB-D cameras commonly used for sensing fail to register valid depth values on shiny, glossy, bright, or distant surfaces, leading to missing data in the map. To address this issue, we propose a framework leveraging probabilistic depth completion as an additional input for spatial mapping. We introduce a deep learning architecture providing uncertainty estimates for the depth completion of RGB-D images. Our pipeline exploits the inferred missing depth values and depth uncertainty to complement raw depth images and improve the speed and quality of free space mapping. Evaluations on synthetic data show that our approach maps significantly more correct free space with relatively low error when compared against using raw data alone in different indoor environments; thereby producing more complete maps that can be directly used for robotic navigation tasks. The performance of our framework is validated using real-world data. © 2016 IEEE.","Computer vision; Machine learning; Mobile robots; Simultaneous localisation and mapping","Agricultural robots; Air navigation; Deep learning; Image enhancement; Mapping; Robotics; Uncertainty analysis; 3-D environments; Commodity grades; Indoor environment; Learning architectures; Robotic applications; Robotic navigation; Spatial mapping; Uncertainty estimates; Robot programming","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85103784977"
"Prusa J.D.; Sagul R.T.; Khoshgoftaar T.M.","Prusa, Joseph D. (57117743400); Sagul, Ryan T. (57201285543); Khoshgoftaar, Taghi M. (7006211475)","57117743400; 57201285543; 7006211475","Extracting Knowledge from Technical Reports for the Valuation of West Texas Intermediate Crude Oil Futures","2019","Information Systems Frontiers","21","1","","109","123","14","4","10.1007/s10796-018-9859-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047833776&doi=10.1007%2fs10796-018-9859-2&partnerID=40&md5=c1300a48089e10bccf7fa223e5be5ca4","This paper proposes and demonstrates an approach for the often-attempted problem of market prediction, framed as classification task. We restrict our study to a widely purchased and well recognized commodity, West Texas Intermediate crude oil, which experiences significant volatility. For this purpose, nine learners using features extracted from monthly International Energy Agency (IEA) reports to predict undervalued, overvalued, and accurate valuation of the oil futures between 2003 and 2015. The often touted “Efficient Market Hypothesis” (EMH) suggests that it is impossible for individual investors to “beat the market” as market and external forces, such as geopolitical crises and natural disasters, are nearly impossible to predict. However, four algorithms were statistically better at the 95% confidence interval than “Zero-Rule” and “Random-Guess” strategies which are expected to pseudo-reflect the EMH. Furthermore, the addition of text features can significantly improve performance compared to only using price history from the oil futures data, challenging the validity of the semi-strong versions of the EMH in the crude oil market. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Crude oil market; Machine learning; Text mining","Commerce; Data mining; Disasters; Financial markets; Forecasting; Investments; Learning systems; Text processing; Classification tasks; Confidence interval; Crude oil market; Efficient market hypothesis; Improve performance; International energy agency; Text mining; West texas intermediates; Crude oil","Article","Final","","Scopus","2-s2.0-85047833776"
"Sharma S.; Elvira V.; Chouzenoux E.; Majumdar A.","Sharma, Shalini (57219900410); Elvira, Víctor (56369475400); Chouzenoux, Emilie (36628043900); Majumdar, Angshul (23971203100)","57219900410; 56369475400; 36628043900; 23971203100","Recurrent dictionary learning for state-space models with an application in stock forecasting","2021","Neurocomputing","450","","","1","13","12","11","10.1016/j.neucom.2021.03.111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104725042&doi=10.1016%2fj.neucom.2021.03.111&partnerID=40&md5=875ec8b0caf8f8a44c19a596f7fdf3e5","In this work, we introduce a new modeling and inferential tool for dynamical processing of time series. The approach is called recurrent dictionary learning (RDL). The proposed model reads as a linear Gaussian Markovian state-space model involving two linear operators, the state evolution and the observation matrices, that we assumed to be unknown. These two unknown operators (that can be seen interpreted as dictionaries) and the sequence of hidden states are jointly learnt via an expectation–maximization algorithm. The RDL model gathers several advantages, namely online processing, probabilistic inference, and a high model expressiveness which is usually typical of neural networks. RDL is particularly well suited for stock forecasting. Its performance is illustrated on two problems: next day forecasting (regression problem) and next day trading (classification problem), given past stock market observations. Experimental results show that our proposed method excels over state-of-the-art stock analysis models such as CNN-TA, MFNN, and LSTM. © 2021 Elsevier B.V.","Dynamical modeling; Expectation-minimization; Kalman filter; Recurrent dictionary learning; Stock forecasting; Uncertainty quantification","Commerce; Electronic trading; Financial markets; Kalman filters; Long short-term memory; Mathematical operators; State space methods; Uncertainty analysis; Dictionary learning; Dynamical model; Expectation minimization; Gaussians; Markovian; Recurrent dictionary learning; State-space models; Stock forecasting; Times series; Uncertainty quantifications; algorithm; Article; calculation; forecasting; machine learning; mathematical analysis; mathematical model; online system; prediction; probability; recurrent dictionary learning; simulation; stock forecasting; validity; Forecasting","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104725042"
"Popov S.; Buchanan W.J.","Popov, Serguei (7202624224); Buchanan, William J. (56206746600)","7202624224; 56206746600","FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures","2021","Journal of Parallel and Distributed Computing","147","","","77","86","9","26","10.1016/j.jpdc.2020.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090601605&doi=10.1016%2fj.jpdc.2020.09.002&partnerID=40&md5=d9da939ef2bad423b41dcbdcd9ef89f9","This paper presents a novel leaderless protocol (FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures) with a low communicational complexity and which allows a set of nodes to come to a consensus on a value of a single bit. The paper makes the assumption that part of the nodes are Byzantine, and are thus controlled by an adversary who intends to either delay the consensus, or break it (this defines that at least a couple of honest nodes come to different conclusions). We prove that, nevertheless, the protocol works with high probability when its parameters are suitably chosen. Along this the paper also provides explicit estimates on the probability that the protocol finalizes in the consensus state in a given time. This protocol could be applied to reaching consensus in decentralized cryptocurrency systems. A special feature of it is that it makes use of a sequence of random numbers which are either provided by a trusted source or generated by the nodes themselves using some decentralized random number generating protocol. This increases the overall trustworthiness of the infrastructure. A core contribution of the paper is that it uses a very weak consensus to obtain a strong consensus on the value of a bit, and which can relate to the validity of a transaction. © 2020 Elsevier Inc.","Consensus; Decentralized cryptocurrency systems; Decentralized randomness; Voting","Artificial intelligence; Computer programming; Communicational complexity; High probability; Random Numbers; Single-bit; Weak consensus; Random number generation","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85090601605"
"De Spiegeleer J.; Madan D.B.; Reyners S.; Schoutens W.","De Spiegeleer, Jan (55597147500); Madan, Dilip B. (7003372814); Reyners, Sofie (57203222312); Schoutens, Wim (6603008020)","55597147500; 7003372814; 57203222312; 6603008020","Machine learning for quantitative finance: fast derivative pricing, hedging and fitting","2018","Quantitative Finance","18","10","","1635","1643","8","87","10.1080/14697688.2018.1495335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050968291&doi=10.1080%2f14697688.2018.1495335&partnerID=40&md5=c5e2c7dcc73bd3bd24e857ac2f82cb84","In this paper, we show how we can deploy machine learning techniques in the context of traditional quant problems. We illustrate that for many classical problems, we can arrive at speed-ups of several orders of magnitude by deploying machine learning techniques based on Gaussian process regression. The price we have to pay for this extra speed is some loss of accuracy. However, we show that this reduced accuracy is often well within reasonable limits and hence very acceptable from a practical point of view. The concrete examples concern fitting and estimation. In the fitting context, we fit sophisticated Greek profiles and summarize implied volatility surfaces. In the estimation context, we reduce computation times for the calculation of vanilla option values under advanced models, the pricing of American options and the pricing of exotic options under models beyond the Black–Scholes setting. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","Derivative pricing; Gaussian processes; Hedging; Machine learning; Volatility surface","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85050968291"
"Lee M.; Seok J.","Lee, Minhyeok (57194701375); Seok, Junhee (24069490100)","57194701375; 24069490100","Estimation with uncertainty via conditional generative adversarial networks","2021","Sensors","21","18","6194","","","","12","10.3390/s21186194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114930195&doi=10.3390%2fs21186194&partnerID=40&md5=0d6236685ea2e32aa719580671d6ddc9","Conventional predictive Artificial Neural Networks (ANNs) commonly employ deterministic weight matrices; therefore, their prediction is a point estimate. Such a deterministic nature in ANNs causes the limitations of using ANNs for medical diagnosis, law problems, and portfolio management in which not only discovering the prediction but also the uncertainty of the prediction is essentially required. In order to address such a problem, we propose a predictive probabilistic neural network model, which corresponds to a different manner of using the generator in the conditional Generative Adversarial Network (cGAN) that has been routinely used for conditional sample genera-tion. By reversing the input and output of ordinary cGAN, the model can be successfully used as a predictive model; moreover, the model is robust against noises since adversarial training is employed. In addition, to measure the uncertainty of predictions, we introduce the entropy and relative entropy for regression problems and classification problems, respectively. The proposed framework is applied to stock market data and an image classification task. As a result, the proposed framework shows superior estimation performance, especially on noisy data; moreover, it is demonstrated that the proposed framework can properly estimate the uncertainty of predictions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Adversarial learning; Deep learning; Generative adversarial network; Portfolio management; Probability estima-tion; Risk estimation","Neural Networks, Computer; Uncertainty; Diagnosis; Electronic trading; Entropy; Financial markets; Forecasting; Investments; Medical problems; Predictive analytics; Uncertainty analysis; Adversarial networks; Estimation performance; Input and outputs; Portfolio managements; Predictive modeling; Probabilistic neural network models; Regression problem; Relative entropy; uncertainty; Neural networks","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85114930195"
"Poongodi M.; Vijayakumar V.; Chilamkurti N.","Poongodi, M. (55806765400); Vijayakumar, V. (57200993506); Chilamkurti, Naveen (6602599658)","55806765400; 57200993506; 6602599658","Bitcoin price prediction using ARIMA model","2020","International Journal of Internet Technology and Secured Transactions","10","4","","396","406","10","42","10.1504/IJITST.2020.108130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088250341&doi=10.1504%2fIJITST.2020.108130&partnerID=40&md5=1569d879a3bf5536cb1072d3e1a21200","Bitcoin is a highly volatile cryptocurrency with rising popularity. It is a turning point in the way currency is seen. Now the currency, rather than being physical is becoming more and more digital. Due to high variance of solo mining, the number of users joining top most famous bitcoin mining pools is increasing due to the fact that users together under a bitcoin pool will have a higher chance of generating next block in the bitcoins blockchain by reducing the variance and earning the mining reward. In this research paper we are doing a survey on the technology lying underneath bitcoin's network and the various machine learning predictive algorithms. We collected the dataset on bitcoin blockchain from 28 April 2013 to 31 July 2017 which is publicly available on https://coinmarketcap.com and applied the ARIMA model for price prediction of bitcoin. Copyright © 2020 Inderscience Enterprises Ltd.","ARIMA model; Bayesian model; Bitcoin; Blockchain; Cryptocurrency; Mining; Neural network; Predictive analysis; Regression model; Support vector machine; SVM","","Article","Final","","Scopus","2-s2.0-85088250341"
"Habyarimana E.; Baloch F.S.","Habyarimana, Ephrem (55096625200); Baloch, Faheem S. (25824197600)","55096625200; 25824197600","Machine learning models based on remote and proximal sensing as potential methods for in-season biomass yields prediction in commercial sorghum fields","2021","PLoS ONE","16","3 March","e0249136","","","","9","10.1371/journal.pone.0249136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103241747&doi=10.1371%2fjournal.pone.0249136&partnerID=40&md5=9a22deff9ede0b628f5c1392e67ad77f","Crop yield monitoring demonstrated the potential to improve agricultural productivity through improved crop breeding, farm management and commodity planning. Remote and proximal sensing offer the possibility to cut crop monitoring costs traditionally associated with surveys and censuses. Fraction of absorbed photosynthetically active radiation (fAPAR), chlorophyll concentration (CI) and normalized difference vegetation (NDVI) indices were used in crop monitoring, but their comparative performances in sorghum monitoring is lacking. This work aimed therefore at closing this gap by evaluating the performance of machine learning modelling of in-season sorghum biomass yields based on Sentinel-2-derived fAPAR and simpler high-throughput optical handheld meters-derived NDVI and CI calculated from sorghum plants reflectance. Bayesian ridge regression showed good cross-validated performance, and high reliability (R2 = 35%) and low bias (mean absolute prediction error, MAPE = 0.4%) during the validation step. Hand-held optical meter-derived CI and Sentinel-2- derived fAPAR showed comparable effects on machine learning performance, but CI outperformed NDVI and was therefore considered as a good alternative to Sentinel-2's fAPAR. The best times to sample the vegetation indices were the months of June (second half) and July. The results obtained in this work will serve several purposes including improvements in plant breeding, farming management and sorghum biomass yield forecasting at extension services and policy making levels. © 2021 Habyarimana, Baloch. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Bayes Theorem; Biomass; Chlorophyll; Crops, Agricultural; Machine Learning; Remote Sensing Technology; Seasons; Sorghum; chlorophyll; agricultural worker; article; forecasting; fraction absorbed; machine learning; management; nonhuman; photosynthetically active radiation; plant breeding; plant yield; prediction; reliability; season; sorghum; vegetation; Bayes theorem; biomass; chemistry; crop; growth, development and aging; physiology; remote sensing; season; sorghum","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85103241747"
"Kobayashi S.; Shirayama S.","Kobayashi, Shusuke (57218367846); Shirayama, Susumu (6603855322)","57218367846; 6603855322","Selecting data adaptive learner from multiple deep learners using Bayesian networks","2021","Neural Computing and Applications","33","9","","4229","4241","12","2","10.1007/s00521-020-05234-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088956411&doi=10.1007%2fs00521-020-05234-6&partnerID=40&md5=dd2d7a2b46141e3be87dfbd404762485","A method to predict time series using multiple deep learners and a Bayesian network is proposed. In this study, the input explanatory variables are Bayesian network nodes that are associated with learners. Training data are divided using K-means clustering, and multiple deep learners are trained depending on the cluster. A Bayesian network is used to determine which deep learner is in charge of predicting a time series. We determine a threshold value and select learners with a posterior probability equal to or greater than the threshold value, which could facilitate more robust prediction. The proposed method is applied to financial time-series data, and the predicted results for the Nikkei 225 index are demonstrated. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Bayesian network; Deep learning; Mixture of experts; Time-series forecasting","Financial data processing; Forecasting; K-means clustering; Time series; Explanatory variables; Financial time series; Posterior probability; Robust predictions; Threshold-value; Training data; Bayesian networks","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85088956411"
"Senapati M.R.; Das S.; Mishra S.","Senapati, Manas Ranjan (56316698800); Das, Sumanjit (57210041798); Mishra, Sarojananda (55554581300)","56316698800; 57210041798; 55554581300","A Novel Model for Stock Price Prediction Using Hybrid Neural Network","2018","Journal of The Institution of Engineers (India): Series B","99","6","","555","563","8","26","10.1007/s40031-018-0343-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055861561&doi=10.1007%2fs40031-018-0343-7&partnerID=40&md5=9ae66078591f8ee1b883c1c99eb9c080","The foremost challenge for investors is to select stock price by analyzing financial data which is a menial task as of distort associated and massive pattern. Thereby, selecting stock poses one of the greatest difficulties for investors. Nowadays, prediction of financial market like stock market, exchange rate and share value are very challenging field of research. The prediction and scrutinization of stock price is also a potential area of research due to its vital significance in decision making by financial investors. This paper presents an intelligent and an optimal model for prophecy of stock market price using hybridization of Adaline Neural Network (ANN) and modified Particle Swarm Optimization (PSO). The connoted model hybrid of Adaline and PSO uses fluctuations of stock market as a factor and employs PSO to optimize and update weights of Adaline representation to depict open price of Bombay stock exchange. The prediction performance of the proposed model is compared with different representations like interval measurements, CMS-PSO and Bayesian-ANN. The result indicates that proposed scheme has an edge over all the juxtaposed schemes in terms of mean absolute percentage error. © 2018, The Institution of Engineers (India).","Artificial Intelligence; Data mining; Neural network; Prediction; Soft computing; Stock market","Artificial intelligence; Commerce; Data mining; Decision making; Electronic trading; Financial markets; Forecasting; Neural networks; Particle swarm optimization (PSO); Soft computing; Adaline neural network; Bombay stock exchanges; Hybrid neural networks; Interval measurement; Mean absolute percentage error; Modified particle swarm optimization; Prediction performance; Stock price prediction; Investments","Article","Final","","Scopus","2-s2.0-85055861561"
"Dash R.; Dash P.K.","Dash, Rajashree (42560989800); Dash, Pradipta Kishore (7102314306)","42560989800; 7102314306","A hybrid stock trading framework integrating technical analysis with machine learning techniques","2016","Journal of Finance and Data Science","2","1","","42","57","15","148","10.1016/j.jfds.2016.03.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021164773&doi=10.1016%2fj.jfds.2016.03.002&partnerID=40&md5=44f27228ce8dc39a0ccb2ea6605d999a","In this paper, a novel decision support system using a computational efficient functional link artificial neural network (CEFLANN) and a set of rules is proposed to generate the trading decisions more effectively. Here the problem of stock trading decision prediction is articulated as a classification problem with three class values representing the buy, hold and sell signals. The CEFLANN network used in the decision support system produces a set of continuous trading signals within the range 0–1 by analyzing the nonlinear relationship exists between few popular technical indicators. Further the output trading signals are used to track the trend and to produce the trading decision based on that trend using some trading rules. The novelty of the approach is to engender the profitable stock trading decision points through integration of the learning ability of CEFLANN neural network with the technical analysis rules. For assessing the potential use of the proposed method, the model performance is also compared with some other machine learning techniques such as Support Vector Machine (SVM), Naive Bayesian model, K nearest neighbor model (KNN) and Decision Tree (DT) model. © 2016 China Science Publishing & Media Ltd.","CEFLANN; Stock trading; Stock trend analysis; Technical indicators","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85021164773"
"Maniatopoulos A.; Gazis A.; Mitianoudis N.","Maniatopoulos, Andreas (57197848249); Gazis, Alexandros (57195803650); Mitianoudis, Nikolaos (55946387600)","57197848249; 57195803650; 55946387600","Technical analysis forecasting and evaluation of stock markets: the probabilistic recovery neural network approach","2022","International Journal of Economics and Business Research","25","1","","64","100","36","1","10.1504/ijebr.2023.127271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144385663&doi=10.1504%2fijebr.2023.127271&partnerID=40&md5=ac6c65e1414c6defd5ef5d1742e26661","The market efficiency theory suggests that stock market pricing reflects all publicly available information regarding a given stock. To outperform the market, a shareholder must study the market’s price volume patterns and predict human behaviour and tendencies. Except for conventional approaches based on fundamental or technical analysis, new tools are currently proposed using big data and artificial intelligence. This publication analyses and evaluates four commonly used deep-learning artificial neural network models. Then, it proposes a new method by adopting the ‘probabilistic recovery’ algorithmic approach. The dataset used consists of 501 unique company names based on real data derived from US Dow Jones. This method closely follows the market’s behaviour, providing daily upwards-downwards data trends. The proposed system can be used as a tool for technical analysis regarding the prediction accuracy of trading strategies, providing approximately 60% future movements’ accuracy, over 90% relative price prediction and annual investment return slightly over 60%. Copyright © 2023 Inderscience Enterprises Ltd.","algorithmic trading; CNNs; decision making; finance convolutional neural networks; finance generative adversarial networks; fully connected neural networks; neural networks; probablistic neural network; recurrent neural networks; RNNs; stock market dynamics; stock market forecast; stock market neural networks forecasting; stock market prediction; technical analysis; technical indicators; trading strategies","","Article","Final","","Scopus","2-s2.0-85144385663"
"Jammalamadaka S.R.; Qiu J.; Ning N.","Jammalamadaka, S. Rao (6701312698); Qiu, Jinwen (57204920122); Ning, Ning (57198887050)","6701312698; 57204920122; 57198887050","Predicting a stock portfolio with the multivariate bayesian structural time series model: Do news or emotions matter?","2019","International Journal of Artificial Intelligence","17","2","","81","104","23","28","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073325015&partnerID=40&md5=134f516a105b80b30fb4dc0e920c65b4","In this paper, we provide methods for creatively incorporating information from financial news and Twitter feeds into predicting the prices of a portfolio of stocks, using the framework of the Multivariate Bayesian Structural Time Series (MBSTS) model. MBSTS is a Bayesian machine learning model designed to capture correlations among multiple target time series, while using a number of contemporaneous predictors. As an illustration of the current model, we use data on two leading online commerce companies, namely Amazon and eBay, and run extensive empirical experiments to examine which if any, text mining predictors would add to the predictability of a stock price. Evaluation of competing models such as the autoregressive integrated moving average (ARIMA) model, and the recurrent neural network (RNN) model with long short term memory (LSTM), in terms of their performances with respect to cumulative one-step-ahead forecast errors with and without sentimental predictors, were carried out. Our contributions are threefold: Firstly, our model is the first one that successfully incorporated the online text mining to an advanced multivariate Bayesian machine learning time series model, which opens the door of applying both text mining and machine learning simultaneously in modern quantitative finance research; Secondly, under the presence of both modern and classical predictors in both fundamental and technical sense, the polarity of news still adds on a complementary effect; Thirdly, we discover that all models under investigation with sentimental predictors do outperform models without these sentimental predictors, and the MBSTS model with sentimental predictors outperforms all the other models. © 2019 [International Journal of Artificial Intelligence].","Feature Selection; Sentiment Analysis; Text Mining; Time Series Forecast","","Article","Final","","Scopus","2-s2.0-85073325015"
"Khedr A.M.; Arif I.; Pravija Raj P.V.; El-Bannany M.; Alhashmi S.M.; Sreedharan M.","Khedr, Ahmed M. (14037564400); Arif, Ifra (57212209244); Pravija Raj, P.V. (57216853293); El-Bannany, Magdi (6504438838); Alhashmi, Saadat M. (14919130700); Sreedharan, Meenu (57215592560)","14037564400; 57212209244; 57216853293; 6504438838; 14919130700; 57215592560","Cryptocurrency price prediction using traditional statistical and machine-learning techniques: A survey","2021","Intelligent Systems in Accounting, Finance and Management","28","1","","3","34","31","90","10.1002/isaf.1488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103254304&doi=10.1002%2fisaf.1488&partnerID=40&md5=b8bbe83a8a14fe055ad61471c8eae2b3","Cryptocurrencies are decentralized electronic counterparts of government-issued money. The first and best-known cryptocurrency example is bitcoin. Cryptocurrencies are used to make transactions anonymously and securely over the internet. The decentralization behavior of a cryptocurrency has radically reduced central control over them, thereby influencing international trade and relations. Wide fluctuations in cryptocurrency prices motivate the urgent requirement for an accurate model to predict its price. Cryptocurrency price prediction is one of the trending areas among researchers. Research work in this field uses traditional statistical and machine-learning techniques, such as Bayesian regression, logistic regression, linear regression, support vector machine, artificial neural network, deep learning, and reinforcement learning. No seasonal effects exist in cryptocurrency, making it hard to predict using a statistical approach. Traditional statistical methods, although simple to implement and interpret, require a lot of statistical assumptions that could be unrealistic, leaving machine learning as the best technology in this field, being capable of predicting price based on experience. This article provides a comprehensive summary of the previous studies in the field of cryptocurrency price prediction from 2010 to 2020. The discussion presented in this article will help researchers to fill the gap in existing studies and gain more future insight. © 2021 John Wiley & Sons, Ltd.","bitcoin (BTC); cryptocurrency price prediction; deep learning (DL); machine learning (ML); reinforcement learning (RL)","","Review","Final","","Scopus","2-s2.0-85103254304"
"Cavus N.; Mohammed Y.B.; Gital A.Y.; Bulama M.; Tukur A.M.; Mohammed D.; Isah M.L.; Hassan A.","Cavus, Nadire (18036901300); Mohammed, Yakubu Bala (57223669830); Gital, Abdulsalam Ya’U (56077965400); Bulama, Mohammed (57703332000); Tukur, Adamu Muhammad (57703791300); Mohammed, Danlami (57703556900); Isah, Muhammad Lamir (57189355545); Hassan, Abba (57703332100)","18036901300; 57223669830; 56077965400; 57703332000; 57703791300; 57703556900; 57189355545; 57703332100","Emotional Artificial Neural Networks and Gaussian Process-Regression-Based Hybrid Machine-Learning Model for Prediction of Security and Privacy Effects on M-Banking Attractiveness","2022","Sustainability (Switzerland)","14","10","5826","","","","12","10.3390/su14105826","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130575545&doi=10.3390%2fsu14105826&partnerID=40&md5=da93bd1b3188735af530d9c4005935ba","With recent advances in mobile and internet technologies, the digital payment market is an increasingly integral part of people’s lives, offering many useful and interesting services, e.g., m-banking and cryptocurrency. The m-banking system allows users to pay for goods, services, and earn money via cryptotrading using any device such as mobile phones from anywhere. With the recent trends in global digital markets, especially the cryptocurrency market, m-banking is projected to have a brighter future. However, information stored or conveyed via these channels is more vulnerable to different security threats. Thus, the aim of this study is to examine the influence of security and confidentiality on m-banking patronage using artificial intelligence ensemble methods (ANFIS, GPR, EANN, and BRT) for the prediction of safety and secrecy effects. AI models were trained and tested using 745 datasets obtained from the study areas. The results indicated that AI models predicted the influence of security with high precision (NSE > 0.95), with the GPR model outperformed the other models. The results indicated that security and privacy were key influential parameters of m-payment system patronage (m-banking), followed by service and interface quali-ties. Unlike previous m-banking studies, the study results showed ease of use and culture to have no influence on m-banking patronage. These study results would assist m-payment system stake-holders, while the approach may serve as motivation for researchers to use AI techniques. The study also provides directions for future m-banking studies. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; ensemble techniques; m-banking; machine learning; privacy; security","artificial intelligence; artificial neural network; banking; Gaussian method; ground penetrating radar; machine learning; numerical method; prediction; regression analysis; safety; security","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85130575545"
"Xiao S.; Yu H.; Wu Y.; Peng Z.; Zhang Y.","Xiao, Shenyong (57196348446); Yu, Han (57196329016); Wu, Yanan (57196345381); Peng, Zijun (57196196227); Zhang, Yin (56298640900)","57196348446; 57196329016; 57196345381; 57196196227; 56298640900","Self-evolving trading strategy integrating Internet of Things and big data","2018","IEEE Internet of Things Journal","5","4","","2518","2525","7","30","10.1109/JIOT.2017.2764957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032661703&doi=10.1109%2fJIOT.2017.2764957&partnerID=40&md5=2606382180fe2ee12eabaef8b0d08177","In the era of Internet of Things (IoT) and big data, data has increased dramatically. Computers have been used in various fields. Algorithmic trading is beginning to develop rapidly in the trading market, more and more algorithms begin to be used in the transaction market. As a form of machine learning, neural network can fully reveal the complex trading market. Based on the characteristics of commodity futures market, this paper chooses back propagation neural network to establish price forecasting model. And then, according to the rules of futures market, a self-evolving commodity futures trading strategy is proposed. We also use the data of the Shanghai Futures Exchange and the Dalian Futures Exchange to back-testing the strategy. Finally, we compare the proposed strategies and traditional strategies, and illustrate the evolution of our strategy. Experiments show that our strategies are superior to other compared strategies in the proposed evaluation indicator. Our strategy has a good performance both in yield and risk. It also proves the feasibility of the model and the strategy. The research of this paper is significant to the research of the futures market, and it also provides a new idea for the application of machine learning in algorithmic trading. © 2017 IEEE.","","Big data; Commerce; Financial markets; Hidden Markov models; Internet of things; Learning algorithms; Learning systems; Neural networks; Algorithm design and analysis; Algorithmic trading; BP neural networks; Commodity futures; Evaluation indicators; Predictive models; Price forecasting; Trading strategies; Electronic trading","Article","Final","","Scopus","2-s2.0-85032661703"
"Li L.; Muwafak B.M.","Li, Liangxiong (57477933900); Muwafak, Bishr Muhamed (57204877450)","57477933900; 57204877450","Adoption of deep learning Markov model combined with copula function in portfolio risk measurement","2022","Applied Mathematics and Nonlinear Sciences","7","1","","901","916","15","1","10.2478/amns.2021.2.00112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123981206&doi=10.2478%2famns.2021.2.00112&partnerID=40&md5=fadd61a613e0a960ceabacd777127e9e","In order to accurately describe the risk dependence structure and correlation between financial variables, carry out scientific financial risk assessment, and provide the basis for accurate financial decision-making, first the basic theory of Copula function is established and the mixed Copula model is constructed. Then the hybrid Copula model is nested in a hidden Markov model (HMM), the risk dependences among banking, insurance, securities and trust industries are analysed, and the Copula-Garch model is constructed for empirical analysis of investment portfolio. Finally, the deep learning Markov model is adopted to predict the financial index. The results show that the mixed Copula model based on HMM is more effective than the single Copula and the mixed Copula models. The empirical structure shows that among the four major financial industries in China, the banking and insurance industries have strong interdependence and high probability of risk contagion. The investment failure rate under 95%, 97.5% and 99% confidence intervals calculated by Copula-Garch model are 4.53%, 2.17% and 1.08%, respectively. Moreover, the errors of deep learning Markov model in stock price prediction of Shanghai Pudong Development Bank (sh600000), Guizhou Moutai (sh600519) and China Ping An Insurance (sh601318) are 2.56%, 2.98% and 3.56% respectively, which indicates that the four major financial industries in China have strong interdependence and risk contagion, so that the macro or systemic risks may arise, and the deep-learning Markov model can be adopted to predict the stock prices.  © 2021 Liangxiong Li et al., published by Sciendo.","financial index; HMM; investment failure rate; mixed Copula model; risk contagion","Computation theory; Computational methods; Learning algorithms; Machine learning; Multilayers; Network layers; 92b20; Cognitive computational model; Computational modelling; Deep belief network algorithm; Deep belief networks; Machine learning algorithms; Machine-learning; Model-based OPC; Multilayers perceptrons; Network algorithms; Multilayer neural networks","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123981206"
"Jang H.; Lee J.","Jang, H. (57196702616); Lee, J. (8852130600)","57196702616; 8852130600","Machine learning versus econometric jump models in predictability and domain adaptability of index options","2019","Physica A: Statistical Mechanics and its Applications","513","","","74","86","12","11","10.1016/j.physa.2018.08.091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052651074&doi=10.1016%2fj.physa.2018.08.091&partnerID=40&md5=a6bcdf67d32486974b71a916d96db87c","Econometric jump models dealing with key stylized facts in financial option markets have an explicit underlying asset process based on stochastic differential equations. Machine learning models with improved prediction accuracy have elicited considerable attention from researchers in the field of financial application. An intensive empirical study is conducted to compare two methods in terms of model estimation, prediction, and domain adaptation using S&P 100 American/European put options. Results indicated that econometric jump models demonstrate better prediction performance than the best-performing machine learning models, and the estimation results of the former are similar to those of the latter. The former also exhibited significantly better domain adaptation performance than the latter regardless of domain adaptation techniques in machine learning. © 2018 Elsevier B.V.","Bayesian neural network; Domain adaptation; Financial time series; Gaussian process regression; Lévy process; Neural network; Support vector regression","Differential equations; Finance; Financial data processing; Forecasting; Machine learning; Stochastic models; Stochastic systems; Support vector regression; Bayesian neural networks; Domain adaptation; Financial applications; Financial time series; Gaussian process regression; Machine learning models; Prediction performance; Stochastic differential equations; Neural networks","Article","Final","","Scopus","2-s2.0-85052651074"
"Kanungsukkasem N.; Leelanupab T.","Kanungsukkasem, Nont (56205725200); Leelanupab, Teerapong (35203370100)","56205725200; 35203370100","Financial Latent Dirichlet Allocation (FinLDA): Feature Extraction in Text and Data Mining for Financial Time Series Prediction","2019","IEEE Access","7","","8726415","71645","71664","19","28","10.1109/ACCESS.2019.2919993","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067393429&doi=10.1109%2fACCESS.2019.2919993&partnerID=40&md5=2291e505ba8c7543da61a043c3f4be5a","News has been an important source for many financial time series predictions based on fundamental analysis. However, digesting a massive amount of news and data published on the Internet to predict a market can be burdensome. This paper introduces a topic model based on latent Dirichlet allocation (LDA) to discover features from a combination of text, especially news articles and financial time series, denoted as Financial LDA (FinLDA). The features from FinLDA are served as additional input features for any machine learning algorithm to improve the prediction of the financial time series. We provide posterior distributions used in Gibbs sampling for two variants of the FinLDA and propose a framework for applying the FinLDA in a text and data mining for financial time series prediction. The experimental results show that the features from the FinLDA empirically add value to the prediction and give better results than the comparative features including topic distributions from the common LDA. © 2013 IEEE.","Bayesian method; data mining; data preparation; data processing; feature extraction; financial time series; information processing; latent Dirichlet allocation; news; prediction; stock market; text mining; topic modeling","Bayesian networks; Commerce; Data handling; Data processing; Extraction; Feature extraction; Finance; Financial data processing; Financial markets; Forecasting; Learning algorithms; Machine learning; Time series; Time series analysis; Bayesian methods; Data preparation; Financial time series; Latent Dirichlet allocation; news; Text mining; Topic Modeling; Data mining","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85067393429"
"Lahmiri S.","Lahmiri, Salim (39061577500)","39061577500","Neural networks and investor sentiment measures for stock market trend prediction","2011","Journal of Theoretical and Applied Information Technology","27","1","","1","10","9","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957931366&partnerID=40&md5=dc0a52073c18146d975cc6183a42c2bc","Soft computing methods and various sentiment indicators are employed to conduct out-of-sample predictions of the future sign of the stock market returns. In particular, we assess the performance of the probabilistic neural network (PNN) against the back-propagation neural network (BPNN) in predicting technology stocks and NYSE up and down moves. Genetic algorithms (GA) are employed to optimize the topologies of the BPNN. Our results from Granger causality tests show strong evidence that all stock returns are strongly related to at least one of the sentiment variables. In addition, the results from simulations show that the GA-BPNN is more capable of distinguishing between market ups and downs than the PNN. Finally, the simulations show that trading given decision rules (for example; buy stock if predicted return is higher than a given threshold) yields to higher accuracy than predicting the stock market ups and downs. © 2005-2011 JATT & LLs All rights reserved.","Artificial intelligence; Classification; Stock market","","Article","Final","","Scopus","2-s2.0-79957931366"
"Parekh R.; Patel N.P.; Thakkar N.; Gupta R.; Tanwar S.; Sharma G.; Davidson I.E.; Sharma R.","Parekh, Raj (58343924800); Patel, Nisarg P. (57216572868); Thakkar, Nihar (57205685975); Gupta, Rajesh (57201584761); Tanwar, Sudeep (56576145100); Sharma, Gulshan (57216326306); Davidson, Innocent E. (7103403083); Sharma, Ravi (57431604600)","58343924800; 57216572868; 57205685975; 57201584761; 56576145100; 57216326306; 7103403083; 57431604600","DL-GuesS: Deep Learning and Sentiment Analysis-Based Cryptocurrency Price Prediction","2022","IEEE Access","10","","","35398","35409","11","43","10.1109/ACCESS.2022.3163305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127503858&doi=10.1109%2fACCESS.2022.3163305&partnerID=40&md5=89d2ec26c60ad190d95ad3b5703b5e90","Cryptocurrencies are peer-to-peer-based transaction systems where the data exchanges are secured using the secure hash algorithm (SHA)-256 and message digest (MD)-5 algorithms. The prices of cryptocurrencies are highly volatile and follow stochastic moments and have reached their unpredictable limits. They are commonly used for investment and have become a substitute for other types of investment like metals, estates, and the stock market. Their importance in the market raises the strict requirement for a sturdy forecasting model. However, cryptocurrency price prediction is quite challenging due to its dependency on other cryptocurrencies. Many researchers have used machine learning and deep learning models, and other market sentiment-based models to predict the price of cryptocurrencies. As all the cryptocurrencies belong to a specific class, we can infer that the increase in the price of one cryptocurrency can lead to a price change for other cryptocurrencies. Researchers had also utilized the sentiments from tweets and other social media platforms to increase the performance of their proposed system. Motivated by these, in this paper, we propose a hybrid and robust framework, DL-Gues, for cryptocurrency price prediction, that considers its interdependency on other cryptocurrencies and also on market sentiments. We have considered price prediction of Dash carried out using price history and tweets of Dash, Litecoin, and Bitcoin for various loss functions for validation. Further, to check the usability of DL-GuesS on other cryptocurrencies, we have also inferred results for price prediction of Bitcoin-Cash with the price history and tweets of Bitcoin-Cash, Litecoin, and Bitcoin. © 2013 IEEE.","complex systems; Cryptocurrency; deep learning; fusion of cryptocurrency; price prediction; sentiment analysis; systems of systems; VADER","Bitcoin; Costs; Data mining; Deep learning; Financial markets; Forecasting; Hash functions; Hidden Markov models; Network security; Online systems; Peer to peer networks; Social networking (online); Stochastic systems; Deep learning; Fusion of cryptocurrency; Hidden-Markov models; Predictive models; Price prediction; Sentiment analysis; Social networking (online); System-of-systems; VADER; Investments","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127503858"
"Law T.; Shawe-Taylor J.","Law, T. (57193534408); Shawe-Taylor, J. (7003290763)","57193534408; 7003290763","Practical Bayesian support vector regression for financial time series prediction and market condition change detection","2017","Quantitative Finance","17","9","","1403","1416","13","46","10.1080/14697688.2016.1267868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014617588&doi=10.1080%2f14697688.2016.1267868&partnerID=40&md5=36f0e2ff9c92477beb3002fec442c4ee","Support vector regression (SVR) has long been proven to be a successful tool to predict financial time series. The core idea of this study is to outline an automated framework for achieving a faster and easier parameter selection process, and at the same time, generating useful prediction uncertainty estimates in order to effectively tackle flexible real-world financial time series prediction problems. A Bayesian approach to SVR is discussed, and implemented. It is found that the direct implementation of the probabilistic framework of Gao et al. returns unsatisfactory results in our experiments. A novel enhancement is proposed by adding a new kernel scaling parameter μ to overcome the difficulties encountered. In addition, the multi-armed bandit Bayesian optimization technique is applied to automate the parameter selection process. Our framework is then tested on financial time series of various asset classes (i.e. equity index, credit default swaps spread, bond yields, and commodity futures) to ensure its flexibility. It is shown that the generalization performance of this parameter selection process can reach or sometimes surpass the computationally expensive cross-validation procedure. An adaptive calibration process is also described to allow practical use of the prediction uncertainty estimates to assess the quality of predictions. It is shown that the machine-learning approach discussed in this study can be developed as a very useful pricing tool, and potentially a market condition change detector. A further extension is possible by taking the prediction uncertainties into consideration when building a financial portfolio. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Bayesian inference; Gaussian process; Kernel scaling; Machine learning; Multi-armed bandit Bayesian optimization; Support vector machines regression","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85014617588"
"Platanios E.A.; Chatzis S.P.","Platanios, Emmanouil A. (56160051200); Chatzis, Sotirios P. (14919099600)","56160051200; 14919099600","Gaussian process-mixture conditional heteroscedasticity","2014","IEEE Transactions on Pattern Analysis and Machine Intelligence","36","5","6613486","888","900","12","18","10.1109/TPAMI.2013.183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900557025&doi=10.1109%2fTPAMI.2013.183&partnerID=40&md5=e381471b2e042098f7027951ed9abc9f","Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies. © 2013 IEEE.","conditional heteroscedasticity; copula; Gaussian process; mixture model; Pitman-Yor process; volatility modeling","Benchmarking; Distribution functions; Gaussian noise (electronic); Mixtures; Regression analysis; Conditional heteroscedasticity; copula; Gaussian Processes; Mixture model; Volatility modeling; Gaussian distribution","Article","Final","","Scopus","2-s2.0-84900557025"
"Wang J.; Feng L.; Li Y.; He J.; Feng C.","Wang, Jujie (36550718400); Feng, Liu (57219011595); Li, Yang (57219007657); He, Junjie (57219018783); Feng, Chunchen (57219016914)","36550718400; 57219011595; 57219007657; 57219018783; 57219016914","Deep Nonlinear Ensemble Framework for Stock Index Forecasting and Uncertainty Analysis","2021","Cognitive Computation","13","6","","1574","1592","18","3","10.1007/s12559-021-09961-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118994414&doi=10.1007%2fs12559-021-09961-3&partnerID=40&md5=b64b0df6d1b9de3942ad787af175d437","Stock index forecasting plays an important role in avoiding risk and increasing returns for financial regulators and investors. However, due to the volatility and uncertainty of the stock market, forecasting stock indices accurately is challenging. In this paper, a deep nonlinear ensemble framework is proposed for stock index forecasting and uncertainty analysis. (1) Singular spectrum analysis (SSA) is utilized to extract features from a raw stock index and eliminate the interference. (2) Enhanced weighted support vector machine (EWSVM) is proposed for forecasting each component that is decomposed, of which the penalty weights are based on the time order and the hyperparameters are optimized using the simulated annealing algorithm. (3) Recurrent neural network (RNN) is used to integrate the forecast of each component into the final point forecast. (4) Gaussian process regression (GPR) is applied to obtain the interval forecast of the original stock index. Two practical cases (Nikkei 225 Index, Japan and Hang Seng Index, Hong Kong, China) are utilized to evaluate the performance of the proposed model. In terms of the results of point forecasting, the MAE, R2, MAPE, and RMSE of Nikkei 225 Index are 66.0745, 0.9972, 0.0066, and 80.0381, and those of Hang Seng Index are 79.2145,0.9968, 0.0073, and 96.7740. In terms of the results of interval forecasting, the CP95 %, MWP95 %, and MC95 % of Nikkei 225 Index are 0.89979, 0.05746, and 0.06385, and those of Hang Seng Index are 0.97985, 0.28223, and 0.28803. Forecasting stock indices accurately is crucial for investment decision and risk management and is extremely meaningful to investors and financial regulators. In this paper, the SSA-EWSVM-RNN-GPR model is used to forecast the closing prices of stock indices, and compared with eight benchmark models, the proposed SSA-EWSVM-RNN-GPR model can be an effective tool for both point and interval forecasting of stock indices. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Deep learning; Enhanced weighted support vector machine; Nonlinear ensemble; Singular spectrum analysis; Stock forecasting","Forecasting; Investments; Nonlinear analysis; Risk management; Simulated annealing; Spectrum analysis; Support vector machines; Uncertainty analysis; Deep learning; Enhanced weighted support vector machine; Gaussian process regression model; Interval forecasting; Nonlinear ensemble; Singular spectrum analysis; Stock forecasting; Stock index forecasting; Stock indices; Weighted support vector machine; Recurrent neural networks","Article","Final","","Scopus","2-s2.0-85118994414"
"Zhang P.; Yang J.; Zhu H.; Hou Y.; Liu Y.; Zhou C.","Zhang, Ping (56604468400); Yang, Jiayao (57274909100); Zhu, Hao (57274909200); Hou, Yuejie (57271966100); Liu, Yi (57211588158); Zhou, Chichun (55490540700)","56604468400; 57274909100; 57274909200; 57271966100; 57211588158; 55490540700","Failure in Stock Price Prediction: A Comparison between the Curve-Shape-Feature and Non-Curve-Shape-Feature Modes of Existing Machine Learning Algorithms","2021","International Journal of Computers, Communications and Control","16","6","4549","","","","1","10.15837/IJCCC.2021.6.4549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125373660&doi=10.15837%2fIJCCC.2021.6.4549&partnerID=40&md5=75a99ba175355b38b4da2a6a112b9953","In the era of artificial intelligence, machine learning methods are successfully used in various fields. Machine learning has attracted extensive attention from investors in the financial market, especially in stock price prediction. However, one argument for the machine learning methods used in stock price prediction is that they are black-box models which are difficult to interpret. In this paper, we focus on the future stock price prediction with the historical stock price by machine learning and deep learning methods, such as support vector machine (SVM), random forest (RF), Bayesian classifier (BC), decision tree (DT), multilayer perceptron (MLP), convolutional neural network (CNN), bi-directional long-short term memory (BiLSTM), the embedded CNN, and the embedded BiLSTM. Firstly, we manually design several financial time series where the future price correlates with the historical stock prices in pre-designed modes, namely the curve-shape-feature (CSF) and the non-curve-shape-feature (NCSF) modes. In the CSF mode, the future prices can be extracted from the curve shapes of the historical stock prices. Conversely, in the NCSF mode, they can’t. Secondly, we apply various algorithms to those pre-designed and real financial time series. We find that the existing machine learning and deep learning algorithms fail in stock price prediction because in the real financial time series, less information of future prices is contained in the CSF mode, and perhaps more information is contained in the NCSF. Various machine learning and deep learning algorithms are good at handling the CSF in historical data, which are successfully applied in image recognition and natural language processing. However, they are inappropriate for stock price prediction on account of the NCSF. Therefore, accurate stock price prediction is the key to successful investment, and new machine learning algorithms handling the NCSF series are needed. © 2021. by the authors.","Deep learning method; Financial time series; Machine learning method; Stock price prediction","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85125373660"
"Ahmed T.; Srivastava A.","Ahmed, Tanveer (57213239734); Srivastava, Abhishek (55506401800)","57213239734; 55506401800","Combining humans and machines for the future: A novel procedure to predict human interest","2019","Future Generation Computer Systems","96","","","713","730","17","1","10.1016/j.future.2018.01.043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042366370&doi=10.1016%2fj.future.2018.01.043&partnerID=40&md5=998cd78b7ea81740f8aab49de637f280","This paper proposes a method to quantify interest. In common terminology, when we engage with an object, e.g. Online Games, Social Networking Websites, Mobile Apps, etc., there is a degree of interest between us and the object. But, owing to the lack of a procedure that can quantify interest, we are unable to tell by how ‘much’ of a factor are we interested in the object. In other words, can we find a number for someone's interest? In this article, we propose a method that uses the principle of Bayesian Inference to tackle this issue. We formulate the “interest estimation problem” as a state estimation problem to deduce interest (in any object) indirectly from user activity. Activity caused by interest is computed through a subjective–objectiveweighted approach, then using indirect inference rules, we provide numerical estimates of interest. To do that, we model the dynamics of interest through the Ornstein–Uhlenbeck process. To further enhance the base performance, we draw inspiration from Stochastic Volatility models from Finance. Subsequently, drawing upon a self-adapting transfer function, we provide an avant-garde statistical procedure to model the transformation of interest into activity. The individual contributions are then combined and a solution is provided via Particle filters. Validation of the method is done in two ways. (1) Experimentation is performed on real datasets. Through numerical investigation we have found that the method shows good performance. (2) We implement the framework as a Web application and deploy it on an Enterprise Service Bus. The framework has been successfully hosted on a Cloud based Virtualized testbed consisting of several Virtual Machines constructed over XENServer as the underlying hypervisor. Through this experimental setup, we show the efficacy of the proposed algorithm in estimating interest, at much the same time, we demonstrate the viability of the method in practical cloud based deployment scenarios. © 2018 Elsevier B.V.","Data analytics; Human machine systems; Interest modeling; Machine learning; Ornstein–Uhlenbeck process; Stochastic volatility models","Bayesian networks; Economic analysis; Inference engines; Learning systems; Man machine systems; Numerical methods; Stochastic systems; Telecommunication services; Bayesian inference; Data analytics; Degree of interests; Deployment scenarios; Enterprise service bus; Numerical investigations; Ornstein-Uhlenbeck process; Stochastic Volatility Model; Stochastic models","Article","Final","","Scopus","2-s2.0-85042366370"
"Ding G.; Qin L.","Ding, Guangyu (57212174174); Qin, Liangxi (8357520300)","57212174174; 8357520300","Study on the prediction of stock price based on the associated network model of LSTM","2020","International Journal of Machine Learning and Cybernetics","11","6","","1307","1317","10","165","10.1007/s13042-019-01041-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076093849&doi=10.1007%2fs13042-019-01041-1&partnerID=40&md5=3d51a1ecdd6a471e127f65e16bf55fa9","Stock market has received widespread attention from investors. It has always been a hot spot for investors and investment companies to grasp the change regularity of the stock market and predict its trend. Currently, there are many methods for stock price prediction. The prediction methods can be roughly divided into two categories: statistical methods and artificial intelligence methods. Statistical methods include logistic regression model, ARCH model, etc. Artificial intelligence methods include multi-layer perceptron, convolutional neural network, naive Bayes network, back propagation network, single-layer LSTM, support vector machine, recurrent neural network, etc. But these studies predict only one single value. In order to predict multiple values in one model, it need to design a model which can handle multiple inputs and produces multiple associated output values at the same time. For this purpose, it is proposed an associated deep recurrent neural network model with multiple inputs and multiple outputs based on long short-term memory network. The associated network model can predict the opening price, the lowest price and the highest price of a stock simultaneously. The associated network model was compared with LSTM network model and deep recurrent neural network model. The experiments show that the accuracy of the associated model is superior to the other two models in predicting multiple values at the same time, and its prediction accuracy is over 95%. © 2019, The Author(s).","Associated network; Deep learning; Deep recurrent neural network; Long short-term memory (LSTM); Machine learning","Backpropagation; Bayesian networks; Brain; Commerce; Deep learning; Deep neural networks; Electronic trading; Financial markets; Forecasting; Investments; Learning systems; Multilayer neural networks; Network layers; Regression analysis; Support vector machines; Artificial intelligence methods; Backpropagation network; Convolutional neural network; Logistic Regression modeling; Multi layer perceptron; Multiple inputs and multiple outputs; Recurrent neural network model; Stock price prediction; Long short-term memory","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85076093849"
"Deng M.; Aminzadeh M.S.","Deng, M. (57201033786); Aminzadeh, M.S. (6603735928)","57201033786; 6603735928","Bayesian predictive analysis for Weibull-Pareto composite model with an application to insurance data","2022","Communications in Statistics: Simulation and Computation","51","5","","2683","2709","26","2","10.1080/03610918.2019.1699572","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076405405&doi=10.1080%2f03610918.2019.1699572&partnerID=40&md5=259ab7e1a82b02686f25692968e1570e","Aminzadeh and Deng, respectively provide Bayesian predictive models for Exponential-Pareto and Inverse Gamma-Pareto composite distributions which are one-parameter models. The purpose of this article is to develop an alternative Bayesian predictive model (two-parameter) which can be used to compute important risk measures that are not defined via the above predictive models. Bayesian predictive density for the Weibull-Pareto composite distribution is developed and is used to compute risk measures such as Value at Risk (VaR), Conditional Tail Expectation (CTE), Predictive Expectation (PE), Limited Predictive Expected value (LPE), Limited Predictive Variance (LPV), and Limited Predictive Tail-VaR (LPCTE). Accuracy of parameter estimates as well as the risk measures are assessed via simulation studies. It is shown that the informative Bayes estimates are consistently more accurate than ML and the non-informative Bayes estimates. Backtesting for the risk measures is performed and goodness-of-fit of Weibull-Pareto among other composite models to the Danish fire data is assessed. © 2019 Taylor & Francis Group, LLC.","Conditional tail expectation; Gamma and inverse-gamma priors; Predictive density; Value at risk; Weibull-Pareto composite model","Risk assessment; Value engineering; Weibull distribution; Composite modeling; Conditional tail expectation; Gamma prior; Predictive density; Value at Risk; Predictive analytics","Article","Final","","Scopus","2-s2.0-85076405405"
"Chandrasekara V.; Tilakaratne C.; Mammadov M.","Chandrasekara, Vasana (55821611900); Tilakaratne, Chandima (56453210500); Mammadov, Musa (15127216400)","55821611900; 56453210500; 15127216400","An improved probabilistic neural network model for directional prediction of a stock market index","2019","Applied Sciences (Switzerland)","9","24","5334","","","","10","10.3390/app9245334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077391934&doi=10.3390%2fapp9245334&partnerID=40&md5=7489ba6da11c4cf79372ded4a6ab9622","Financial market prediction attracts immense interest among researchers nowadays due to rapid increase in the investments of financial markets in the last few decades. The stock market is one of the leading financial markets due to importance and interest of many stakeholders. With the development of machine learning techniques, the financial industry thrived with the enhancement of the forecasting ability. Probabilistic neural network (PNN) is a promising machine learning technique which can be used to forecast financial markets with a higher accuracy. A major limitation of PNN is the assumption of Gaussian distribution as the distribution of input variables which is violated with respect to financial data. The main objective of this study is to improve the standard PNN by incorporating a proper multivariate distribution as the joint distribution of input variables and addressing the multi-class imbalanced problem persisting in the directional prediction of the stock market. This model building process is illustrated and tested with daily close prices of three stock market indices: AORD, GSPC and ASPI and related financial market indices. Results proved that scaled t distribution with location, scale and shape parameters can be used as more suitable distribution for financial return series. Global optimization methods are more appropriate to estimate better parameters of multivariate distributions. The global optimization technique used in this study is capable of estimating parameters with considerably high dimensional multivariate distributions. The proposed PNN model, which considers multivariate scaled t distribution as the joint distribution of input variables, exhibits better performance than the standard PNN model. The ensemble technique: multi-class undersampling based bagging (MCUB) was introduced to handle class imbalanced problem in PNNs is capable enough to resolve multi-class imbalanced problem persisting in both standard and proposed PNNs. Final model proposed in the study with proposed PNN and proposed MCUB technique is competent in forecasting the direction of a given stock market index with higher accuracy, which helps stakeholders of stock markets make accurate decisions. © 2019 by the authors.","Directional prediction; Global optimization; Multi-class undersampling based bagging (MCUB); Multivariate distribution; Probabilistic neural network (PNN); Stock market indices","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85077391934"
"Chen Y.-C.; Huang W.-C.","Chen, Yu-Chen (57226536083); Huang, Wen-Chen (55709674600)","57226536083; 55709674600","Constructing a stock-price forecast CNN model with gold and crude oil indicators[Formula presented]","2021","Applied Soft Computing","112","","107760","","","","64","10.1016/j.asoc.2021.107760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111886797&doi=10.1016%2fj.asoc.2021.107760&partnerID=40&md5=194f5d00359c43aa438f1296112e6a2a","In this study, we propose algorithms to predict future stock market trends based on 8 different input features, including financial technology indicators, gold prices, a gold price volatility index, crude oil price, a crude oil price volatility index, and other characteristic data using two different labeling methods with separate classification algorithms of two and three output categories, respectively including predicted stock price changes (up and down) and recommended trading actions (buy, sell, and hold), and analyze the validity of these characteristic data in terms of their ability to predict future trends. The S&P 500 (GSPC) is the target of these forecasts. Sample data from 2010 to 2018 are divided 8:2, between training and verification data, while data from 2019 are used to test the proposed approach. CNN and LSTM models are used for comparison of classification accuracy and investment returns, respectively. Bayesian optimization (BO) hyperparameters are used to improve the accuracy of the model and increase the return on investment (ROI) of the output predictions. The purpose of this study is to verify whether using gold prices, a gold volatility index, crude oil price, and a crude oil price volatility indices as input features can enable a deep learning model accurately to predict future stock price trends, and to discuss separately the applicability of CNN and LSTM models to the abovementioned characteristics and financial indicators. We also present the results of experiments conducted to evaluate the proposed method in terms of classification accuracy and confusion matrix. In the case of three-category classification, the model takes feature data as input to outputs a predicted trading order on whether to buy, sell, or hold a given set of stocks tomorrow as well as the timing of entry and exit from each position, and also backtests the data outside the sample to find the combination of characteristics and indicators best maximizing ROI. Using this three-category method, we obtain a comprehensive ROI for a given set of individual stocks and assess whether each type of stock is suitable for the prediction model based on input features such as gold and crude oil or the fields that are suitable for the given feature. Experimental results show that the proposed approach as able to predict whether stock price will rise or fall in the next 10 days, and the model accuracy rate can reach 67%. The results of experiments on the proposed combined CNN model with eight features, referred to as CNN8, achieved an ROI on 2019 data outside the sample period of up to 13.23%, which was superior to the 12.08% and 11.06% obtained by the models designed CNN4 (CNN with four input features) and LSTM8(LSTM with eight input features), respectively. The F1 score increased from 0.75 0.79 as a result of applying BO. The results indicate that considering the price of gold, the gold volatility index, crude oil price, and crude oil price volatility index can help obtain better ROI for companies in certain fields, such as the semiconductor, petroleum, and automotive industries, rather than merely considering financial indicators. However, for companies related to apparel, fast food, and copy processing, the input characteristics of purely financial technical indicators were found to be suitable. © 2021 Elsevier B.V.","Bayesian optimization; Convolutional neural networks; Deep learning; Long short-term memory; Stock price forecast","Classification (of information); Commerce; Costs; Deep learning; Electronic trading; Gold; Investments; Long short-term memory; Oils and fats; Petroleum analysis; Petroleum industry; Predictive analytics; Technological forecasting; Bayesian optimization; Classification accuracy; Classification algorithm; Confusion matrices; Financial indicator; Oil price volatility; Stock price forecasts; Technical indicator; Crude oil price","Article","Final","","Scopus","2-s2.0-85111886797"
"Khedmati M.; Seifi F.; Azizi M.J.","Khedmati, M. (53863407600); Seifi, F. (57208340827); Azizi, M.J. (57202516153)","53863407600; 57208340827; 57202516153","Time series forecasting of bitcoin price based on autoregressive integrated moving average and machine learning approaches","2020","International Journal of Engineering, Transactions A: Basics","33","7","","1293","1303","10","16","10.5829/ije.2020.33.07a.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089415941&doi=10.5829%2fije.2020.33.07a.16&partnerID=40&md5=7ea1db24d06767a63b4bc7f2cb2c846e","Bitcoin as the current leader in cryptocurrencies is a new asset class receiving significant attention in the financial and investment community and presents an interesting time series prediction problem. In this paper, some forecasting models based on classical like ARIMA and machine learning approaches including Kriging, Artificial Neural Network (ANN), Bayesian method, Support Vector Machine (SVM) and Random Forest (RF) are proposed and analyzed for modelling and forecasting the Bitcoin price. While some of the proposed models are univariate, the other models are multivariate and as a result, the maximum, minimum and the opening daily price of Bitcoin are also used in these models. The proposed models are applied on the Bitcoin price from December 18, 2019 to March 1, 2020 and their performances are compared in terms of the performance measures of RMSE and MAPE by Diebold- Mariano statistical test. Based on RMSE and MAPE measures, the results show that SVM provides the best performance among all the models. In addition, ARIMA and Bayesian approaches outperform other univariate models where they provide smaller values for RMSE and MAPE. © 2020 Materials and Energy Research Center. All rights reserved.","Bitcoin; Machine learning; Multivariate models; Time series forecasting","Autoregressive moving average model; Bayesian networks; Bitcoin; Decision trees; Forecasting; Support vector machines; Time series; Auto-regressive integrated moving average; Bayesian approaches; Investment community; Machine learning approaches; Modelling and forecasting; Performance measure; Time series forecasting; Time series prediction; Learning systems","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85089415941"
"Zhang M.; Jiang X.; Fang Z.; Zeng Y.; Xu K.","Zhang, Mengqi (57204575067); Jiang, Xin (57191283508); Fang, Zehua (57225694448); Zeng, Yue (57204571910); Xu, Ke (56799555700)","57204575067; 57191283508; 57225694448; 57204571910; 56799555700","High-order Hidden Markov Model for trend prediction in financial time series","2019","Physica A: Statistical Mechanics and its Applications","517","","","1","12","11","56","10.1016/j.physa.2018.10.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056213871&doi=10.1016%2fj.physa.2018.10.053&partnerID=40&md5=e5332d4b50b1b3cdc44c34eff8aacd1e","Financial price series trend prediction is an essential problem which has been discussed extensively using tools and techniques of economic physics and machine learning. Time dependence and volatility issues in this problem have made Hidden Markov Model (HMM) a useful tool in predicting the states of stock market. In this paper, we present an approach to predict the stock market price trend based on high-order HMM. Different from the commonly used first-order HMM, short and long-term time dependence are both considered in the high order HMM. By introducing a dimension reduction method which could transform the high-dimensional state vector of high-order HMM into a single one, we present a dynamic high-order HMM trading strategy to predict and trade CSI 300 and S&P 500 stock index for the next day given historical data. In our approach, we make a statistic of the daily returns in the history to demonstrate the relationship between hidden states and the price change trend. Experiments on CSI 300 and S&P 500 index illustrate that high-order HMM has preferable ability to identify market price trend than first-order one. Thus, the high-order HMM has higher accuracy and lower risk than the first-order model in predicting the index price trend. © 2018 Elsevier B.V.","High-order HMM; Trading algorithm; Trend prediction","Commerce; Electronic trading; Financial markets; Forecasting; Dimension reduction method; Essential problems; Financial time series; First-order models; High-order; Stock market prices; Tools and techniques; Trend prediction; Hidden Markov models","Article","Final","","Scopus","2-s2.0-85056213871"
"Chen X.; Tian Y.","Chen, Xiurong (57195596099); Tian, Yixiang (55480203500)","57195596099; 55480203500","The big data mining forecasting model based on combination of improved manifold learning and deep learning","2019","International Journal of Grid and Utility Computing","10","2","","119","131","12","1","10.1504/IJGUC.2019.098213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062778036&doi=10.1504%2fIJGUC.2019.098213&partnerID=40&md5=c3620ee57b557df106ccfad94cc736a1","In this paper, we use the combination of Local Linear Embedding (LLE) with Continuous Deep Belief Networks (CDBN) as the input of RBF, and construct a mixed-feature RBF model. However, LLE depends too much on the local domain which is not easy to be determined, so we propose a new method, Kernel Entropy Linear Embedding (KELE) which uses Kernel Entropy Component Analysis (KECA) to transfer the non-linear problem into linear problem. CDBN has the difficulty in confirming network structure and lacks supervision, so we improve the situations by using the kernel entropy information obtained from KECA, which is called KECDBN. In the empirical part, we use the foreign exchange rate time series to examine the effects of the improved methods, and results show that both the KELE and the KECDBN show better effects in reducing dimensionality and extracting features, respectively, an also improve the prediction accuracy of the mixed-feature RBF. Copyright © 2019 Inderscience Enterprises Ltd.","CDBN; Continuous deep belief network; KECA; KECDBN; KELE; Kernel entropy component analysis; Kernel entropy continuous deep belief network; Kernel entropy linear embedding; LLE; Local linear embedding","Bayesian networks; Big data; Data mining; Embeddings; Entropy; CDBN; Component analysis; Deep belief networks; KECA; KECDBN; KELE; Linear embedding; Local Linear Embedding; Deep learning","Article","Final","","Scopus","2-s2.0-85062778036"
"Xing F.Z.; Cambria E.; Zhang Y.","Xing, Frank Z. (57196019442); Cambria, Erik (56140547500); Zhang, Yue (56066648800)","57196019442; 56140547500; 56066648800","Sentiment-aware volatility forecasting","2019","Knowledge-Based Systems","176","","","68","76","8","57","10.1016/j.knosys.2019.03.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063733190&doi=10.1016%2fj.knosys.2019.03.029&partnerID=40&md5=76fd451e919da1400fbff4fcdb82e3cb","Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled using Variational Bayes via the data generation and inference operations. We benchmark our model with 9 other popular ones in terms of the likelihood of forecasts given the observed sequence. Experimental results suggest that our model not only outperforms pure statistical models, e.g., GARCH and its variants, Gaussian-process volatility model, but also outperforms the state-of-the-art autoregressive deep neural nets architectures, such as the variational recurrent neural network and the neural stochastic volatility model. © 2019 Elsevier B.V.","Financial text mining; Sentiment knowledge; Time series analysis; Variational neural networks; Volatility modeling","Commerce; Data mining; Deep neural networks; Economic analysis; Forecasting; Harmonic analysis; Investments; Recurrent neural networks; Signal processing; Stochastic systems; Time series analysis; Bi-directional interaction; Financial forecasting; Financial text minings; Sentiment knowledge; Statistical inference; Stochastic Volatility Model; Volatility forecasting; Volatility modeling; Stochastic models","Article","Final","","Scopus","2-s2.0-85063733190"
"Dixon M.","Dixon, Matthew (55982004900)","55982004900","Industrial Forecasting with Exponentially Smoothed Recurrent Neural Networks","2022","Technometrics","64","1","","114","124","10","4","10.1080/00401706.2021.1921035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108184664&doi=10.1080%2f00401706.2021.1921035&partnerID=40&md5=991767bcf2cec5c942fecbaad78d5cf9","Time series modeling has entered an era of unprecedented growth in the size and complexity of data which require new modeling approaches. While many new general purpose machine learning approaches have emerged, they remain poorly understand and irreconcilable with more traditional statistical modeling approaches. We present a general class of exponential smoothed recurrent neural networks (RNNs) which are well suited to modeling nonstationary dynamical systems arising in industrial applications. In particular, we analyze their capacity to characterize the nonlinear partial autocorrelation structure of time series and directly capture dynamic effects such as seasonality and trends. Application of exponentially smoothed RNNs to forecasting electricity load, weather data, and stock prices highlight the efficacy of exponential smoothing of the hidden state for multistep time series forecasting. The results also suggest that popular, but more complicated neural network architectures originally designed for speech processing are likely over-engineered for industrial forecasting and light-weight exponentially smoothed architectures, trained in a fraction of the time, capture the salient features while being superior and more robust than simple RNNs and autoregressive models. Additionally, uncertainty quantification of Bayesian exponential smoothed RNNs is shown to provide improved coverage. © 2021 American Statistical Association and the American Society for Quality.","Exponential smoothing; Forecasting; Nonstationarity; Partial autocorrelations; Quantification; Uncertainty","Dynamical systems; Electric load forecasting; Electronic trading; Forecasting; Network architecture; Speech processing; Time series; Auto regressive models; Forecasting electricity; Machine learning approaches; Non-stationary dynamical systems; Partial autocorrelation; Recurrent neural network (RNNs); Time series forecasting; Uncertainty quantifications; Recurrent neural networks","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85108184664"
"Su Z.; Yi B.","Su, Zhi (57191838693); Yi, Bo (57547140600)","57191838693; 57547140600","Research on HMM-Based Efficient Stock Price Prediction","2022","Mobile Information Systems","2022","","8124149","","","","10","10.1155/2022/8124149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126919166&doi=10.1155%2f2022%2f8124149&partnerID=40&md5=2f4d58c8ba7553c714957228786a853b","Stock market is one of the most important parts of the investment market. Compared with other industries, the stock market not only has a higher rate of return on investment but also has a higher risk, and stock price prediction has always been a close concern of investors. Therefore, the research on stock price prediction methods and how to reduce the error of stock price prediction has become a hot topic for many scholars at home and abroad. In recent years, the development of computer technology such as machine learning and econometric method makes the stock price prediction more reliable. Due to the hidden Markov nature of stock price, this paper proposes a stock price prediction method based on hidden Markov model (HMM). To be specific, since the data of stock price have continuity in time series, it is necessary to extend the discrete HMM to the continuous HMM, and then put forward the up and down trend prediction model based on the continuous HMM. The first-order continuous HMM is extended to the second-order continuous HMM, and the stock price is predicted by combining the prediction method of fluctuation range. As a result, the proposed second-order continuous HMM-based stock price prediction model is simulated on Hang Seng Index (HSI), one of the earliest stock market indexes in Hong Kong. The evaluation results on six months HSI show that the predicted value of the proposed model is very close to the actual value and outperforms three benchmarks in terms of RMSE, MAE, and R2. © 2022 Zhi Su and Bo Yi.","","Commerce; Earnings; Forecasting; Hidden Markov models; Investments; Continuous hidden Markov model; Hidden-Markov models; High rate; Investment market; Model-based OPC; Prediction methods; Rate of return; Second orders; Stock price; Stock price prediction; Financial markets","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126919166"
"Huang S.-C.; Chiou C.-C.; Chiang J.-T.; Wu C.-F.","Huang, Shian-Chang (15044616100); Chiou, Chei-Chang (23097250700); Chiang, Jui-Te (57209208445); Wu, Cheng-Feng (57204839262)","15044616100; 23097250700; 57209208445; 57204839262","Online sequential pattern mining and association discovery by advanced artificial intelligence and machine learning techniques","2020","Soft Computing","24","11","","8021","8039","18","6","10.1007/s00500-019-04100-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066863977&doi=10.1007%2fs00500-019-04100-5&partnerID=40&md5=80ed387bf51718230ffc42e1167e7de9","With the advances in information science, vast amounts of financial time series data can been collected and analyzed. In modern time series analysis, sequential pattern mining (SPM) and association discovery (AD) are the most important techniques to predict the future trends. This study aims at developing advanced SPM and AD for financial data by cutting edge techniques from artificial intelligence and machine learning. The nonlinearity and non-stationarity of financial time series dynamics pose a major challenge for SPM and AD. This study employs time–frequency analysis to extract features for SPM. Then, a sparse multi-manifold clustering (SMMC) is used to partition the feature space into several disjointed regions for better AD. Finally, local relevance vector machines (RVMs) are employed for AD and perform the forecasting. Different from traditional methods, the novel forecasting system operates on multiple resolutions and multiple dynamic regimes. SMMC finds both the neighbors and the weights automatically by a sparse solution, which approximately spans a low-dimensional affine subspace at that point. RVM, the Bayesian kernel machines, can produce parsimonious models with excellent generalization properties. Taking multiple time series data from financial markets as an example, the empirical results demonstrate that the proposed model outperforms traditional models and significantly reduces the forecasting errors. The framework is effective and suitable for other time series forecasting. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Kernel machine; Local modeling; Manifold clustering; Multi-scale representation; Time–frequency analysis","Data mining; E-learning; Electronic trading; Finance; Forecasting; Machine learning; Frequency Analysis; Kernel machine; Local model; Manifold clustering; Multiscale representations; Time series analysis","Article","Final","","Scopus","2-s2.0-85066863977"
"Pandey T.N.; Jagadev A.K.; Dehuri S.; Cho S.-B.","Pandey, Trilok Nath (57201073039); Jagadev, Alok Kumar (26325488100); Dehuri, Satchidananda (55890604700); Cho, Sung-Bae (7404884741)","57201073039; 26325488100; 55890604700; 7404884741","A review and empirical analysis of neural networks based exchange rate prediction","2019","Intelligent Decision Technologies","12","4","","423","439","16","8","10.3233/IDT-180346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060013629&doi=10.3233%2fIDT-180346&partnerID=40&md5=64fce96ac8371b8055ce7ff97769bb34","Financial time series data is very chaotic, noisy, fluctuating and nonlinear as different events have occurred in various time periods. Therefore, it is very challenging for researchers to develop the accurate predictive model. Prediction for Foreign Exchange rate is also a very crucial task for N days ahead prediction because of volatile nature of Foreign Exchange rate data. It is also become highly desirable due to it's role in financial and managerial decision making capacity of any country. A lot of efforts have been done by researchers over many years for the development of efficient models to improve the forecasting accuracy. As a result, various important time series forecasting models have been evolved in literature. From the literature survey we have analyzed that statistical techniques are not able to efficiently predict the Foreign Exchange rate. Hence, different machine learning techniques have been used by many researchers for accurate prediction. Over the years different types of neural network models such as multi - layer perceptron, radial basis function neural network, functional link artificial neural network and integrated model such as auto - regressive integrated moving average models are developed to predict the currency exchange rates of different countries with varying parameters. In this paper, we divide our effort into two parts. In the first part, we have reviewed a few selected models based on neural networks and statistical methods including fundamental and technical aspects of currency exchange rate prediction. In the second part, we have made a thorough and careful empirical study of the models reviewed in part one. Our study reveals that the daily currency exchange rates with multi - layer neural network having Bayesian learning technique produces more accurate results against the multi - layer neural network with back propagation learning technique. Similarly, integrated models of radial basis function neural network and functional link neural networks produce less amount of error in comparison to single radial basis neural networks and functional link neural network models. Additionally, we critically analyze an integrated work on statistical model such as auto-regressive integrated moving average model with neural networks and revealed that the integrated models produces better results than the individual models. © 2018 - IOS Press and the authors. All rights reserved.","autoregressive integrated moving average; Bayesian learning; cascaded functional link artificial neural networks; currency exchange rate; Foreign exchange rate; functional link artificial neural network; multilayer perceptron; neural network; radial basis function network","Backpropagation; Bayesian networks; Decision making; Economics; Electronic trading; Finance; Forecasting; Functions; Learning algorithms; Network layers; Neural networks; Radial basis function networks; Time series; Time series analysis; Auto-regressive integrated moving average; Bayesian learning; Cascaded functional link artificial neural networks; Currency exchange rates; Foreign exchange rates; Functional link artificial neural networks; Multilayer neural networks","Review","Final","","Scopus","2-s2.0-85060013629"
"Rahmani Cherati M.; Haeri A.; Ghannadpour S.F.","Rahmani Cherati, Mahdiye (57222467462); Haeri, Abdorrahman (36499549900); Ghannadpour, Seyed Farid (23974410800)","57222467462; 36499549900; 23974410800","Cryptocurrency direction forecasting using deep learning algorithms","2021","Journal of Statistical Computation and Simulation","91","12","","2475","2489","14","10","10.1080/00949655.2021.1899179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102745786&doi=10.1080%2f00949655.2021.1899179&partnerID=40&md5=44cb55adde0d979e5d66d484004f0cca","Recently, the deep learning architecture has been used with an increasing rate for forecasting in financial markets. In this paper, the LSTM model is used to forecast the daily closing price direction of the BTC/USD. Both model accuracy and the profit or loss of the trades made based on the proposed model are analyzed. In addition, the effects of the MACD indicator and the input matrix dimension on forecasting accuracy are evaluated. The potential risks and actual risks encountered by the trader who trades based on the proposed model were also analyzed. The obtained results indicate that the optimization of the LSTM parameters using the Bayesian optimization model has enhanced the model’s accuracy. The results obtained from analyzing the drawdown and reward/risk resulting from the trades made based on the model show that the model enables the trader to trade with peace of mind due to the low level of actual risks and potential risks. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","BPNN; BTC/USD forecasting; Cryptocurrency forecasting; deep learning","","Article","Final","","Scopus","2-s2.0-85102745786"
"Kong B.; Chen Z.","Kong, Bing (57125564000); Chen, Zhuoheng (55769104900)","57125564000; 55769104900","Data-driven EUR modeling and optimization in the liquid-rich Duvernay Formation, western Canada sedimentary basin, Canada","2022","Journal of Petroleum Science and Engineering","213","","110352","","","","2","10.1016/j.petrol.2022.110352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125923600&doi=10.1016%2fj.petrol.2022.110352&partnerID=40&md5=3c705a0e9eb04fff96ecd9c11aaf4913","Estimated Ultimate Recovery (EUR) is one of the focuses of the feasibility assessment for oil and gas development projects. EUR is the utmost recoverable oil and gas volume under the current assumption of technology and economics. Many factors including geology, drilling, completion, operation, and commodity prices influence EUR, which makes the prediction a difficult task. Reservoir numerical simulation and production decline curve analysis (DCA) are two broadly accepted method to calculate EUR. However, the former requires substantial data and resources, while the latter is lack of causative mechanism to associate the fundamentals to productivity. This study proposes a machine learning (ML) procedure in EUR modeling, by which EUR is linked to fundamental variables from available data and the variation in EUR can be explained by various factors so that the results can be applied to optimize future projects. In the proposed procedure, the EUR was estimated using a probabilistic dual flow regime model and Markov Chain Monte Carlo (MCMC) simulation. The resulting EUR in each well was then modeled using a two-level stacked ensemble ML approach, while Shapley value was used to explain feature sensitivity in the trained model. In the last, the EUR is optimized by adjusting the most sensitive factors in the trained model. The trained ML model achieved high accuracy on EUR prediction, and the Shapley value analysis showed that completion length, condensate gas ratio and fracturing fluid volume are among the most important features to EUR. The EUR optimization result showed that there is large room for improvement by adjusting the key features. This proposed approach provides a new perspective to find associations between the fundamental factors and the well EUR which improves the understanding of oil and gas production in unconventional reservoirs. © 2022","EUR; Machine learning; Shapley value; Stacked model","Western Canada Sedimentary Basin; Fracturing fluids; Gases; Hydraulic fracturing; Machine learning; Markov processes; Monte Carlo methods; Numerical methods; Petroleum reservoir evaluation; Data driven; Estimated ultimate recoveries; Feasibility assessment; Modeling and optimization; Oil and gas; Recovery model; Recovery optimizations; Shapley value; Stacked model; Western canada sedimentary basins; development project; gas production; hydrocarbon reservoir; machine learning; modeling; oil production; optimization; Game theory","Article","Final","","Scopus","2-s2.0-85125923600"
"Naidoo L.; Main R.; Cho M.A.; Madonsela S.; Majozi N.","Naidoo, Laven (36021472900); Main, Russell (26666957000); Cho, Moses A. (57203276945); Madonsela, Sabelo (56228213200); Majozi, Nobuhle (56121054600)","36021472900; 26666957000; 57203276945; 56228213200; 56121054600","Machine learning modelling of crop structure within the Maize Triangle of South Africa","2022","International Journal of Remote Sensing","43","1","","27","51","24","3","10.1080/01431161.2021.1998714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122698484&doi=10.1080%2f01431161.2021.1998714&partnerID=40&md5=b67ee345d54d06c9c9e9e96030ba2c1e","Maize has been identified as a strategic commodity for the reduction of poverty and enhancement of food security in the African continent. Climate variability and difficult economic conditions are pressuring farmers to produce higher (maize) yields with fewer inputs, per hectare. The remote sensing of crop specific structural parameters are essential in identifying the particular growth stages of the maize crop which require specific tasks from the farmer (e.g. weed control, top dressing, pesticide application for disease and borer control and critical moisture phase). This study sought to assess the performance of multiple linear regression (LR), Random Forest (RF) and Gaussian Process Regression (GPR) in the estimation of four maize crop structural parameters in a study area in the Vereeniging region of the Maize Triangle of South Africa. These parameters were leaf area index (LAI), stem height (HT), stem diameter (DIA) and stem density (SD). An additional aim was to investigate whether the combination of selected spectral vegetation indices (red-edge, chlorophyll, senescence and greenness) with Sentinel-2 reflectance bands as modelling predictors yielded improved results over the individual spectral bands alone. Combining reflectance bands and vegetation indices as modelling predictors yielded the highest validation accuracy, over other scenarios, for only one out of the four crop structural parameters (DAI). The reflectance bands only scenario yielded the highest validation accuracies for two crop structural parameters (HT and SD). The use of spectral vegetation indices alone as modelling predictors yielded the highest modelling accuracies for the LAI crop parameter than the other scenarios. These trends indicate that the combination of Sentinel-2 reflectance bands and derived vegetation indices do not always yield improved modelling results for the four crop structural parameters under investigation. As a result, reflectance bands (mostly) or indices alone could suffice for nearly all of the parameters. With respect to the modelling algorithms, LR yielded the highest accuracies for DIA and SD (Standard Error of Prediction or SEP values of 22.40%±4.65 and 34.15%±2.72 respectively). GPR yielded the highest accuracies for LAI and HT (SEP values of 28.69%±3.84 and 23.19%±2.27 respectively) while RF did not yield the highest validation accuracy for any of the crop structural parameters. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","","South Africa; Decision trees; Disease control; Food supply; Linear regression; Machine learning; Reflection; Remote sensing; Vegetation; Weed control; Gaussian process regression; High-accuracy; Leaf Area Index; Machine learning models; Random forests; South Africa; Spectral vegetation indices; Stem density; Structural parameter; Vegetation index; growth rate; leaf area index; machine learning; maize; modeling; remote sensing; Sentinel; stem; vegetation index; Crops","Article","Final","","Scopus","2-s2.0-85122698484"
"Marvin H.J.P.; Bouzembrak Y.","Marvin, Hans J.P. (6701404990); Bouzembrak, Yamine (44860959400)","6701404990; 44860959400","A system approach towards prediction of food safety hazards: Impact of climate and agrichemical use on the occurrence of food safety hazards","2020","Agricultural Systems","178","","102760","","","","33","10.1016/j.agsy.2019.102760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075944207&doi=10.1016%2fj.agsy.2019.102760&partnerID=40&md5=8197d4427adf0d200baff511d96f80d2","In this study, we aimed to demonstrate the aptness of a system approach to predict the level of contamination in a given agricultural product. As a showcase, the impact of climate and agrichemical use on the occurrence of food safety hazards in feed of dairy cows in the Netherlands was used. Data on chemical hazards in dairy cows' feed in the Netherlands for the years 2000 to 2013 were retrieved from the Dutch monitoring program KAP (Quality Program for Agricultural Products). Climate data (17 variables) and agrichemical usage figs. (6 variables) for the Netherlands were obtained from the NOAA's National Centers for Environmental Information, the European Commission Joint Research Center's Agri4Cast database, and FAO's FAOSTAT. A Bayesian Network (BN) was constructed with this data and optimized for the prediction of the contamination level. The overall accuracy of prediction of the level of contamination in feed was 90.3%. Sensitivity analysis demonstrated that many climate and agrichemical variables contributed to the prediction; however, their individual contribution was generally small. The applicability of the BN was demonstrated in more detail for grass and maize as feed components. The observed trends in contamination of these crops were accounted for by climate and agrichemical variables, with the impact varying amongst the specific variables and commodities. The variables with the highest impact were “days of precipitations in a month with ≥ 2.5 mm” and “annual use of herbicides"". The results demonstrate that data-driven BNs can capture complex interactions, thereby enabling high-accuracy predictions. Whilst the applicability of this approach to the safety of dairy cows' feed in the Netherlands has thus been demonstrated, it can also be applied to other areas of food safety when a systems approach is needed. Such models can support risk assessors and risk managers in their understanding of the impacts of a given factor on food and feed safety, and inform the latter's decisions to mitigate potential risks. © 2019 The Authors","Bayesian Networks; Dairy and milk; Feed; Food supply chain; Machine learning","Netherlands; Zea mays; accuracy assessment; agrochemical; Bayesian analysis; cattle; climate effect; dairy farming; database; European Commission; food safety; food supply; hazard assessment; machine learning; milk production; NOAA satellite; prediction","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85075944207"
"Ari Y.; Papadopoulos A.","Ari, Yakup (57217065221); Papadopoulos, Alex (7101944727)","57217065221; 7101944727","Bayesian estimation of student-t garch model using Lindley’s approximation","2019","Economic Computation and Economic Cybernetics Studies and Research","53","1","","75","88","13","3","10.24818/18423264/53.1.19.05","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086010988&doi=10.24818%2f18423264%2f53.1.19.05&partnerID=40&md5=6c48b47d762337d3f56b81ec0a66a91d","The dependency of conditional second moments of financial time series is modelled by Generalized Autoregressive conditionally heteroscedastic (GARCH) processes. The maximum likelihood estimation (MLE) procedure is most commonly used for estimating the unknown parameters of a GARCH model. In this study, the parameters of the GARCH models with student-t innovations are discussed for estimations using the Bayesian approach. It is assumed that the parameters of the GARCH model are random variables having known prior probability density functions. Lindley’s approximation will be used to estimate the Bayesian estimators since they are not in a closed form. The Bayesian estimators are derived under squared error loss function. Finally, a simulation study is performed in order to compare the ML estimates to the Bayesian ones and in addition to simulations an example is given in order to illustrate the findings. MLE’s and Bayesian estimates are compared according to the expected risks in the simulation study which shows that as the sample size increases the expected risks decrease and also it is observed that Bayesian estimates have performed better than MLE’s. © 2019, Bucharest University of Economic Studies. All rights reserved.","Bayesian methods; GARCH; Lindley’s approximation; MLE; Squared error","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85086010988"
"Wang Z.-J.; Zhao L.-T.","Wang, Zi-Jie (57211429678); Zhao, Lu-Tao (50662424700)","57211429678; 50662424700","The impact of the global stock and energy market on EU ETS: A structural equation modelling approach","2021","Journal of Cleaner Production","289","","125140","","","","29","10.1016/j.jclepro.2020.125140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096835312&doi=10.1016%2fj.jclepro.2020.125140&partnerID=40&md5=4c737c8a23e572c1960a795a57b1c349","The industrial revolution has brought about great development in the economy, but it has also increased the dependence on fossil energy. The emissions of CO2 and other greenhouse gases have contradicted economic development and the ecological environment. The establishment of the EU Emission Trading System (EU ETS) has improved the global carbon emission price mechanism, but as a new commodity, its price trend will affect buyers’ risk evaluation. Therefore, it is influential to master the driving factors behind carbon emission prices and make effective predictions. First, the paper points out that the driving factors are divided into macroeconomic risk factors and energy factors. Second, the Bayesian Network is used to select variables and make prediction of carbon prices. The results show that its accuracy exceeds other machine learning algorithms. Third, a structural equation model is used to study the impact of the selected markets on the carbon market. Finally, from the perspective of global carbon emission reduction, the relationship between driving factors and the carbon futures market is explained. The empirical results show that Cotation Assistée en Continu 40, natural gas and Brent crude oil will directly affect the yield of European Union Allowances and Certified Emission Reduction futures, and the Standard Poor 500 and Global Clean Energy Index will indirectly affect the yield of European Union Allowances and Certified Emission Reduction futures. The energy market will affect the carbon market through the intermediary effect of the stock market, in which the clean energy index is the most relevant factor. From the perspective of how to improve the carbon trading system, this paper proposes suggestions for the sustainable development of the world to promote the virtuous cycle of the global carbon emission market and the high-quality development of the global economy. © 2020 Elsevier Ltd","Bayesian network; Carbon price; EU ETS; Structural equation model","Bayesian networks; Carbon; Costs; Emission control; Gas emissions; Greenhouse gases; International law; Learning algorithms; Machine learning; Power markets; Sustainable development; Carbon emission prices; Certified emission reductions; Ecological environments; Global carbon emission; Global economies; Industrial revolutions; Structural equation modeling; Structural equation modelling; Economic and social effects","Article","Final","","Scopus","2-s2.0-85096835312"
"Roy Choudhury A.; Abrishami S.; Turek M.; Kumar P.","Roy Choudhury, Ahana (55608481400); Abrishami, Soheila (57211071238); Turek, Michael (57216050080); Kumar, Piyush (57199976385)","55608481400; 57211071238; 57216050080; 57199976385","Enhancing profit from stock transactions using neural networks","2020","AI Communications","33","2","","75","92","17","9","10.3233/AIC-200629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093868126&doi=10.3233%2fAIC-200629&partnerID=40&md5=753a0cd5ad1b1ad27bdea5a7dc9a40a3","Financial time-series forecasting, and profit maximization is a challenging task, which has attracted the interest of several researchers and is immensely important for investors. In this paper, we present a deep learning system, which uses a variety of data for a subset of the stocks on the NASDAQ exchange to forecast the stock price. Our framework allows the use of a variational autoencoder (VAE) to remove noise and time-series data engineering to extract higher-level features. A Stacked LSTM Autoencoder is used to perform multi-step-ahead prediction of the stock closing price. This prediction is used by two profit-maximization strategies that include greedy approach and short selling. Besides, we use reinforcement learning as a third profit-enhancement strategy and compare these three strategies to offline strategies that use the actual future prices. Results show that the proposed methods outperform the state-of-the-art time-series forecasting approaches in terms of predictive accuracy and profitability. © 2020 - IOS Press and the authors. All rights reserved.","feature engineering; Financial time series prediction; LSTM autoencoder; reinforcement learning; stock price","Deep learning; Financial markets; Forecasting; Learning systems; Long short-term memory; Profitability; Reinforcement learning; Time series; Financial time series forecasting; Greedy approaches; Multi-step-ahead predictions; Predictive accuracy; Profit maximization; State of the art; Stock transaction; Time series forecasting; Electronic trading","Article","Final","","Scopus","2-s2.0-85093868126"
"Do Amaral Burghi A.C.; Hirsch T.; Pitz-Paal R.","Do Amaral Burghi, Ana Carolina (55903826900); Hirsch, Tobias (23090890100); Pitz-Paal, Robert (55897757300)","55903826900; 23090890100; 55897757300","Artificial learning dispatch planning with probabilistic forecasts: Using uncertainties as an asset","2020","Energies","13","3","616","","","","5","10.3390/en13030616","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079180909&doi=10.3390%2fen13030616&partnerID=40&md5=2362cd10ec2e878e0da8ac3d1ab13dcf","Weather forecast uncertainty is a key element for energy market volatility. By intelligently considering uncertainties on the schedule development, renewable energy systems with storage could improve dispatching accuracy, and therefore, effectively participate in electricity wholesale markets. Deterministic forecasts have been traditionally used to support dispatch planning, representing reduced or no uncertainty information about the future weather. Aiming at better representing the uncertainties involved, probabilistic forecasts have been developed to increase forecasting accuracy. For the dispatch planning, this can highly influence the development of a more precise schedule. This work extends a dispatch planning method to the use of probabilistic weather forecasts. The underlying method used a schedule optimizer coupled to a post-processing machine learning algorithm. This machine learning algorithm was adapted to include probabilistic forecasts, considering their additional information on uncertainties. This post-processing applied a calibration of the planned schedule considering the knowledge about uncertainties obtained from similar past situations. Simulations performed with a concentrated solar power plant model following the proposed strategy demonstrated promising financial improvement and relevant potential in dealing with uncertainties. Results especially show that information included in probabilistic forecasts can increase financial revenues up to 15% (in comparison to a persistence solar driven approach) if processed in a suitable way. © 2020 by the authors.","Dispatch; Machine learning; Optimization; Probabilistic forecasts; Renewable systems; Storage","Commerce; Energy storage; Learning algorithms; Learning systems; Machine learning; Optimization; Solar energy; Solar power plants; Concentrated solar power; Deterministic forecasts; Dispatch; Financial improvement; Forecasting accuracy; Probabilistic forecasts; Renewable energy systems; Uncertainty informations; Weather forecasting","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85079180909"
"Malagrino L.S.; Roman N.T.; Monteiro A.M.","Malagrino, Luciana S. (57201435199); Roman, Norton T. (12446313600); Monteiro, Ana M. (42962047000)","57201435199; 12446313600; 42962047000","Forecasting stock market index daily direction: A Bayesian Network approach","2018","Expert Systems with Applications","105","","","11","22","11","85","10.1016/j.eswa.2018.03.039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044785082&doi=10.1016%2fj.eswa.2018.03.039&partnerID=40&md5=3b7871c2283283ee527215efc34e0395","In this work, we investigate the feasibility of Bayesian Networks as a way to verify the extent to which stock market indices from around the globe influence iBOVESPA – the main index at the São Paulo Stock Exchange, Brazil. To do so, index directions were input to a network designed to reflect some intuitive dependencies amongst continental markets, moving through 24 and 48 h cycles, and outputting iBOVESPA's next day closing direction. Two different network topologies were tested, with different numbers of stock indices used in each test. Best results were obtained with the model that accounts for a single index per continent, up to 24 h before iBOVESPA's closing time. Mean accuracy with this configuration was around 71% (with almost 78% top accuracy). With results comparable to those of the related literature, our model has the further advantage of being simpler and more tractable for its users. Also, along with the fact that it not only gives the next day closing direction, but also furnishes the set of indices that influence iBovespa the most, the model lends itself both to academic research purposes and as one of the building blocks in more robust decision support systems. © 2018 Elsevier Ltd","Applied artificial intelligence; Bayesian Networks; Machine learning; Stock direction prediction","Artificial intelligence; Associative processing; Commerce; Decision support systems; Financial markets; Learning systems; Academic research; Building blockes; Network topology; Robust decisions; Stock exchange; Stock indices; Stock market index; Bayesian networks","Article","Final","","Scopus","2-s2.0-85044785082"
"Bagnato M.; Bottasso A.; Giribone P.G.","Bagnato, Marco (57311678000); Bottasso, Anna (6506745975); Giribone, Pier Giuseppe (59016027900)","57311678000; 6506745975; 59016027900","Implementation of a Commitment Machine for an Adaptive and Robust Expected Shortfall Estimation","2021","Frontiers in Artificial Intelligence","4","","732805","","","","0","10.3389/frai.2021.732805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117916035&doi=10.3389%2ffrai.2021.732805&partnerID=40&md5=2317ca107168f71d52018978f13698e3","This study proposes a metaheuristic for the selection of models among different Expected Shortfall (ES) estimation methods. The proposed approach, denominated “Commitment Machine” (CM), has a strong focus on assets cross-correlation and allows to measure adaptively the ES, dynamically evaluating which is the most performing method through the minimization of a loss function. The CM algorithm compares four different ES estimation techniques which all take into account the interaction effects among assets: a Bayesian Vector autoregressive model, Stochastic Differential Equation (SDE) numerical schemes with Exponential Weighted Moving Average (EWMA), a Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) volatility model and a hybrid method that integrates Dynamic Recurrent Neural Networks together with a Monte Carlo approach. The integration of traditional Monte Carlo approaches with Machine Learning technologies and the heterogeneity of dynamically selected methodologies lead to an improved estimation of the ES. The study describes the techniques adopted by the CM and the logic behind model selection; moreover, it provides a market application case of the proposed metaheuristic, by simulating an equally weighted multi-asset portfolio. © Copyright © 2021 Bagnato, Bottasso and Giribone.","artificial intelligence; bayesian vector autoregressive; commitment machine; dynamic neural networks; expected shortfall; monte carlo methods; nonlinear auto-regressive networks; stochastic differential equation","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85117916035"
"Chandra R.; He Y.","Chandra, Rohitash (35106707300); He, Yixuan (57226041234)","35106707300; 57226041234","Bayesian neural networks for stock price forecasting before and during COVID-19 pandemic","2021","PLoS ONE","16","7 July","e0253217","","","","31","10.1371/journal.pone.0253217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110251020&doi=10.1371%2fjournal.pone.0253217&partnerID=40&md5=9c04fca0f7bcb581b2dc0f8afdbb6f93","Recently, there has been much attention in the use of machine learning methods, particularly deep learning for stock price prediction. A major limitation of conventional deep learning is uncertainty quantification in predictions which affect investor confidence. Bayesian neural networks feature Bayesian inference for providing inference (training) of model parameters that provides a rigorous methodology for uncertainty quantification in predictions. Markov Chain Monte Carlo (MCMC) sampling methods have been prominent in implementing inference of Bayesian neural networks; however certain limitations existed due to a large number of parameters and the need for better computational resources. Recently, there has been much progress in the area of Bayesian neural networks given the use of Langevin gradients with parallel tempering MCMC that can be implemented in a parallel computing environment. The COVID-19 pandemic had a drastic impact in the world economy and stock markets given different levels of lockdowns due to rise and fall of daily infections. It is important to investigate the performance of related forecasting models during the COVID-19 pandemic given the volatility in stock markets. In this paper, we use novel Bayesian neural networks for multi-step-ahead stock price forecasting before and during COVID-19. We also investigate if the pre-COVID-19 datasets are useful of modelling stock price forecasting during COVID-19. Our results indicate due to high volatility in the stock-price during COVID-19, it is more challenging to provide forecasting. However, we found that Bayesian neural networks could provide reasonable predictions with uncertainty quantification despite high market volatility during the first peak of the COVID-19 pandemic. © 2021 Chandra, He. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","Bayes Theorem; COVID-19; Forecasting; Humans; Investments; Marketing; Neural Networks, Computer; Pandemics; Article; Bayesian network; coronavirus disease 2019; economic aspect; forecasting; gross national product; lockdown; machine learning; pandemic; prediction; stock market; stock price; Bayes theorem; epidemiology; forecasting; human; investment; marketing; pandemic","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85110251020"
"Ito S.; Kiyoki Y.","Ito, Shin (55575805700); Kiyoki, Yasushi (6701615368)","55575805700; 6701615368","A multidimensional market analysis method using level-velocity-momentum time-series vector space","2014","Frontiers in Artificial Intelligence and Applications","260","","","158","173","15","0","10.3233/978-1-61499-361-2-158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894534776&doi=10.3233%2f978-1-61499-361-2-158&partnerID=40&md5=8a3defc7e53a956b4370535b2ad91286","Numerous stock market analysis methods have been proposed from simple moving average to the use of artificial intelligence such as neural networks and Bayesian networks. In this paper, we introduce a new concept and a methodology that enable predictability of asset price movement in the market by way of inference from the past data. We use schema to describe an economic instance, and a set of schema in time series to describe the flow of economic instances in the past. Within the schema, we introduce a concept of velocity and momentum to effectively characterize the dynamic nature of the market. We compare the current and the past instances to identify resemblance and take inference as a predictive capability of future asset price movement. © 2014 The authors and IOS Press.","market; momentum; multidimensional; prediction; schema; time-series; Vector space analysis; velocity","Bayesian networks; Commerce; Knowledge based systems; Momentum; Time series analysis; Vector spaces; Analysis method; Asset prices; Market; Market analysis; Multidimensional; Price movement; Schema; Stock market analysis; Times series; Vector space analysis; Time series","Article","Final","","Scopus","2-s2.0-84894534776"
"Shen F.; Chao J.; Zhao J.","Shen, Furao (24482362400); Chao, Jing (53863299300); Zhao, Jinxi (56144098100)","24482362400; 53863299300; 56144098100","Forecasting exchange rate using deep belief networks and conjugate gradient method","2015","Neurocomputing","167","","","243","253","10","222","10.1016/j.neucom.2015.04.071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952629849&doi=10.1016%2fj.neucom.2015.04.071&partnerID=40&md5=78a1218fac5686cd410cb7fa33ad90bf","Forecasting exchange rates is an important financial problem. In this paper, an improved deep belief network (DBN) is proposed for forecasting exchange rates. By using continuous restricted Boltzmann machines (CRBMs) to construct a DBN, we update the classical DBN to model continuous data. The structure of DBN is optimally determined through experiments for application in exchange rates forecasting. Also, conjugate gradient method is applied to accelerate the learning for DBN. In the experiments, three exchange rate series are tested and six evaluation criteria are adopted to evaluate the performance of the proposed method. Comparison with typical forecasting methods such as feed forward neural network (FFNN) shows that the proposed method is applicable to the prediction of foreign exchange rate and works better than traditional methods. © 2015 Elsevier B.V.","Conjugate gradient; Continuous restricted Boltmann machines; Deep belief networks; Exchange rate forecasting","Bayesian networks; Finance; Forecasting; Deep belief network (DBN); Deep belief networks; Evaluation criteria; Exchange rate forecasting; Financial problems; Forecasting methods; Foreign exchange rates; Restricted boltzmann machine; Article; artificial neural network; conjugate gradient method; continuous restricted Boltzmann machine; controlled study; deep belief network; feed forward neural network; forecasting; forecasting exchange rate; learning algorithm; machine learning; mathematical computing; mathematical model; priority journal; statistical analysis; time series analysis; Conjugate gradient method","Article","Final","","Scopus","2-s2.0-84952629849"
"Patashkova Y.; Niyazbekova S.; Kerimkhulle S.; Serikova M.; Troyanskaya M.","Patashkova, Yelena (57227223200); Niyazbekova, Shakizada (56530857900); Kerimkhulle, Seyit (57195807370); Serikova, Madina (57206737796); Troyanskaya, Marija (57192640463)","57227223200; 56530857900; 57195807370; 57206737796; 57192640463","Dynamics of Bitcoin trading on the Binance cryptocurrency exchange; [Динаміка розвитку торгів біткоїнами на криптовалютній біржі Binance]; [Динамика развития торгов биткоинами на криптовалютной бирже Binance]","2021","Economic Annals-XXI","187","1-2","","177","188","11","19","10.21003/EA.V187-17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113325063&doi=10.21003%2fEA.V187-17&partnerID=40&md5=1499ed1c2782ff6aeedebe8ad968bfc2","Currently, there are a great number of platform-projects and frameworks based on blockchain technology. Consequently, it is necessary to define the most relevant blockchain platforms and analyze them taking into consideration a variety of features. Also, there is a need to investigate the logistics growth and the price of Bitcoin on the Binance cryptocurrency exchange. The authors have examined modern technologies used by manufacturing companies in the field of fintech in the context of the 2019-2024 period. The results show that sensors and automatic identification take the leading position both at present and in 2024. Artificial intelligence and blockchain are also in demand by manufacturers today, however in the nearest future their ranking positions will increase sixfold from 10% to 60%. In the current paper the authors review the largest companies that effectively use blockchain technology in their businesses. The conducted survey shows that 18% of companies use blockchain technology based on Bitcoin. The authors have analysed a number of Bitcoin transactions for the period from January 2017 to February 2021 and concluded that the COVID-19 pandemic has had a favourable effect on the indicator data. A maximum number of transactions equal to 10.15 million was carried out in July 2020. Using the method of the Ordinary Least Squares (OLS) and statistical estimation methods the authors have revealed an underestimation of the equilibrium state of the empirical distribution of price data and the volume of daily trading of Bitcoin on the Binance cryptocurrency exchange through the channel of the right-hand confidence interval. The blockchain technology based on Bitcoin has positively reacted to the macroeconomic factors such as the COVID-19 pandemics and further growth in Bitcoin transactions is expected. With the help of economic modelling, the authors have defined the predictable volume and the price of Bitcoin on the Binance cryptocurrency exchange. © Institute of Society Transformation, 2021.","Bitcoin; Blockchain technology; Cryptocurrency; Financial market; Fintech","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85113325063"
"Risk J.; Ludkovski M.","Risk, Jimmy (57188593851); Ludkovski, Michael (16304519100)","57188593851; 16304519100","Sequential design and spatial modeling for portfolio tail risk measurement∗                     ","2018","SIAM Journal on Financial Mathematics","9","4","","1137","1174","37","14","10.1137/17M1158380","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060169694&doi=10.1137%2f17M1158380&partnerID=40&md5=46c754585115bd1b92da36cd3789e101","We consider calculation of capital requirements when the underlying economic scenarios are determined by simulatable risk factors. In the respective nested simulation framework, the goal is to estimate portfolio tail risk, quantified via value-at-risk (VaR) or tail value-at-risk (TVaR), of portfolio losses in a given collection of future economic scenarios represented by factor levels at the risk horizon. Traditionally, evaluating portfolio losses in an outer scenario is done by computing a conditional expectation via inner-level Monte Carlo simulations and is computationally expensive. We introduce several inter-related machine learning techniques to speed up this computation, in particular by properly accounting for the simulation noise. Our main workhorse is an advanced Gaussian process (GP) regression approach that uses nonparametric spatial modeling to efficiently learn the relationship between the stochastic factors defining scenarios and corresponding portfolio values. Leveraging this emulator, we develop sequential algorithms that adaptively allocate inner simulation budgets to target the quantile region. The GP framework also yields better uncertainty quantification for the resulting VaR/TVaR estimators which reduce bias and variance compared to existing methods. We illustrate the proposed strategies with two case-studies in two and six dimensions. © 2018 Society for Industrial and Applied Mathematics.","Gaussian process regression; Nested simulation; Portfolio tail risk; Sequential design; Value-at-risk estimation","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85060169694"
"Antulov-Fantulin N.; Guo T.; Lillo F.","Antulov-Fantulin, Nino (36168955200); Guo, Tian (55292713300); Lillo, Fabrizio (57203233459)","36168955200; 55292713300; 57203233459","Temporal mixture ensemble models for probabilistic forecasting of intraday cryptocurrency volume","2021","Decisions in Economics and Finance","44","2","","905","940","35","4","10.1007/s10203-021-00344-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112232226&doi=10.1007%2fs10203-021-00344-9&partnerID=40&md5=7a8ef939e99d7f4fd5b0c8e4ed40ab67","We study the problem of the intraday short-term volume forecasting in cryptocurrency multi-markets. The predictions are built by using transaction and order book data from different markets where the exchange takes place. Methodologically, we propose a temporal mixture ensemble, capable of adaptively exploiting, for the forecasting, different sources of data and providing a volume point estimate, as well as its uncertainty. We provide evidence of the clear outperformance of our model with respect to econometric models. Moreover our model performs slightly better than Gradient Boosting Machine while having a much clearer interpretability of the results. Finally, we show that the above results are robust also when restricting the prediction analysis to each volume quartile. © 2021, The Author(s).","Cryptocurrency markets; Econometrics; Machine learning; Temporal mixture ensemble","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85112232226"
"Tegnér M.; Roberts S.","Tegnér, Martin (57196478251); Roberts, Stephen (57203276441)","57196478251; 57203276441","Probabilistic machine learning for local volatility","2021","Journal of Computational Finance","25","3","","1","50","49","2","10.21314/JCF.2021.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127478092&doi=10.21314%2fJCF.2021.012&partnerID=40&md5=a0c586eb120e768bf473fbdb6183d615","The local volatility model is widely used for pricing and hedging financial deriva-tives. While its main appeal is its capability of reproducing any given surface of observed option prices – it provides a perfect fit – the essential component is a latent function that can be uniquely determined only in the limit of infinite data. To (re)construct this function, numerous calibration methods have been suggested that involve steps of interpolation and extrapolation, most often of parametric form and with point-estimate representations. We use probabilistic machine learning to look at the calibration problem in a probabilistic framework based on Gaussian processes. This immediately gives a way of encoding prior beliefs about the local volatility function and a hypothesis model that is highly flexible yet not prone to overfitting. Besides providing a method for calibrating a (range of) point estimate(s), we draw posterior inference from the distribution over local volatility. This leads to a better understanding of uncertainty associated with the model in general, and with the calibration in particular. Further, we infer dynamical properties of local volatility by augmenting the hypothesis space with a time dimension. Ideally, this provides predictive distributions not only locally, but also for entire surfaces forward in time. We apply our approach to S&P 500 market data. © 2021 Infopro Digital Risk (IP) Limited.","Gaussian processes; local volatility; machine learning; option pricing; probabilistic inference","","Article","Final","","Scopus","2-s2.0-85127478092"
"Zhou M.; Wang B.; Watada J.","Zhou, Min (57200192958); Wang, Bo (57216235966); Watada, Junzo (57189052014)","57200192958; 57216235966; 57189052014","Deep learning-based rolling horizon unit commitment under hybrid uncertainties","2019","Energy","186","","115843","","","","24","10.1016/j.energy.2019.07.173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073701107&doi=10.1016%2fj.energy.2019.07.173&partnerID=40&md5=e21aeab440ab99a9e7b6bb921517d706","Unit commitment is an optimization problem in power systems, which aims to satisfy future load at minimal cost by scheduling the on/off state and output of generation resources like thermal units. One challenge herein is the uncertainties that exist in both supply and demand sides of power systems, which becomes more severe with the growing penetration of renewable energy and the popularity of diversified loads. This paper proposes a rolling horizon model for unit commitment optimization under hybrid uncertainties. First, a probabilistic forecast approach for future load and wind power is given by exploiting the advanced deep learning structures, i.e. long short-term memory neural networks. Second, a Value-at-Risk-based unit commitment model is applied to decide the on/off state and output of thermal units in the next 24 h. Then at each time window, the distributions of future load and wind power are dynamically adjusted by a rolling forecast mechanism to involve the real-time collected data, whereafter a look-ahead economic dispatch model is applied to improve the output of units. Finally, the effectiveness of this research is demonstrated by a series of experiments. Generally, this study introduces a fundamental way to integrate forecast approaches into classical unit commitment optimization models. © 2019 Elsevier Ltd","Data-driven; Long short-term memory neural networks; Look-ahead economic dispatch; Rolling forecast; Rolling horizon unit commitment","Brain; Economics; Electric load dispatching; Long short-term memory; Optimization; Scheduling; Value engineering; Weather forecasting; Wind power; Data driven; Economic Dispatch; Generation resources; Optimization models; Optimization problems; Probabilistic forecasts; Renewable energies; Unit-commitment; algorithm; artificial neural network; experimental study; optimization; uncertainty analysis; wind power; Deep learning","Article","Final","","Scopus","2-s2.0-85073701107"
"Thawornwong S.; Enke D.","Thawornwong, Suraphan (6506494415); Enke, David (54945335700)","6506494415; 54945335700","The adaptive selection of financial and economic variables for use with artificial neural networks","2004","Neurocomputing","56","1-4","","205","232","27","116","10.1016/j.neucom.2003.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0742289149&doi=10.1016%2fj.neucom.2003.05.001&partnerID=40&md5=554de36a74606739e63d2311e2c63f0b","It has been widely accepted that predicting stock returns is not a simple task since many market factors are involved and their structural relationships are not perfectly linear. Recently, a promising data mining technique in machine learning has been proposed to uncover the predictive relationships of numerous financial and economic variables. Inspired by the fact that the determinant between these variables and their interrelationships over stock returns changes over time, we explore this issue further by using data mining to uncover the recent relevant variables with the greatest predictive ability. The objective is to examine whether using the recent relevant variables leads to additional improvements in stock return forecasting. Given evidence of non-linearity in the financial market, the resulting variables are then provided to neural networks, including probabilistic and feed-forward neural networks, for predicting the directions of future excess stock return. The results show that redeveloped neural network models that use the recent relevant variables generate higher profits with lower risks than the buy-and-hold strategy, conventional linear regression, and the random walk model, as well as the neural network models that use constant relevant variables. © 2003 Elsevier B.V. All rights reserved.","Financial and economic variables; Neural networks; Stock market prediction; Variable relevance analysis","Data mining; Forecasting; Learning systems; Mathematical models; Regression analysis; article; artificial neural network; controlled study; data analysis; economic evaluation; empiricism; financial management; forecasting; information processing; intermethod comparison; learning; linear regression analysis; linear system; mathematical computing; nonlinear system; prediction; priority journal; probability; profit; randomization; risk assessment; simulation; time; Economic variables; Neural networks","Article","Final","","Scopus","2-s2.0-0742289149"
"Qian B.; Rasheed K.","Qian, Bo (56266136700); Rasheed, Khaled (7003492982)","56266136700; 7003492982","Foreign exchange market prediction with multiple classifiers","2010","Journal of Forecasting","29","3","","271","284","13","21","10.1002/for.1124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949615819&doi=10.1002%2ffor.1124&partnerID=40&md5=df66f3ea02c975e9f3567dd345cb12f0","Foreign exchange market prediction is attractive and challenging. According to the efficient market and random walk hypotheses, market prices should follow a random walk pattern and thus should not be predictable with more than about 50% accuracy. In this article, we investigate the predictability of foreign exchange spot rates of the US dollar against the British pound to show that not all periods are equally random. We used the Hurst exponent to select a period with great predictability. Parameters for generating training patterns were determined heuristically by auto-mutual information and false nearestneighbor methods. Some inductive machine-learning classifiers-artificial neural network, decision tree, k-nearest neighbor, and naïve Bayesian classifier-were then trained with these generated patterns. Through appropriate collaboration of these models, we achieved a prediction accuracy of up to 67%. © 2009 John Wiley and Sons, Ltd.","Efficient market hypothesis; Foreign exchange market prediction; Hurst exponent; Machine learning; Model ensemble","Commerce; Decision trees; Electronic trading; Forecasting; Learning systems; Nearest neighbor search; Neural networks; Random processes; Efficient market hypothesis; Foreign exchange; Foreign exchange market prediction; Hurst exponents; Machine-learning; Market prediction; Market price; Model ensembles; Multiple-classifiers; Random Walk; Financial markets","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-77949615819"
"Lee C.-B.","Lee, Chung-Bow (7410142784)","7410142784","Bayesian analysis of a change-point in exponential families with applications","1998","Computational Statistics and Data Analysis","27","2","","195","208","13","24","10.1016/S0167-9473(98)00009-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032478490&doi=10.1016%2fS0167-9473%2898%2900009-7&partnerID=40&md5=c0f026667db8b9398479cf649049087f","A Bayesian analysis is used to detect a change-point in a sequence of independent random variables from exponential family distributions. The conjugate priors for the exponential families are considered in the analysis. The marginal posterior distribution of the change-point j is derived. Since some hyperparameters are involved in the conjugate priors, the Type II maximum likelihood (ML-II) approach (cf. Berger, 1995) will be used to estimate these hyperparameters in applications. The method is simple and is easily applied to the Nile problem, Illinois traffic data, British coal-mining disasters, accident data and stock-market prices. © 1998 Elsevier Science B.V. All rights reserved.","Change-point; Conjugate prior; ML-II approach; Posterior distribution","Applications; Functions; Mathematical techniques; Random processes; Bayesian analysis; change point; Change-point; Conjugate prior; Statistical methods","Article","Final","","Scopus","2-s2.0-0032478490"
"Liesenfeld R.; Richard J.-F.","Liesenfeld, Roman (6603606826); Richard, Jean-François (57202768604)","6603606826; 57202768604","Classical and Bayesian analysis of univariate and multivariate stochastic volatility models","2006","Econometric Reviews","25","2-3","","335","360","25","42","10.1080/07474930600713424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747784985&doi=10.1080%2f07474930600713424&partnerID=40&md5=822315fc5f497781553a82d73b4544f2","In this paper, efficient importance sampling (EIS) is used to perform a classical and Bayesian analysis of univariate and multivariate stochastic volatility (SV) models for financial return series. EIS provides a highly generic and very accurate procedure for the Monte Carlo (MC) evaluation of high-dimensional interdependent integrals. It can be used to carry out ML-estimation of SV models as well as simulation smoothing where the latent volatilities are sampled at once. Based on this EIS simulation smoother, a Bayesian Markov chain Monte Carlo (MCMC) posterior analysis of the parameters of SV models can be performed. Copyright © Taylor & Francis Group, LLC.","Dynamic latent variables; Markov chain Monte Carlo; Maximum likelihood; Simulation smoother","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-33747784985"
"Zarepour M.; Bédard T.; Dabrowski A.R.","Zarepour, Mahmoud (6507435604); Bédard, Thierry (24402462500); Dabrowski, André R. (7101722062)","6507435604; 24402462500; 7101722062","Return and value at risk using the Dirichlet process","2008","Applied Mathematical Finance","15","3","","205","218","13","2","10.1080/13504860701718448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-45949084992&doi=10.1080%2f13504860701718448&partnerID=40&md5=899d98467da9423a4e791a9f8e2850f8","There exists a wide variety of models for return, and the chosen model determines the tool required to calculate the value at risk (VaR). This paper introduces an alternative methodology to model-based simulation by using a Monte Carlo simulation of the Dirichlet process. The model is constructed in a Bayesian framework, using properties initially described by Ferguson. A notable advantage of this model is that, on average, the random draws are sampled from a mixed distribution that consists of a prior guess by an expert and the empirical process based on a random sample of historical asset returns. The method is relatively automatic and similar to machine learning tools, e.g. the estimate is updated as new data arrive. © 2008 Taylor & Francis.","Bayes estimates; Dirichlet process; Quantiles; Value at risk","","Article","Final","","Scopus","2-s2.0-45949084992"
"Wong F.S.; Wang P.Z.","Wong, F.S. (16431776200); Wang, P.Z. (7405460280)","16431776200; 7405460280","A stock selection strategy using fuzzy neural networks","1991","Neurocomputing","2","5-6","","233","242","9","12","10.1016/0925-2312(91)90026-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040588983&doi=10.1016%2f0925-2312%2891%2990026-8&partnerID=40&md5=bb127d8132a4d9a202b52020559e875a","This paper describes, from a general system-design perspective, an artificial neural network (ANN) approach to a stock selection strategy. The paper suggests a concept of neural gates which are similar to the processing elements in ANN, but generalized for handling various types of information such as fuzzy logic, probabilistic and Boolean information together. Forecasting of stock market returns, assessing of country risk and rating of stocks based on fuzzy rules, probabilistic and Boolean data can be done using the proposed neural gates. Fuzzy logic is known to be useful for decision-making where there is a great deal of uncertainty as well as vague phenomena, but lacks the learning capability; on the other hand, neural networks are useful in constructing an adaptive system which can learn from historical data, but are not able to process ambiguous rules and probabilistic data sets. This paper describes how these problems can be solved using the proposed neural gates. © 1991.","artificial intelligence; financial analysis; fuzzy logic; neural network; risk analysis; Stock market analysis","","Article","Final","","Scopus","2-s2.0-0040588983"
"Bauwens L.; Rombouts J.V.K.","Bauwens, L. (56363422800); Rombouts, J.V.K. (16029670000)","56363422800; 16029670000","Bayesian inference for the mixed conditional heteroskedasticity model","2007","Econometrics Journal","10","2","","408","425","17","11","10.1111/j.1368-423X.2007.00213.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34347394131&doi=10.1111%2fj.1368-423X.2007.00213.x&partnerID=40&md5=d1d56b33c4440c5ab26e4a0ee09c8bc7","We estimate by Bayesian inference the mixed conditional heteroskedasticity model of Haas et al. (2004a Journal of Financial Econometrics 2, 211-50). We construct a Gibbs sampler algorithm to compute posterior and predictive densities. The number of mixture components is selected by the marginal likelihood criterion. We apply the model to the SP500 daily returns. © Royal Economic Society 2007.","Bayesian inference; Finite mixture; ML estimation; Value at risk","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-34347394131"
"Liesenfeld R.; Richard J.-F.","Liesenfeld, Roman (6603606826); Richard, Jean-François (57202768604)","6603606826; 57202768604","Estimation of Dynamic Bivariate Mixture Models: Comments on Watanabe (2000)","2003","Journal of Business and Economic Statistics","21","4","","570","576","6","8","10.1198/073500103288619287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242381883&doi=10.1198%2f073500103288619287&partnerID=40&md5=e70a817b5dac688dd8dc9a289159711c","This note compares a Bayesian Markov chain Monte Carlo approach implemented by Watanabe with a maximum likelihood ML approach based on an efficient importance sampling procedure to estimate dynamic bivariate mixture models. In these models, stock price volatility and trading volume are jointly directed by the unobservable number of price-relevant information arrivals, which is specified as a serially correlated random variable. It is shown that the efficient importance sampling technique is extremely accurate and that it produces results that differ significantly from those reported by Watanabe.","Bayesian posterior means; Efficient importance sampling; Latent variable; Markov chain Monte Carlo; Maximum likelihood","","Review","Final","","Scopus","2-s2.0-0242381883"
"Lux T.","Lux, Thomas (7003769381)","7003769381","The Markov-switching multifractal model of asset returns: GMM estimation and linear forecasting of volatility","2008","Journal of Business and Economic Statistics","26","2","","194","210","16","91","10.1198/073500107000000403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41649118014&doi=10.1198%2f073500107000000403&partnerID=40&md5=e5acf0ae58230c0c1b042475dae46053","Multifractal processes have recently been proposed as a new formalism for modeling the time series of returns in finance. The major attraction of these processes is their ability to generate various degrees of long memory in different powers of returns - a feature that has been found in virtually all financial data. Initial difficulties stemming from nonstationarity and the combinatorial nature of the original model have been overcome by the introduction of an iterative Markov-switching multifractal model which allows for estimation of its parameters via maximum likelihood (ML) and Bayesian forecasting of volatility. However, applicability of MLE is restricted to cases with a discrete distribution of volatility components. From a practical point of view, ML also becomes computationally unfeasible for large numbers of components even if they are drawn from a discrete distribution. Here we propose an alternative generalized method of moments (GMM) estimator together with linear forecasts which in principle is applicable for any continuous distribution with any number of volatility components. Monte Carlo studies show that GMM performs reasonably well for the popular binomial and lognormal models and that the loss incurred with linear compared to optimal forecasts is small. Extending the number of volatility components beyond what is feasible with MLE leads to gains in forecasting accuracy for some time series. © 2008 American Statistical Association.","Generalized method of moments; Levinson-Durbin algorithm; Long memory; Multiplicative volatility model","","Article","Final","","Scopus","2-s2.0-41649118014"
"Wong F.S.; Wang P.Z.; Teh H.H.","Wong, F.S. (16431776200); Wang, P.Z. (7405460280); Teh, H.H. (7006085846)","16431776200; 7405460280; 7006085846","A stock selection strategy using fuzzy neural networks","1991","Computer Science in Economics and Management","4","2","","77","89","12","3","10.1007/BF00436283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249919736&doi=10.1007%2fBF00436283&partnerID=40&md5=ed286fb82f1858488798d44e6257ab33","This paper describes, from a general system-design perspective, an artificial neural network (ANN) approach to a stock selection strategy. The paper suggests a concept of neural gates which are similar to the processing elements in ANN, but generalized into handling various types of information such as fuzzy logic, probabilistic and Boolean information together. Forecasting of stock market returns, assessing of country risk and rating of stocks based on fuzzy rules, probabilistic and Boolean data can be done using the proposed neural gates. Fuzzy logic is known to be useful for decision-making where there is a great deal of uncertainty as well as vague phenomena, but lacks the learning capability; on the other hand, neural networks are useful in constructing an adaptive system which can learn from historical data, but are not able to process ambiguous rules and probabilistic data sets. This paper describes how these problems can be solved using the proposed neural gates. © 1991 Kluwer Academic Publishers.","artificial intelligence; financial analysis; fuzzy logic; neural network; risk analysis; Stock market analysis","","Article","Final","","Scopus","2-s2.0-34249919736"
"Cheng C.-H.; Chen T.-L.; Wei L.-Y.","Cheng, Ching-Hsue (7404797459); Chen, Tai-Liang (56143516900); Wei, Liang-Ying (23062367300)","7404797459; 56143516900; 23062367300","A hybrid model based on rough sets theory and genetic algorithms for stock price forecasting","2010","Information Sciences","180","9","","1610","1629","19","184","10.1016/j.ins.2010.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76349121290&doi=10.1016%2fj.ins.2010.01.014&partnerID=40&md5=b8aecb9742d737adf3000aeebac2a788","In the stock market, technical analysis is a useful method for predicting stock prices. Although, professional stock analysts and fund managers usually make subjective judgments, based on objective technical indicators, it is difficult for non-professionals to apply this forecasting technique because there are too many complex technical indicators to be considered. Moreover, two drawbacks have been found in many of the past forecasting models: (1) statistical assumptions about variables are required for time series models, such as the autoregressive moving average model (ARMA) and the autoregressive conditional heteroscedasticity (ARCH), to produce forecasting models of mathematical equations, and these are not easily understood by stock investors; and (2) the rules mined from some artificial intelligence (AI) algorithms, such as neural networks (NN), are not easily realized. In order to overcome these drawbacks, this paper proposes a hybrid forecasting model, using multi-technical indicators to predict stock price trends. Further, it includes four proposed procedures in the hybrid model to provide efficient rules for forecasting, which are evolved from the extracted rules with high support value, by using the toolset based on rough sets theory (RST): (1) select the essential technical indicators, which are highly related to the future stock price, from the popular indicators based on a correlation matrix; (2) use the cumulative probability distribution approach (CDPA) and minimize the entropy principle approach (MEPA) to partition technical indicator value and daily price fluctuation into linguistic values, based on the characteristics of the data distribution; (3) employ a RST algorithm to extract linguistic rules from the linguistic technical indicator dataset; and (4) utilize genetic algorithms (GAs) to refine the extracted rules to get better forecasting accuracy and stock return. The effectiveness of the proposed model is verified with two types of performance evaluations, accuracy and stock return, and by using a six-year period of the TAIEX (Taiwan Stock Exchange Capitalization Weighted Stock Index) as the experiment dataset. The experimental results show that the proposed model is superior to the two listed forecasting models (RST and GAs) in terms of accuracy, and the stock return evaluations have revealed that the profits produced by the proposed model are higher than the three listed models (Buy-and-Hold, RST and GAs). © 2010 Elsevier Inc. All rights reserved.","Cumulative probability distribution approach; Genetic algorithms; Minimize entropy principle approach; Rough set theory; Technical indicators","Communication channels (information theory); Costs; Entropy; Fuzzy clustering; Genetic algorithms; Hybrid sensors; Linguistics; Neural networks; Petroleum refining; Probabilistic logics; Probability density function; Probability distributions; Profitability; Technological forecasting; Time series; Cumulative probability distribution approach; Cumulative probability distribution approaches; Entropy principle; Minimize entropy principle approach; Technical indicator; Rough set theory","Article","Final","","Scopus","2-s2.0-76349121290"
"Kim S.H.; Chun S.H.","Kim, Steven H. (7601578179); Chun, Se Hak (7202148435)","7601578179; 7202148435","Graded forecasting using an array of bipolar predictions: Application of probabilistic neural networks to a stock market index","1998","International Journal of Forecasting","14","3","","323","337","14","85","10.1016/S0169-2070(98)00003-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000558764&doi=10.1016%2fS0169-2070%2898%2900003-X&partnerID=40&md5=e0d3afb01336cb9507bb93b8edb8f5ca","To an increasing extent over the past decade, software learning methods including neural networks have been used for prediction in financial markets and other areas. By far the most popular type of neural network has been backpropagation. However, the advantages of other learning techniques such as the swift response of the probabilistic neural network (PNN) suggest the desirability of adapting other models to the predictive function. Unfortunately, the conventional architecture for probabilistic neural networks yields only a bipolar output corresponding to Yes or No; Up or Down. This limitation may be circumvented in part by using a graded forecast of multiple discrete values. More specifically, the approach involves an architecture comprising an array of elementary PNNs with bipolar output. This paper explores a number of interrelated topics: (1) presentation of a new architecture for graded forecasting using an arrayed probabilistic network (APN); (2) use of a ""mistake chart"" to compare the accuracy of learning systems against default performance based on a constant prediction; and (3) evaluation of several backpropagation models against a recurrent neural network (RNN) as well as PNN, APN, and case based reasoning. These concepts are investigated against the backdrop of a practical application involving the prediction of a stock market index. © 1998 Elsevier Science B.V. All rights reserved.","Artificial intelligence; Financial market forecasting; Forecasting system","","Article","Final","","Scopus","2-s2.0-0000558764"
"Ward C.","Ward, Colin (36978441900)","36978441900","Bayesian REIT volatility estimation and institutional portfolio allocation","2008","Journal of Real Estate Portfolio Management","14","4","","425","441","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049216446&partnerID=40&md5=05c75249fce94ba273dd86e73c354e37","Volatility estimation is an integral part of institutional finance with applications in risk management and portfolio allocation. Real estate investment trust volatility is examined using a Bayesian asymmetric GARCH model and is found to better estimate the true volatility series than does the traditional maximum likelihood approach. This paper discusses the shortfalls of maximum likelihood (ML) estimation and the advantages of the Bayesian estimation, particularly to real estate. Conditional variance estimation uncertainty is found to increase with volatility. A portfolio allocation problem highlights that the Bayesian approach performed better than the ML method in preserving capital.","","","Article","Final","","Scopus","2-s2.0-58049216446"
