"Title","Subtitle","Author","Publication","SourceType","Publisher","Volume","Issue","PubDate","AlphaDate","StartPage","EndPage","PageRange","ISSN","EISSN","ISBN","Language","Abstract","DocumentUrl","DOI"
"Gaussian Process-Mixture Conditional Heteroscedasticity.","","Platanios, Emmanouil A; Chatzis, Sotirios P","IEEE transactions on pattern analysis and machine intelligence","Undefined","","36","5","2014-05-01","May 2014","888","900","888-900","","1939-3539","","ENG","Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.","https://www.proquest.com/docview/1711536889?accountid=12870&bdid=83737&_bd=6noCn7np%2FVznZhUREUGDHrrF%2Biw%3D","https://doi.org/10.1109/TPAMI.2013.183"
"Conducting Causal Analysis by Means of Approximating Probabilistic Truths","","Bo Pieter Johannes Andrée","Entropy","Scholarly Journals","","24","1","2022-01-01","2022","92","","","10994300","","","ENG","Simple SummaryThe current paper develops a probabilistic theory of causation and suggests practical routines for conducting causal inference applicable to new machine learning methods that have, so far, remained relatively underutilized in this context.AbstractThe current paper develops a probabilistic theory of causation using measure-theoretical concepts and suggests practical routines for conducting causal inference. The theory is applicable to both linear and high-dimensional nonlinear models. An example is provided using random forest regressions and daily data on yield spreads. The application tests how uncertainty in short- and long-term inflation expectations interacts with spreads in the daily Bitcoin price. The results are contrasted with those obtained by standard linear Granger causality tests. It is shown that the suggested measure-theoretic approaches do not only lead to better predictive models, but also to more plausible parsimonious descriptions of possible causal flows. The paper concludes that researchers interested in causal analysis should be more aspirational in terms of developing predictive capabilities, even if the interest is in inference and not in prediction per se. The theory developed in the paper provides practitioners guidance for developing causal models using new machine learning methods that have, so far, remained relatively underutilized in this context.","https://www.proquest.com/docview/2621295030?accountid=12870&bdid=83737&_bd=AgaP8%2Bc8Hhyg97w11ISioYlM94I%3D","https://doi.org/10.3390/e24010092"
"A New Framework for Fraud Detection in Bitcoin Transactions Through Ensemble Stacking Model in Smart Cities","","Nayyer, Noor; Javaid, Nadeem; Akbar, Mariam; Aldegheishem, Abdulaziz; Alrajeh, Nabil; Mohsin Jamil","IEEE Access","Scholarly Journals","","11","","2023-01-01","2023","90916","","90916-90938","21693536","","","ENG","Bitcoin has a reputation of being used for unlawful activities, such as money laundering, dark web transactions, and payments for ransomware in the context of smart cities. Blockchain technology prevents illegal transactions, but cannot detect these transactions. Anomaly detection is a fundamental technique for recognizing potential fraud. The heuristic and signature-based approaches were the foundation of earlier detection techniques, but tragically, these methods were insufficient to explore the entire complexity of anomaly detection. Machine Learning (ML) is a promising approach to anomaly detection, as it can be trained on large datasets of known malware samples to identify patterns and features of the transactions. Researchers are focusing on determining an efficient fraud and security threat detection model that overcomes the drawbacks of the existing methods. Therefore, ensemble learning can be applied to anomaly detection in Bitcoin by combining multiple ML classifiers. In the proposed model, the ADASYN-TL (Adaptive Synthetic + Tomek Link) balancing technique is used for data balancing. Random search, grid search and Bayesian optimization are used for hyperparameter tuning. The hyperparameters have a great impact on the performance of the model. For classification, we used the stacking model by combining Decision Tree, Naive Bayes, K-Nearest Neighbors, and Random Forest. We used SHapley Additive exPlanation (SHAP) to interpret the predictions of the stacking model. The model also explores the performance of different classifiers using accuracy, F1-score, Area Under Curve-Receiver Operating Characteristic (AUC-ROC), precision, recall, False Positive Rate (FPR) and execution time, and ultimately selects the ideal model. The proposed model contributes to the development of effective fraud detection models that address the limitations of the existing algorithms. Our stacking model, which combines the prediction of multiple classifiers, achieved the highest F1-score of 97%, precision of 96%, recall of 98%, accuracy of 97%, AUC-ROC of 99% and FPR of 3%.","https://www.proquest.com/docview/2859716063?accountid=12870&bdid=83737&_bd=nMhvaiCmZr%2F3nrjqi2wG%2By3mvoI%3D","https://doi.org/10.1109/ACCESS.2023.3308298"
"RETRACTED ARTICLE: A Bayesian analysis based on multivariate stochastic volatility model: evidence from green stocks","","Ma, Ming; Zhang, Jing","Journal of Combinatorial Optimization","Scholarly Journals","","45","1","2023-01-01","2023","","","","13826905","","","ENG","Green stocks are companies environmental protective and friendly. We test Green stock index in Shanghai Stock Exchange and China Securities Index as safe-havens for global investors. Suitable multivariate-SV model and Bayesian method are used to estimate the spillover effect between different assets among local and global markets. We choose multivariate volatility model because it can efficiently simulate the spillover effect by using machine learning MCMC method. The results show that the Environmental Protection Index (EPI) of Shanghai Stock Exchange (SSE) and China Securities Index (CSI) have no significant volatility spillover from Shanghai Stock index, S &P index, gold price, oil future prices of USA and China. During COVID-19 pandemic, we find Green stock index is a suitable safe-haven with low volatility spillover. Green stock indexes has a strongly one-way spillover to the crude oil future price. Environmentally friendly investor can use diversity green assets to provide a low risk investment portfolio in EPI stock market. The DCGCt-MSV model using machine learning of MCMC method is accurate and outperform others in Bayes parameter estimation.","https://www.proquest.com/docview/2740530868?accountid=12870&bdid=83737&_bd=0%2F%2BwZ56ysGIFRVGtw2CRb%2B75D0g%3D","https://doi.org/10.1007/s10878-022-00936-0"
"Forecasting Crude Oil Prices with Major S&P 500 Stock Prices: Deep Learning, Gaussian Process, and Vine Copula","","Jong-Min, Kim; Jong-Min, Kim; Han, Hope H; Kim, Sangjin","Axioms","Scholarly Journals","","11","8","2022-01-01","2022","375","","","20751680","","","ENG","This paper introduces methodologies in forecasting oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. We also apply Bayesian variable selection and nonlinear principal component analysis (NLPCA) for data dimension reduction. With a reduced number of important covariates, we also forecast oil prices (Brent and WTI) with multivariate time series of major S&P 500 stock prices using Gaussian process modeling, deep learning, and vine copula regression. To apply real data to the proposed methods, we select monthly log returns of 2 oil prices and 74 large-cap, major S&P 500 stock prices across the period of February 2001–October 2019. We conclude that vine copula regression with NLPCA is superior overall to other proposed methods in terms of the measures of prediction errors.","https://www.proquest.com/docview/2706102072?accountid=12870&bdid=83737&_bd=2lkiwwrrP6%2B2UFUMfkPNYMv%2BdZI%3D","https://doi.org/10.3390/axioms11080375"
"Bayesian REIT Volatility Estimation and Institutional Portfolio Allocation","","Ward, Colin","Journal of Real Estate Portfolio Management","Scholarly Journals","","14","4","2008-10-01","Oct-Dec 2008","425","","425-441","10835547","","","ENG","Volatility estimation is an integral part of institutional finance with applications in risk management and portfolio allocation. Real estate investment trust volatility is examined using a Bayesian asymmetric GARCH model and is found to better estimate the true volatility series than does the traditional maximum likelihood approach. This paper discusses the shortfalls of maximum likelihood (ML) estimation and the advantages of the Bayesian estimation, particularly to real estate. Conditional variance estimation uncertainty is found to increase with volatility. A portfolio allocation problem highlights that the Bayesian approach performed better than the ML method in preserving capital. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/197897315?accountid=12870&bdid=83737&_bd=lJNZXBf6hw00NYwtrUIRkEQ3NrI%3D",""
"Industrial Forecasting With Exponentially Smoothed Recurrent Neural Networks","","Dixon, Matthew","Technometrics","Scholarly Journals","","64","1","2022-02-01","Feb 2022","114","","","00401706","","","ENG","Time series modeling has entered an era of unprecedented growth in the size and complexity of data which require new modeling approaches. While many new general purpose machine learning approaches have emerged, they remain poorly understand and irreconcilable with more traditional statistical modeling approaches. We present a general class of exponential smoothed recurrent neural networks (RNNs) which are well suited to modeling nonstationary dynamical systems arising in industrial applications. In particular, we analyze their capacity to characterize the nonlinear partial autocorrelation structure of time series and directly capture dynamic effects such as seasonality and trends. Application of exponentially smoothed RNNs to forecasting electricity load, weather data, and stock prices highlight the efficacy of exponential smoothing of the hidden state for multistep time series forecasting. The results also suggest that popular, but more complicated neural network architectures originally designed for speech processing are likely over-engineered for industrial forecasting and light-weight exponentially smoothed architectures, trained in a fraction of the time, capture the salient features while being superior and more robust than simple RNNs and autoregressive models. Additionally, uncertainty quantification of Bayesian exponential smoothed RNNs is shown to provide improved coverage.","https://www.proquest.com/docview/2868299758?accountid=12870&bdid=83737&_bd=cdmO7J8RCIA06uzF6wUCv1focmw%3D","https://doi.org/10.1080/00401706.2021.1921035"
"SIM.QM-S17 Ethanol in Aqueous Matrix: Supplement Key Comparison, Model 1","","Ávila Calderón, Marco Antonio; Hugo Gasca Aragón; Serrano Caballero, Víctor Manuel; Mariana Arce Osuna; Eliane Cristina Pires do Rego; Bruno Carius Garrido; Valnei Smarçaro da Cunha; Bebić, Jelena; Banjanac, Katarina; Adrian Vicent Claramunt; Paola Avendaño Rivera; Barrios, Juliana; Gonzalez, Ivonne; Wagner Wollinger; Carvalho, Lucas J; Monteiro, Tânia M; Castañeda, Tomas; Etcheverry, Jimena; Marcelo Soto Varas; Almirón, Florencia; Silva, Ana; Shearman, Kittiya; Chaiphet, Thitiphan; Marajh, Dominique; Makgatho, Phaswe; Visser, Ria; Fernandes-Whaley, Maria","Metrologia","Scholarly Journals","","60","1A","2023-01-01","Jan 2023","08020","","","00261394","","","ENG","Main textTo establish international measurement capabilities for the determination of ethanol in aqueous matrices, the CCQM Organic Analysis Working Group (OAWG) has performed three ethanol Key comparisons (2002: CCQM-K27a for forensic aqueous ethanol and CCQM-K27b for ethanol in wine as a commodity; 2005: CCQM-K27 subsequent studies - four levels of ethanol in water; 2007: CCQM-K27.2 Subsequent 2 for forensic levels). To provide an opportunity for the NMIs and DIs within the RMOs, three Key comparisons has been conducted within SIM (SIM.QM-K1, SIM.QM-K27) and AFRIMETS (AFRIMETS.QM-K27). In addition, for the NMIs to support their ethanol in aqueous matrices measurements capabilities, a Track A Model 2 (formerly known as Track B) Key comparison CCQM-K79 (2010) has been completed to compare aqueous ethanol certified reference material (CRM) solutions certified by the participant NMIs and DIs. The current comparison is important to NMIs and DIs to maintain their ethanol in water measurement capabilities, to claim it as a new one as well as to complement their existing measurement capabilities, mainly within the range where the alcohol meter (breathalyzer) needs to be calibrated and verified.In 2017, several NMIs and DIs in SIM expressed their interest in a complementary SIM.QM-K27 comparison, therefore CENAM and INMETRO agreed to collaborate for the realization of a SIM supplement comparison, which was identified as SIM.QM-K27.2019 by the OAWG, and the final assigned name by SIM was SIM.QM-S17. The main purpose of this comparison was to offer to SIM countries and other regions an additional opportunity for the NMI and DIs to evaluate their measurements capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. Fourteen laboratories were registered to take part in this comparison, and thirteen sent their results. This report presents the results of the SIM Key comparison SIM.QM-S17.The measurements capabilities demonstrated by the participants in SIM.QM-S17, underpin their ability to assign reference values of ethanol content in aqueous samples for both forensic and commodities applications. Successful participation in SIM.QM-S17 demonstrates the laboratories measurement capabilities in determining mass fraction of ethanol in an aqueous matrix within the mass fraction range from 0.1 mg/g to 5 mg/g. The study material was two batches of solutions of ethanol in water prepared gravimetrically at concentrations between 0.1 mg/g - 5 mg/g by CENAM, dispensed in glass bottles of 50 mL sealed with tear off aluminum crimp seals, with rubber stoppers. In previous SIM.QM.K27 comparison, the purity-corrected gravimetric value of the aqueous ethanol solutions assigned by the coordinating NMI was used to link SIM.QM-K27 to the CCQM-K27 Key comparison reference value (KCRV), where 1 % uncertainty was assigned to the KCRV to have the same uncertainty from the CCQM-K27.2. For this comparison, SIM.QM-S17 two levels aqueous ethanol solutions, the purity assigned by CENAM was not used for KCRV as was informed initially in the protocol, instead in 5-June-2020 at the OAWG, CENAM gravimetric values were presented, as well as the participants results evaluated by four different statistical approaches to assess the candidate KCRV. For both levels of ethanol in aqueous matrix solutions, the DerSimonian-Laird Weighted mean and the Hierarchical Bayes mean methods seem to give a better estimation of the KCRV ± KCRU95 candidate and was agreed by OAWG to use the Hierarchical Bayesian mean, from where the KCRV for SIM.QM-S17 Level 1 (Low-level) and Level 2 (high-level) were (240.92 ± 1.28) mg/kg (k =2) and (389.87 ± 1.52) mg/kg (k =2), respectively. All the thirteen participants in the SIM.QM-S17, including both coordinators, demonstrated their capability to measure ethanol in aqueous matrix in the mass fraction range of 0.1 mg/g to 5 mg/g.To reach the main text of this paper, click on Final Report. Note that this text is that which appears in Appendix B of the BIPM key comparison database https://www.bipm.org/kcdb/.The final report has been peer-reviewed and approved for publication by the CCQM, according to the provisions of the CIPM Mutual Recognition Arrangement (CIPM MRA).","https://www.proquest.com/docview/2872949649?accountid=12870&bdid=83737&_bd=yyiSP%2BRuFpbKAmQUeoZHoEPhIhs%3D","https://doi.org/10.1088/0026-1394/60/1A/08020"
"Negation scope detection in sentiment analysis: Decision support for news-driven trading","","Pröllochs, Nicolas; Feuerriegel, Stefan; Neumann, Dirk","Decision Support Systems","Scholarly Journals","","88","","2016-08-01","Aug 2016","67","","","01679236","","","ENG","Decision support for financial news using natural language processing requires robust methods that process all sentences correctly, including those that are negated. To predict the corresponding negation scope, related literature commonly utilizes rule-based algorithms and generative probabilistic models. In contrast, we propose the use of a tailored reinforcement learning method, since it can conquer learning task of arbitrary length. We then perform a thorough comparison with a two-pronged evaluation. First, we compare the predictive performance using a manually-labeled dataset. Here, reinforcement learning outperforms common approaches from the related literature, leading to a balanced classification accuracy of up to 70.17%. Second, we examine how detecting negation scopes can improve the accuracy of sentiment analysis for financial news, leading to an improvement of up to 10.63% in the correlation between news sentiment and stock market returns. This reveals negation scope detection as a crucial leverage in decision support from sentiment.","https://www.proquest.com/docview/1809597152?accountid=12870&bdid=83737&_bd=TX5itq9BW3%2ByN8dQGZBK5WVpPA4%3D",""
"Gaussian Process-Mixture Conditional Heteroscedasticity","","Platanios, Emmanouil A; Chatzis, Sotirios P","IEEE Transactions on Pattern Analysis and Machine Intelligence","Undefined","Institute of Electrical and Electronics Engineers, Inc., 345 E. 47th St. NY NY 10017-2394 United States","36","5","2014-05-01","May 2014","888","900","888-900","0162-8828","0162-8828","","ENG","Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian process-mixture conditional heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.","https://www.proquest.com/docview/1620103378?accountid=12870&bdid=83737&_bd=tnfDMU2QF9zxuQqJmk55Wc0qtDY%3D","https://doi.org/10.1109/TPAMI.2013.183"
"Failure in Stock Price Prediction: A Comparison bettwen the Curve-Shape-Feature and Non-Curve-Shape-Feature Modes of Existing Machine Learning Algorithms","","Zhang, Ping; Jia-Yao, Yang; Zhu, Hao; Yue-Jie Hou; Liu, Yi; Chi-Chun, Zhou","International Journal of Computers, Communications and Control","Scholarly Journals","","16","6","2021-12-01","Dec 2021","","","","18419836","","","ENG","In the era of artificial intelligence, machine learning methods are successfully used in various fields. Machine learning has attracted extensive attention from investors in the financial market, especially in stock price prediction. However, one argument for the machine learning methods used in stock price prediction is that they are black-box models which are difficult to interpret. In this paper, we focus on the future stock price prediction with the historical stock price by machine learning and deep learning methods, such as support vector machine (SVM), random forest (RF), Bayesian classifier (BC), decision tree (DT), multilayer perceptron (MLP), convolutional neural network (CNN), bi-directional long-short term memory (BiLSTM), the embedded CNN, and the embedded BiLSTM. Firstly, we manually design several financial time series where the future price correlates with the historical stock prices in pre-designed modes, namely the curve-shape-feature (CSF) and the non-curve-shape-feature (NCSF) modes. In the CSF mode, the future prices can be extracted from the curve shapes of the historical stock prices. Conversely, in the NCSF mode, they can’t. Secondly, we apply various algorithms to those pre-designed and real financial time series. We find that the existing machine learning and deep learning algorithms fail in stock price prediction because in the real financial time series, less information of future prices is contained in the CSF mode, and perhaps more information is contained in the NCSF. Various machine learning and deep learning algorithms are good at handling the CSF in historical data, which are successfully applied in image recognition and natural language processing. However, they are inappropriate for stock price prediction on account of the NCSF. Therefore, accurate stock price prediction is the key to successful investment, and new machine learning algorithms handling the NCSF series are needed.","https://www.proquest.com/docview/2615132614?accountid=12870&bdid=83737&_bd=ODl%2FYM2GESB11Z0KaS8nmgBQrPk%3D","https://doi.org/10.15837/ijccc.2021.6.4549"
"Temporal mixture ensemble models for probabilistic forecasting of intraday cryptocurrency volume","","Antulov-Fantulin Nino; Guo, Tian; Lillo Fabrizio","Decisions in Economics and Finance","Scholarly Journals","","44","2","2021-01-01","2021","905","940","905-940","15938883","","","ENG","We study the problem of the intraday short-term volume forecasting in cryptocurrency multi-markets. The predictions are built by using transaction and order book data from different markets where the exchange takes place. Methodologically, we propose a temporal mixture ensemble, capable of adaptively exploiting, for the forecasting, different sources of data and providing a volume point estimate, as well as its uncertainty. We provide evidence of the clear outperformance of our model with respect to econometric models. Moreover our model performs slightly better than Gradient Boosting Machine while having a much clearer interpretability of the results. Finally, we show that the above results are robust also when restricting the prediction analysis to each volume quartile.","https://www.proquest.com/docview/2610094508?accountid=12870&bdid=83737&_bd=yYLKT8cvaEaw0wL4eod6TwShJDY%3D","https://doi.org/10.1007/s10203-021-00344-9"
"Enhancing profit from stock transactions using neural networks","","Ahana Roy Choudhury; Abrishami, Soheila; Turek, Michael; Kumar, Piyush","AI Communications","Scholarly Journals","","33","2","2020-01-01","2020","75","","75-92","0921-7126","","","ENG","Financial time-series forecasting, and profit maximization is a challenging task, which has attracted the interest of several researchers and is immensely important for investors. In this paper, we present a deep learning system, which uses a variety of data for a subset of the stocks on the NASDAQ exchange to forecast the stock price. Our framework allows the use of a variational autoencoder (VAE) to remove noise and time-series data engineering to extract higher-level features. A Stacked LSTM Autoencoder is used to perform multi-step-ahead prediction of the stock closing price. This prediction is used by two profit-maximization strategies that include greedy approach and short selling. Besides, we use reinforcement learning as a third profit-enhancement strategy and compare these three strategies to offline strategies that use the actual future prices. Results show that the proposed methods outperform the state-of-the-art time-series forecasting approaches in terms of predictive accuracy and profitability.","https://www.proquest.com/docview/2444669356?accountid=12870&bdid=83737&_bd=qmVbYNm6u%2BBTOFxQNLJN8FfhJlk%3D","https://doi.org/10.3233/AIC-200629"
"Foreign exchange market prediction with multiple classifiers","","Qian, Bo; Rasheed, Khaled","Journal of Forecasting","Scholarly Journals","","29","3","2010-04-01","Apr 2010","271","","","02776693","","","ENG","Foreign exchange market prediction is attractive and challenging. According to the efficient market and random walk hypotheses, market prices should follow a random walk pattern and thus should not be predictable with more than about 50% accuracy. In this article, we investigate the predictability of foreign exchange spot rates of the US dollar against the British pound to show that not all periods are equally random. We used the Hurst exponent to select a period with great predictability. Parameters for generating training patterns were determined heuristically by auto-mutual information and false nearest-neighbor methods. Some inductive machine-learning classifiers - artificial neural network, decision tree, k-nearest neighbor, and naive Bayesian classifier - were then trained with these generated patterns. Through appropriate collaboration of these models, we achieved a prediction accuracy of up to 67%. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/219135850?accountid=12870&bdid=83737&_bd=38zB0VRZZtZCLcDzWg5p%2FCWfmcw%3D",""
"DL-GuesS : Deep Learning and Sentiment Analysis-Based Cryptocurrency Price Prediction","","Parekh, Raj; Patel, Nisarg P; Thakkar, Nihar; Gupta, Rajesh; Tanwar, Sudeep; Sharma, Gulshan; Davidson, Innocent E; Sharma, Ravi","IEEE Access","Scholarly Journals","","10","","2022-01-01","2022","35398","","35398-35409","21693536","","","ENG","Cryptocurrencies are peer-to-peer-based transaction systems where the data exchanges are secured using the secure hash algorithm (SHA)-256 and message digest (MD)-5 algorithms. The prices of cryptocurrencies are highly volatile and follow stochastic moments and have reached their unpredictable limits. They are commonly used for investment and have become a substitute for other types of investment like metals, estates, and the stock market. Their importance in the market raises the strict requirement for a sturdy forecasting model. However, cryptocurrency price prediction is quite challenging due to its dependency on other cryptocurrencies. Many researchers have used machine learning and deep learning models, and other market sentiment-based models to predict the price of cryptocurrencies. As all the cryptocurrencies belong to a specific class, we can infer that the increase in the price of one cryptocurrency can lead to a price change for other cryptocurrencies. Researchers had also utilized the sentiments from tweets and other social media platforms to increase the performance of their proposed system. Motivated by these, in this paper, we propose a hybrid and robust framework, DL-Gues , for cryptocurrency price prediction, that considers its interdependency on other cryptocurrencies and also on market sentiments. We have considered price prediction of Dash carried out using price history and tweets of Dash , Litecoin , and Bitcoin for various loss functions for validation. Further, to check the usability of DL-GuesS on other cryptocurrencies, we have also inferred results for price prediction of Bitcoin-Cash with the price history and tweets of Bitcoin-Cash , Litecoin , and Bitcoin .","https://www.proquest.com/docview/2648289501?accountid=12870&bdid=83737&_bd=tI3dXIGoLnu6dmS4m4PyBoX2Ccs%3D","https://doi.org/10.1109/ACCESS.2022.3163305"
"A stacked generalization system for automated FOREX portfolio trading","","Petropoulos, Anastasios; Chatzis, Sotirios P; Siakoulis, Vasilis; Vlachogiannakis, Nikos","Expert Systems with Applications","Scholarly Journals","","90","","2017-12-30","Dec 30, 2017","290","","","0957-4174","","","ENG","Multiple FOREX time series forecasting is a hot research topic in the literature of portfolio trading. To this end, a large variety of machine learning algorithms have been examined. However, it is now widely understood that, in real-world trading settings, no single machine learning model can consistently outperform the alternatives. In this work, we examine the efficacy and the feasibility of developing a stacked generalization system, intelligently combining the predictions of diverse machine learning models. Our approach establishes a novel inferential framework that comprises the following levels of data processing: (i) We model the dependence patterns between major currency pairs via a diverse set of commonly used machine learning algorithms, namely support vector machines (SVMs), random forests (RFs), Bayesian autoregressive trees (BART), dense-layer neural networks (NNs), and naïve Bayes (NB) classifiers. (ii) We generate implied signals of exchange rate fluctuation, based on the output of these models, as well as appropriate side information obtained by analyzing the correlations across currency pairs in our training datasets. (iii) We finally combine these implied signals into an aggregate predictive waveform, by leveraging majority voting, genetic algorithm optimization, and regression weighting techniques. We thoroughly test our framework in real-world trading scenarios; we show that our system leads to significantly better trading performance than the considered benchmarks. Thus, it represents an attractive solution for financial firms and corporations that perform foreign exchange portfolio management and daily trading. Our system can be used as an integrated part in international commercial trade activities or in a quantitative investing framework for algorithmic trading and carry-trade speculation.","https://www.proquest.com/docview/1967822563?accountid=12870&bdid=83737&_bd=%2FhDhAHa2bZo5kNm1h6ntph%2B5qdk%3D",""
"Cloud based Financial Market Prediction through Genetic Algorithms: A Review","","Soni, Nitasha; Kumar, Tapas","International Journal of Computer Applications","Undefined","Foundation of Computer Science, 244 5th Avenue, # 1526, New York, NY 10001, USA India","123","8","2015-01-01","20150000","","","","","0975-8887","","ENG","This paper surveys recent literature in the area of stock market forecasting using advanced engineering based methods like Neural Network, fractal theory, Data Mining, Hidden Markov Model and Neuro-Fuzzy system. Neural Networks and Neuro-Fuzzy systems are emerging as an effective tool to be used in the forecasting of stock market especially in machine learning techniques. Due to chaotic behavior of the market, traditional techniques are insufficient to cover all the possible relation of the stock price fluctuations. Neural Network and Markov Model is being used exclusively in the forecasting of finance markets but in third world countries. In this paper, we will discuss the relevance of existing methods based on neural network and discussed gaps between these methods. We also propose a forecasting method to provide better an accuracy rather traditional method.","https://www.proquest.com/docview/1753536682?accountid=12870&bdid=83737&_bd=HKiUWeTmfulBaMBZk63AS%2BxqRVE%3D","https://doi.org/10.5120/ijca2015905413"
"Bayesian neural networks for stock price forecasting before and during COVID-19 pandemic","","Chandra, Rohitash; He, Yixuan","PLoS One","Scholarly Journals","","16","7","2021-07-01","Jul 2021","e0253217","","","19326203","","","ENG","Recently, there has been much attention in the use of machine learning methods, particularly deep learning for stock price prediction. A major limitation of conventional deep learning is uncertainty quantification in predictions which affect investor confidence. Bayesian neural networks feature Bayesian inference for providing inference (training) of model parameters that provides a rigorous methodology for uncertainty quantification in predictions. Markov Chain Monte Carlo (MCMC) sampling methods have been prominent in implementing inference of Bayesian neural networks; however certain limitations existed due to a large number of parameters and the need for better computational resources. Recently, there has been much progress in the area of Bayesian neural networks given the use of Langevin gradients with parallel tempering MCMC that can be implemented in a parallel computing environment. The COVID-19 pandemic had a drastic impact in the world economy and stock markets given different levels of lockdowns due to rise and fall of daily infections. It is important to investigate the performance of related forecasting models during the COVID-19 pandemic given the volatility in stock markets. In this paper, we use novel Bayesian neural networks for multi-step-ahead stock price forecasting before and during COVID-19. We also investigate if the pre-COVID-19 datasets are useful of modelling stock price forecasting during COVID-19. Our results indicate due to high volatility in the stock-price during COVID-19, it is more challenging to provide forecasting. However, we found that Bayesian neural networks could provide reasonable predictions with uncertainty quantification despite high market volatility during the first peak of the COVID-19 pandemic.","https://www.proquest.com/docview/2547537398?accountid=12870&bdid=83737&_bd=TmxwcSKiACLkjVvhuOC5N9f8QLo%3D","https://doi.org/10.1371/journal.pone.0253217"
"Predicting IoT Distributed Ledger Fraud Transactions With a Lightweight GAN Network","","Rawlins, Charles; Sarangapani, Jagannathan","IEEE Transactions on Mobile Computing","Scholarly Journals","","23","7","2024-01-01","2024","7818","","7818-7829","15361233","","","ENG","Decision-making and consensus in traditional blockchain protocols is formulated as a repeated Bernoulli trial that solves a computationally-intense lottery puzzle, called Proof-of-Work (PoW) in Bitcoin. This approach has shown robustness through practice, but does not scale with increasing network size and generation of new transactions. Resource constrained Internet of Things (IoT) networks are incompatible with full computation of schemes like Bitcoin's PoW. Our effort proposes a first step towards an alternative consensus using machine learning-based decision-making with prediction of fraud transactions to alleviate need for intense computation. To improve base approval probabilities for fraud detection in an ideal security setting, Vector GAN (VecGAN) is proposed to augment blockchain data in classifier training, which combines error-driven learning with Bayesian estimation to alleviate calculations. This two-step approach with augmentation and classification on new transactions is proposed as a novel approach to blockchain decision-making. Experimental prediction accuracy using VecGAN improved up to 3% on simplistic classifiers compared to other state-of-the-art augmentation techniques. Resource consumption in a realistic blockchain setting was reduced while improving block throughput by 50% compared to PoW. Future work will explore Sybil-spam defensive measures for realistic protocol implementation with this approach.","https://www.proquest.com/docview/3064715243?accountid=12870&bdid=83737&_bd=VGf3DW%2B3mSHN%2BZgPVhnADPGZSw8%3D","https://doi.org/10.1109/TMC.2023.3339384"
"Fuzzy Neural Systems for Stock Selection","","Wong, F S; Wang, P Z; Goh, T H; Quek, B K","Financial Analysts Journal","Scholarly Journals","","48","1","1992-01-01","Jan/Feb 1992","47","","47","0015198X","","","ENG","Artificial neural systems suffer from an inability to explain the steps by which they reach decisions and from an inability to incorporate rules into their structure.  Fuzzy neural systems (FNS) address some of the shortcomings of artificial intelligence tools.  An FNS uses a new concept called neural gates, which are similar to the processing elements of artificial neural systems but can handle a broader range of information.  Neural gates can be applied to forecasting stock market returns, assessing country risk, and rating stocks based on fuzzy rules and probabilistic and Boolean logic.  An intelligent stock selection (ISS) system incorporating neural gates is presented.  The ISS combines the various advantages of expert systems, artificial neural systems, and fuzzy reasoning.  A stock selection application is provided.","https://www.proquest.com/docview/219166244?accountid=12870&bdid=83737&_bd=M1dq4bdZyfDeAwGeVrw6X6kBbTM%3D",""
"Negation scope detection in sentiment analysis: Decision support for news-driven trading","","Prollochs, Nicolas; Feuerriegel, Stefan; Neumann, Dirk","Decision Support Systems","Undefined","North-Holland, P.O. Box 211 Amsterdam 1000 AE Netherlands","88","","2016-08-01","August 1, 2016","67","75","67-75","0167-9236","0167-9236","","ENG","Decision support for financial news using natural language processing requires robust methods that process all sentences correctly, including those that are negated. To predict the corresponding negation scope, related literature commonly utilizes rule-based algorithms and generative probabilistic models. In contrast, we propose the use of a tailored reinforcement learning method, since it can conquer learning task of arbitrary length. We then perform a thorough comparison with a two-pronged evaluation. First, we compare the predictive performance using a manually-labeled dataset. Here, reinforcement learning outperforms common approaches from the related literature, leading to a balanced classification accuracy of up to 70.17%. Second, we examine how detecting negation scopes can improve the accuracy of sentiment analysis for financial news, leading to an improvement of up to 10.63% in the correlation between news sentiment and stock market returns. This reveals negation scope detection as a crucial leverage in decision support from sentiment.","https://www.proquest.com/docview/1835569442?accountid=12870&bdid=83737&_bd=5VThbs5x9xoCQnjUvZwySWkR1sk%3D","https://doi.org/10.1016/j.dss.2016.05.009"
"A Systematic Survey of AI Models in Financial Market Forecasting for Profitability Analysis","","Bilal Hassan Ahmed Khattak; Shafi, Imran; Abdul Saboor Khan; Emmanuel Soriano Flores; Roberto Garcia Lara; Samad, Md Abdus; Imran Ashraf","IEEE Access","Scholarly Journals","","11","","2023-01-01","2023","125359","","125359-125380","21693536","","","ENG","Artificial intelligence (AI)-based models have emerged as powerful tools in financial markets, capable of reducing investment risks and aiding in selecting highly profitable stocks by achieving precise predictions. This holds immense value for investors, as it empowers them to make data-driven decisions. Identifying current and future trends in multi-class forecasting techniques employed within financial markets, particularly profitability analysis as an evaluation metric is important. The review focuses on examining stud-ies conducted between 2018 and 2023, sourced from three prominent academic databases. A meticulous three-stage approach was employed, encompassing the systematic planning, conduct, and analysis of the se-lected studies. Specifically, the analysis emphasizes technical assessment, profitability analysis, hybrid mod-eling, and the type of results generated by models. Articles were shortlisted based on inclusion and exclusion criteria, while a rigorous quality assessment through ten quality criteria questions, utilizing a Likert-type scale was employed to ensure methodological robustness. We observed that ensemble and hybrid models with long short-term memory (LSTM) and support vector machines (SVM) are being more adopted for financial trends and price prediction. Moreover, hybrid models employing AI algorithms for feature engineering have great potential at par with ensemble techniques. Most studies only employ performance metrics and lack utilization of profitability metrics or investment or trading strategy (simulated or real-time). Similarly, research on multi-class or output is severely lacking in financial forecasting and can be a good avenue for future research.","https://www.proquest.com/docview/2890103747?accountid=12870&bdid=83737&_bd=C1Szs7OvOq8uSBa87HBI3brYTLo%3D","https://doi.org/10.1109/ACCESS.2023.3330156"
"Assess deep learning models for Egyptian exchange prediction using nonlinear artificial neural networks","","Houssein, Essam H; Dirar Mahmoud; Hussain Kashif; Mohamed, Waleed M","Neural Computing & Applications","Scholarly Journals","","33","11","2021-06-01","Jun 2021","5965","5987","5965-5987","09410643","","","ENG","Financial analysis of the stock market using the historical data is the exigent demand in business and academia. This work explores the efficiency of three deep learning (Dl) techniques, namely Bayesian regularization (BE), Levenberg–Marquardt (lM), and scaled conjugate gradient (SCG), for training nonlinear autoregressive artificial neural networks (NARX) for predicting specifically the closing price of the Egyptian Stock Exchange indices (EGX-30, EGX-30-Capped, EGX-50-EWI, EGX-70, EGX-100, and NIlE). An empirical comparison is established among the experimented prediction models considering all techniques for the time horizon of 1 day, 3 days, 5 days, 7 days, 5 days and 30 days in advance, applying on all the datasets used in this study. For performance evaluation, statistical measures such as mean squared error (MSE) and correlation R are used. From the simulation result, it can be clearly suggested that BR outperforms other models for short-term prediction especially for 3 days ahead. On the other hand, lM generates better prediction accuracy than BR- and SCG-based models for long-term prediction, especially for 7-day prediction.","https://www.proquest.com/docview/2529012451?accountid=12870&bdid=83737&_bd=SivhV0GQNAmWQfGFpOU6BvvmZ3M%3D","https://doi.org/10.1007/s00521-020-05374-9"
"Identification and prediction of economic regimes to guide decision making in multi-agent marketplaces","","Ketter, Wolfgang","ProQuest Dissertations and Theses","Dissertations & Theses","","","","2007-01-01","2007","","","","","","978-1-109-88417-3","ENG","Supply chain management is commonly employed by businesses to improve organizational processes by optimizing the transfer of goods, information, and services between buyers and suppliers. Traditionally, supply chains have been created and maintained through the interactions of human representatives of the various companies involved. However, the recent advent of autonomous software agents opens new possibilities for automating and coordinating the decision making processes between the various parties involved. Autonomous agents participating in supply chain management must typically make their decisions in environments of high complexity, high variability, and high uncertainty since only limited information is visible. We present an approach whereby an autonomous agent is able to make tactical decisions, such as product pricing, as well as strategic decisions, such as product mix and production planning, in order to maximize its profit despite the uncertainties in the market. The agent predicts future market conditions and adapts its decisions on procurement, production, and sales accordingly. Using a combination of machine learning and optimization techniques; the agent first characterizes the microeconomic conditions, such as over-supply or scarcity, of the market. These conditions are distinguishable statistical patterns that we call economic regimes. They are learned from historical data by using a Gaussian Mixture Model to model the price density of the different products and by clustering price distributions that recur across days. In real-time the agent identifies the current dominant market condition and forecasts market changes over a planning horizon. Methods for the identification of regimes are explored in detail, and three different algorithms are presented. One is based on exponential smoothing, the second on a Markov prediction process, and the third on a Markov correction-prediction process. We examine a wide range of tuning options for these algorithms, and show how they can be used to predict prices, price trends, and the probability of receiving a customer order. We validate our methods by presenting experimental results from the Trading Agent Competition for Supply Chain Management, an international competition of software agents that has provided inspiration for this work. We also show how the same approach can be applied to the stock market.","https://www.proquest.com/docview/304838032?accountid=12870&bdid=83737&_bd=r5HhkmlZgp2RFXWqhC%2BhGc6WPM0%3D",""
"Financial Latent Dirichlet Allocation (FinLDA): Feature Extraction in Text and Data Mining for Financial Time Series Prediction","","Kanungsukkasem, Nont; Leelanupab, Teerapong","IEEE Access","Scholarly Journals","","7","","2019-01-01","2019","71645","","71645-71664","21693536","","","ENG","News has been an important source for many financial time series predictions based on fundamental analysis. However, digesting a massive amount of news and data published on the Internet to predict a market can be burdensome. This paper introduces a topic model based on latent Dirichlet allocation (LDA) to discover features from a combination of text, especially news articles and financial time series, denoted as Financial LDA (FinLDA). The features from FinLDA are served as additional input features for any machine learning algorithm to improve the prediction of the financial time series. We provide posterior distributions used in Gibbs sampling for two variants of the FinLDA and propose a framework for applying the FinLDA in a text and data mining for financial time series prediction. The experimental results show that the features from the FinLDA empirically add value to the prediction and give better results than the comparative features including topic distributions from the common LDA.","https://www.proquest.com/docview/2455605460?accountid=12870&bdid=83737&_bd=mKPa6guHxp7JGWsHSwYhDiHCPH4%3D","https://doi.org/10.1109/ACCESS.2019.2919993"
"Analyzing Different Machine Learning Techniques for Stock Market Prediction","","Ahmad, Waqas","International Journal of Computer Science and Information Security","Undefined","L J S Publishing","12","12","2014-12-01","Dec 2014","17","17","17","","1947-5500","","ENG","Stock market prediction is one of most challenging issue and attracted attention from many researches and stock market investors. With passing time these stock market prediction techniques are getting better with different machine learning algorithms and investors have started relying on these prediction model proposed by many researchers. Many machine learning techniques for stock market prediction are developed. There are no specifications available that which techniques are optimal or not. Also I will analyze and compare different techniques and will discuss their strength and weakness. I have analyzed how these technique works and compare these techniques with other stock market prediction techniques and explained how some techniques have advantage over others and perform better.","https://www.proquest.com/docview/1677986728?accountid=12870&bdid=83737&_bd=IOAMcItlQ3YW0G4FLx2gXkr%2FyEQ%3D",""
"Impact of Hyperparameter Tuning on Machine Learning Models in Stock Price Forecasting","","Hoque, Kazi Ekramul; Hamoud Aljamaan","IEEE Access","Scholarly Journals","","9","","2021-01-01","2021","163815","","163815-163830","21693536","","","ENG","Stock price forecasting has been reported as a challenging task in the scientific and financial communities due to stock prices’ nonlinear and dynamic nature. Machine learning models exhibit capabilities that allow them to handle nonlinear data and be candidate tools for stock price forecasting. In this study, an empirical evaluation of eight conventional machine learning models’ is conducted to forecast the stock price of eleven companies belonging to the Saudi Stock Exchange. Moreover, the optimal configuration of hyperparameters in each machine learning model is identified. Forecasting performance is evaluated by two well-known error metrics: Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE). Wilcoxson effect size is utilized to determine the impact of hyperparameter tuning by comparing tuned and un-tuned machine learning models’ forecasting performance. Empirical results indicate there are varying impacts of hyperparameter tuning of machine learning models in forecasting stock price. After tuning the hyperparameters, Support Vector Regression outperforms other forecasting models with a significant statistical difference. In contrast, Kernel Ridge Regression shows noteworthy forecasting performance without hyperparameter tuning with respect to other un-tuned forecasting models. However, Decision Tree and K-Nearest Neighbour are the poor-performing models which demonstrate inadequate forecasting performance even after hyperparameter tuning.","https://www.proquest.com/docview/2610984193?accountid=12870&bdid=83737&_bd=QVJBt1yjncPQdXiYHAt6uox4VtY%3D","https://doi.org/10.1109/ACCESS.2021.3134138"
"Identification and prediction of economic regimes to guide decision making in multi-agent marketplaces.","","Ketter, Wolfgang","Dissertation Abstracts International","Undefined","University Microfilms International, P.O. Box 1764, Ann Arbor, MI, 48106, USA","68","2","2007-01-01","2007","","","","0419-4217","0419-4217","","ENG","Supply chain management is commonly employed by businesses to improve organizational processes by optimizing the transfer of goods, information, and services between buyers and suppliers. Traditionally, supply chains have been created and maintained through the interactions of human representatives of the various companies involved. However, the recent advent of autonomous software agents opens new possibilities for automating and coordinating the decision making processes between the various parties involved. Autonomous agents participating in supply chain management must typically make their decisions in environments of high complexity, high variability, and high uncertainty since only limited information is visible. We present an approach whereby an autonomous agent is able to make tactical decisions, such as product pricing, as well as strategic decisions, such as product mix and production planning, in order to maximize its profit despite the uncertainties in the market. The agent predicts future market conditions and adapts its decisions on procurement, production, and sales accordingly. Using a combination of machine learning and optimization techniques; the agent first characterizes the microeconomic conditions, such as over-supply or scarcity, of the market. These conditions are distinguishable statistical patterns that we call economic regimes. They are learned from historical data by using a Gaussian Mixture Model to model the price density of the different products and by clustering price distributions that recur across days. In real-time the agent identifies the current dominant market condition and forecasts market changes over a planning horizon. Methods for the identification of regimes are explored in detail, and three different algorithms are presented. One is based on exponential smoothing, the second on a Markov prediction process, and the third on a Markov correction-prediction process. We examine a wide range of tuning options for these algorithms, and show how they can be used to predict prices, price trends, and the probability of receiving a customer order. We validate our methods by presenting experimental results from the Trading Agent Competition for Supply Chain Management, an international competition of software agents that has provided inspiration for this work. We also show how the same approach can be applied to the stock market.","https://www.proquest.com/docview/33148512?accountid=12870&bdid=83737&_bd=%2FrdrVcNuOOGwoS4xKSEJ9ymcma8%3D",""
"DeepAR-Attention probabilistic prediction for stock price series","","Li, Jiacheng; Chen, Wei; Zhou, Zhiheng; Yang, Junmei; Zeng, Delu","Neural Computing & Applications","Scholarly Journals","","36","25","2024-09-01","Sep 2024","15389","15406","15389-15406","09410643","","","ENG","Stock price prediction is a significant research domain, intersecting statistics, finance, and economics. Accurately forecasting stock price trends has always been a focal point for many researchers. However, traditional statistical methods for time series prediction still lack accuracy. The existing deep learning-based methods for stock price prediction have significantly enhanced the accuracy of predicting individual stock prices. However, they are not effective in forecasting the probability range of future stock price trends. In this paper, to address these limitations, we propose a novel DeepAR model based on the attention mechanism (DeepARA) for both single-point and probabilistic predictions of stock prices. This enhances the accuracy and flexibility of stock price forecasting. Although the attention mechanism was initially developed for natural language processing, it has now found applications in time series forecasting, including the dynamics of the stock market. Attention allocates different weights to time points of varying importance, thereby enhancing the model’s ability to capture fundamental market dynamics. We conducted multiple experiments in the Chinese stock market, involving 30 stocks across the top six sectors. Compared with baseline models, the DeepARA model demonstrates superior predictive capabilities.","https://www.proquest.com/docview/3095794012?accountid=12870&bdid=83737&_bd=TSb4EU7bTADpIo0cSaap9jbwqGA%3D","https://doi.org/10.1007/s00521-024-09916-3"
"A COMPARATIVE STUDY OF BAYESIAN AND MAXIMUM LIKELIHOOD APPROACHES FOR ARCH MODELS WITH EVIDENCE FROM BRAZILIAN FINANCIAL SERIES","","Andrade, Marinho G; Oliveira, Sandra C","New Mathematics and Natural Computation","Undefined","World Scientific Publishing Co., Inc.","7","2","2011-07-01","Jul 2011","347","361","347-361","1793-0057","1793-0057","","ENG","The purpose of this study is to address the inference problem of the parameters of autoregressive conditional heteroscedasticity (ARCH) models. Specifically, we present a comparison of the two approaches - Bayesian and Maximum Likelihood (ML) for ARCH models, and the specific mathematical and algorithmic formulations of these approaches. In the ML, estimation we obtain confidence intervals by using the Bootstrap simulation technique. In the Bayesian estimation, we present a reparametrization of the model which allows us to apply prior normal densities to the transformed parameters. The posterior estimates are obtained using Monte Carlo Markov Chain (MCMC) methods. The methodology is exemplified by considering two Brazilian financial time series: the Bovespa Stock Index - IBovespa and the Telebras series. The order of each ARCH model is selected by using the Bayesian Information Criterion (BIC).","https://www.proquest.com/docview/963894230?accountid=12870&bdid=83737&_bd=%2FBFJRVxxla31wrZ0oUmqWE6tzGg%3D","https://doi.org/10.1142/S1793005711001974"
"Time-series forecasting using manifold learning, radial basis function interpolation, and geometric harmonics","","Papaioannou, Panagiotis G; Talmon Ronen; Kevrekidis, Ioannis G; Siettos Constantinos","Chaos","Scholarly Journals","","32","8","2022-08-01","Aug 2022","","","","1054-1500","","","ENG","We address a three-tier numerical framework based on nonlinear manifold learning for the forecasting of high-dimensional time series, relaxing the “curse of dimensionality” related to the training phase of surrogate/machine learning models. At the first step, we embed the high-dimensional time series into a reduced low-dimensional space using nonlinear manifold learning (local linear embedding and parsimonious diffusion maps). Then, we construct reduced-order surrogate models on the manifold (here, for our illustrations, we used multivariate autoregressive and Gaussian process regression models) to forecast the embedded dynamics. Finally, we solve the pre-image problem, thus lifting the embedded time series back to the original high-dimensional space using radial basis function interpolation and geometric harmonics. The proposed numerical data-driven scheme can also be applied as a reduced-order model procedure for the numerical solution/propagation of the (transient) dynamics of partial differential equations (PDEs). We assess the performance of the proposed scheme via three different families of problems: (a) the forecasting of synthetic time series generated by three simplistic linear and weakly nonlinear stochastic models resembling electroencephalography signals, (b) the prediction/propagation of the solution profiles of a linear parabolic PDE and the Brusselator model (a set of two nonlinear parabolic PDEs), and (c) the forecasting of a real-world data set containing daily time series of ten key foreign exchange rates spanning the time period 3 September 2001–29 October 2020.","https://www.proquest.com/docview/2700121309?accountid=12870&bdid=83737&_bd=Rq63nXHwkro3WoWZvCOkYByBmV8%3D",""
"The roles of liquidity and delay in financial markets based on an optimal forecasting model","","Guo-Hui, Yang; Si-Qi, Ma; Xiao-Dong, Bian; Jiang-Cheng, Li","PLoS One","Scholarly Journals","","18","9","2023-09-01","Sep 2023","e0290869","","","19326203","","","ENG","We investigate the roles of liquidity and delay in financial markets through our proposed optimal forecasting model. The efficiency and liquidity of the financial market are examined using stochastic models that incorporate information delay. Based on machine learning, we estimate the in-sample and out-of-sample forecasting price performances of the six proposed methods using the likelihood function and Bayesian methods, and the out-of-sample prediction performance is compared with the benchmark model ARIMA-GARCH. We discover that the forecasting price performance of the proposed simplified delay stochastic model is superior to that of the benchmark methods by the test methods of a variety of loss function, superior predictive ability test (SPA), Akaike information criterion (AIC), and Bayesian information criterion (BIC). Using data from the Chinese stock market, the best forecasting model assesses the efficiency and liquidity of the financial market while accounting for information delay and trade probability. The rise in trade probability and delay time affects the stability of the return distribution and raises the risk, according to stochastic simulation. The empirical findings show that empirical and best forecasting approaches are compatible, that company size and liquidity (delay time) have an inverse relationship, and that delay time and liquidity have a nonlinear relationship. The most efficient have optimal liquidity.","https://www.proquest.com/docview/2859970572?accountid=12870&bdid=83737&_bd=iRAiEWVlNl31cBIUavbctgD4g38%3D","https://doi.org/10.1371/journal.pone.0290869"
"Nonparametric Bayesian Models for Learning Network Coupling Relationships","","Fan, Xuhui","PQDT - Global","Dissertations & Theses","","","","2015-01-01","2015","","","","","","9798382067292","ENG","As the traditional machine learning setting assumes that the data are identically and independently distributed (i.i.d), this is quite like a perfect conditioned vacuum and seldom a real case in practical applications. Thus, the non-i.i.d learning (Cao, Ou, Yu & Wei 2010)(Cao, Ou & Yu 2012)(Cao 2014) has emerged as a powerful tool in describing the fundamental phenomena in the real world, as more factors to be well catered in this modelling. One critical factor in the non-i.i.d. learning is the relations among the data, ranging from the feature information, node partitioning to the correlation of the outcome, which is referred to as the coupling relation in the non-i.i.d. learning. In our work, we aim at uncovering this coupling relation with the nonparametric Bayesian relational models, that is, the data points in our work are supposed to be coupled with each other, and it is this coupling relation we are interested in for further investigation. The coupling relation is widely seen and motivated in real world applications, for example, the hidden structure learning in social networks for link prediction and structure understanding, the fraud detection in the transactional stock market, the protein interaction modelling in biology.In this thesis, we are particularly interested in the learning and inferencing on the relational data, which is to further discover the coupling relation between the corresponding points. For the detail modelling perspective, we have focused on the framework of mixed-membership stochastic blockmodel, in which membership indicator and mixed-membership distributionare noted to represent the nodes’ belonging community for one relation and the histogram of all the belonging communities for one node. More specifically, we are trying to model the coupling relation through three different aspects: 1) the mixed-membership distributions’ coupling relation across the time. In this work, the coupling relation is reflected in the sticky phenomenon between the mixed-membership distributions in two consecutive time; 2) the membership indicators’ coupling relation, in which the Copula function is utilized to depict the coupling relation; 3) the node information and mixed-membership distribution’s coupling relation. This is achieved by the new proposal transform for the node information’s integration. As these three aspects describe the critical parts of the nodes’ interaction with the communities, we are hoping the complex hidden structures can thus be well studied.In all of the above extensions, we set the number of the communities in a nonparametric Bayesian prior (mainly Hierarchical Dirichlet Process), instead of fixing it as in the previous classical models. In such a way, the complexity of our model can grow along with the data size. That is to say, while we have more data, our model can have a larger amount of communities to account for them. This appealing property enables our models to fit the data better. Moreover, the nice formalization of the Hierarchical Dirichlet Process facilitates us to some benefits, such as the conjugate prior. Thus, this nonparametric Bayesian prior has introduced new elements to the coupling relations’ learning.Under this varying backgrounds and scenarios, we have shown our proposed models and frameworks for learning the coupling relations are evidenced to outperform the state-of-the-art methods via literature explanation and empirical results. The outcomes are sequentially accepted by top journals. Therefore, the nonparametric Bayesian models in learning the coupling relations presents high research value and would still be attractive opportunities for further exploration and exploit.","https://www.proquest.com/docview/3039731158?accountid=12870&bdid=83737&_bd=PVfzzfXr4sio%2BRUbc5UXC22GhDI%3D",""
"Combining Deep Learning and Multiresolution Analysis for Stock Market Forecasting","","Althelaya, Khaled A; Mohammed, Salahadin A; El-Alfy, El-Sayed M","IEEE Access","Scholarly Journals","","9","","2021-01-01","2021","13099","","13099-13111","21693536","","","ENG","Due to its complexity, financial time-series forecasting is regarded as one of the most challenging problems. During the past two decades, nonlinear modeling techniques, such as artificial neural networks, were commonly employed to solve a variety of time-series problems. Recently, however, deep neural network has been found to be more efficient than those in many application domains. In this article, we propose a model based on deep neural networks that improves the forecasting of stock prices. We investigate the impact of combining deep learning techniques with multiresolution analysis to improve the forecasting accuracy. Our proposed model is based on an empirical wavelet transform which is shown to outperform traditional stationary wavelet transform in capturing price fluctuations at different time scales. The proposed model is demonstrated to be substantially more effective than other models when evaluated on the S&P500 stock index and Mackey-Glass time series.","https://www.proquest.com/docview/2480866447?accountid=12870&bdid=83737&_bd=kyrPWMDlpBKVpJbE9HLkFWzEFXY%3D","https://doi.org/10.1109/ACCESS.2021.3051872"
"Time series modelling, NARX neural network and hybrid KPCA–SVR approach to forecast the foreign exchange market in Mauritius","","Lydie Myriam Marcelle Amelot; Agathee, Ushad Subadar; Sunecher, Yuvraj","African Journal of Economic and Management Studies","Scholarly Journals","","12","1","2021-01-01","2021","18","54","18-54","20400705","","","ENG","PurposeThis study constructs time series model, artificial neural networks (ANNs) and statistical topologies to examine the volatility and forecast foreign exchange rates. The Mauritian forex market has been utilized as a case study, and daily data for nominal spot rate (during a time period of five years spanning from 2014 to 2018) for EUR/MUR, GBP/MUR, CAD/MUR and AUD/MUR have been applied for the predictions.Design/methodology/approachAutoregressive integrated moving average (ARIMA) and generalized autoregressive conditional heteroskedasticity (GARCH) models are used as a basis for time series modelling for the analysis, along with the non-linear autoregressive network with exogenous inputs (NARX) neural network backpropagation algorithm utilizing different training functions, namely, Levenberg–Marquardt (LM), Bayesian regularization and scaled conjugate gradient (SCG) algorithms. The study also features a hybrid kernel principal component analysis (KPCA) using the support vector regression (SVR) algorithm as an additional statistical tool to conduct financial market forecasting modelling. Mean squared error (MSE) and root mean square error (RMSE) are employed as indicators for the performance of the models.FindingsThe results demonstrated that the GARCH model performed better in terms of volatility clustering and prediction compared to the ARIMA model. On the other hand, the NARX model indicated that LM and Bayesian regularization training algorithms are the most appropriate method of forecasting the different currency exchange rates as the MSE and RMSE seemed to be the lowest error compared to the other training functions. Meanwhile, the results reported that NARX and KPCA–SVR topologies outperformed the linear time series models due to the theory based on the structural risk minimization principle. Finally, the comparison between the NARX model and KPCA–SVR illustrated that the NARX model outperformed the statistical prediction model. Overall, the study deduced that the NARX topology achieves better prediction performance results compared to time series and statistical parameters.Research limitations/implicationsThe foreign exchange market is considered to be instable owing to uncertainties in the economic environment of any country and thus, accurate forecasting of foreign exchange rates is crucial for any foreign exchange activity. The study has an important economic implication as it will help researchers, investors, traders, speculators and financial analysts, users of financial news in banking and financial institutions, money changers, non-banking financial companies and stock exchange institutions in Mauritius to take investment decisions in terms of international portfolios. Moreover, currency rates instability might raise transaction costs and diminish the returns in terms of international trade. Exchange rate volatility raises the need to implement a highly organized risk management measures so as to disclose future trend and movement of the foreign currencies which could act as an essential guidance for foreign exchange participants. By this way, they will be more alert before conducting any forex transactions including hedging, asset pricing or any speculation activity, take corrective actions, thus preventing them from making any potential losses in the future and gain more profit.Originality/valueThis is one of the first studies applying artificial intelligence (AI) while making use of time series modelling, the NARX neural network backpropagation algorithm and hybrid KPCA–SVR to predict forex using multiple currencies in the foreign exchange market in Mauritius.","https://www.proquest.com/docview/2534608615?accountid=12870&bdid=83737&_bd=gew7ovIrEnzUgzUv226uDuMOzsc%3D","https://doi.org/10.1108/AJEMS-04-2019-0161"
"A Hybrid Model Using PCA and BP Neural Network for Time Series Prediction in Chinese Stock Market with TOPSIS Analysis","","Hang, Lei; Liu, Dandan; Xie, Fusheng","Scientific Programming","Scholarly Journals","","2023","","2023-01-01","2023","","","","1058-9244","1875-919X","","ENG","The stock price changes rapidly and is highly nonlinear in the financial market. One of the common concerns of many scholars and investors is how to accurately predict the stock price and the trend of rising and falling in a short time. Machine learning and deep learning techniques have found their place in financial institutions thanks to the ability of time series data prediction with high precision. However, the prediction accuracy of these models is still far from satisfactory. Most existing studies use original, single prediction algorithms that cannot overcome inherent limitations. This study proposes a hybrid model using principal component analysis (PCA) and backpropagation (BP) neural networks. The historical records of China Merchants Bank are used for data collection from 2015 to 2021. PCA preprocesses the original data to reduce the dimensionality and is then adopted by the BP neural network to predict the stock closing price of China Merchants Bank. We compare and analyze the PCA–BP model with three training algorithms, and the results indicate that the Bayesian regularization algorithm performs best. Besides, we perform the stock prediction using a traditional exponential smoothing approach. The experiment results show that the predicted stock closing price is close to the actual value, and the mean absolute percentage error can reach 0.0130, which is more significant than the traditional approach. Furthermore, A TOPSIS approach is utilized to evaluate the robustness of the proposed model. Finally, we demonstrate the usability of the designed hybrid model by predicting the stock price of another selected stock.","https://www.proquest.com/docview/2834810573?accountid=12870&bdid=83737&_bd=Fj%2FWbWk6QZmTqGYoqgxJmMLasFw%3D","https://doi.org/10.1155/2023/9963940"
"Predicting stock price of construction companies using weighted ensemble learning","","Song, Xinyuan","Heliyon","Undefined","","10","11","2024-06-15","Jun 15, 2024","e31604","","e31604","2405-8440","2405-8440","","ENG","Modeling the behavior of stock price data has always been one of the challenging applications of Artificial Intelligence (AI) and Machine Learning (ML) due to its high complexity and dependence on various conditions. Recent studies show that this will be difficult to do with just one learning model. The problem can be more complex for companies in the construction sector, due to the dependency of their behavior on more conditions. This study aims to provide a hybrid model for improving the accuracy of prediction for the stock price index of companies in the construction section. The contribution of this paper can be considered as follows: First, a combination of several prediction models is used to predict stock prices so that learning models can cover each other's errors. In this research, an ensemble model based on Artificial Neural Network (ANN), Gaussian Process Regression (GPR), and Classification and Regression Tree (CART) is presented for predicting the stock price index. Second, the optimization technique is used to determine the effect of each learning model on the prediction result. For this purpose, first, all three mentioned algorithms process the data simultaneously and perform the prediction operation. Then, using the Cuckoo Search (CS) algorithm, the output weight of each algorithm is determined as a coefficient. Finally, using the ensemble technique, these results are combined and the final output is generated through weighted averaging on optimal coefficients. The proposed system was implemented, and its efficiency was evaluated by real stock data of construction companies. The results showed that using CS optimization in the proposed ensemble system is highly effective in reducing prediction error. According to the results, the proposed system can predict the price index with an average accuracy of 96.6 %, which shows a reduction of at least 2.4 % in prediction error compared to the previous methods. Comparing the evaluation results of the proposed system with similar algorithms indicates that our model is more accurate and can be useful for predicting the stock price index in real-world scenarios.Modeling the behavior of stock price data has always been one of the challenging applications of Artificial Intelligence (AI) and Machine Learning (ML) due to its high complexity and dependence on various conditions. Recent studies show that this will be difficult to do with just one learning model. The problem can be more complex for companies in the construction sector, due to the dependency of their behavior on more conditions. This study aims to provide a hybrid model for improving the accuracy of prediction for the stock price index of companies in the construction section. The contribution of this paper can be considered as follows: First, a combination of several prediction models is used to predict stock prices so that learning models can cover each other's errors. In this research, an ensemble model based on Artificial Neural Network (ANN), Gaussian Process Regression (GPR), and Classification and Regression Tree (CART) is presented for predicting the stock price index. Second, the optimization technique is used to determine the effect of each learning model on the prediction result. For this purpose, first, all three mentioned algorithms process the data simultaneously and perform the prediction operation. Then, using the Cuckoo Search (CS) algorithm, the output weight of each algorithm is determined as a coefficient. Finally, using the ensemble technique, these results are combined and the final output is generated through weighted averaging on optimal coefficients. The proposed system was implemented, and its efficiency was evaluated by real stock data of construction companies. The results showed that using CS optimization in the proposed ensemble system is highly effective in reducing prediction error. According to the results, the proposed system can predict the price index with an average accuracy of 96.6 %, which shows a reduction of at least 2.4 % in prediction error compared to the previous methods. Comparing the evaluation results of the proposed system with similar algorithms indicates that our model is more accurate and can be useful for predicting the stock price index in real-world scenarios.","https://www.proquest.com/docview/3067915731?accountid=12870&bdid=83737&_bd=HQ%2B3LBT5o5MevmoP%2BSQjIrVgntQ%3D","https://doi.org/10.1016/j.heliyon.2024.e31604"
"A Machine Learning Model for Healthcare Stocks Forecasting in the US Stock Market during COVID-19 Period","","Jariyapan, Prapatchon; Singvejsakul, Jittima; Chaiboonsri, Chukiat","Journal of Physics: Conference Series","Scholarly Journals","","2287","1","2022-06-01","Jun 2022","012018","","","17426588","","","ENG","This paper study the nowcasting and forecasting for the healthcare stock price in the united states during the Covid-19 period including the google trend data information. The data is collected in monthly data from 2015 to 2020 which are five interested stock price indexes in the healthcare sector. Empirically, the finding reveals that the Bayesian structural time series analysis can be used to investigate the stock price indexes with the google trend data is becoming useful for the prediction in term of current movement. In term of the machine learning algorithms, the unsupervised learning k-Mean algorithm is employed to cluster the cycle regimes of the stock market which provided three regimes such as Bull market, Sideways and Bear market. There are twenty-nine months stand for bull market, thirty-seven months are predictively provided sideways market and five months are referred as the bear market. Additionally, the supervised learning algorithms by using the Linear Discriminant Analysis (LDA), k-Nearest Neighbors (kNN) and Support vector machine (SVM) are used to investigate the cycle regimes of healthcare stock in next five year. The results indicated that LDA is chosen by the highest coefficient validation which represented the the regimes of stock in the healcare sector of the unites states of America will stay on the sideways periods in the next five years. Thus, the finding in this paper can be the useful information for investor to manage their portfolio especially, in healthcare sector during the Covid-19 period.","https://www.proquest.com/docview/2684604819?accountid=12870&bdid=83737&_bd=iG8QBKfdmMNk882jwJ2x643LPJo%3D","https://doi.org/10.1088/1742-6596/2287/1/012018"
"Bayesian Aggregation Improves Traditional Single-Image Crop Classification Approaches","","Matvienko, Ivan; Gasanov, Mikhail; Gasanov, Mikhail; Petrovskaia, Anna; Kuznetsov, Maxim; Raghavendra, Jana; Pukalchik, Maria; Oseledets, Ivan","Sensors","Scholarly Journals","","22","22","2022-01-01","2022","8600","","","14248220","","","ENG","Accurate information about growing crops allows for regulating the internal stocks of agricultural products and drawing strategies for negotiating agricultural commodities on financial markets. Machine learning methods are widely implemented for crop type recognition and classification based on satellite images. However, field classification is complicated by class imbalance and aggregation of pixel-wise into field-wise forecasting. We propose here a Bayesian methodology for the aggregation of classification results. We report the comparison of class balancing techniques. We also report the comparison of classical machine learning methods and the U-Net convolutional neural network for classifying crops using a single satellite image. The best result for single-satellite-image crop classification was achieved with an overall accuracy of 77.4% and a Macro F1-score of 0.66. Bayesian aggregation for field-wise classification improved the result obtained using majority voting aggregation by 1.5%. We demonstrate here that the Bayesian aggregation approach outperforms the majority voting and averaging strategy in overall accuracy for the single-image crop classification task.","https://www.proquest.com/docview/2739457293?accountid=12870&bdid=83737&_bd=VDALSs7M%2BJmB%2FSnKt1uEuU4TY1k%3D","https://doi.org/10.3390/s22228600"
"Predicting Market Impact Costs Using Nonparametric Machine Learning Models","","Park, Saerom; Lee, Jaewook; Son, Youngdoo","PLoS One","Scholarly Journals","","11","2","2016-02-01","Feb 2016","e0150243","","","19326203","","","ENG","Market impact cost is the most significant portion of implicit transaction costs that can reduce the overall transaction cost, although it cannot be measured directly. In this paper, we employed the state-of-the-art nonparametric machine learning models: neural networks, Bayesian neural network, Gaussian process, and support vector regression, to predict market impact cost accurately and to provide the predictive model that is versatile in the number of variables. We collected a large amount of real single transaction data of US stock market from Bloomberg Terminal and generated three independent input variables. As a result, most nonparametric machine learning models outperformed a-state-of-the-art benchmark parametric model such as I-star model in four error measures. Although these models encounter certain difficulties in separating the permanent and temporary cost directly, nonparametric machine learning models can be good alternatives in reducing transaction costs by considerably improving in prediction performance.","https://www.proquest.com/docview/1768879472?accountid=12870&bdid=83737&_bd=MSFRrCVUga7Nx6tzQc4scMOsRXs%3D","https://doi.org/10.1371/journal.pone.0150243"
"Machine Learning Predictions of Housing Market Synchronization across US States: The Role of Uncertainty","","Gupta Rangan; Marfatia, Hardik A; Pierdzioch, Christian; Salisu, Afees A","Journal of Real Estate Finance and Economics","Scholarly Journals","","64","4","2022-05-01","May 2022","523","545","523-545","08955638","","","ENG","We analyze the role of macroeconomic uncertainty in predicting synchronization in housing price movements across all the United States (US) states plus District of Columbia (DC). We first use a Bayesian dynamic factor model to decompose the house price movements into a national, four regional (Northeast, South, Midwest, and West), and state-specific factors. We then study the ability of macroeconomic uncertainty in forecasting the comovements in housing prices, by controlling for a wide-array of predictors, such as factors derived from a large macroeconomic dataset, oil shocks, and financial market-related uncertainties. To accommodate for multiple predictors and nonlinearities, we take a machine learning approach of random forests. Our results provide strong evidence of forecastability of the national house price factor based on the information content of macroeconomic uncertainties over and above the other predictors. This result also carries over, albeit by a varying degree, to the factors associated with the four census regions, and the overall house price growth of the US economy. Moreover, macroeconomic uncertainty is found to have predictive content for (stochastic) volatility of the national factor and aggregate US house price. Our results have important implications for policymakers and investors.","https://www.proquest.com/docview/2645694887?accountid=12870&bdid=83737&_bd=q7cyTGqfqw1M%2FtG0Kd1d2Sp9GVM%3D","https://doi.org/10.1007/s11146-020-09813-1"
"DeepVaR: a framework for portfolio risk assessment leveraging probabilistic deep neural networks.","","Fatouros, Georgios; Makridis, Georgios; Kotios, Dimitrios; Soldatos, John; Filippakis, Michael; Kyriazis, Dimosthenis","Digital finance","Undefined","","5","1","2023-01-01","2023","29","56","29-56","","2524-6186","","ENG","Determining and minimizing risk exposure pose one of the biggest challenges in the financial industry as an environment with multiple factors that affect (non-)identified risks and the corresponding decisions. Various estimation metrics are utilized towards robust and efficient risk management frameworks, with the most prevalent among them being the Value at Risk (VaR). VaR is a valuable risk-assessment approach, which offers traders, investors, and financial institutions information regarding risk estimations and potential investment insights. VaR has been adopted by the financial industry for decades, but the generated predictions lack efficiency in times of economic turmoil such as the 2008 global financial crisis and the COVID-19 pandemic, which in turn affects the respective decisions. To address this challenge, a variety of well-established variations of VaR models are exploited by the financial community, including data-driven and data analytics models. In this context, this paper introduces a probabilistic deep learning approach, leveraging time-series forecasting techniques with high potential of monitoring the risk of a given portfolio in a quite efficient way. The proposed approach has been evaluated and compared to the most prominent methods of VaR calculation, yielding promising results for VaR 99% for forex-based portfolios.Supplementary InformationThe online version contains supplementary material available at 10.1007/s42521-022-00050-0.","https://www.proquest.com/docview/2652029743?accountid=12870&bdid=83737&_bd=gQyM%2FKXyrHG5SJPb2aWxCcUi5MY%3D","https://doi.org/10.1007/s42521-022-00050-0"
"Forecasting State Tax Revenues, Recessions and Their Uncertainties Using Mixed-Frequency Data, Model Averaging, Bootstrap, ROC Analysis and Machine Learning","","Yang, Cheng","ProQuest Dissertations and Theses","Dissertations & Theses","","","","2020-01-01","2020","","","","","","9798664751994","ENG","In recent years models with mixed frequency have been extensively used to forecast low-frequency variables such as GDP and inflation, but we are one of the first to use this framework in state government revenue forecasting. New York State had a record of passing late budgets before. In order to facilitate budget negotiations, which often center on forecasts, we develop a Mixed-Data Sampling (MIDAS) model for revenue forecasting using jagged edge data sets in the first chapter. We forecast yearly tax revenues using monthly data on tax receipts and also two dynamic factors extracted from a set of selected monthly and quarterly indicators specific to the New York State and the U.S. economy separately. These three models are combined with optimal weights to generate monthly multi-period forecasts. The weights of the two dynamic factors are high at horizons more than 11 months, after which the monthly tax revenue variable picks up in its contribution as uncertainty is resolved. By combining we gain forecast efficiency at all horizons. Our sample covers fiscal years 1986–2020; and data till FY 2007 is used in estimation to generate and evaluate out-of-sample forecasts over FY 2008–2020. To coincide with the budget process, our forecasts start 18 months, and are continuously updated monthly till the end of the fiscal year. Our model allows for identification of reasons for forecast revisions as new information arrives on a monthly basis in a transparent manner. We document significant gains in forecast accuracy. The relative gain in forecasting efficiency is particularly significant during the cyclical downturns, including COVID-19 in 2020. Counterfactual analysis is implemented to study the marginal contribution of data at each horizon. We estimate the variances of combined out-of-sample forecasts with blocking-based residual bootstrap methodology. With the variance estimates, we provide fan charts for each fixed target fiscal year showing the underlying forecast uncertainty.In the second chapter, we study the role of the components of Conference Board Leading Economic Indicator (LEI). LEI has ten monthly variables. Out of the ten variables, S&P 500 stock price index, Initial Claims and Interest Rate Spread can be observed at frequencies higher than monthly. We explore if there are further improvements when the three variables are used in terms of higher frequencies. In our analysis, MIDAS regression is integrated with probit model (Probit-MIDAS). We find data at higher frequencies can perform at least as well as data at monthly frequency. Even if forecasts from high-frequency data do not outperform their monthly counterparts significantly, the high-frequency data still have timing advantages at some particular horizons as the recession forecasts are updated daily or weekly. Finally, we also find efficiency gain from the probability forecast combination in terms of receiver operating characteristic (ROC) curves.Even though many studies have established the existence of structural breaks and declining predictability in the relationship between GDP growth and yield spreads, business analysts continue to watch for the inversion of the spread as a leading indicator for recessions. In the third chapter, we reestablish the enduring power of spread to forecast recessions, notwithstanding the temporal instabilities. We use daily data on 10-year minus 3-month Treasury rates and other spreads to find the threshold value that produces the highest discriminatory power as measured by the ROC curve, and its functionals such as the hit rate, false alarm rate, area under the curve (AUC), and the Youden's index. Based on data from January 2, 1962 to July 16, 2020, we find that the threshold value has slowly drifted upwards from zero since the recessions of 1980, and was at 0.89% for 12-month-ahead forecasts as the recession of 2020 approached. Once the threshold is adjusted to its optimal value recursively in real time, the type I and II errors associated with each 10-month ahead forecasts for the six recent recessions remained unchanged around 80% hit rate accompanied by a false alarm rate of 20%. To account for the sampling variability, we use a circular block bootstrap procedure to construct the confidence intervals for these statistics. We also studied a modified interest rate spread where the 10-year rate was replaced by its near-term historical minimum value (Iqbal et al. 2019). It produced slightly better ROC curves, but the qualitative results remained the same.In the fourth chapter, we forecast New York State tax revenues with mixed-frequency data using newly evolving machine learning techniques. We experiment different options such as boosting, LASSO, sparse-group LASSO and a few other options. State tax revenues can be affected by recession, which is a rare event without large size of data for training. Thus we suggest boosting with restricted lags of macro variables as our final model. The role of monthly or quarterly data releases in annual state tax revenues is discussed by studying variables/lags selected by boosting. Forecast after COVID-19 in 2020 shows a negative tax revenue growth in the next fiscal year.","https://www.proquest.com/docview/2444888413?accountid=12870&bdid=83737&_bd=VXEXYruGxYwKswhp7zrV6h2ruC8%3D",""
"Forecasting Stock Market Indices using Machine Learning Algorithms","","Žmuk, Berislav; Jošić, Hrvoje","Interdisciplinary Description of Complex Systems","Scholarly Journals","","18","4","2020-01-01","2020","471","","471-489","13344684","","","ENG","In recent years machine learning algorithms have become a very popular tool for analysing financial data and forecasting stock prices. The goal of this article is to forecast five major stock market indexes (DAX, Dow Jones, NASDAQ, Nikkei 225 and S&P 500) using machine learning algorithms (Linear regression, Gaussian Processes, SMOreg and neural network Multilayer Perceptron) on historical data covering the period February 1, 2010, to January 31, 2020. The forecasts were made by using historical data in different base period lengths and forecasting horizons. The precision of machine learning algorithms was evaluated with the help of error metrics. The results of the analysis have shown that machine learning algorithms achieved highly accurate forecasting performance. The overall precision of all algorithms was better for shorter base period lengths and forecast horizons. The results obtained from this analysis could help investors in determining their optimal investment strategy. Stock price prediction remains, however, one of the most complex issues in the field of finance.","https://www.proquest.com/docview/2465700149?accountid=12870&bdid=83737&_bd=PjD3wERtBOeicuXbOLkeHoaauxg%3D","https://doi.org/10.7906/indecs.18.4.7"
"The Influence of Cognitive Biases and Financial Factors on Forecast Accuracy of Analysts.","","Nardi, Paula Carolina Ciampaglia; Ribeiro, Evandro Marcos Saidel; Bueno, José Lino Oliveira; Aggarwal, Ishani","Frontiers in psychology","Undefined","","12","","2021-01-01","2021","773894","773894","773894","1664-1078","1664-1078","","ENG","The objective of this study was to jointly analyze the importance of cognitive and financial factors in the accuracy of profit forecasting by analysts. Data from publicly traded Brazilian companies in 2019 were obtained. We used text analysis to assess the cognitive biases from the qualitative reports of analysts. Further, we analyzed the data using statistical regression learning methods and statistical classification learning methods, such as Multiple Linear Regression (MRL), k-dependence Bayesian (k-DB), and Random Forest (RF). The Bayesian inference and classification methods allow an expansion of the research line, especially in the area of machine learning, which can benefit from the examples of factors addressed in this research. The results indicated that, among cognitive biases, optimism had a negative relationship with forecasting accuracy while anchoring bias had a positive relationship. Commonality, to a lesser extent, also had a positive relationship with the analyst's accuracy. Among financial factors, the most important aspects in the accuracy of analysts were volatility, indebtedness, and profitability. Age of the company, fair value, American Depositary Receipts (ADRs), performance, and loss were still important but on a smaller scale. The results of the RF models showed a greater explanatory power. This research sheds light on the cognitive as well as financial aspects that influence the analyst's accuracy, jointly using text analysis and machine learning methods, capable of improving the explanatory power of predictive models, together with the use of training models followed by testing.","https://www.proquest.com/docview/2622278828?accountid=12870&bdid=83737&_bd=BYYviO7ia5tVVWKqJBVvEH605sE%3D","https://doi.org/10.3389/fpsyg.2021.773894"
"Forecasting the Stock Price of Listed Innovative SMEs Using Machine Learning Methods Based on Bayesian optimization: Evidence from China","","Liu, Wei; Suzuki, Yoshihisa; Du, Shuyi","Computational Economics","Scholarly Journals","","63","5","2024-05-01","May 2024","2035","2068","2035-2068","09277099","","","ENG","Innovative SMEs have had an important impact on the economies of emerging countries in recent years. In particular, the volatility of their share prices is closely related to economic development and investor behaviors. Therefore, this study takes the Chinese market as an example, after constructing 34 determinants that affect the stock price, the RF, DNN, GBDT, and Adaboost models under Bayesian optimization are employed to forecast the next day's closing price of listed innovative SMEs. The number of samples is 78,708 from 337 SMEs listed on the Chinese SSE STAR market, from July 22, 2019, to September 10, 2021 period. The experimental results show the RF and DNN models perform at a better prediction level than the GBDT and Adaboost models, in terms of the evaluation indicators of R2, RMSE, MAPE, and DA. Then K-fold method and t-tests as robustness checks ensure our experimental results are more reliable and robust.","https://www.proquest.com/docview/3065136947?accountid=12870&bdid=83737&_bd=bvj0TxqkFBMoLt9Vg%2BV%2Bh0bh3dQ%3D","https://doi.org/10.1007/s10614-023-10393-4"
"Cryptocurrency price prediction using traditional statistical and machine‐learning techniques: A survey","","Khedr, Ahmed M; Ifra Arif; Pravija, Raj P, V; Magdi El‐Bannany; Alhashmi, Saadat M; Sreedharan, Meenu","Intelligent Systems in Accounting, Finance and Management","Scholarly Journals","","28","1","2021-01-01","Jan/Mar 2021","3","34","3-34","15501949","","","ENG","Cryptocurrencies are decentralized electronic counterparts of government‐issued money. The first and best‐known cryptocurrency example is bitcoin. Cryptocurrencies are used to make transactions anonymously and securely over the internet. The decentralization behavior of a cryptocurrency has radically reduced central control over them, thereby influencing international trade and relations. Wide fluctuations in cryptocurrency prices motivate the urgent requirement for an accurate model to predict its price. Cryptocurrency price prediction is one of the trending areas among researchers. Research work in this field uses traditional statistical and machine‐learning techniques, such as Bayesian regression, logistic regression, linear regression, support vector machine, artificial neural network, deep learning, and reinforcement learning. No seasonal effects exist in cryptocurrency, making it hard to predict using a statistical approach. Traditional statistical methods, although simple to implement and interpret, require a lot of statistical assumptions that could be unrealistic, leaving machine learning as the best technology in this field, being capable of predicting price based on experience. This article provides a comprehensive summary of the previous studies in the field of cryptocurrency price prediction from 2010 to 2020. The discussion presented in this article will help researchers to fill the gap in existing studies and gain more future insight.","https://www.proquest.com/docview/2509281736?accountid=12870&bdid=83737&_bd=Vh%2BaxuzCltKw2L0zX2HUB2x%2B9WA%3D","https://doi.org/10.1002/isaf.1488"
"Multivariate Financial Time-Series Prediction With Certified Robustness","","Li, Hui; Cui, Yunpeng; Wang, Shuo; Liu, Juan; Qin, Jinyuan; Yang, Yilin","IEEE Access","Scholarly Journals","","8","","2020-01-01","2020","109133","","109133-109143","21693536","","","ENG","The futures market’s forecasts are significant to investors and policymakers, where the application of deep learning approaches to finance has received a great deal of attention. In this study, we propose a multivariate financial time-series forecasting method. Our model addresses the long- and short-term features, multimodal and non-stationarity nature of multivariate time-series by incorporating the improved deep neural networks and certified noise injection. Specifically, multimodal variational autoencoder is used to extract deep high-level features of multivariate time-series, Long- and Short- Term recurrent neural network is applied for multivariate time-series forecasting, and certified noise injection mechanism, inspired by differential privacy, is proposed to improve the robustness and accuracy of prediction. Extensive empirical results on real-world agricultural commodity futures price time series and relevant external data demonstrate that our model achieves better performance over that of several state-of-the-art baseline methods.","https://www.proquest.com/docview/2454444493?accountid=12870&bdid=83737&_bd=azujYpylBQeUJW0gVjdgm1QWhe4%3D","https://doi.org/10.1109/ACCESS.2020.3001287"
"Forecasting Bitcoin Prices Using Deep Learning for Consumer-Centric Industrial Applications","","Roy, Pradeep Kumar; Kumar, Abhinav; Singh, Ashish; Sangaiah, Arun Kumar","IEEE Transactions on Consumer Electronics","Scholarly Journals","","70","1","2024-01-01","2024","1351","","1351-1358","00983063","","","ENG","As cryptocurrencies become more popular as investment vehicles, bitcoin draws interest from businesses, consumers, and computer scientists all across the world. Bitcoin is a computer file stored in digital wallet applications where each transaction is secured using strong cryptographic algorithms. It was challenging to forecast the future price of bitcoin due to its nonlinearity and extreme volatility. Several recent classic parametric models have been found with limited accuracy. To address the limitations and fill the existing research gaps, there is a need for a good prediction model which will provide the desired accuracy in the case of uncertainty and dynamism. This research suggested a deep learning-based framework for predicting and forecasting Bitcoin price. The research will be helpful for worldwide consumers and industries to take their decision on whether to invest or not. The research utilizes Yahoo! finance dataset for the period of 01-03-2016 to 26-02-2021 having 1828 samples. The experimental outcomes of the proposed Long Short-Term Memory (LSTM) model outperformed similar deep learning models by securing minimum loss and confirming that it can be used for future price prediction of the cryptocurrencies, which is helpful for the buyer to take their decision.","https://www.proquest.com/docview/3049492352?accountid=12870&bdid=83737&_bd=ULtEi%2FXxsKmNtAc8GpwQAJ29OZc%3D","https://doi.org/10.1109/TCE.2023.3321653"
"A Novel Deterministic Probabilistic Forecasting Framework for Gold Price with a New Pandemic Index Based on Quantile Regression Deep Learning and Multi-Objective Optimization","","Wang, Yan; Lin, Tong; Lin, Tong","Mathematics","Scholarly Journals","","12","1","2024-01-01","2024","29","","","22277390","","","ENG","The significance of precise gold price forecasting is accentuated by its financial attributes, mirroring global economic conditions, market uncertainties, and investor risk aversion. However, predicting the gold price is challenging due to its inherent volatility, influenced by multiple factors, such as COVID-19, financial crises, geopolitical issues, and fluctuations in other metals and energy prices. These complexities often lead to non-stationary time series, rendering traditional time series modeling methods inadequate. Our paper presents a multi-objective optimization algorithm that refines the interval prediction framework with quantile regression deep learning in response to this issue. This framework comprehensively responds to gold’s financial market dynamics and uncertainties with a screening process of various factors, including pandemic-related indices, geopolitical indices, the US dollar index, and prices of various commodities. The quantile regression deep-learning models optimized by multi-objective optimization algorithms deliver robust, interpretable, and highly accurate predictions for handling non-linear relationships and complex data structures and enhance the overall predictive performance. The results demonstrate that the QRBiLSTM model, optimized using the MOALO algorithm, delivers excellent forecasting performance. The composite indicator AIS reaches −15.6240 and −11.5581 at 90% and 95% confidence levels, respectively. This underscores the model’s high forecasting accuracy and its potential to provide valuable insights for assessing future trends in gold prices. The deterministic and probabilistic forecasting framework for gold prices captures the market dynamics with the new pandemic index and comprehensively sets a new benchmark for predictive modeling in volatile market commodities like gold.","https://www.proquest.com/docview/2912650144?accountid=12870&bdid=83737&_bd=p9S1XpSZHk32Me1VvPfvidFSNmw%3D","https://doi.org/10.3390/math12010029"
"Predicting Stock Market Indices Using Classification Tools","","Park, Minjae; Mi Lim Lee; Lee, Jinpyo","Asian Economic and Financial Review","Scholarly Journals","","9","2","2019-01-01","2019","243","","243-256","23052147","","","ENG","Increasing interest has been shown in the use of classifiers to extract informative patterns from time series data generated by monitoring financial phenomena. This paper investigates data mining and pattern recognition methods in forecasting the movement of the Standard & Poor?s 500 index. We use functional forms of varying classifiers to predict financial time series data and to evaluate the performance of different classifiers. By using the time series ARIMA model, we forecast the Standard & Poor?s 500 index. Additionally, with the AdaBoost algorithm and its extensions, we compare the classifying accuracy rates of bagging and boosting models with several classifiers, such as support vector machines, k-nearest neighbor, the probabilistic neural network, and the classification and regression tree. Results indicate that the boosting classifier with real AdaBoost (exponential loss) best forecast the Standard & Poor?s 500 index movements. This result should be relevant to firms that want to predict the stock prices.","https://www.proquest.com/docview/2249758891?accountid=12870&bdid=83737&_bd=rMXWzJUDPH2XZkMBLWpm2EStPI8%3D","https://doi.org/10.18488/journal.aefr.2019.92.243.256"
"Prediction and Statistical Inference in Feedback Loops","","Zrnic, Tijana","ProQuest Dissertations and Theses","Dissertations & Theses","","","","2023-01-01","2023","","","","","","9798380382243","ENG","Classical machine learning and statistics are built on the paradigm that there is a fixed quantity that we want to learn about a population, such as the best predictor of outcomes from features or the average effect of a treatment. In modern practices, however, predictions and inferences beget other predictions and inferences, causing the quantity of interest to change over time and drift away in a feedback loop. The feedback poses challenges for traditional methods, calling for new solutions. This thesis introduces new principles for prediction and inference in the presence of feedback loops.The first part focuses on performative prediction. Performative prediction formalizes the phenomenon that predictive models—by means of being used to make consequential downstream decisions—often influence the outcomes they aim to predict in the first place. For example, travel time estimates on navigation apps influence traffic patterns and thus realized travel times, stock price predictions influence trading activity and hence prices. We examine common heuristics such as retraining, as well as more refined optimization strategies for dealing with performative feedback. At the end of the first part, we identify important scenarios where the act of prediction triggers feedback loops that are not explained by the framework of performativity, and we develop theory to describe and study such feedback.The second part discusses principles for valid statistical inference, i.e., valid p-values and confidence intervals, in the presence of feedback. We consider two types of feedback: the first is due to data snooping, i.e., the practice of choosing which results to report only after seeing the data; the second arises when machine-learning systems are used to supply cheap predictions to augment or supplant high-quality data in future scientific analyses. In both cases, ignoring the feedback and naively applying classical statistical methods leads to inflated error rates and false discoveries; we provide alternative approaches that guarantee valid inferences in the face of feedback.","https://www.proquest.com/docview/2867910031?accountid=12870&bdid=83737&_bd=Qgl%2BWJi4%2F2ADVSKklTfoQ6rwMCA%3D",""
"Accurate Stock Price Forecasting Based on Deep Learning and Hierarchical Frequency Decomposition","","Li, Yi; Chen, Lei; Sun, Cuiping; Liu, Guoxu; Chen, Chunlei; Zhang, Yonghui","IEEE Access","Scholarly Journals","","12","","2024-01-01","2024","49878","","49878-49894","21693536","","","ENG","The stock market is playing an increasingly important role in the global economy. Accurate stock price forecasting not only aids the government in predicting economic trends but also helps investors anticipate higher expected returns. Nevertheless, hurdles such as nonlinearity, complexity and high volatility make it a daunting task to predict stock prices. To address this issue, this study proposes a new hybrid model, termed Hierarchical Decomposition-based Forecasting Model (HDFM), to decompose and forecast stock prices in a hierarchical fashion. The model utilizes complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) for the initial decomposition of stock price time series. To enhance the predictive efficiency, sub-series with similar sample entropy from the decomposition were combined using the K-means clustering method. Through a thorough analysis, it was found that the first combined sub-series contained more high-frequency signals. Therefore, the first combined sub-series is subjected to a second decomposition with variational mode decomposition (VMD). Subsequently, the gated recurrent unit (GRU) model was used to individually predict each sub-series. The final results were obtained by merging the prediction outcomes. The proposed model was evaluated on three different stock markets. The experimental results show that the proposed model outperforms other forecasting methods across all stock indices. Moreover, ablation studies demonstrated the effectiveness of each component within the proposed model.","https://www.proquest.com/docview/3035278500?accountid=12870&bdid=83737&_bd=06zdWPSJ25xeNnJmtLlMfiXLZaU%3D","https://doi.org/10.1109/ACCESS.2024.3384430"
"Learning Sentimental and Financial Signals With Normalizing Flows for Stock Movement Prediction","","Tai, Wenxin; Zhong, Ting; Mo, Yuhua; Zhou, Fan","IEEE Signal Processing Letters","Scholarly Journals","","29","","2022-01-01","2022","414","","414-418","10709908","","","ENG","Stockmovement prediction using Tweets (text) and historical price signals (time series) remains a challenging task due to the complex, noisy and dynamic nature of the stock market. The key to improve prediction performance is effectively capturing the complementarity between market sentiment signal from Tweets and time-series signal from the stock price. In this paper, we contribute a new solution StockNF by exploiting a deep generative model technique, Normalizing Flow (NF), to learn more flexible and expressive posterior distributions of latent variables of Tweets and price signals, which can largely ameliorate the bias inference problem in existing methods. We empirically evaluate the NF technique on a public stock movement prediction dataset and show that StockNF outperforms the state-of-the-art baselines.","https://www.proquest.com/docview/2623470644?accountid=12870&bdid=83737&_bd=WV8KYmBdkkx2bqjhNezjrL8eT10%3D","https://doi.org/10.1109/LSP.2021.3135793"
"Developing a Novel Hybrid Model Double Exponential Smoothing and Dual Attention Encoder-Decoder Based Bi-Directional Gated Recurrent Unit Enhanced With Bayesian Optimization to Forecast Stock Price","","Talabathula Jayanth; Manimaran, A","IEEE Access","Scholarly Journals","","12","","2024-01-01","2024","114760","","114760-114785","21693536","","","ENG","Financial market prediction has shown considerable potential in the past few years from the combination of contemporary Deep Learning (DL) techniques and traditional time series forecasting methodologies. To predict the stock prices of three distinct companies General Electric (GE), Microsoft (MSFT), and Amazon (AMZN) datasets. This study presents a novel hybrid model that combines the Double Exponential Smoothing (DES) method with a Deep Learning (DL) model Dual Attention Encoder-Decoder based Bi-directional GRU, optimized using Bayesian Optimization (DES-DA-ED-Bi-GRU-BO). By combining the best features of contemporary and old methods, the hybrid model seeks to efficiently identify patterns and trends in stock data. When handling time series data, the DES method offers a reliable and flexible mechanism that considers trends and seasonality in the data. The DA-ED-Bi-GRU added to the deep learning model further improves its comprehension of intricate patterns found in the stock data. The parameters are adjusted using Bayesian optimization (BO) to maximize the model’s performance. Several performance indicators, such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-Square ([Formula Omitted]), and Theil’s U-Statistics (TUS), are used to assess the effectiveness of the model. These measures offer thorough insights into the precision, dependability, and accuracy of the model’s predictions. The experimental findings show that the proposed hybrid model has the ability to predict GE, MSFT, and AMZN stock values with reasonable accuracy. Along with the optimization framework, DL and conventional smoothing approaches combine to provide a potent forecasting tool that may help traders and investors make wise judgments.","https://www.proquest.com/docview/3096382269?accountid=12870&bdid=83737&_bd=N4XUyZLYDyv4Y1Ey23%2FdTNDERWM%3D","https://doi.org/10.1109/ACCESS.2024.3435683"
"Probability rough set and portfolio optimization integrated three-way predication decisions approach to stock price","","Bai, Juncheng; Guo, Jianfeng; Sun, Bingzhen; Guo, Yuqi; Chen, Youwei; Xiao, Xia","Applied Intelligence","Scholarly Journals","","53","24","2023-12-01","Dec 2023","29918","29942","29918-29942","0924669X","","","ENG","In the stock market, accurate trend judgment and reasonable asset distribution are effective ways to obtain ideal return. However, the real stock market is affected by the objective economic environment, investors’ expected return and other potential factors, which makes the classical portfolio strategy face more challenges and pressures. How to build a reliable portfolio strategy in an uncertain environment will be a scientific problem worthy of in-depth discussion. To address this issue, this paper combines machine learning with rough set to establish a new rough set theory prediction model, quantitatively dividing the stock data into three categories and targetedly predicting the future trend according to the complexity. Based on the proposed prediction model, a new portfolio strategy is proposed by integrating the mean-variance model. Firstly, for reducing the volatility and noise of the original data of stock price, outlier processing (OP) and wavelet denoising (WD) are utilized. Secondly, for the sake of pertinently forecasting the future trend of different characteristic stock price, a three-way prediction (TWP) decisions approach is constructed based on multiscale permutation entropy (MPE), probabilistic rough set (PRS), variational modal decomposition (VMD) and deep learning. Finally, 20 stocks of Shanghai and Shenzhen stock exchanges are taken as research samples to verify the scientificity and rationality of the portfolio strategy. The results show that the proposed approach not only provides scientific support and reference for investors’ investment decisions, but also provides a new investment strategy theory and method for the investment decisions of the stock market.","https://www.proquest.com/docview/2907014383?accountid=12870&bdid=83737&_bd=61Ywry0YEbW0hfL%2BrRuaLLBLiK4%3D","https://doi.org/10.1007/s10489-023-05085-3"
"Probabilistic Life-Cycle Connectivity Assessment of Transportation Networks Using Deep Learning","","Jiyu Xin; Frangopol, Dan M; Akiyama, Mitsuyoshi; Xu, Han","Journal of Bridge Engineering","Scholarly Journals","","28","9","2023-09-01","Sep 2023","","","","1084-0702","","","ENG","Bridges and pavements are two major infrastructure components of a transportation network providing mobility of freight and commodities for economic vitality and access to a range of users as social benefits. However, the lack of a comprehensive infrastructure management system incorporating bridges and pavements inhibits accurate performance prediction, optimal maintenance actions, and the associated use of shrinking budgets. This paper presents an integrated probabilistic life-cycle connectivity framework for the performance analysis of transportation networks containing bridges and asphalt pavements by considering flexural and shear failure modes for prestressed concrete and steel bridges and four failure modes, including international roughness index, rut depth, alligator cracking, and transverse cracking, for asphalt pavements. In this framework, neural network–based deep learning models are used to assess the probabilistic performance of transportation networks and to provide guidance for the associated maintenance strategies. An existing transportation network consisting of bridges and asphalt pavement segments is selected to investigate its life-cycle connectivity reliability and component importance using the matrix-based system reliability method. Results show that the consideration of asphalt pavement failure probability has a significant effect on the probability of transportation network connectivity.","https://www.proquest.com/docview/2836121646?accountid=12870&bdid=83737&_bd=XxUV%2F5RwUfPcSrjJo0yN4mxILmQ%3D","https://doi.org/10.1061/JBENF2.BEENG-6149"
"Predictions of bitcoin prices through machine learning based frameworks","","Cocco, Luisanna; Tonelli, Roberto; Marchesi, Michele","PeerJ Computer Science","Scholarly Journals","","","","2021-03-29","Mar 29, 2021","n/a","","","23765992","","","ENG","The high volatility of an asset in financial markets is commonly seen as a negative factor. However short-term trades may entail high profits if traders open and close the correct positions. The high volatility of cryptocurrencies, and in particular of Bitcoin, is what made cryptocurrency trading so profitable in these last years. The main goal of this work is to compare several frameworks each other to predict the daily closing Bitcoin price, investigating those that provide the best performance, after a rigorous model selection by the so-called k-fold cross validation method. We evaluated the performance of one stage frameworks, based only on one machine learning technique, such as the Bayesian Neural Network, the Feed Forward and the Long Short Term Memory Neural Networks, and that of two stages frameworks formed by the neural networks just mentioned in cascade to Support Vector Regression. Results highlight higher performance of the two stages frameworks with respect to the correspondent one stage frameworks, but for the Bayesian Neural Network. The one stage framework based on Bayesian Neural Network has the highest performance and the order of magnitude of the mean absolute percentage error computed on the predicted price by this framework is in agreement with those reported in recent literature works.","https://www.proquest.com/docview/2506710841?accountid=12870&bdid=83737&_bd=klWSC%2B5YcDshvTj2rvlVo9A01cU%3D","https://doi.org/10.7717/peerj-cs.413"
"Machine Learning the Carbon Footprint of Bitcoin Mining","","Calvo-Pardo, Hector F; Calvo-Pardo, Hector F; Mancini, Tullio; Olmo, Jose; Olmo, Jose","Journal of Risk and Financial Management","Scholarly Journals","","15","2","2022-01-01","2022","71","","","19118066","","","ENG","Building on an economic model of rational Bitcoin mining, we measured the carbon footprint of Bitcoin mining power consumption using feed-forward neural networks. We found associated carbon footprints of 2.77, 16.08 and 14.99 MtCO2e for 2017, 2018 and 2019 based on a novel bottom-up approach, which (i) conform with recent estimates, (ii) lie within the economic model bounds while (iii) delivering much narrower prediction intervals and yet (iv) raise alarming concerns, given recent evidence (e.g., from climate–weather integrated models). We demonstrate how machine learning methods can contribute to not-for-profit pressing societal issues, such as global warming, where data complexity and availability can be overcome.","https://www.proquest.com/docview/2632815962?accountid=12870&bdid=83737&_bd=XWKv6sQvdIf5z%2Fw0QEH%2F9O7n2V0%3D","https://doi.org/10.3390/jrfm15020071"
"Treatment Effect Risk: Bounds and Inference","","Kallus, Nathan","Management Science","Scholarly Journals","","69","8","2023-08-01","Aug 2023","4579","","","00251909","","","ENG","Because the average treatment effect (ATE) measures the change in social welfare, even if positive, there is a risk of negative effect on, say, some 10% of the population. Assessing such risk is difficult, however, because any one individual treatment effect (ITE) is never observed, so the 10% worst-affected cannot be identified, whereas distributional treatment effects only compare the first deciles within each treatment group, which does not correspond to any 10% subpopulation. In this paper, we consider how to nonetheless assess this important risk measure, formalized as the conditional value at risk (CVaR) of the ITE distribution. We leverage the availability of pretreatment covariates and characterize the tightest possible upper and lower bounds on ITE-CVaR given by the covariate-conditional average treatment effect (CATE) function. We then proceed to study how to estimate these bounds efficiently from data and construct confidence intervals. This is challenging even in randomized experiments as it requires understanding the distribution of the unknown CATE function, which can be very complex if we use rich covariates to best control for heterogeneity. We develop a debiasing method that overcomes this and prove it enjoys favorable statistical properties even when CATE and other nuisances are estimated by black box machine learning or even inconsistently. Studying a hypothetical change to French job search counseling services, our bounds and inference demonstrate a small social benefit entails a negative impact on a substantial subpopulation.","https://www.proquest.com/docview/2847936884?accountid=12870&bdid=83737&_bd=BnTrZiEkgrLtTWfJogZyv5hEaIY%3D","https://doi.org/10.1287/mnsc.2023.4819"
"The roles of liquidity and delay in financial markets based on an optimal forecasting model.","","Yang, Guo-Hui; Ma, Si-Qi; Bian, Xiao-Dong; Li, Jiang-Cheng","PloS one","Undefined","","18","9","2023-01-01","2023","e0290869","e0290869","e0290869","","1932-6203","","ENG","We investigate the roles of liquidity and delay in financial markets through our proposed optimal forecasting model. The efficiency and liquidity of the financial market are examined using stochastic models that incorporate information delay. Based on machine learning, we estimate the in-sample and out-of-sample forecasting price performances of the six proposed methods using the likelihood function and Bayesian methods, and the out-of-sample prediction performance is compared with the benchmark model ARIMA-GARCH. We discover that the forecasting price performance of the proposed simplified delay stochastic model is superior to that of the benchmark methods by the test methods of a variety of loss function, superior predictive ability test (SPA), Akaike information criterion (AIC), and Bayesian information criterion (BIC). Using data from the Chinese stock market, the best forecasting model assesses the efficiency and liquidity of the financial market while accounting for information delay and trade probability. The rise in trade probability and delay time affects the stability of the return distribution and raises the risk, according to stochastic simulation. The empirical findings show that empirical and best forecasting approaches are compatible, that company size and liquidity (delay time) have an inverse relationship, and that delay time and liquidity have a nonlinear relationship. The most efficient have optimal liquidity.","https://www.proquest.com/docview/2860401547?accountid=12870&bdid=83737&_bd=UbWSUk3opJYRbsLj07NAPxf5x4o%3D","https://doi.org/10.1371/journal.pone.0290869"
"Sentiment-aware volatility forecasting","","Xing, Frank Z; Cambria, Erik; Zhang, Yue","Knowledge-Based Systems","Scholarly Journals","","176","","2019-07-15","Jul 15, 2019","68","","","0950-7051","","","ENG","Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled using Variational Bayes via the data generation and inference operations. We benchmark our model with 9 other popular ones in terms of the likelihood of forecasts given the observed sequence. Experimental results suggest that our model not only outperforms pure statistical models, e.g., GARCH and its variants, Gaussian-process volatility model, but also outperforms the state-of-the-art autoregressive deep neural nets architectures, such as the variational recurrent neural network and the neural stochastic volatility model.","https://www.proquest.com/docview/2236171793?accountid=12870&bdid=83737&_bd=KkAUEZq7eho3MEwtHVh1sDJx9us%3D","https://doi.org/10.1016/j.knosys.2019.03.029"
"Prediction of events based on Complex Event Processing and Probabilistic Fuzzy Logic","","Govindasamy, V; Ganesh, R; Nivash, G; Shivaraman, S","The Institute of Electrical and Electronics Engineers, Inc. (IEEE) Conference Proceedings.","Undefined","Institute of Electrical and Electronics Engineers, Inc., 3 Park Avenue, 17th Fl New York NY 10016-5997 USA","","","2014-04-01","April 2014","494","499","494-499","","","","ENG","This paper proposes a prediction system named as PECEP. PECEP is based on Complex Event Processing (CEP) and Probabilistic Fuzzy Logic (PFL). CEP is event processing that combines data from multiple sources to infer events or patterns that suggest more complicated circumstances. The main aim of CEP is to identify meaningful events such as opportunities or threats and respond to them as quickly as possible. A PFL is a type of logic that recognizes more than simple truth values. Fuzzy logic can be represented with degrees of truthfulness and falsehood. The event data are downloaded and updated dynamically from the online data source. PECEP consists of three steps namely Collection of Data Set, Feature Processing and Machine Learning. PECEP is validated using Esper in the stock market domain. A stock market or equity market is a public entity for the trading of company stock and derivatives at an agreed price. The output of the PECEP provides a guideline about the future price of stock. The performance of PECEP is compared with the existing system in terms of the four parameters- Accuracy, Error Rate Analysis, Processing Time and Throughput.","https://www.proquest.com/docview/1770334703?accountid=12870&bdid=83737&_bd=Hz0F0Inl59fm%2BwbKcpPvX9ZQ59I%3D","https://doi.org/10.1109/ICCPEIC.2014.6915414"
"Annotators’ Selection Impact on the Creation of a Sentiment Corpus for the Cryptocurrency Financial Domain","","Manoel Fernando Alonso Gadi; Sicilia, Miguel Angel","IEEE Access","Scholarly Journals","","11","","2023-01-01","2023","131081","","131081-131088","21693536","","","ENG","Well labeled natural language corpus data is essential for most natural language processing techniques, especially in specialized fields. However, cohort biases remain a significant challenge in machine learning. The narrow origin of data sampling or human annotators in cohorts is a prevalent issue for machine learning researchers due to its potential to induce bias in the final product. During the development of the CryptoLin corpus for another research project, the authors became concerned about the potential influence of cohort bias on the selection of annotators. Therefore, this paper addresses the question of whether cohort diversity improves the labeling result through the implementation of a repeated annotator process, involving two annotator cohorts and a statistically robust comparison methodology. The utilization of statistical tests, such as the Chi-Square Independence test for absolute frequency tables, and the construction of confidence intervals for Kappa point estimates, facilitates a rigorous analysis of the differences between Kappa estimates. Furthermore, the application of a two-proportion z-test to compare the accuracy scores of UTAD and IE annotators for various pre-trained models, including Vader Sentiment Analysis, TextBlob Sentiment Analysis, Flair NLP library, and FinBERT Financial Sentiment Analysis with BERT, contributes to the advancement of knowledge in this field. The paper utilizes Cryptocurrency Linguo (CryptoLin), a corpus containing 2683 cryptocurrency-related news articles spanning more than three years, and compares two different selection criteria for the annotators. CryptoLin was annotated twice with discrete values representing negative, neutral, and positive news respectively. The first annotation was done by twenty-seven annotators from the same cohort. Each news title was randomly assigned and blindly annotated by three human annotators. The second annotation was carried out by eighty-three annotators from three cohorts. Each news title was randomly assigned and blindly annotated by three human annotators, one in each different cohort. In both annotations, a consensus mechanism using simple voting was applied. The first annotation used the same cohort with students from the same nationality and background. The second used three cohorts with students from a very diverse set of nationalities and educational backgrounds. The results demonstrate that manual labeling done by both groups was acceptable according to inter-rater reliability coefficients Fleiss’s Kappa, Krippendorff’s Alpha, and Gwet’s AC1. Preliminary analysis utilizing Vader, Textblob, Flair, and FinBERT confirmed the utility of the data set labeling for further refinement of sentiment analysis algorithms. Our results also highlight that the more diverse annotator pool performed better in all measured aspects.","https://www.proquest.com/docview/2895003352?accountid=12870&bdid=83737&_bd=g%2BkWKujv4Hd%2BQMPc6umLV2Ki3xM%3D","https://doi.org/10.1109/ACCESS.2023.3334260"
"Deep learning-based rolling horizon unit commitment under hybrid uncertainties","","Zhou, Min; Wang, Bo https://orcid.org/0000-0002-9264-9741; Watada, J. (Junzo), https://orcid.org/0000-0002-3322-2086","Energy","Undefined","Elsevier Ltd","","","2019-07-28","Jul 28, 2019","","","","0360-5442","0360-5442","","ENG","Unit commitment is an optimization problem in power systems, which aims to satisfy future load at minimal cost by scheduling the on/off state and output of generation resources like thermal units. One challenge herein is the uncertainties that exist in both supply and demand sides of power systems, which becomes more severe with the growing penetration of renewable energy and the popularity of diversified loads. This paper proposes a rolling horizon model for unit commitment optimization under hybrid uncertainties. First, a probabilistic forecast approach for future load and wind power is given by exploiting the advanced deep learning structures, i.e. long short-term memory neural networks. Second, a Value-at-Risk-based unit commitment model is applied to decide the on/off state and output of thermal units in the next 24 h. Then at each time window, the distributions of future load and wind power are dynamically adjusted by a rolling forecast mechanism to involve the real-time collected data, whereafter a look-ahead economic dispatch model is applied to improve the output of units. Finally, the effectiveness of this research is demonstrated by a series of experiments. Generally, this study introduces a fundamental way to integrate forecast approaches into classical unit commitment optimization models.","https://www.proquest.com/docview/2305231872?accountid=12870&bdid=83737&_bd=ekLIXxVz%2FOdenhHHm6UBvlxRGXg%3D","https://doi.org/10.1016/j.energy.2019.07.173"
"Artificial Learning Dispatch Planning with Probabilistic Forecasts: Using Uncertainties as an Asset","","Ana Carolina do Amaral Burghi; Hirsch, Tobias; Pitz-Paal, Robert","Energies","Scholarly Journals","","13","3","2020-01-01","2020","616","","","19961073","","","ENG","Weather forecast uncertainty is a key element for energy market volatility. By intelligently considering uncertainties on the schedule development, renewable energy systems with storage could improve dispatching accuracy, and therefore, effectively participate in electricity wholesale markets. Deterministic forecasts have been traditionally used to support dispatch planning, representing reduced or no uncertainty information about the future weather. Aiming at better representing the uncertainties involved, probabilistic forecasts have been developed to increase forecasting accuracy. For the dispatch planning, this can highly influence the development of a more precise schedule. This work extends a dispatch planning method to the use of probabilistic weather forecasts. The underlying method used a schedule optimizer coupled to a post-processing machine learning algorithm. This machine learning algorithm was adapted to include probabilistic forecasts, considering their additional information on uncertainties. This post-processing applied a calibration of the planned schedule considering the knowledge about uncertainties obtained from similar past situations. Simulations performed with a concentrated solar power plant model following the proposed strategy demonstrated promising financial improvement and relevant potential in dealing with uncertainties. Results especially show that information included in probabilistic forecasts can increase financial revenues up to 15% (in comparison to a persistence solar driven approach) if processed in a suitable way.","https://www.proquest.com/docview/2422313451?accountid=12870&bdid=83737&_bd=XS%2B%2BOLwlr5wNauGWfCoS4qS%2BI6M%3D","https://doi.org/10.3390/en13030616"
"Return and Value at Risk using the Dirichlet Process","","Zarepour, Mahmoud; Bédard, Thierry; Dabrowski, André R","Applied Mathematical Finance","Scholarly Journals","","15","3","2008-06-01","Jun 2008","205","","","1350486X","","","ENG","There exists a wide variety of models for return, and the chosen model determines the tool required to calculate the value at risk (VaR). This paper introduces an alternative methodology to model-based simulation by using a Monte Carlo simulation of the Dirichlet process. The model is constructed in a Bayesian framework, using properties initially described by Ferguson. A notable advantage of this model is that, on average, the random draws are sampled from a mixed distribution that consists of a prior guess by an expert and the empirical process based on a random sample of historical asset returns. The method is relatively automatic and similar to machine learning tools, e.g. the estimate is updated as new data arrive. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/216641869?accountid=12870&bdid=83737&_bd=QimCMdR3MiiMaJkAuig0V65YNGQ%3D",""
"Modeling Bitcoin Prices using Signal Processing Methods, Bayesian Optimization, and Deep Neural Networks","","Tripathi, Bhaskar; Sharma, Rakesh Kumar","Computational Economics","Scholarly Journals","","62","4","2023-12-01","Dec 2023","1919","1945","1919-1945","09277099","","","ENG","Bitcoin is a volatile financial asset that runs on a decentralized peer-to-peer Blockchain network. Investors need accurate price forecasts to minimize losses and maximize profits. Extreme volatility, speculative nature, and dependence on intrinsic and external factors make Bitcoin price forecast challenging. This research proposes a reliable forecasting framework by reducing the inherent noise in Bitcoin time series and by examining the predictive power of three distinct types of predictors, namely fundamental indicators, technical indicators, and univariate lagged prices. We begin with a three-step hybrid feature selection procedure to identify the variables with the highest predictive ability, then use Hampel and Savitzky–Golay filters to impute outliers and remove signal noise from the Bitcoin time series. Next, we use several deep neural networks tuned by Bayesian Optimization to forecast short-term prices for the next day, three days, five days, and seven days ahead intervals. We found that the Deep Artificial Neural Network model created using technical indicators as input data outperformed other benchmark models like Long Short Term Memory, Bi-directional LSTM (BiLSTM), and Convolutional Neural Network (CNN)-BiLSTM. The presented results record a high accuracy and outperform all existing models available in the past literature with an absolute percentage error as low as 0.28% for the next day forecast and 2.25% for the seventh day for the latest out of sample period ranging from Jan 1, 2021, to Nov 1, 2021. With contributions in feature selection, data-preprocessing, and hybridizing deep learning models, this work contributes to researchers and traders in fundamental and technical domains.","https://www.proquest.com/docview/2885676416?accountid=12870&bdid=83737&_bd=8AwvMPrAqAd0rUke2m53UnbQx8U%3D","https://doi.org/10.1007/s10614-022-10325-8"
"IoT-based group size prediction and recommendation system using machine learning and deep learning techniques","","Chopra, Deepti; Kaur, Arvinder","SN Applied Sciences","Scholarly Journals","","3","2","2021-02-01","Feb 2021","160","","160","25233963","","","ENG","In an open source software development environment, it is hard to decide the number of group members required for resolving software issues. Developers generally reply to issues based totally on their domain knowledge and interest, and there are no predetermined groups. The developers openly collaborate on resolving the issues based on many factors, such as their interest, domain expertise, and availability. This study compares eight different algorithms employing machine learning and deep learning, namely—Convolutional Neural Network, Multilayer Perceptron, Classification and Regression Trees, Generalized Linear Model, Bayesian Additive Regression Trees, Gaussian Process, Random Forest and Conditional Inference Tree for predicting group size in five open source software projects developed and managed using an open source development framework GitHub. The social information foraging model has also been extended to predict group size in software issues, and its results compared to those obtained using machine learning and deep learning algorithms. The prediction results suggest that deep learning and machine learning models predict better than the extended social information foraging model, while the best-ranked model is a deep multilayer perceptron((R.M.S.E. sequelize—1.21, opencv—1.17, bitcoin—1.05, aseprite—1.01, electron—1.16). Also it was observed that issue labels helped improve the prediction performance of the machine learning and deep learning models. The prediction results of these models have been used to build an Issue Group Recommendation System as an Internet of Things application that recommends and alerts additional developers to help resolve an open issue.","https://www.proquest.com/docview/2788427527?accountid=12870&bdid=83737&_bd=aHkp5XMQqKwYQ%2F5PcqK0zoSiz50%3D","https://doi.org/10.1007/s42452-021-04162-x"
"Research on HMM-Based Efficient Stock Price Prediction","","Su, Zhi; Yi, Bo","Mobile Information Systems","Scholarly Journals","","2022","","2022-01-01","2022","","","","1574-017X","1875-905X","","ENG","Stock market is one of the most important parts of the investment market. Compared with other industries, the stock market not only has a higher rate of return on investment but also has a higher risk, and stock price prediction has always been a close concern of investors. Therefore, the research on stock price prediction methods and how to reduce the error of stock price prediction has become a hot topic for many scholars at home and abroad. In recent years, the development of computer technology such as machine learning and econometric method makes the stock price prediction more reliable. Due to the hidden Markov nature of stock price, this paper proposes a stock price prediction method based on hidden Markov model (HMM). To be specific, since the data of stock price have continuity in time series, it is necessary to extend the discrete HMM to the continuous HMM, and then put forward the up and down trend prediction model based on the continuous HMM. The first-order continuous HMM is extended to the second-order continuous HMM, and the stock price is predicted by combining the prediction method of fluctuation range. As a result, the proposed second-order continuous HMM-based stock price prediction model is simulated on Hang Seng Index (HSI), one of the earliest stock market indexes in Hong Kong. The evaluation results on six months HSI show that the predicted value of the proposed model is very close to the actual value and outperforms three benchmarks in terms of RMSE, MAE, and R2.","https://www.proquest.com/docview/2640855827?accountid=12870&bdid=83737&_bd=eFrXCiVqai%2BiHooCcJj2FTh2snk%3D","https://doi.org/10.1155/2022/8124149"
"Bayesian Aggregation Improves Traditional Single-Image Crop Classification Approaches.","","Matvienko, Ivan; Gasanov, Mikhail; Petrovskaia, Anna; Kuznetsov, Maxim; Jana, Raghavendra; Pukalchik, Maria; Oseledets, Ivan","Sensors (Basel, Switzerland)","Undefined","","22","22","2022-11-08","November 8, 2022","","","","","1424-8220","","ENG","Accurate information about growing crops allows for regulating the internal stocks of agricultural products and drawing strategies for negotiating agricultural commodities on financial markets. Machine learning methods are widely implemented for crop type recognition and classification based on satellite images. However, field classification is complicated by class imbalance and aggregation of pixel-wise into field-wise forecasting. We propose here a Bayesian methodology for the aggregation of classification results. We report the comparison of class balancing techniques. We also report the comparison of classical machine learning methods and the U-Net convolutional neural network for classifying crops using a single satellite image. The best result for single-satellite-image crop classification was achieved with an overall accuracy of 77.4% and a Macro F1-score of 0.66. Bayesian aggregation for field-wise classification improved the result obtained using majority voting aggregation by 1.5%. We demonstrate here that the Bayesian aggregation approach outperforms the majority voting and averaging strategy in overall accuracy for the single-image crop classification task.","https://www.proquest.com/docview/2740510439?accountid=12870&bdid=83737&_bd=1sfH3UYQItm7lOOzmiRczogeUcw%3D","https://doi.org/10.3390/s22228600"
"Financial risk assessment in shipping: a holistic machine learning based methodology","","Clintworth, Mark; Lyridis, Dimitrios; Boulougouris, Evangelos","Maritime Economics & Logistics","Scholarly Journals","","25","1","2023-03-01","Mar 2023","90","121","90-121","14792931","","","ENG","Corporate financial distress (FD) prediction models are of great importance to all stakeholders, including regulators and banks, who rely on acceptable estimates of default risk, for both individual borrowers and bank loan portfolios. Whilst this subject has been covered extensively in finance research, its application to international shipping companies has been limited while the focus has mainly been on the application of traditional linear modelling, using sparse, cross-sectional financial statement data. Insufficient attention has been paid to the noisy and incomplete nature of shipping company financial statement information. This study contributes to the literature through the design, development and testing of a novel holistic machine learning methodology which integrates predictor evaluation and missing data analysis into the distress prediction process. The model was validated using a longitudinal dataset of over 5000 company year-end financial statements combined with macroeconomic and market predictors. We applied this methodology first for individual company level distress prediction before testing the models’ ability to provide accurate confidence intervals by backtesting conditional value-at-risk estimations of the distress rates for bank portfolios. We conclude that, by adopting a holistic approach, our methodology can enhance financial monitoring of company loans and bank loan portfolios thereby providing a practical “early warning system” for financial distress.","https://www.proquest.com/docview/2783534809?accountid=12870&bdid=83737&_bd=Cm0DPD8A%2F%2FzbcWM3lUccUz%2FkCXY%3D","https://doi.org/10.1057/s41278-020-00183-2"
"A general Bayesian model for heteroskedastic data with fully conjugate full-conditional distributions","","Parker, Paul A; Holan, Scott H; Wills, Skye A","Journal of Statistical Computation and Simulation","Scholarly Journals","","91","15","2021-10-01","Oct 2021","3207","3227","3207-3227","00949655","","","ENG","Models for heteroskedastic data are relevant in a variety of applications ranging from financial time series to environmental statistics. However, the topic of modelling the variance function conditionally has not seen as much attention as modelling the mean. Volatility models have been used in specific applications, but these models can be difficult to fit in a Bayesian setting due to posterior distributions that are challenging to sample efficiently. In this work, we introduce a general model for heteroskedastic data. This approach models the conditional variance as a function of any desired covariates or random effects. We rely on multivariate log-Gamma distribution theory to construct priors that yield fully conjugate full-conditional distributions for Gibbs sampling. Furthermore, we extend the model to a deep learning approach that can provide highly accurate estimates for time dependent data. We also provide an extension for heavy-tailed data. We illustrate our methodology via three applications.","https://www.proquest.com/docview/2578277200?accountid=12870&bdid=83737&_bd=Q%2FRPcPDqLHDECksX23jj8oyuAe8%3D","https://doi.org/10.1080/00949655.2021.1925279"
"Prediction of KLCI Index Through Economic LASSO Regression Model and Model Averaging","","Pillay, Khuneswari Gopal; Lin, Soh Pei","Pakistan Journal of Statistics and Operation Research","Scholarly Journals","","19","1","2023-01-01","2023","103","113","103-113","18162711","","","ENG","The Financial Times Stock Exchange (FTSE) Bursa Malaysia KLCI Index is a key component in the development of Malaysia's economic growth and the complexity in terms of identifying the factors that have a substantial impact on the Malaysian stock market has always been a contentious issue. In this study, the macroeconomic factors of exchange rate, interest rate, gold price, consumer price index, money supply Ml, М2, and М3, industrial production, and oil price were discussed by using economic LASSO regression and Bayesian Model Averaging (BMA) with monthly average and monthly end time-series data spanning from January 2015 to June 2021, with a total of 78 observations by using the R Studio. The findings demonstrate that month-end data is better suited for stock market prediction than month-average data and that the BMA model is more suitable than the LASSO model, as seen by lower Mean Square Error of Prediction, MSE(P) and Residual Mean Square Error of Prediction, RMSE(P) values. The exchange rate, gold price, and money supply have a negative association with the dependent variables, while the consumer price index has a positive relationship associated with the dependent variables. The consumer price index is the most significant contributing factor, whereas gold price is the least significant. The result depicted that the KLCI index has no significant relationship with the variables interest rate, money supply М2, Ml, industrial production index, and oil price. In conclusion, investors could specifically focus on the positive contributor and put lesser attention on improving their portfolio return.","https://www.proquest.com/docview/2882573538?accountid=12870&bdid=83737&_bd=Q2w1PC3Z7d7IBqjJ2W%2FJgQxYPMU%3D","https://doi.org/10.18187/pjsor.v19i1.4214"
"Dynamic Machine Learning with Least Square Objectives","","Gultekin, San","ProQuest Dissertations and Theses","Dissertations & Theses","","","","2019-01-01","2019","","","","","","978-1-392-07688-0","ENG","As of the writing of this thesis, machine learning has become one of the most active research fields. The interest comes from a variety of disciplines which include computer science, statistics, engineering, and medicine. The main idea behind learning from data is that, when an analytical model explaining the observations is hard to find—often in contrast to the models in physics such as Newton's laws—a statistical approach can be taken where one or more candidate models are tuned using data.Since the early 2000's this challenge has grown in two ways: (i) The amount of collected data has seen a massive growth due to the proliferation of digital media, and (ii) the data has become more complex. One example for the latter is the high dimensional datasets, which can for example correspond to dyadic interactions between two large groups (such as customer and product information a retailer collects), or to high resolution image/video recordings. Another important issue is the study of dynamic data, which exhibits dependence on time. Virtually all datasets fall into this category as all data collection is performed over time, however I use the term dynamic to hint at a system with an explicit temporal dependence. A traditional example is target tracking from signal processing literature. Here the position of a target is modeled using Newton's laws of motion, which relates it to time via the target's velocity and acceleration.Dynamic data, as I defined above, poses two important challenges. Firstly, the learning setup is different from the standard theoretical learning setup, also known as Probably Approximately Correct (PAC) learning. To derive PAC learning bounds one assumes a collection of data points sampled independently and identically from a distribution which generates the data. On the other hand, dynamic systems produce correlated outputs. The learning systems we use should accordingly take this difference into consideration. Secondly, as the system is dynamic, it might be necessary to perform the learning online. In this case the learning has to be done in a single pass. Typical applications include target tracking and electricity usage forecasting.In this thesis I investigate several important dynamic and online learning problems, where I develop novel tools to address the shortcomings of the previous solutions in the literature. The work is divided into three parts for convenience. The first part is about matrix factorization for time series analysis which is further divided into two chapters. In the first chapter, matrix factorization is used within a Bayesian framework to model time-varying dyadic interactions, with examples in predicting user-movie ratings and stock prices. In the next chapter, a matrix factorization which uses autoregressive models to forecast future values of multivariate time series is proposed, with applications in predicting electricity usage and traffic conditions. Inspired by the machinery we use in the first part, the second part is about nonlinear Kalman filtering, where a hidden state is estimated over time given observations. The nonlinearity of the system generating the observations is the main challenge here, where a divergence minimization approach is used to unify the seemingly unrelated methods in the literature, and propose new ones. This has applications in target tracking and options pricing. The third and last part is about cost sensitive learning, where a novel method for maximizing area under receiver operating characteristics curve is proposed. Our method has theoretical guarantees and favorable sample complexity. The method is tested on a variety of benchmark datasets, and also has applications in online advertising.","https://www.proquest.com/docview/2217121439?accountid=12870&bdid=83737&_bd=NLtZdALasgtflv5ZRSynofKSAbE%3D",""
"Predicting Market Impact Costs Using Nonparametric Machine Learning Models.","","Park, Saerom; Lee, Jaewook; Son, Youngdoo","PloS one","Undefined","","11","2","2016-01-01","2016","e0150243","e0150243","e0150243","","1932-6203","","ENG","Market impact cost is the most significant portion of implicit transaction costs that can reduce the overall transaction cost, although it cannot be measured directly. In this paper, we employed the state-of-the-art nonparametric machine learning models: neural networks, Bayesian neural network, Gaussian process, and support vector regression, to predict market impact cost accurately and to provide the predictive model that is versatile in the number of variables. We collected a large amount of real single transaction data of US stock market from Bloomberg Terminal and generated three independent input variables. As a result, most nonparametric machine learning models outperformed a-state-of-the-art benchmark parametric model such as I-star model in four error measures. Although these models encounter certain difficulties in separating the permanent and temporary cost directly, nonparametric machine learning models can be good alternatives in reducing transaction costs by considerably improving in prediction performance.","https://www.proquest.com/docview/1770222026?accountid=12870&bdid=83737&_bd=ahzeK8gEd6YaVY0H8SYZ7OzLgio%3D","https://doi.org/10.1371/journal.pone.0150243"
"Prevalence of money laundering and terrorism financing through stock market: a comprehensive conceptual review paper","","Akram, Tooba; Suresh A/I Ramakrishnan; Muhammad Naveed","Journal of Money Laundering Control","Scholarly Journals","","26","5","2023-01-01","2023","1027","1044","1027-1044","13685201","","","ENG","PurposeThis paper aims to provide a comprehensive conceptual framework and strong arguments with an intent to examine the stock market variables (predictors) indicating the money laundering (ML) and terrorism financing (FT) proceeds.Design/methodology/approachThis paper provides a comprehensive review of ML/FT through the stock market across developed, developing and emerging jurisdictions, sheds light on the existing literature and critically evaluates the gap in the relevant studies. Moving forward, this paper develops the conceptual framework and formulates hypotheses to explore the empirical relationship.FindingsThis paper advocates and finds a basis to carry out much-needed empirical research between the ML/FT and stock market keeping in view the growing criminal cases in the developing countries. This paper suggests mining proxies from the publically available stock market data and the results of existing seminal research as variables of the study. These data and results carry information about the ML determinants. After developing hypothetical research providing concepts, this paper also finds that using a suitable methodology, preferable Bayesian logistic and linear regression models, it is possible to find the typologies and factors that can indicate and endorse the use of the stock market for ML/FT. Broadly, it is found that the significance of this study will be two-pronged: empirical development and policy implications.Research limitations/implicationsThis paper mainly focuses on the developing region, a newly emerging market and, peculiarly, a grey-listed region by the Financial Action Task Force (FATF).Practical implicationsIn light of the existing literature and to the best of the researchers’ knowledge, this study will bring into focus the new age of the action research on the ML regime in the securities markets of the developing countries, hence, the emerging markets. Moreover, this research shall have a sheer significance for the policy measures on FATF recommendations on ML and FT, especially for the countries listed as “grey”.Social implicationsThe research based on comprehensive review will help in controlling the social behaviours aiding the proceeds of ML.Originality/valueThis research is extremely novel to the best of the researcher's knowledge.","https://www.proquest.com/docview/2891924996?accountid=12870&bdid=83737&_bd=u4DwBQJSg7JpvW3y7YbAF2qFHvc%3D","https://doi.org/10.1108/JMLC-06-2022-0094"
"Prediction of Ethereum gas prices using DeepAR and probabilistic forecasting","","Ferenczi, Andras; Costin Bădică","Journal of Information and Telecommunication","Scholarly Journals","","8","1","2024-03-01","Mar 2024","18","32","18-32","24751839","","","ENG","Ethereum is a major public blockchain. Besides being the second-largest digital currency by market capitalization for its cryptocurrency, the Ether (Ξ), it is also the foundation of Web3 and decentralized applications, or DApps, that are fuelled by Smart Contracts. At the time of this writing, Ethereum still uses Proof of Work (PoW) consensus algorithm to ensure the integrity of the blockchain and to prevent double spend. PoW requires the participation of miners, who are incentivized to assemble blocks of transactions by being rewarded with cryptocurrency paid by transaction originators and by the blockchain network itself via newly minted Ξ. Network fees for transaction submissions are called gas, by analogy to the fuel used by cars, and are negotiable. They are also highly volatile and hence it is critical to predict the direction they are heading into, so that one can time transaction submissions, when feasible. There have been several efforts to predict gas prices, including usage of large Mempools, analysis of committed blocks, and more recent ones using Facebook's Prophet model [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2]. In this study, we introduce an innovative approach that employs the DeepAR [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001] model, known for its superior forecasting accuracy over conventional methods by virtue of its ability to learn from multiple related time series. This methodology not only offers immediate advantages but also holds promise for ongoing enhancements. We substantiate our claims through empirical testing, utilizing data extracts from the Ethereum blockchain and cryptocurrency price feeds. This document is an extended version of our ICCS 2022 paper on the same topic. In this paper, we dive deeper into the internals of DeepAR forecasting algorithm [Salinas, D., Flunkert, V., Gasthaus, J., & Januschowski, T. (2020). Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 36(3), 1181–1191. https://doi.org/10.1016/j.ijforecast.2019.07.001], analyse the correlation between the on-chain/off-chain sample data, and describe additional experiments that empirically prove our findings and, finally, perform a comparison of our outputs with those from the Prophet [Taylor, S. J., & Letham, B. (2017). Forecasting at scale. PeerJ Preprints, 5, e3190v2. https://doi.org/10.7287/peerj.preprints.3190v2] model.","https://www.proquest.com/docview/2954113442?accountid=12870&bdid=83737&_bd=Fghvi6XE%2FuKFs9gzXRGOrdHpOCM%3D","https://doi.org/10.1080/24751839.2023.2250113"
"Bitcoin Price Prediction Using Deep Bayesian LSTM With Uncertainty Quantification: A Monte Carlo Dropout–Based Approach","","Hassan, Masoud Muhammed","Stat","Scholarly Journals","","13","3","2024-09-01","Sep 2024","","","","20491573","","","ENG","Bitcoin, being one of the most triumphant cryptocurrencies, is gaining increasing popularity online and is being used in a variety of transactions. Recently, research on Bitcoin price predictions is receiving more attention, and researchers have investigated the various state‐of‐the‐art machine learning (ML) and deep learning (DL) models to predict Bitcoin price. However, despite these models providing promising predictions, they consistently exhibit uncertainty, which cannot be adequately quantified by classical ML models alone. Motivated by the enormous success of applying Bayesian approaches in several disciplines of ML and DL, this study aims to use Bayesian methods alongside Long Short‐Term Memory (LSTM) to predict the closing Bitcoin price and consequently measure the uncertainty of the prediction model. Specifically, we adopted the Monte Carlo dropout (MC‐Dropout) method with the Bayesian LSTM model to quantify the epistemic uncertainty of the model's predictions and provided confidence intervals for the predicted outputs. Experimental results showed that the proposed model is efficient and outperforms other state‐of‐the‐art models in terms of root mean square error (RMSE), mean absolute error (MAE) and R2. Thus, we believe that these models may assist the investors and traders in making critical decisions based on short‐term predictions of Bitcoin price. This study illustrates the potential benefits of utilizing Bayesian DL approaches in time series analysis to improve data prediction accuracy and reliability.","https://www.proquest.com/docview/3106200925?accountid=12870&bdid=83737&_bd=KwK74z3yA89ej9%2BRnoX%2BOn7qorQ%3D","https://doi.org/10.1002/sta4.70001"
"Modeling and prediction of KSE – 100 index closing based on news sentiments: an applications of machine learning model and ARMA (p, q) model","","Zaffar, Asma; Hussain, S. M. Aalim","Multimedia Tools and Applications","Scholarly Journals","","81","23","2022-09-01","Sep 2022","33311","33333","33311-33333","13807501","","","ENG","The main financial markets of every country are stock exchange and consider as an imperative cause for the corporations to increase capital. The novelty of this study to explore machine learning techniques when applied to financial stock market data, and to understand how machine learning algorithms can be applied and compare the result with time series analysis to real lifetime series data and helpful for any investor. Investors are constantly reviewing past pricing history and using it to influence their future investment decisions. The another novelty of this study, using news sentiments, the values will be processed into lists displaying and representing the stock and predicting the future rates to describe the market, and to compare investments, which will help to avoid uncertainty amongst the investors regarding the stock index. Using artificial neural network technique for prediction for KSE 100 index data on closing day. In this regard, six months’ data cycle trained the data and apply the statistical interference using a ARMA (p, q) model to calculate numerical result. The novelty of this study to find the relation between them either they are strongly correlated or not, using machine learning techniques and ARMA (p, q) process to forecast the behavior KSE 100 index cycles. The adequacy of model describes via least values Akaike information criterion (AIC), Bayesian Schwarz information criterion (SIC) and Hannan Quinn information criterion (HIC). Durbin- Watson (DW) test is also applied. DW values (< 2) shows that all cycles are strongly correlated. Most of the KSE-100 index cycles expresses that the appropriate model is ARMA (2,1). Cycle’s 2nd,3rd,4th and 5th shows that ARMA (3,1) is best fitted. Cycle 8th is shows ARMA (1,1) best fit and cycle 12th shows that the most appropriate model is ARMA (4,1). Diagnostic checking tests like Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Theil’s U-Statistics are used to predict KSE-100 index cycles. Theil’s U-Statistics demonstrate that each cycle is strongly correlated to previous one.","https://www.proquest.com/docview/2705205672?accountid=12870&bdid=83737&_bd=filOImmD5Itt%2BiI93Vm7ybuXfy4%3D","https://doi.org/10.1007/s11042-022-13052-2"
"Asymptotically Unbiased Estimation of A Nonsymmetric Dependence Measure Applied to Sensor Data Analytics and Financial Time Series","","Cațaron, Angel; Andonie, Razvan; Chueh, Yvonne","International Journal of Computers, Communications and Control","Scholarly Journals","","12","4","2017-08-01","Aug 2017","","","","18419836","","","ENG","A fundamental concept frequently applied to statistical machine learning is the detection of dependencies between unknown random variables found from data samples. In previous work, we have introduced a nonparametric unilateral dependence measure based on Onicescu’s information energy and a kNN method for estimating this measure from an available sample set of discrete or continuous variables. This paper provides the formal proofs which show that the estimator is asymptotically unbiased and has asymptotic zero variance when the sample size increases. It implies that the estimator has good statistical qualities. We investigate the performance of the estimator for data analysis applications in sensor data analysis and financial time series.","https://www.proquest.com/docview/2518357574?accountid=12870&bdid=83737&_bd=90kl9TB9vsOjmxg%2FcagI7PkIpIM%3D",""
"A Bayesian analysis based on multivariate stochastic volatility model: evidence from green stocks.","","Ma, Ming; Zhang, Jing","Journal of combinatorial optimization","Undefined","","45","1","2023-01-01","2023","19","19","19","1382-6905","1382-6905","","ENG","Green stocks are companies environmental protective and friendly. We test Green stock index in Shanghai Stock Exchange and China Securities Index as safe-havens for global investors. Suitable multivariate-SV model and Bayesian method are used to estimate the spillover effect between different assets among local and global markets. We choose multivariate volatility model because it can efficiently simulate the spillover effect by using machine learning MCMC method. The results show that the Environmental Protection Index (EPI) of Shanghai Stock Exchange (SSE) and China Securities Index (CSI) have no significant volatility spillover from Shanghai Stock index, S &P index, gold price, oil future prices of USA and China. During COVID-19 pandemic, we find Green stock index is a suitable safe-haven with low volatility spillover. Green stock indexes has a strongly one-way spillover to the crude oil future price. Environmentally friendly investor can use diversity green assets to provide a low risk investment portfolio in EPI stock market. The DCGCt-MSV model using machine learning of MCMC method is accurate and outperform others in Bayes parameter estimation.","https://www.proquest.com/docview/2747006132?accountid=12870&bdid=83737&_bd=%2BS4BQiya8yf4%2Bill7AS9lci4F%2Fo%3D","https://doi.org/10.1007/s10878-022-00936-0"
"Variance-based clustering methods and higher order data transformations and their applications","","Lytkin, Nikita I.","ProQuest Dissertations and Theses","Dissertations & Theses","","","","2009-01-01","2009","","","","","","978-1-109-52503-8","ENG","Two approaches have been proposed in statistical and machine learning communities in order to address the problem of uncovering clusters with complex structure. One approach relies on the development of clustering criteria that are able to accommodate increasingly complex characteristics of the data. The other approach is based on simplification of structure of data by mapping it to a different feature space via a non-linear function and then clustering in the new space. This dissertation covers three related studies: development of a novel multi-dimensional clustering method, development of non-linear mapping functions that leverage higher-order co-occurrences between features in boolean data, and applications of these mapping functions for improving the performance of clustering methods. In particular, we treat clustering as a combinatorial optimization problem of finding a partition of the data so as to minimize a certain criterion. We develop a novel multi-dimensional clustering method based on a statistically-motivated criterion proposed by J. Neyman for stratified sampling from one-dimensional data. We show that this criterion is more reflective of the underlying data structure than the seemingly similar K-means criterion when second order variability is not homogeneous between constituent subgroups. Furthermore, experimental results demonstrate that generalization of the Neyman's criterion to multi-dimensional spaces and development of the associated clustering algorithm allow for statistically efficient estimation of the grand mean vector of a population. In the framework of the mapping-based approach to discovering complex cluster structures, we introduced a novel adaptive non-linear data transformation termed Unsupervised Second Order Transformation (USOT). The novelties behind USOT are (a) that it leverages in a unsupervised manner, higher-order co-occurrences between features in boolean data, and (b) that it considers each feature in the context of probabilistic relationships with other features. In addition, USOT has two desirable properties. USOT adaptively selects features that would influence the mapping of a given feature, and preserves the interpretability of dimensions of the transformed space. Experimental results on text corpora and financial time series demonstrate that by leveraging higher-order co-occurrences between features, clustering methods achieved statistically significant improvements in USOT space over the original boolean space.","https://www.proquest.com/docview/304992622?accountid=12870&bdid=83737&_bd=oX7U%2FuPOpTISnlR74P3f0nOw%2Bio%3D",""
"Global Stock Selection with Hidden Markov Model","","","Risks","Scholarly Journals","","9","1","2021-01-01","2021","9","","","22279091","","","ENG","Hidden Markov model (HMM) is a powerful machine-learning method for data regime detection, especially time series data. In this paper, we establish a multi-step procedure for using HMM to select stocks from the global stock market. First, the five important factors of a stock are identified and scored based on its historical performances. Second, HMM is used to predict the regimes of six global economic indicators and find the time periods in the past during which these indicators have a combination of regimes that is similar to those predicted. Then, we analyze the five stock factors of the All country world index (ACWI) in the identified time periods to assign a weighted score for each stock factor and to calculate the composite score of the five factors. Finally, we make a monthly selection of 10% of the global stocks that have the highest composite scores. This strategy is shown to outperform those relying on either ACWI, any single stock factor, or the simple average of the five stock factors.","https://www.proquest.com/docview/2475061325?accountid=12870&bdid=83737&_bd=ua7qIuP77T0iwAjRXr2SrvDykJc%3D","https://doi.org/10.3390/risks9010009"
"Deep learning-based rolling horizon unit commitment under hybrid uncertainties","","Zhou, Min; Wang, Bo; Watada, Junzo","Energy","Scholarly Journals","","186","","2019-11-01","Nov 1, 2019","1","","","0360-5442","","","ENG","Unit commitment is an optimization problem in power systems, which aims to satisfy future load at minimal cost by scheduling the on/off state and output of generation resources like thermal units. One challenge herein is the uncertainties that exist in both supply and demand sides of power systems, which becomes more severe with the growing penetration of renewable energy and the popularity of diversified loads. This paper proposes a rolling horizon model for unit commitment optimization under hybrid uncertainties. First, a probabilistic forecast approach for future load and wind power is given by exploiting the advanced deep learning structures, i.e. long short-term memory neural networks. Second, a Value-at-Risk-based unit commitment model is applied to decide the on/off state and output of thermal units in the next 24 h. Then at each time window, the distributions of future load and wind power are dynamically adjusted by a rolling forecast mechanism to involve the real-time collected data, whereafter a look-ahead economic dispatch model is applied to improve the output of units. Finally, the effectiveness of this research is demonstrated by a series of experiments. Generally, this study introduces a fundamental way to integrate forecast approaches into classical unit commitment optimization models.","https://www.proquest.com/docview/2310648580?accountid=12870&bdid=83737&_bd=KqtEnE%2Fh%2FAepdoVjvqnGDXG5SMk%3D","https://doi.org/10.1016/j.energy.2019.07.173"
"A Bayesian-based classification framework for financial time series trend prediction","","Dezhkam Arsalan; Manzuri, Mohammad Taghi; Aghapour Ahmad; Karimi Afshin; Rabiee, Ali; Shalmani, Shervin Manzuri","The Journal of Supercomputing","Scholarly Journals","","79","4","2023-01-01","2023","4622","4659","4622-4659","09208542","","","ENG","Financial time series have been extensively studied within the past decades; however, the advent of machine learning and deep neural networks opened new horizons to apply supercomputing techniques to extract more insights from the underlying patterns of price data. This paper presents a tri-state labeling approach to classify the underlying patterns in price data into up, down and no-action classes. The introduction of a no-action state in our novel approach alleviates the burden of denoising the dataset as a preprocessing task. The performance of our labeling algorithm is experimented with using machine learning and deep learning models. The framework is augmented by applying the Bayesian optimization technique for the selection of the best tuning values of the hyperparameters. The price trend prediction module generates the required trading signals. The results show that the average annualized Sharpe ratio as the trading performance metric is about 2.823, indicating the framework produces excellent cumulative returns.","https://www.proquest.com/docview/2770321474?accountid=12870&bdid=83737&_bd=kgu8sxZVdrU4XjttqFhdDcvmfWM%3D","https://doi.org/10.1007/s11227-022-04834-4"
"Forecasting classification of operating performance of enterprises by probabilistic neural network","","Huang, Jui-Ching; Pan, Wen-Tsao","Journal of Information & Optimization Sciences","Scholarly Journals","","31","2","2010-03-01","Mar 2010","333","","","02522667","","","ENG","Classification of operating performance of the enterprises is not only a hot issue emphasized by the management, but it is even the important reference by investors in their decision-making. In general, the analysis of its performance is usually undertaken by models of financial prediction or credit rating. This paper address a lot of models to analyze it through the financial ratio from 287 private enterprises of traditional industry public listed in Taiwan's stock market and OTC as sample data. A hybrid methodology that combines both data mining and artificial intelligence is proposed to take advantage of the unique strength of single one model. First, we use the data mining technique, such as traditional principal components analysis, to select network input variables. Second, the various different models, including the Probabilistic Neural Network are also considered. Third, this paper shows that the classification ability of the Probabilistic Neural Network model, after the parameter adjusted by genetic algorithm, does significantly outperform other simple methods-back-propagation network, decision tree, and logistic regression model. In conclusion, experimental results with real data sets indicate that combined model can be an effective way to improve forecasting classification accuracy achieved by either of the one single models. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/722501416?accountid=12870&bdid=83737&_bd=8oB4UP90UYb75yWzrvbiF0Ga9Fs%3D",""
"Online sequential pattern mining and association discovery by advanced artificial intelligence and machine learning techniques","","Huang, Shian-Chang; Chiou, Chei-Chang; Chiang, Jui-Te; Wu, Cheng-Feng","Soft Computing","Scholarly Journals","","24","11","2020-06-01","Jun 2020","8021","8039","8021-8039","14327643","","","ENG","With the advances in information science, vast amounts of financial time series data can been collected and analyzed. In modern time series analysis, sequential pattern mining (SPM) and association discovery (AD) are the most important techniques to predict the future trends. This study aims at developing advanced SPM and AD for financial data by cutting edge techniques from artificial intelligence and machine learning. The nonlinearity and non-stationarity of financial time series dynamics pose a major challenge for SPM and AD. This study employs time–frequency analysis to extract features for SPM. Then, a sparse multi-manifold clustering (SMMC) is used to partition the feature space into several disjointed regions for better AD. Finally, local relevance vector machines (RVMs) are employed for AD and perform the forecasting. Different from traditional methods, the novel forecasting system operates on multiple resolutions and multiple dynamic regimes. SMMC finds both the neighbors and the weights automatically by a sparse solution, which approximately spans a low-dimensional affine subspace at that point. RVM, the Bayesian kernel machines, can produce parsimonious models with excellent generalization properties. Taking multiple time series data from financial markets as an example, the empirical results demonstrate that the proposed model outperforms traditional models and significantly reduces the forecasting errors. The framework is effective and suitable for other time series forecasting.","https://www.proquest.com/docview/2918064252?accountid=12870&bdid=83737&_bd=EfhfCocPHEGJ9TEp6kK%2F8xe26Nw%3D","https://doi.org/10.1007/s00500-019-04100-5"
"An Improved Probabilistic Neural Network Model for Directional Prediction of a Stock Market Index","","Chandrasekara, Vasana; Tilakaratne, Chandima; Mammadov, Musa","Applied Sciences","Scholarly Journals","","9","24","2019-01-01","2019","5334","","","20763417","","","ENG","Financial market prediction attracts immense interest among researchers nowadays due to rapid increase in the investments of financial markets in the last few decades. The stock market is one of the leading financial markets due to importance and interest of many stakeholders. With the development of machine learning techniques, the financial industry thrived with the enhancement of the forecasting ability. Probabilistic neural network (PNN) is a promising machine learning technique which can be used to forecast financial markets with a higher accuracy. A major limitation of PNN is the assumption of Gaussian distribution as the distribution of input variables which is violated with respect to financial data. The main objective of this study is to improve the standard PNN by incorporating a proper multivariate distribution as the joint distribution of input variables and addressing the multi-class imbalanced problem persisting in the directional prediction of the stock market. This model building process is illustrated and tested with daily close prices of three stock market indices: AORD, GSPC and ASPI and related financial market indices. Results proved that scaled t distribution with location, scale and shape parameters can be used as more suitable distribution for financial return series. Global optimization methods are more appropriate to estimate better parameters of multivariate distributions. The global optimization technique used in this study is capable of estimating parameters with considerably high dimensional multivariate distributions. The proposed PNN model, which considers multivariate scaled t distribution as the joint distribution of input variables, exhibits better performance than the standard PNN model. The ensemble technique: multi-class undersampling based bagging (MCUB) was introduced to handle class imbalanced problem in PNNs is capable enough to resolve multi-class imbalanced problem persisting in both standard and proposed PNNs. Final model proposed in the study with proposed PNN and proposed MCUB technique is competent in forecasting the direction of a given stock market index with higher accuracy, which helps stakeholders of stock markets make accurate decisions.","https://www.proquest.com/docview/2533769947?accountid=12870&bdid=83737&_bd=Oek%2FmDz1KY2MzyXRhEmdd9Y2q%2F4%3D","https://doi.org/10.3390/app9245334"
"Welcome to SIGNALS: A New Open-Access Scientific Journal on Signal Analysis, Retrieval and Processing","","Cichocki, Andrzej","Signals","Scholarly Journals","","1","1","2018-01-01","2018","1","","","26246120","","","ENG","The sheer exposure to vast amounts of signals created in our modern society and an ever increasing need to make sense of such data calls for continuing advances in signal processing as an enabling technology for a huge number of applications, ranging from wireless communication and medicine, through to bioengineering, the economy and entertainment.Activity recognition, event detection, anomaly detection Adaptive filtering and signal processing Applications of signal processing (Biomedical, Bioinformatics, Genomic, Seismic, Radar, Sonar, Remote Sensing, Positioning, Embedded Systems, etc.) Array signal processing Audio/speech processing and coding Biometrics and authentification Biomedical Signal Processing and biomedical data analysis (EEG/MEG, fMRI, PET etc.) Biological network and data analysis/modelling Biosignal processing and understanding Blind and semi-blind signal separation (e.g., single- and multi-channel recordings, audio source separation, bio-signal separation, independent component analysis (ICA), nonnegative matrix/tensor factorization (NMF/NTF) Brain Computer Interface (BCI) Communication signal processing Compressive Sensing (CS) and sparse information retrieval Computer Vision (CV) and Virtual Reality (VR) Computational Neuroscience and brain data analysis/modelling Cryptography and network security Emerging technologies Image processing and understanding Image/Video Processing and Coding Inference and prediction of hidden patterns in signals/images Multimedia signal processing Natural Language Processing (NLP) Neuroimaging and signal processing Signal processing for human-computer interaction (HCI) and Brain Computer Interface (BCI).Image and multidimensional signal processing using tensor representation Scalable and distributed algorithms for tensor processing Methods for robust tensor processing with noisy, incomplete and/or missing signals/data Tensor methods in neural networks and deep learning Tensor-based time series and image processing Tensor processing and analysis in social networks and economics Applications of tensor processing in wireless communications and sensor networks Tensor developments in computer vision Tensor methods in neuroscience and medicine and Stochastic modelling of biological processes, systems biology, Information theory articles with a signal processing perspective Deep learning probabilistic neural networks with signals/data processing perspective Financial time series analysis Bioinformatics and neuroinfomatics Biochemical interaction in biological and biologically-inspired systems Signal processing for performance arts using audio, and video Signal processing for renewable energy Game theory and group theory for signal processing Environmental signal processing Signal processing with intelligent user interfaces Quantum signal processing.","https://www.proquest.com/docview/2656394299?accountid=12870&bdid=83737&_bd=yFxkdxDhgIXY%2BXN3h%2FcPXnPnMZs%3D","https://doi.org/10.3390/signals1010001"
"Gaussian Process-Mixture Conditional Heteroscedasticity","","Platanios, Emmanouil A.; Chatzis, Sotirios P.","IEEE Transactions on Pattern Analysis and Machine Intelligence","Scholarly Journals","","36","5","2014-05-01","May 2014","888","","888-900","01628828","","","ENG"," Generalized autoregressive conditional heteroscedasticity (GARCH) models have long been considered as one of the most successful families of approaches for volatility modeling in financial return series. In this paper, we propose an alternative approach based on methodologies widely used in the field of statistical machine learning. Specifically, we propose a novel nonparametric Bayesian mixture of Gaussian process regression models, each component of which models the noise variance process that contaminates the observed data as a separate latent Gaussian process driven by the observed data. This way, we essentially obtain a Gaussian Process-Mixture Conditional Heteroscedasticity (GPMCH) model for volatility modeling in financial return series. We impose a nonparametric prior with power-law nature over the distribution of the model mixture components, namely the Pitman-Yor process prior, to allow for better capturing modeled data distributions with heavy tails and skewness. Finally, we provide a copula-based approach for obtaining a predictive posterior for the covariances over the asset returns modeled by means of a postulated GPMCH model. We evaluate the efficacy of our approach in a number of benchmark scenarios, and compare its performance to state-of-the-art methodologies.","https://www.proquest.com/docview/1545937602?accountid=12870&bdid=83737&_bd=hboNlMHM5qrbisNbT%2F9RMoxVaw0%3D","https://doi.org/10.1109/TPAMI.2013.183"
"Probabilistic forecasting of the solar irradiance with recursive ARMA and GARCH models","","David, M; Ramahatana, F; Trombe, PJ; Lauret, P","Solar Energy","Scholarly Journals","","133","","2016-08-01","Aug 2016","55","","","0038092X","","","ENG","Forecasting of the solar irradiance is a key feature in order to increase the penetration rate of solar energy into the energy grids. Indeed, the anticipation of the fluctuations of the solar renewables allows a better management of the production means of electricity and a better operation of the grid-connected storage systems. If numerous methods for forecasting the mean of the solar irradiance were recently developed, there are only few works dedicated to the evaluation of prediction intervals associated to these point forecasts. Time series of solar irradiance and more specifically of clear sky index show some similarities with that of financial time series. The aim of this paper is to assess the performances of a commonly used combination of two linear models (ARMA and GARCH) in econometrics in order to provide probabilistic forecasts of solar irradiance. In addition, a recursive estimation of the parameters of the models has been set up in order to provide a framework that can be applied easily in an operational context. A comprehensive testing procedure has been used to assess both point forecasts and probabilistic forecasts. Using only the past records of the solar irradiance, the proposed model is able to perform point forecasts as accurately as other methods based on machine learning techniques. Moreover, the recursive ARMA-GARCH model is easier to set-up and it gives additional information about the uncertainty of the forecasts. Even if some strong assumption has been made regarding the statistical distribution of the error, the reliability of the probabilistic forecasts stands in the same order of magnitude as other works done in the field of solar forecasting.","https://www.proquest.com/docview/1795527809?accountid=12870&bdid=83737&_bd=0T0JmALQm4CVU%2FKwoz%2BCt4bvPmg%3D",""
"Safe Reinforcement Learning Using Wasserstein Distributionally Robust MPC and Chance Constraint","","Arash Bahari Kordabad; Wisniewski, Rafael; Gros, Sebastien","IEEE Access","Scholarly Journals","","10","","2022-01-01","2022","130058","","130058-130067","21693536","","","ENG","In this paper, we address the chance-constrained safe Reinforcement Learning (RL) problem using the function approximators based on Stochastic Model Predictive Control (SMPC) and Distributionally Robust Model Predictive Control (DRMPC). We use Conditional Value at Risk (CVaR) to measure the probability of constraint violation and safety. In order to provide a safe policy by construction, we first propose using parameterized nonlinear DRMPC at each time step. DRMPC optimizes a finite-horizon cost function subject to the worst-case constraint violation in an ambiguity set. We use a statistical ball around the empirical distribution with a radius measured by the Wasserstein metric as the ambiguity set. Unlike the sample average approximation SMPC, DRMPC provides a probabilistic guarantee of the out-of-sample risk and requires lower samples from the disturbance. Then the Q-learning method is used to optimize the parameters in the DRMPC to achieve the best closed-loop performance. Wheeled Mobile Robot (WMR) path planning with obstacle avoidance will be considered to illustrate the efficiency of the proposed method.","https://www.proquest.com/docview/2756561328?accountid=12870&bdid=83737&_bd=n9MctP%2BsgvsaJra5qUiQpWihAPM%3D","https://doi.org/10.1109/ACCESS.2022.3228922"
"Predictions of bitcoin prices through machine learning based frameworks.","","Cocco, Luisanna; Tonelli, Roberto; Marchesi, Michele","PeerJ. Computer science","Undefined","","7","","2021-01-01","2021","e413","e413","e413","","2376-5992","","ENG","The high volatility of an asset in financial markets is commonly seen as a negative factor. However short-term trades may entail high profits if traders open and close the correct positions. The high volatility of cryptocurrencies, and in particular of Bitcoin, is what made cryptocurrency trading so profitable in these last years. The main goal of this work is to compare several frameworks each other to predict the daily closing Bitcoin price, investigating those that provide the best performance, after a rigorous model selection by the so-called k-fold cross validation method. We evaluated the performance of one stage frameworks, based only on one machine learning technique, such as the Bayesian Neural Network, the Feed Forward and the Long Short Term Memory Neural Networks, and that of two stages frameworks formed by the neural networks just mentioned in cascade to Support Vector Regression. Results highlight higher performance of the two stages frameworks with respect to the correspondent one stage frameworks, but for the Bayesian Neural Network. The one stage framework based on Bayesian Neural Network has the highest performance and the order of magnitude of the mean absolute percentage error computed on the predicted price by this framework is in agreement with those reported in recent literature works.","https://www.proquest.com/docview/2511246640?accountid=12870&bdid=83737&_bd=2QMFOuCUSR1wQYVaxD4MtyjpSfE%3D","https://doi.org/10.7717/peerj-cs.413"
"Time Series Forecasting of Bitcoin Price Based on Autoregressive Integrated Moving Average and Machine Learning Approaches","","Khedmati, M; Seifi, F; Azizi, M J","International Journal of Engineering. Transactions A, Basics","Scholarly Journals","","33","7","2020-07-01","Jul 2020","1293","","","1728-1431","","","ENG","Bitcoin as the current leader in cryptocurrencies is a new asset class receiving significant attention in the financial and investment community and presents an interesting time series prediction problem. In this paper, some forecasting models based on classical like ARIMA and machine learning approaches including Kriging, Artificial Neural Network (ANN), Bayesian method, Support Vector Machine (SVM) and Random Forest (RF) are proposed and analyzed for modelling and forecasting the Bitcoin price. While some of the proposed models are univariate, the other models are multivariate and as a result, the maximum, minimum and the opening daily price of Bitcoin are also used in these models. The proposed models are applied on the Bitcoin price from December 18, 2019 to March 1, 2020 and their performances are compared in terms of the performance measures of RMSE and MAPE by Diebold-Mariano statistical test. Based on RMSE and MAPE measures, the results show that SVM provides the best performance among all the models. In addition, ARIMA and Bayesian approaches outperform other univariate models where they provide smaller values for RMSE and MAPE.","https://www.proquest.com/docview/2474304887?accountid=12870&bdid=83737&_bd=7DMBNKe36fj3JTIZPNHjurq1%2FlY%3D","https://doi.org/10.5829/IJE.2020.33.07A.16"
"Improved Financial Predicting Method Based on Time Series Long Short-Term Memory Algorithm","","Li, Kangyi; Zhou, Yang; Zhou, Yang","Mathematics","Scholarly Journals","","12","7","2024-01-01","2024","1074","","","22277390","","","ENG","With developments in global economic integration and the increase in future economic uncertainty, it is imperative to have the ability to predict future capital in relation to financial capital inflow and outflow predictions to ensure capital optimization is within a controllable range within the current macroeconomic environment and situation. This paper proposes an automated capital prediction strategy for the capital supply chain using time series analysis artificial intelligence methods. Firstly, to analyze the fluctuation and tail risk of the financial characteristics, the paper explores the financial characteristics for measuring the dynamic VaR from the perspectives of volatility, tail, and peak with the Bayesian peaks over threshold (POT) model. Following this, in order to make the modeling more refined, the forecast targets are split before modeling with seasonal Autoregressive Integrated Moving Average (ARIMA) models and Prophet models. Finally, the time series modeling of the wavelet Long Short-Term Memory (LSTM) model is carried out using a two-part analysis method to determine the linear separated wavelet and non-linear embedded wavelet parts to predict strong volatility in financial capital. Taking the user capital flow of the Yu’e Bao platform, the results prove the feasibility and prediction accuracy of the innovative model proposed.","https://www.proquest.com/docview/3037514247?accountid=12870&bdid=83737&_bd=qoc5JgUk3mfzYoXpi4OTKzJMK%2BQ%3D","https://doi.org/10.3390/math12071074"
"Bayesian neural networks for stock price forecasting before and during COVID-19 pandemic","","Chandra, Rohitash; He, Yixuan","PloS one","Undefined","","16","7","2021-01-01","Jan 2021","e0253217","","e0253217","1932-6203","","","ENG","Recently, there has been much attention in the use of machine learning methods, particularly deep learning for stock price prediction. A major limitation of conventional deep learning is uncertainty quantification in predictions which affect investor confidence. Bayesian neural networks feature Bayesian inference for providing inference (training) of model parameters that provides a rigorous methodology for uncertainty quantification in predictions. Markov Chain Monte Carlo (MCMC) sampling methods have been prominent in implementing inference of Bayesian neural networks; however certain limitations existed due to a large number of parameters and the need for better computational resources. Recently, there has been much progress in the area of Bayesian neural networks given the use of Langevin gradients with parallel tempering MCMC that can be implemented in a parallel computing environment. The COVID-19 pandemic had a drastic impact in the world economy and stock markets given different levels of lockdowns due to rise and fall of daily infections. It is important to investigate the performance of related forecasting models during the COVID-19 pandemic given the volatility in stock markets. In this paper, we use novel Bayesian neural networks for multi-step-ahead stock price forecasting before and during COVID-19. We also investigate if the pre-COVID-19 datasets are useful of modelling stock price forecasting during COVID-19. Our results indicate due to high volatility in the stock-price during COVID-19, it is more challenging to provide forecasting. However, we found that Bayesian neural networks could provide reasonable predictions with uncertainty quantification despite high market volatility during the first peak of the COVID-19 pandemic.Recently, there has been much attention in the use of machine learning methods, particularly deep learning for stock price prediction. A major limitation of conventional deep learning is uncertainty quantification in predictions which affect investor confidence. Bayesian neural networks feature Bayesian inference for providing inference (training) of model parameters that provides a rigorous methodology for uncertainty quantification in predictions. Markov Chain Monte Carlo (MCMC) sampling methods have been prominent in implementing inference of Bayesian neural networks; however certain limitations existed due to a large number of parameters and the need for better computational resources. Recently, there has been much progress in the area of Bayesian neural networks given the use of Langevin gradients with parallel tempering MCMC that can be implemented in a parallel computing environment. The COVID-19 pandemic had a drastic impact in the world economy and stock markets given different levels of lockdowns due to rise and fall of daily infections. It is important to investigate the performance of related forecasting models during the COVID-19 pandemic given the volatility in stock markets. In this paper, we use novel Bayesian neural networks for multi-step-ahead stock price forecasting before and during COVID-19. We also investigate if the pre-COVID-19 datasets are useful of modelling stock price forecasting during COVID-19. Our results indicate due to high volatility in the stock-price during COVID-19, it is more challenging to provide forecasting. However, we found that Bayesian neural networks could provide reasonable predictions with uncertainty quantification despite high market volatility during the first peak of the COVID-19 pandemic.","https://www.proquest.com/docview/2548413070?accountid=12870&bdid=83737&_bd=MTyUewgGWoq79PWrbO5aJyfFRyo%3D","https://doi.org/10.1371/journal.pone.0253217"
"A Bayesian-based classification framework for financial time series trend prediction.","","Dezhkam, Arsalan; Manzuri, Mohammad Taghi; Aghapour, Ahmad; Karimi, Afshin; Rabiee, Ali; Shalmani, Shervin Manzuri","The Journal of supercomputing","Undefined","","79","4","2023-01-01","2023","4622","4659","4622-4659","0920-8542","0920-8542","","ENG","Financial time series have been extensively studied within the past decades; however, the advent of machine learning and deep neural networks opened new horizons to apply supercomputing techniques to extract more insights from the underlying patterns of price data. This paper presents a tri-state labeling approach to classify the underlying patterns in price data into up, down and no-action classes. The introduction of a no-action state in our novel approach alleviates the burden of denoising the dataset as a preprocessing task. The performance of our labeling algorithm is experimented with using machine learning and deep learning models. The framework is augmented by applying the Bayesian optimization technique for the selection of the best tuning values of the hyperparameters. The price trend prediction module generates the required trading signals. The results show that the average annualized Sharpe ratio as the trading performance metric is about 2.823, indicating the framework produces excellent cumulative returns.","https://www.proquest.com/docview/2721637057?accountid=12870&bdid=83737&_bd=cFBItE3AsjyxgXGokD0zUMFyL1A%3D","https://doi.org/10.1007/s11227-022-04834-4"
"Cloud based Financial Market Prediction through Genetic Algorithms: A Review","","Soni, Nitasha; Kumar, Tapas","International Journal of Computer Applications","Scholarly Journals","","123","8","2015-01-01","2015","n/a","","","09758887","","","ENG"," This paper surveys recent literature in the area of stock market forecasting using advanced engineering based methods like Neural Network, fractal theory, Data Mining, Hidden Markov Model and Neuro-Fuzzy system. Neural Networks and Neuro-Fuzzy systems are emerging as an effective tool to be used in the forecasting of stock market especially in machine learning techniques. Due to chaotic behavior of the market, traditional techniques are insufficient to cover all the possible relation of the stock price fluctuations. Neural Network and Markov Model is being used exclusively in the forecasting of finance markets but in third world countries. In this paper, we will discuss the relevance of existing methods based on neural network and discussed gaps between these methods. We also propose a forecasting method to provide better an accuracy rather traditional method.","https://www.proquest.com/docview/1714344194?accountid=12870&bdid=83737&_bd=oTlNUqgW2dC%2BLoTTag0TiVlMAoQ%3D","https://doi.org/10.5120/ijca2015905413"
"Modeling Bitcoin Prices using Signal Processing Methods, Bayesian Optimization, and Deep Neural Networks.","","Tripathi, Bhaskar; Sharma, Rakesh Kumar","Computational economics","Undefined","","","","2022-10-28","October 28, 2022","1","27","1-27","","1572-9974","","ENG","Bitcoin is a volatile financial asset that runs on a decentralized peer-to-peer Blockchain network. Investors need accurate price forecasts to minimize losses and maximize profits. Extreme volatility, speculative nature, and dependence on intrinsic and external factors make Bitcoin price forecast challenging. This research proposes a reliable forecasting framework by reducing the inherent noise in Bitcoin time series and by examining the predictive power of three distinct types of predictors, namely fundamental indicators, technical indicators, and univariate lagged prices. We begin with a three-step hybrid feature selection procedure to identify the variables with the highest predictive ability, then use Hampel and Savitzky-Golay filters to impute outliers and remove signal noise from the Bitcoin time series. Next, we use several deep neural networks tuned by Bayesian Optimization to forecast short-term prices for the next day, three days, five days, and seven days ahead intervals. We found that the Deep Artificial Neural Network model created using technical indicators as input data outperformed other benchmark models like Long Short Term Memory, Bi-directional LSTM (BiLSTM), and Convolutional Neural Network (CNN)-BiLSTM. The presented results record a high accuracy and outperform all existing models available in the past literature with an absolute percentage error as low as 0.28% for the next day forecast and 2.25% for the seventh day for the latest out of sample period ranging from Jan 1, 2021, to Nov 1, 2021. With contributions in feature selection, data-preprocessing, and hybridizing deep learning models, this work contributes to researchers and traders in fundamental and technical domains.","https://www.proquest.com/docview/2733201902?accountid=12870&bdid=83737&_bd=lRfMxMAyoay69f7A15Qk130x1fc%3D","https://doi.org/10.1007/s10614-022-10325-8"
"Short-Term Prediction of Foreign Exchange Rates by Collective Knowledge of Counterparty Banks","","Yano, Kazuto; Suzuki, Takehiro; Suzuki, Tomoya","Shingo Shori","Scholarly Journals","","24","3","2020-05-01","2020","113","","113-122","13426230","","","ENG","Foreign-exchange (FX) brokers have some risk factors such as price fluctuation risk and latency of data transmission. To reduce these risks in FX brokerage services, we propose a short-term prediction of exchange rates quoted by counter-party banks. We consider that these exchange rates are generated by the knowledge of each counter-party bank, and therefore try to extract the knowledge by using a machine learning method. As a result, we could predict the direction of exchange rates with a prediction accuracy of about 80% if the prediction interval is 100[ms]. Furthermore, by integrating the knowledge of counterparty banks by the ensemble learning, we could improve not only prediction accuracy but also profitability of foreign-exchange brokers. These improvements can be considered as an effect of collective knowledge based on the diversity prediction theorem, but this effect might be limited by extremely short-term prediction of foreign-exchange rates after 100[ms]~200[ms].","https://www.proquest.com/docview/2408563716?accountid=12870&bdid=83737&_bd=5G7aB7GdcL49BsyO73tFvBYeA7M%3D","https://doi.org/10.2299/jsp.24.113"
"DIVIDENDS AND COMPOUND POISSON PROCESSES: A NEW STOCHASTIC STOCK PRICE MODEL","","GANKHUU, BATTULGA; Kleinow, Jacob; LKHAMSUREN, ALTANGEREL; Horsch, Andreas","International Journal of Theoretical & Applied Finance","Scholarly Journals","","25","3","2022-05-01","May 2022","","","","02190249","","","ENG","This study introduces a stochastic multi-period dividend discount model (DDM) that includes (i) a compound nonhomogenous Poisson process for dividend growth and (ii) the probability of firm default. We obtain maximum likelihood (ML) estimators and confidence interval formulas of our model parameters. We apply the model to a set of firms from the S&P 500 index using historical dividend and price data over a 42-year period. Interestingly, stock price estimations calculated with the model are close to the observable prices. Overall, we prove that the model can be a useful tool for stock pricing.","https://www.proquest.com/docview/2683005569?accountid=12870&bdid=83737&_bd=kHpENIshgD3JJ8h1JLxlxcRqick%3D","https://doi.org/10.1142/S0219024922500145"
"Time-series forecasting using manifold learning, radial basis function interpolation, and geometric harmonics.","","Papaioannou, Panagiotis G; Talmon, Ronen; Kevrekidis, Ioannis G; Siettos, Constantinos","Chaos (Woodbury, N.Y.)","Undefined","","32","8","2022-08-01","August 2022","083113","083113","083113","","1089-7682","","ENG","We address a three-tier numerical framework based on nonlinear manifold learning for the forecasting of high-dimensional time series, relaxing the ""curse of dimensionality"" related to the training phase of surrogate/machine learning models. At the first step, we embed the high-dimensional time series into a reduced low-dimensional space using nonlinear manifold learning (local linear embedding and parsimonious diffusion maps). Then, we construct reduced-order surrogate models on the manifold (here, for our illustrations, we used multivariate autoregressive and Gaussian process regression models) to forecast the embedded dynamics. Finally, we solve the pre-image problem, thus lifting the embedded time series back to the original high-dimensional space using radial basis function interpolation and geometric harmonics. The proposed numerical data-driven scheme can also be applied as a reduced-order model procedure for the numerical solution/propagation of the (transient) dynamics of partial differential equations (PDEs). We assess the performance of the proposed scheme via three different families of problems: (a) the forecasting of synthetic time series generated by three simplistic linear and weakly nonlinear stochastic models resembling electroencephalography signals, (b) the prediction/propagation of the solution profiles of a linear parabolic PDE and the Brusselator model (a set of two nonlinear parabolic PDEs), and (c) the forecasting of a real-world data set containing daily time series of ten key foreign exchange rates spanning the time period 3 September 2001-29 October 2020.","https://www.proquest.com/docview/2709742689?accountid=12870&bdid=83737&_bd=sbc2DOMEqLOco%2Fo2XLq3Guy88Ls%3D","https://doi.org/10.1063/5.0094887"
"Classical and Bayesian Analysis of Univariate and Multivariate Stochastic Volatility Models","","Liesenfeld, Roman; Jean-François, Richard","Econometric Reviews","Scholarly Journals","","25","2/3","2006-01-01","2006","335","","335","07474938","","","ENG","In this paper, efficient importance sampling (EIS) is used to perform a classical and Bayesian analysis of univariate and multivariate stochastic volatility (SV) models for financial return series. EIS provides a highly generic and very accurate procedure for the Monte Carlo (MC) evaluation of high-dimensional interdependent integrals. It can be used to carry out ML-estimation of SV models as well as simulation smoothing where the latent volatilities are sampled at once. Based on this EIS simulation smoother, a Bayesian Markov chain Monte Carlo (MCMC) posterior analysis of the parameters of SV models can be performed. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/212083404?accountid=12870&bdid=83737&_bd=niT6U3sW98l98riL4dJ6O7PayuA%3D",""
"Implementation of a Commitment Machine for an Adaptive and Robust Expected Shortfall Estimation.","","Bagnato, Marco; Bottasso, Anna; Giribone, Pier Giuseppe","Frontiers in artificial intelligence","Undefined","","4","","2021-01-01","2021","732805","732805","732805","","2624-8212","","ENG","This study proposes a metaheuristic for the selection of models among different Expected Shortfall (ES) estimation methods. The proposed approach, denominated ""Commitment Machine"" (CM), has a strong focus on assets cross-correlation and allows to measure adaptively the ES, dynamically evaluating which is the most performing method through the minimization of a loss function. The CM algorithm compares four different ES estimation techniques which all take into account the interaction effects among assets: a Bayesian Vector autoregressive model, Stochastic Differential Equation (SDE) numerical schemes with Exponential Weighted Moving Average (EWMA), a Generalized AutoRegressive Conditional Heteroskedasticity (GARCH) volatility model and a hybrid method that integrates Dynamic Recurrent Neural Networks together with a Monte Carlo approach. The integration of traditional Monte Carlo approaches with Machine Learning technologies and the heterogeneity of dynamically selected methodologies lead to an improved estimation of the ES. The study describes the techniques adopted by the CM and the logic behind model selection; moreover, it provides a market application case of the proposed metaheuristic, by simulating an equally weighted multi-asset portfolio.","https://www.proquest.com/docview/2574382753?accountid=12870&bdid=83737&_bd=wgfgoyMhuB3g6GsIlC8WOau14IM%3D","https://doi.org/10.3389/frai.2021.732805"
"The impact of the global stock and energy market on EU ETS: A structural equation modelling approach","","Wang, Zi-Jie; Zhao, Lu-Tao","Journal of cleaner production","Undefined","Elsevier Ltd","289 p.125140-","","2021-03-20","Mar 20, 2021","","","","0959-6526","0959-6526","","ENG","The industrial revolution has brought about great development in the economy, but it has also increased the dependence on fossil energy. The emissions of CO₂ and other greenhouse gases have contradicted economic development and the ecological environment. The establishment of the EU Emission Trading System (EU ETS) has improved the global carbon emission price mechanism, but as a new commodity, its price trend will affect buyers’ risk evaluation. Therefore, it is influential to master the driving factors behind carbon emission prices and make effective predictions. First, the paper points out that the driving factors are divided into macroeconomic risk factors and energy factors. Second, the Bayesian Network is used to select variables and make prediction of carbon prices. The results show that its accuracy exceeds other machine learning algorithms. Third, a structural equation model is used to study the impact of the selected markets on the carbon market. Finally, from the perspective of global carbon emission reduction, the relationship between driving factors and the carbon futures market is explained. The empirical results show that Cotation Assistée en Continu 40, natural gas and Brent crude oil will directly affect the yield of European Union Allowances and Certified Emission Reduction futures, and the Standard Poor 500 and Global Clean Energy Index will indirectly affect the yield of European Union Allowances and Certified Emission Reduction futures. The energy market will affect the carbon market through the intermediary effect of the stock market, in which the clean energy index is the most relevant factor. From the perspective of how to improve the carbon trading system, this paper proposes suggestions for the sustainable development of the world to promote the virtuous cycle of the global carbon emission market and the high-quality development of the global economy.","https://www.proquest.com/docview/2511185497?accountid=12870&bdid=83737&_bd=dWRjXbeLcBMZ2GnTLukks%2BeOKg8%3D","https://doi.org/10.1016/j.jclepro.2020.125140"
"Bayesian analysis of a change-point in exponential families with applications","","Lee, Ch-B","COMPUT STAT DATA ANAL","Undefined","ELSEVIER SCI B.V , AMSTERDAM, (NETHERLANDS)","27","2","1998-04-03","3 Apr. 1998","195","208","195-208","0167-9473","0167-9473","","ENG","A Bayesian analysis is used to detect a change-point in a sequence of independent random variables from exponential family distributions. The conjugate priors for the exponential families are considered in the analysis. The marginal posterior distribution of the change-point j is derived. Since some hyperparameters are involved in the conjugate priors, the Type II maximum likelihood (ML-II) approach (cf. Berger, 1995) will be used to estimate these hyperparameters in applications. The method is simple and is easily applied to the Nile problem, Illinois traffic data, British coal-mining disasters, accident data and stock-market prices.","https://www.proquest.com/docview/27449074?accountid=12870&bdid=83737&_bd=Vt%2FieeOXNnmgYqWD%2FMlhz1AZlVY%3D",""
"Conducting Causal Analysis by Means of Approximating Probabilistic Truths.","","Andrée, Bo Pieter Johannes","Entropy (Basel, Switzerland)","Undefined","","24","1","2022-01-06","January 6, 2022","","","","","1099-4300","","ENG","The current paper develops a probabilistic theory of causation using measure-theoretical concepts and suggests practical routines for conducting causal inference. The theory is applicable to both linear and high-dimensional nonlinear models. An example is provided using random forest regressions and daily data on yield spreads. The application tests how uncertainty in short- and long-term inflation expectations interacts with spreads in the daily Bitcoin price. The results are contrasted with those obtained by standard linear Granger causality tests. It is shown that the suggested measure-theoretic approaches do not only lead to better predictive models, but also to more plausible parsimonious descriptions of possible causal flows. The paper concludes that researchers interested in causal analysis should be more aspirational in terms of developing predictive capabilities, even if the interest is in inference and not in prediction per se. The theory developed in the paper provides practitioners guidance for developing causal models using new machine learning methods that have, so far, remained relatively underutilized in this context.","https://www.proquest.com/docview/2622283022?accountid=12870&bdid=83737&_bd=peQc44dsoTe4239WJGWROurwaJc%3D","https://doi.org/10.3390/e24010092"
